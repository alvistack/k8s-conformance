  I0419 15:45:08.265999      14 e2e.go:109] Starting e2e run "382b244f-26f0-439d-b230-5b385b51cde5" on Ginkgo node 1
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1713541506 - will randomize all specs

Will run 402 of 7197 specs
------------------------------
[ReportBeforeSuite] 
k8s.io/kubernetes/test/e2e/e2e_test.go:157
[ReportBeforeSuite] PASSED [0.000 seconds]
------------------------------
[SynchronizedBeforeSuite] 
k8s.io/kubernetes/test/e2e/e2e.go:69
  I0419 15:45:08.572126 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 15:45:08.576921 14 helper.go:48] Waiting up to 30m0s for all (but 0) nodes to be schedulable
  I0419 15:45:08.670290 14 e2e.go:142] Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
  I0419 15:45:08.683227 14 e2e.go:153] 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds' (0 seconds elapsed)
  I0419 15:45:08.684044 14 e2e.go:153] 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
  I0419 15:45:08.684197 14 e2e.go:245] e2e test version: v1.30.0
  I0419 15:45:08.687702 14 e2e.go:254] kube-apiserver version: v1.30.0
  I0419 15:45:08.688402 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 15:45:08.700707 14 e2e.go:383] Cluster IP family: ipv4
[SynchronizedBeforeSuite] PASSED [0.129 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:147
  STEP: Creating a kubernetes client @ 04/19/24 15:45:09.014
  I0419 15:45:09.014081 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename kubelet-test @ 04/19/24 15:45:09.016
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:45:09.1
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:45:09.106
  STEP: Waiting for pod completion @ 04/19/24 15:45:09.132
  I0419 15:45:13.200313 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-9959" for this suite. @ 04/19/24 15:45:13.217
• [4.217 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:113
  STEP: Creating a kubernetes client @ 04/19/24 15:45:13.236
  I0419 15:45:13.236656 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename replication-controller @ 04/19/24 15:45:13.239
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:45:13.272
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:45:13.28
  STEP: creating a ReplicationController @ 04/19/24 15:45:13.293
  STEP: waiting for RC to be added @ 04/19/24 15:45:13.311
  STEP: waiting for available Replicas @ 04/19/24 15:45:13.312
  STEP: patching ReplicationController @ 04/19/24 15:45:14.997
  STEP: waiting for RC to be modified @ 04/19/24 15:45:15.012
  STEP: patching ReplicationController status @ 04/19/24 15:45:15.014
  STEP: waiting for RC to be modified @ 04/19/24 15:45:15.023
  STEP: waiting for available Replicas @ 04/19/24 15:45:15.026
  STEP: fetching ReplicationController status @ 04/19/24 15:45:15.037
  STEP: patching ReplicationController scale @ 04/19/24 15:45:15.049
  STEP: waiting for RC to be modified @ 04/19/24 15:45:15.066
  STEP: waiting for ReplicationController's scale to be the max amount @ 04/19/24 15:45:15.069
  STEP: fetching ReplicationController; ensuring that it's patched @ 04/19/24 15:45:15.984
  STEP: updating ReplicationController status @ 04/19/24 15:45:15.99
  STEP: waiting for RC to be modified @ 04/19/24 15:45:16.007
  STEP: listing all ReplicationControllers @ 04/19/24 15:45:16.007
  STEP: checking that ReplicationController has expected values @ 04/19/24 15:45:16.017
  STEP: deleting ReplicationControllers by collection @ 04/19/24 15:45:16.017
  STEP: waiting for ReplicationController to have a DELETED watchEvent @ 04/19/24 15:45:16.043
  I0419 15:45:16.157306 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0419 15:45:16.157587      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "replication-controller-6500" for this suite. @ 04/19/24 15:45:16.165
• [2.943 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance] [sig-storage, Serial, Conformance]
k8s.io/kubernetes/test/e2e/storage/empty_dir_wrapper.go:188
  STEP: Creating a kubernetes client @ 04/19/24 15:45:16.18
  I0419 15:45:16.180083 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename emptydir-wrapper @ 04/19/24 15:45:16.182
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:45:16.221
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:45:16.225
  STEP: Creating 50 configmaps @ 04/19/24 15:45:16.23
  STEP: Creating RC which spawns configmap-volume pods @ 04/19/24 15:45:16.622
  I0419 15:45:16.654224 14 resource.go:87] Pod name wrapped-volume-race-c8edf75d-a190-41fd-8304-e273d07d02da: Found 0 pods out of 5
  E0419 15:45:17.158848      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:45:18.159125      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:45:19.159753      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:45:20.160236      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:45:21.160307      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:45:21.674176 14 resource.go:87] Pod name wrapped-volume-race-c8edf75d-a190-41fd-8304-e273d07d02da: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 04/19/24 15:45:21.674
  STEP: Creating RC which spawns configmap-volume pods @ 04/19/24 15:45:21.73
  I0419 15:45:21.766436 14 resource.go:87] Pod name wrapped-volume-race-0f1a903d-4a35-4a5b-a7b2-848cf7e74aaa: Found 0 pods out of 5
  E0419 15:45:22.161323      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:45:23.162280      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:45:24.162458      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:45:25.162849      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:45:26.163696      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:45:26.786129 14 resource.go:87] Pod name wrapped-volume-race-0f1a903d-4a35-4a5b-a7b2-848cf7e74aaa: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 04/19/24 15:45:26.786
  STEP: Creating RC which spawns configmap-volume pods @ 04/19/24 15:45:26.843
  I0419 15:45:26.885076 14 resource.go:87] Pod name wrapped-volume-race-91121225-98d6-48a8-850c-3b01cd8a49c5: Found 0 pods out of 5
  E0419 15:45:27.164927      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:45:28.165183      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:45:29.165507      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:45:30.166420      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:45:31.167079      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:45:31.905613 14 resource.go:87] Pod name wrapped-volume-race-91121225-98d6-48a8-850c-3b01cd8a49c5: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 04/19/24 15:45:31.905
  STEP: deleting ReplicationController wrapped-volume-race-91121225-98d6-48a8-850c-3b01cd8a49c5 in namespace emptydir-wrapper-1266, will wait for the garbage collector to delete the pods @ 04/19/24 15:45:31.947
  I0419 15:45:32.028095 14 resources.go:139] Deleting ReplicationController wrapped-volume-race-91121225-98d6-48a8-850c-3b01cd8a49c5 took: 17.755424ms
  E0419 15:45:32.167436      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:45:32.229813 14 resources.go:163] Terminating ReplicationController wrapped-volume-race-91121225-98d6-48a8-850c-3b01cd8a49c5 pods took: 201.70697ms
  E0419 15:45:33.167683      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-0f1a903d-4a35-4a5b-a7b2-848cf7e74aaa in namespace emptydir-wrapper-1266, will wait for the garbage collector to delete the pods @ 04/19/24 15:45:33.831
  I0419 15:45:33.903717 14 resources.go:139] Deleting ReplicationController wrapped-volume-race-0f1a903d-4a35-4a5b-a7b2-848cf7e74aaa took: 14.084191ms
  I0419 15:45:34.004228 14 resources.go:163] Terminating ReplicationController wrapped-volume-race-0f1a903d-4a35-4a5b-a7b2-848cf7e74aaa pods took: 100.50055ms
  E0419 15:45:34.168506      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:45:35.169210      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-c8edf75d-a190-41fd-8304-e273d07d02da in namespace emptydir-wrapper-1266, will wait for the garbage collector to delete the pods @ 04/19/24 15:45:36.005
  I0419 15:45:36.079940 14 resources.go:139] Deleting ReplicationController wrapped-volume-race-c8edf75d-a190-41fd-8304-e273d07d02da took: 13.516724ms
  E0419 15:45:36.169220      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:45:36.181509 14 resources.go:163] Terminating ReplicationController wrapped-volume-race-c8edf75d-a190-41fd-8304-e273d07d02da pods took: 101.581314ms
  E0419 15:45:37.170304      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Cleaning up the configMaps @ 04/19/24 15:45:37.582
  I0419 15:45:38.159168 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-1266" for this suite. @ 04/19/24 15:45:38.167
  E0419 15:45:38.170909      14 retrywatcher.go:129] "Watch failed" err="context canceled"
• [22.001 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:641
  STEP: Creating a kubernetes client @ 04/19/24 15:45:38.182
  I0419 15:45:38.182399 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename statefulset @ 04/19/24 15:45:38.185
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:45:38.205
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:45:38.211
  STEP: Creating service test in namespace statefulset-4422 @ 04/19/24 15:45:38.217
  STEP: Initializing watcher for selector baz=blah,foo=bar @ 04/19/24 15:45:38.229
  STEP: Creating stateful set ss in namespace statefulset-4422 @ 04/19/24 15:45:38.238
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4422 @ 04/19/24 15:45:38.253
  I0419 15:45:38.259057 14 wait.go:40] Found 0 stateful pods, waiting for 1
  E0419 15:45:39.171306      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:45:40.171746      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:45:41.172728      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:45:42.172187      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:45:43.172574      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:45:44.172652      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:45:45.173354      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:45:46.173558      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:45:47.174334      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:45:48.174980      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:45:48.264115 14 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod @ 04/19/24 15:45:48.264
  I0419 15:45:48.271563 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=statefulset-4422 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0419 15:45:48.689602 14 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0419 15:45:48.689691 14 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0419 15:45:48.689716 14 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0419 15:45:48.698658 14 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E0419 15:45:49.175236      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:45:50.175633      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:45:51.176077      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:45:52.176093      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:45:53.176451      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:45:54.176790      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:45:55.177109      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:45:56.177539      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:45:57.178502      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:45:58.178999      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:45:58.699767 14 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0419 15:45:58.699895 14 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I0419 15:45:58.735852 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 9.999999494s
  E0419 15:45:59.179509      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:45:59.747341 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 8.990278231s
  E0419 15:46:00.179306      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:46:00.758934 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 7.979177013s
  E0419 15:46:01.181023      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:46:01.772570 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 6.967934513s
  E0419 15:46:02.181662      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:46:02.781544 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 5.954581203s
  E0419 15:46:03.182814      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:46:03.791066 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 4.945729164s
  E0419 15:46:04.182797      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:46:04.802711 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 3.936130089s
  E0419 15:46:05.184426      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:46:05.810966 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 2.924523746s
  E0419 15:46:06.184573      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:46:06.822724 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 1.91623207s
  E0419 15:46:07.184389      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:46:07.836611 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 903.863128ms
  E0419 15:46:08.185481      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4422 @ 04/19/24 15:46:08.837
  I0419 15:46:08.851134 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=statefulset-4422 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0419 15:46:09.161191 14 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0419 15:46:09.161278 14 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0419 15:46:09.161304 14 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0419 15:46:09.170706 14 wait.go:40] Found 1 stateful pods, waiting for 3
  E0419 15:46:09.185938      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:10.186136      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:11.186521      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:12.186790      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:13.187141      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:14.187903      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:15.187909      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:16.188086      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:17.188230      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:18.188415      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:46:19.175036 14 wait.go:40] Found 2 stateful pods, waiting for 3
  E0419 15:46:19.189545      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:20.190353      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:21.191191      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:22.192123      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:23.192088      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:24.193537      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:25.192779      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:26.193287      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:27.194241      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:28.193788      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:46:29.180081 14 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I0419 15:46:29.180755 14 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  I0419 15:46:29.181314 14 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Verifying that stateful set ss was scaled up in order @ 04/19/24 15:46:29.182
  STEP: Scale down will halt with unhealthy stateful pod @ 04/19/24 15:46:29.182
  E0419 15:46:29.197774      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:46:29.214694 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=statefulset-4422 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0419 15:46:29.563684 14 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0419 15:46:29.563767 14 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0419 15:46:29.563816 14 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0419 15:46:29.564295 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=statefulset-4422 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0419 15:46:29.916578 14 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0419 15:46:29.916689 14 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0419 15:46:29.916724 14 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0419 15:46:29.917264 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=statefulset-4422 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  E0419 15:46:30.197017      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:46:30.212806 14 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0419 15:46:30.212976 14 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0419 15:46:30.213021 14 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0419 15:46:30.213169 14 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I0419 15:46:30.219863 14 wait.go:114] Waiting for statefulset status.readyReplicas to become 0, currently 1
  E0419 15:46:31.197198      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:32.202594      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:33.200101      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:34.200258      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:35.200238      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:36.200556      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:37.200666      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:38.201038      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:39.201411      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:40.201841      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:46:40.235516 14 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0419 15:46:40.235715 14 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  I0419 15:46:40.235777 14 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  I0419 15:46:40.272000 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 9.99999925s
  E0419 15:46:41.202538      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:46:41.286308 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 8.986245494s
  E0419 15:46:42.202697      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:46:42.305311 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 7.972416206s
  E0419 15:46:43.203384      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:46:43.320127 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 6.952662569s
  E0419 15:46:44.204352      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:46:44.330301 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 5.93869656s
  E0419 15:46:45.204681      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:46:45.343439 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 4.92771649s
  E0419 15:46:46.205283      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:46:46.361116 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 3.915719915s
  E0419 15:46:47.206032      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:46:47.376076 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 2.896260824s
  E0419 15:46:48.206898      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:46:48.396725 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 1.874681265s
  E0419 15:46:49.207209      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:46:49.417744 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 861.171623ms
  E0419 15:46:50.208339      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4422 @ 04/19/24 15:46:50.418
  I0419 15:46:50.433981 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=statefulset-4422 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0419 15:46:50.876507 14 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0419 15:46:50.876633 14 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0419 15:46:50.876672 14 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0419 15:46:50.878115 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=statefulset-4422 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  E0419 15:46:51.208392      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:46:51.219548 14 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0419 15:46:51.219671 14 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0419 15:46:51.220086 14 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0419 15:46:51.220530 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=statefulset-4422 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0419 15:46:51.613676 14 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0419 15:46:51.613800 14 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0419 15:46:51.613842 14 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0419 15:46:51.613898 14 rest.go:150] Scaling statefulset ss to 0
  E0419 15:46:52.209295      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:53.209870      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:54.210490      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:55.210934      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:56.212460      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:57.211973      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:58.213019      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:59.213261      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:00.219048      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:01.216399      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying that stateful set ss was scaled down in reverse order @ 04/19/24 15:47:01.648
  I0419 15:47:01.648918 14 statefulset.go:135] Deleting all statefulset in ns statefulset-4422
  I0419 15:47:01.657789 14 rest.go:150] Scaling statefulset ss to 0
  I0419 15:47:01.691385 14 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0419 15:47:01.701275 14 rest.go:88] Deleting statefulset ss
  I0419 15:47:01.746932 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-4422" for this suite. @ 04/19/24 15:47:01.762
• [83.596 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:425
  STEP: Creating a kubernetes client @ 04/19/24 15:47:01.789
  I0419 15:47:01.789420 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename replication-controller @ 04/19/24 15:47:01.795
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:47:01.836
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:47:01.844
  STEP: Creating ReplicationController "e2e-rc-fznzp" @ 04/19/24 15:47:01.85
  I0419 15:47:01.866499 14 rc.go:792] Get Replication Controller "e2e-rc-fznzp" to confirm replicas
  E0419 15:47:02.222023      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:47:02.867799 14 rc.go:792] Get Replication Controller "e2e-rc-fznzp" to confirm replicas
  I0419 15:47:02.880074 14 rc.go:801] Found 1 replicas for "e2e-rc-fznzp" replication controller
  STEP: Getting scale subresource for ReplicationController "e2e-rc-fznzp" @ 04/19/24 15:47:02.88
  STEP: Updating a scale subresource @ 04/19/24 15:47:02.89
  STEP: Verifying replicas where modified for replication controller "e2e-rc-fznzp" @ 04/19/24 15:47:02.906
  I0419 15:47:02.907032 14 rc.go:792] Get Replication Controller "e2e-rc-fznzp" to confirm replicas
  E0419 15:47:03.225836      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:47:03.907401 14 rc.go:792] Get Replication Controller "e2e-rc-fznzp" to confirm replicas
  I0419 15:47:03.916327 14 rc.go:801] Found 2 replicas for "e2e-rc-fznzp" replication controller
  I0419 15:47:03.917463 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-3349" for this suite. @ 04/19/24 15:47:03.927
• [2.156 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:70
  STEP: Creating a kubernetes client @ 04/19/24 15:47:03.949
  I0419 15:47:03.949455 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename cronjob @ 04/19/24 15:47:03.954
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:47:03.989
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:47:03.997
  STEP: Creating a cronjob @ 04/19/24 15:47:04.007
  STEP: Ensuring more than one job is running at a time @ 04/19/24 15:47:04.025
  E0419 15:47:04.222870      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:05.228195      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:06.224993      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:07.226732      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:08.227507      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:09.227727      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:10.228430      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:11.228823      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:12.229635      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:13.230311      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:14.232617      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:15.232665      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:16.232796      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:17.233100      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:18.233275      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:19.234026      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:20.234786      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:21.235847      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:22.235943      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:23.236047      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:24.237099      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:25.237394      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:26.238301      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:27.238649      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:28.239340      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:29.239755      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:30.240587      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:31.240699      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:32.241356      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:33.241573      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:34.241975      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:35.242365      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:36.243696      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:37.244082      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:38.245109      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:39.244498      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:40.244803      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:41.245630      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:42.246049      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:43.248252      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:44.247331      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:45.247937      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:46.248155      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:47.249257      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:48.249669      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:49.249964      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:50.251206      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:51.250692      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:52.251052      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:53.251700      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:54.251859      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:55.253113      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:56.253218      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:57.254003      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:58.255401      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:59.255721      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:00.258621      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:01.257940      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:02.258609      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:03.258523      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:04.259446      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:05.259752      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:06.260569      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:07.261186      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:08.261432      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:09.262227      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:10.262988      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:11.263454      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:12.264221      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:13.265267      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:14.265993      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:15.266847      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:16.266985      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:17.267626      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:18.268548      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:19.269539      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:20.270485      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:21.271267      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:22.271892      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:23.272790      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:24.273012      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:25.273407      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:26.274465      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:27.274972      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:28.275493      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:29.275907      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:30.276093      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:31.276655      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:32.276967      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:33.277252      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:34.277759      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:35.278154      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:36.278634      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:37.279574      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:38.280210      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:39.280318      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:40.280576      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:41.281087      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:42.281295      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:43.283151      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:44.283038      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:45.283933      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:46.285035      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:47.285236      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:48.286198      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:49.290276      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:50.287988      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:51.290019      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:52.289382      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:53.290152      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:54.290908      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:55.291050      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:56.293098      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:57.294457      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:58.293862      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:59.294810      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:00.297642      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:01.296266      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring at least two running jobs exists by listing jobs explicitly @ 04/19/24 15:49:02.037
  STEP: Removing cronjob @ 04/19/24 15:49:02.05
  I0419 15:49:02.069132 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-5426" for this suite. @ 04/19/24 15:49:02.083
• [118.154 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:380
  STEP: Creating a kubernetes client @ 04/19/24 15:49:02.111
  I0419 15:49:02.111985 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename proxy @ 04/19/24 15:49:02.116
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:49:02.177
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:49:02.184
  I0419 15:49:02.190991 14 proxy.go:387] Creating pod...
  E0419 15:49:02.297294      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:03.297470      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:49:04.220136 14 proxy.go:411] Creating service...
  I0419 15:49:04.259074 14 proxy.go:448] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9609/pods/agnhost/proxy?method=DELETE
  I0419 15:49:04.295402 14 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0419 15:49:04.299227 14 proxy.go:448] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9609/pods/agnhost/proxy?method=OPTIONS
  E0419 15:49:04.298518      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:49:04.306872 14 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0419 15:49:04.306956 14 proxy.go:448] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9609/pods/agnhost/proxy?method=PATCH
  I0419 15:49:04.314383 14 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0419 15:49:04.314451 14 proxy.go:448] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9609/pods/agnhost/proxy?method=POST
  I0419 15:49:04.325718 14 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0419 15:49:04.325837 14 proxy.go:448] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9609/pods/agnhost/proxy?method=PUT
  I0419 15:49:04.331424 14 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0419 15:49:04.332019 14 proxy.go:459] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9609/services/e2e-proxy-test-service/proxy?method=DELETE
  I0419 15:49:04.341694 14 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0419 15:49:04.341783 14 proxy.go:459] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9609/services/e2e-proxy-test-service/proxy?method=OPTIONS
  I0419 15:49:04.353043 14 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0419 15:49:04.353174 14 proxy.go:459] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9609/services/e2e-proxy-test-service/proxy?method=PATCH
  I0419 15:49:04.361582 14 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0419 15:49:04.362578 14 proxy.go:459] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9609/services/e2e-proxy-test-service/proxy?method=POST
  I0419 15:49:04.371400 14 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0419 15:49:04.371454 14 proxy.go:459] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9609/services/e2e-proxy-test-service/proxy?method=PUT
  I0419 15:49:04.379133 14 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0419 15:49:04.379480 14 proxy.go:479] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9609/pods/agnhost/proxy?method=GET
  I0419 15:49:04.383831 14 proxy.go:487] http.Client request:GET StatusCode:301
  I0419 15:49:04.384413 14 proxy.go:479] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9609/services/e2e-proxy-test-service/proxy?method=GET
  I0419 15:49:04.392310 14 proxy.go:487] http.Client request:GET StatusCode:301
  I0419 15:49:04.392535 14 proxy.go:479] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9609/pods/agnhost/proxy?method=HEAD
  I0419 15:49:04.398353 14 proxy.go:487] http.Client request:HEAD StatusCode:301
  I0419 15:49:04.398540 14 proxy.go:479] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9609/services/e2e-proxy-test-service/proxy?method=HEAD
  I0419 15:49:04.405972 14 proxy.go:487] http.Client request:HEAD StatusCode:301
  I0419 15:49:04.406625 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-9609" for this suite. @ 04/19/24 15:49:04.423
• [2.326 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:78
  STEP: Creating a kubernetes client @ 04/19/24 15:49:04.443
  I0419 15:49:04.443454 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename projected @ 04/19/24 15:49:04.446
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:49:04.467
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:49:04.473
  STEP: Creating projection with secret that has name projected-secret-test-map-86f424cc-6a2e-44b8-84ca-a61047370cb4 @ 04/19/24 15:49:04.478
  STEP: Creating a pod to test consume secrets @ 04/19/24 15:49:04.485
  E0419 15:49:05.298408      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:06.298647      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:07.299531      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:08.300765      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 15:49:08.534
  I0419 15:49:08.543545 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-projected-secrets-f2b292b7-3f03-4a7a-bede-7bf3371f1cba container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/24 15:49:08.592
  I0419 15:49:08.626603 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5801" for this suite. @ 04/19/24 15:49:08.635
• [4.205 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:392
  STEP: Creating a kubernetes client @ 04/19/24 15:49:08.649
  I0419 15:49:08.650025 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/19/24 15:49:08.652
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:49:08.682
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:49:08.688
  STEP: set up a multi version CRD @ 04/19/24 15:49:08.694
  I0419 15:49:08.696259 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  E0419 15:49:09.301511      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:10.312087      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:11.312814      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:12.314037      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:13.314321      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: rename a version @ 04/19/24 15:49:13.76
  STEP: check the new version name is served @ 04/19/24 15:49:13.81
  E0419 15:49:14.314371      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the old version name is removed @ 04/19/24 15:49:15.06
  E0419 15:49:15.315585      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the other version is not changed @ 04/19/24 15:49:16.01
  E0419 15:49:16.316252      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:17.317517      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:18.318734      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:49:19.316262 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0419 15:49:19.319068      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "crd-publish-openapi-3735" for this suite. @ 04/19/24 15:49:19.332
• [10.693 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_inline.go:157
  STEP: Creating a kubernetes client @ 04/19/24 15:49:19.346
  I0419 15:49:19.346356 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename csiinlinevolumes @ 04/19/24 15:49:19.349
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:49:19.374
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:49:19.378
  STEP: Creating two CSIDrivers @ 04/19/24 15:49:19.382
  STEP: Getting "inline-driver-43bedbb1-9d90-45c2-821d-fe504457fd97" & "inline-driver-727eec79-7dde-429b-a2e0-933a96daf53a" @ 04/19/24 15:49:19.41
  STEP: Patching the CSIDriver "inline-driver-727eec79-7dde-429b-a2e0-933a96daf53a" @ 04/19/24 15:49:19.421
  STEP: Updating the CSIDriver "inline-driver-727eec79-7dde-429b-a2e0-933a96daf53a" @ 04/19/24 15:49:19.43
  STEP: Listing all CSIDrivers with the labelSelector: "e2e-test=csiinlinevolumes-7437" @ 04/19/24 15:49:19.445
  STEP: Deleting CSIDriver "inline-driver-43bedbb1-9d90-45c2-821d-fe504457fd97" @ 04/19/24 15:49:19.451
  STEP: Confirm deletion of CSIDriver "inline-driver-43bedbb1-9d90-45c2-821d-fe504457fd97" @ 04/19/24 15:49:19.461
  STEP: Deleting CSIDriver "inline-driver-727eec79-7dde-429b-a2e0-933a96daf53a" via DeleteCollection @ 04/19/24 15:49:19.467
  STEP: Confirm deletion of CSIDriver "inline-driver-727eec79-7dde-429b-a2e0-933a96daf53a" @ 04/19/24 15:49:19.483
  I0419 15:49:19.489357 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-7437" for this suite. @ 04/19/24 15:49:19.5
• [0.175 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:125
  STEP: Creating a kubernetes client @ 04/19/24 15:49:19.521
  I0419 15:49:19.521390 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename projected @ 04/19/24 15:49:19.526
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:49:19.555
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:49:19.56
  STEP: Creating projection with configMap that has name projected-configmap-test-upd-7aa19675-c1be-41f8-92cb-43804e3cde60 @ 04/19/24 15:49:19.576
  STEP: Creating the pod @ 04/19/24 15:49:19.587
  E0419 15:49:20.319738      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:21.320217      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating configmap projected-configmap-test-upd-7aa19675-c1be-41f8-92cb-43804e3cde60 @ 04/19/24 15:49:21.68
  STEP: waiting to observe update in volume @ 04/19/24 15:49:21.697
  E0419 15:49:22.320778      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:23.321602      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:24.322177      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:25.322641      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:26.322824      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:27.323365      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:28.323818      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:29.324079      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:30.324365      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:31.324566      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:32.324705      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:33.326209      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:34.326521      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:35.327176      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:36.328126      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:37.329371      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:38.330263      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:39.332477      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:40.331241      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:41.331673      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:42.331839      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:43.332387      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:44.333199      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:45.334352      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:46.335277      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:47.336028      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:48.336567      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:49.337213      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:50.337378      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:51.338291      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:52.338636      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:53.338533      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:54.338825      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:55.339613      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:56.339984      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:57.341054      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:58.341082      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:59.341333      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:00.341811      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:01.342141      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:02.342536      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:03.343799      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:04.344192      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:05.344554      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:06.344998      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:07.345289      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:08.346450      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:09.347257      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:10.347954      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:11.348790      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:12.349466      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:13.350273      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:14.350957      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:15.351363      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:16.352549      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:17.353075      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:18.353551      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:19.353789      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:20.354161      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:21.354473      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:22.354543      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:23.355580      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:24.356228      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:25.357463      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:26.357615      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:27.358421      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:28.358504      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:29.358674      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:30.358846      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:31.359193      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:32.359514      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:33.360798      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:34.361926      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:35.361425      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:36.361884      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:50:36.588855 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7418" for this suite. @ 04/19/24 15:50:36.602
• [77.099 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:95
  STEP: Creating a kubernetes client @ 04/19/24 15:50:36.63
  I0419 15:50:36.631253 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename configmap @ 04/19/24 15:50:36.636
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:50:36.687
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:50:36.693
  STEP: Creating configMap configmap-9359/configmap-test-b9fc917c-7c82-43cf-99b0-ae9538b7b9ac @ 04/19/24 15:50:36.7
  STEP: Creating a pod to test consume configMaps @ 04/19/24 15:50:36.712
  E0419 15:50:37.362319      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:38.363185      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 15:50:38.754
  I0419 15:50:38.766705 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-configmaps-265bdba2-b60b-4df0-a774-f4b1e3979498 container env-test: <nil>
  STEP: delete the pod @ 04/19/24 15:50:38.789
  I0419 15:50:38.835452 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9359" for this suite. @ 04/19/24 15:50:38.847
• [2.234 seconds]
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1368
  STEP: Creating a kubernetes client @ 04/19/24 15:50:38.865
  I0419 15:50:38.865383 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename kubectl @ 04/19/24 15:50:38.869
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:50:38.912
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:50:38.92
  STEP: validating cluster-info @ 04/19/24 15:50:38.928
  I0419 15:50:38.929472 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-7060 cluster-info'
  I0419 15:50:39.113625 14 builder.go:146] stderr: ""
  I0419 15:50:39.113723 14 builder.go:147] stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.233.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
  I0419 15:50:39.113937 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7060" for this suite. @ 04/19/24 15:50:39.122
• [0.271 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:79
  STEP: Creating a kubernetes client @ 04/19/24 15:50:39.136
  I0419 15:50:39.136445 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename subpath @ 04/19/24 15:50:39.139
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:50:39.176
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:50:39.182
  STEP: Setting up data @ 04/19/24 15:50:39.187
  STEP: Creating pod pod-subpath-test-configmap-996g @ 04/19/24 15:50:39.208
  STEP: Creating a pod to test atomic-volume-subpath @ 04/19/24 15:50:39.208
  E0419 15:50:39.363972      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:40.364997      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:41.365116      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:42.365722      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:43.366247      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:44.366499      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:45.368039      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:46.368220      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:47.368607      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:48.369804      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:49.370491      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:50.370745      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:51.371638      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:52.372967      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:53.373808      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:54.375005      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:55.375854      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:56.376627      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:57.376378      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:58.377206      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:59.377926      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:00.378746      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:01.380248      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:02.380545      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 15:51:03.377
  E0419 15:51:03.381279      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:51:03.385258 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-subpath-test-configmap-996g container test-container-subpath-configmap-996g: <nil>
  STEP: delete the pod @ 04/19/24 15:51:03.407
  STEP: Deleting pod pod-subpath-test-configmap-996g @ 04/19/24 15:51:03.449
  I0419 15:51:03.449871 14 delete.go:62] Deleting pod "pod-subpath-test-configmap-996g" in namespace "subpath-4967"
  I0419 15:51:03.459733 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-4967" for this suite. @ 04/19/24 15:51:03.473
• [24.359 seconds]
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:707
  STEP: Creating a kubernetes client @ 04/19/24 15:51:03.5
  I0419 15:51:03.500627 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename sched-pred @ 04/19/24 15:51:03.506
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:51:03.553
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:51:03.56
  I0419 15:51:03.569914 14 helper.go:121] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0419 15:51:03.596525 14 util.go:400] Waiting for terminating namespaces to be deleted...
  I0419 15:51:03.606426 14 predicates.go:121] 
  Logging pods the apiserver thinks is on node eipo9quoh3ef-1 before test
  I0419 15:51:03.624345 14 predicates.go:887] kube-addon-manager-eipo9quoh3ef-1 from kube-system started at 2024-04-19 15:40:13 +0000 UTC (1 container statuses recorded)
  I0419 15:51:03.624461 14 predicates.go:889] 	Container kube-addon-manager ready: true, restart count 1
  I0419 15:51:03.624503 14 predicates.go:887] kube-apiserver-eipo9quoh3ef-1 from kube-system started at 2024-04-19 15:40:13 +0000 UTC (1 container statuses recorded)
  I0419 15:51:03.624530 14 predicates.go:889] 	Container kube-apiserver ready: true, restart count 1
  I0419 15:51:03.624559 14 predicates.go:887] kube-controller-manager-eipo9quoh3ef-1 from kube-system started at 2024-04-19 15:40:13 +0000 UTC (1 container statuses recorded)
  I0419 15:51:03.624585 14 predicates.go:889] 	Container kube-controller-manager ready: true, restart count 1
  I0419 15:51:03.624613 14 predicates.go:887] kube-flannel-ds-nk72d from kube-system started at 2024-04-19 15:44:46 +0000 UTC (1 container statuses recorded)
  I0419 15:51:03.624637 14 predicates.go:889] 	Container kube-flannel ready: true, restart count 0
  I0419 15:51:03.624665 14 predicates.go:887] kube-proxy-fpxst from kube-system started at 2024-04-19 15:44:45 +0000 UTC (1 container statuses recorded)
  I0419 15:51:03.624689 14 predicates.go:889] 	Container kube-proxy ready: true, restart count 0
  I0419 15:51:03.624716 14 predicates.go:887] kube-scheduler-eipo9quoh3ef-1 from kube-system started at 2024-04-19 15:40:13 +0000 UTC (1 container statuses recorded)
  I0419 15:51:03.624740 14 predicates.go:889] 	Container kube-scheduler ready: true, restart count 1
  I0419 15:51:03.624767 14 predicates.go:887] sonobuoy-systemd-logs-daemon-set-946d96f11a954c8b-87528 from sonobuoy started at 2024-04-19 15:45:05 +0000 UTC (2 container statuses recorded)
  I0419 15:51:03.624791 14 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0419 15:51:03.624814 14 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  I0419 15:51:03.624843 14 predicates.go:121] 
  Logging pods the apiserver thinks is on node eipo9quoh3ef-2 before test
  I0419 15:51:03.642748 14 predicates.go:887] coredns-7db6d8ff4d-2k6mj from kube-system started at 2024-04-19 15:44:44 +0000 UTC (1 container statuses recorded)
  I0419 15:51:03.642826 14 predicates.go:889] 	Container coredns ready: true, restart count 0
  I0419 15:51:03.642886 14 predicates.go:887] kube-addon-manager-eipo9quoh3ef-2 from kube-system started at 2024-04-19 15:34:39 +0000 UTC (1 container statuses recorded)
  I0419 15:51:03.642910 14 predicates.go:889] 	Container kube-addon-manager ready: true, restart count 1
  I0419 15:51:03.642934 14 predicates.go:887] kube-apiserver-eipo9quoh3ef-2 from kube-system started at 2024-04-19 15:34:39 +0000 UTC (1 container statuses recorded)
  I0419 15:51:03.642956 14 predicates.go:889] 	Container kube-apiserver ready: true, restart count 1
  I0419 15:51:03.642980 14 predicates.go:887] kube-controller-manager-eipo9quoh3ef-2 from kube-system started at 2024-04-19 15:34:39 +0000 UTC (1 container statuses recorded)
  I0419 15:51:03.643024 14 predicates.go:889] 	Container kube-controller-manager ready: true, restart count 1
  I0419 15:51:03.643059 14 predicates.go:887] kube-flannel-ds-nw295 from kube-system started at 2024-04-19 15:44:46 +0000 UTC (1 container statuses recorded)
  I0419 15:51:03.643084 14 predicates.go:889] 	Container kube-flannel ready: true, restart count 0
  I0419 15:51:03.643111 14 predicates.go:887] kube-proxy-thxpg from kube-system started at 2024-04-19 15:44:45 +0000 UTC (1 container statuses recorded)
  I0419 15:51:03.643134 14 predicates.go:889] 	Container kube-proxy ready: true, restart count 0
  I0419 15:51:03.643162 14 predicates.go:887] kube-scheduler-eipo9quoh3ef-2 from kube-system started at 2024-04-19 15:34:39 +0000 UTC (1 container statuses recorded)
  I0419 15:51:03.643186 14 predicates.go:889] 	Container kube-scheduler ready: true, restart count 1
  I0419 15:51:03.643214 14 predicates.go:887] sonobuoy-systemd-logs-daemon-set-946d96f11a954c8b-bhgtx from sonobuoy started at 2024-04-19 15:45:05 +0000 UTC (2 container statuses recorded)
  I0419 15:51:03.643238 14 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0419 15:51:03.643261 14 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  I0419 15:51:03.643285 14 predicates.go:121] 
  Logging pods the apiserver thinks is on node eipo9quoh3ef-3 before test
  I0419 15:51:03.663100 14 predicates.go:887] coredns-7db6d8ff4d-bcl67 from kube-system started at 2024-04-19 15:44:44 +0000 UTC (1 container statuses recorded)
  I0419 15:51:03.663178 14 predicates.go:889] 	Container coredns ready: true, restart count 0
  I0419 15:51:03.663217 14 predicates.go:887] kube-flannel-ds-p5c44 from kube-system started at 2024-04-19 15:44:46 +0000 UTC (1 container statuses recorded)
  I0419 15:51:03.663244 14 predicates.go:889] 	Container kube-flannel ready: true, restart count 0
  I0419 15:51:03.663273 14 predicates.go:887] kube-proxy-nh75b from kube-system started at 2024-04-19 15:44:45 +0000 UTC (1 container statuses recorded)
  I0419 15:51:03.663303 14 predicates.go:889] 	Container kube-proxy ready: true, restart count 0
  I0419 15:51:03.663333 14 predicates.go:887] sonobuoy from sonobuoy started at 2024-04-19 15:45:04 +0000 UTC (1 container statuses recorded)
  I0419 15:51:03.663359 14 predicates.go:889] 	Container kube-sonobuoy ready: true, restart count 0
  I0419 15:51:03.663388 14 predicates.go:887] sonobuoy-e2e-job-154f7ff9c64444f9 from sonobuoy started at 2024-04-19 15:45:05 +0000 UTC (2 container statuses recorded)
  I0419 15:51:03.663412 14 predicates.go:889] 	Container e2e ready: true, restart count 0
  I0419 15:51:03.663440 14 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0419 15:51:03.663468 14 predicates.go:887] sonobuoy-systemd-logs-daemon-set-946d96f11a954c8b-hhhbm from sonobuoy started at 2024-04-19 15:45:05 +0000 UTC (2 container statuses recorded)
  I0419 15:51:03.663493 14 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0419 15:51:03.663516 14 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 04/19/24 15:51:03.663
  E0419 15:51:04.382312      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:05.382659      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 04/19/24 15:51:05.733
  STEP: Trying to apply a random label on the found node. @ 04/19/24 15:51:05.809
  STEP: verifying the node has the label kubernetes.io/e2e-64431592-e97b-425c-bfdb-c04eb05ecc68 95 @ 04/19/24 15:51:05.84
  STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled @ 04/19/24 15:51:05.851
  E0419 15:51:06.382809      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:07.383338      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 192.168.121.127 on the node which pod4 resides and expect not scheduled @ 04/19/24 15:51:07.877
  E0419 15:51:08.384415      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:09.384107      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:10.384750      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:11.385155      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:12.386341      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:13.386705      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:14.387006      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:15.387380      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:16.388458      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:17.388772      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:18.389526      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:19.391335      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:20.390877      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:21.390965      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:22.392036      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:23.393083      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:24.393993      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:25.394718      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:26.395708      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:27.396183      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:28.396972      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:29.397341      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:30.397843      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:31.398543      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:32.399805      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:33.399874      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:34.401128      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:35.401120      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:36.401660      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:37.402233      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:38.402789      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:39.403309      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:40.404116      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:41.404192      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:42.405289      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:43.406281      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:44.406972      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:45.407214      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:46.407960      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:47.409128      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:48.409814      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:49.409743      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:50.410132      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:51.410459      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:52.411245      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:53.411950      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:54.412523      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:55.413087      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:56.414246      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:57.414288      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:58.414439      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:59.415119      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:00.415850      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:01.415918      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:02.416526      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:03.416814      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:04.417742      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:05.418012      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:06.418929      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:07.419473      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:08.419628      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:09.419544      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:10.419931      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:11.420392      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:12.420744      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:13.421879      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:14.422802      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:15.423394      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:16.423859      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:17.423940      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:18.424345      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:19.424838      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:20.425653      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:21.425086      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:22.425897      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:23.426405      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:24.427371      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:25.427643      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:26.428205      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:27.428709      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:28.428240      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:29.428538      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:30.429080      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:31.429879      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:32.430189      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:33.430662      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:34.431212      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:35.431399      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:36.431676      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:37.432033      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:38.432095      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:39.432781      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:40.432721      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:41.433566      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:42.434171      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:43.435534      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:44.436437      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:45.436789      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:46.437651      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:47.437664      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:48.437836      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:49.438683      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:50.438567      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:51.439668      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:52.440868      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:53.441974      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:54.442403      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:55.442707      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:56.442937      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:57.443279      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:58.443419      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:59.443790      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:00.444131      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:01.444351      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:02.444744      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:03.445077      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:04.446167      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:05.446852      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:06.447644      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:07.447749      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:08.447955      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:09.448051      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:10.448412      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:11.448748      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:12.449592      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:13.449878      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:14.450715      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:15.450978      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:16.451487      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:17.451744      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:18.452024      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:19.452206      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:20.452536      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:21.452797      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:22.452809      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:23.453871      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:24.454191      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:25.454909      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:26.455091      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:27.456227      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:28.456774      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:29.456988      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:30.458740      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:31.458461      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:32.458332      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:33.458698      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:34.460040      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:35.459620      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:36.460448      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:37.460739      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:38.461293      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:39.461475      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:40.462277      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:41.462467      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:42.463480      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:43.464495      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:44.464796      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:45.465151      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:46.465287      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:47.465600      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:48.465900      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:49.466291      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:50.466710      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:51.466735      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:52.467059      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:53.468178      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:54.468524      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:55.468765      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:56.469424      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:57.470244      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:58.470733      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:59.471058      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:00.471895      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:01.472079      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:02.472500      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:03.472761      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:04.473602      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:05.473891      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:06.474006      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:07.474390      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:08.475521      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:09.475653      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:10.475915      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:11.476127      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:12.476510      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:13.477587      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:14.478623      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:15.478851      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:16.480559      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:17.480313      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:18.480585      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:19.481811      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:20.482277      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:21.482562      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:22.482821      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:23.484752      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:24.485580      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:25.486515      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:26.487675      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:27.487858      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:28.488993      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:29.489732      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:30.490559      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:31.490693      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:32.491840      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:33.492468      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:34.492766      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:35.493082      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:36.493320      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:37.493649      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:38.493901      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:39.494153      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:40.494572      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:41.495598      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:42.495815      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:43.496438      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:44.497430      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:45.497631      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:46.497816      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:47.498772      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:48.499227      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:49.499895      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:50.500771      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:51.501194      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:52.501620      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:53.502829      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:54.503315      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:55.503476      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:56.504246      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:57.504162      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:58.504732      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:59.505076      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:00.505401      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:01.506539      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:02.507679      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:03.508295      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:04.508575      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:05.508729      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:06.509128      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:07.509706      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:08.510861      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:09.513323      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:10.513667      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:11.514616      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:12.515746      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:13.516525      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:14.517624      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:15.517845      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:16.518778      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:17.519772      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:18.520768      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:19.521665      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:20.522766      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:21.523615      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:22.524111      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:23.524816      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:24.525645      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:25.525965      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:26.526334      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:27.526678      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:28.527094      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:29.528104      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:30.528230      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:31.528365      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:32.529006      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:33.529441      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:34.529704      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:35.530230      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:36.530771      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:37.531735      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:38.532677      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:39.533083      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:40.533967      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:41.534485      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:42.535323      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:43.535779      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:44.536211      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:45.537357      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:46.537836      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:47.538295      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:48.538845      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:49.539209      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:50.539620      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:51.540082      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:52.540709      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:53.540446      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:54.540949      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:55.541599      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:56.543317      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:57.543650      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:58.543629      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:59.545173      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:00.545794      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:01.545842      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:02.545917      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:03.547064      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:04.547303      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:05.546840      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:06.547386      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:07.548130      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-64431592-e97b-425c-bfdb-c04eb05ecc68 off the node eipo9quoh3ef-3 @ 04/19/24 15:56:07.894
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-64431592-e97b-425c-bfdb-c04eb05ecc68 @ 04/19/24 15:56:07.926
  I0419 15:56:07.939739 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-3460" for this suite. @ 04/19/24 15:56:07.952
• [304.468 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1759
  STEP: Creating a kubernetes client @ 04/19/24 15:56:07.98
  I0419 15:56:07.980485 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename kubectl @ 04/19/24 15:56:07.991
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:56:08.04
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:56:08.056
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 04/19/24 15:56:08.071
  I0419 15:56:08.072223 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-1208 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4'
  I0419 15:56:08.334534 14 builder.go:146] stderr: ""
  I0419 15:56:08.334638 14 builder.go:147] stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 04/19/24 15:56:08.334
  I0419 15:56:08.352322 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-1208 delete pods e2e-test-httpd-pod'
  E0419 15:56:08.550226      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:09.549112      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:56:10.071987 14 builder.go:146] stderr: ""
  I0419 15:56:10.072113 14 builder.go:147] stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  I0419 15:56:10.072601 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1208" for this suite. @ 04/19/24 15:56:10.089
• [2.132 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:119
  STEP: Creating a kubernetes client @ 04/19/24 15:56:10.112
  I0419 15:56:10.112856 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename projected @ 04/19/24 15:56:10.117
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:56:10.182
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:56:10.192
  STEP: Creating secret with name projected-secret-test-6defdde8-9470-431b-b089-493d07cf735c @ 04/19/24 15:56:10.204
  STEP: Creating a pod to test consume secrets @ 04/19/24 15:56:10.222
  E0419 15:56:10.550503      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:11.551858      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:12.551743      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:13.552834      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 15:56:14.281
  I0419 15:56:14.292015 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-projected-secrets-8a0d83d7-c4e8-4aa9-9785-13eb2535e782 container secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/24 15:56:14.346
  I0419 15:56:14.382911 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4535" for this suite. @ 04/19/24 15:56:14.397
• [4.305 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:256
  STEP: Creating a kubernetes client @ 04/19/24 15:56:14.423
  I0419 15:56:14.423928 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename init-container @ 04/19/24 15:56:14.431
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:56:14.476
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:56:14.483
  STEP: creating the pod @ 04/19/24 15:56:14.491
  I0419 15:56:14.491492 14 init_container.go:294] PodSpec: initContainers in spec.initContainers
  E0419 15:56:14.553454      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:15.554594      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:16.554853      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:17.555070      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:56:18.082303 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-2489" for this suite. @ 04/19/24 15:56:18.099
• [3.696 seconds]
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:100
  STEP: Creating a kubernetes client @ 04/19/24 15:56:18.119
  I0419 15:56:18.119210 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename emptydir @ 04/19/24 15:56:18.126
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:56:18.181
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:56:18.189
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 04/19/24 15:56:18.201
  E0419 15:56:18.556205      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:19.556248      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 15:56:20.271
  I0419 15:56:20.280478 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-05cda401-0737-4ca7-b38e-2249dab71c35 container test-container: <nil>
  STEP: delete the pod @ 04/19/24 15:56:20.306
  I0419 15:56:20.355911 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-798" for this suite. @ 04/19/24 15:56:20.37
• [2.277 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:223
  STEP: Creating a kubernetes client @ 04/19/24 15:56:20.399
  I0419 15:56:20.399446 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename projected @ 04/19/24 15:56:20.404
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:56:20.446
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:56:20.454
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 15:56:20.463
  E0419 15:56:20.556260      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:21.557312      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:22.557389      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:23.558066      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 15:56:24.522
  I0419 15:56:24.531136 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod downwardapi-volume-26e39835-7241-438c-8f43-409aa4ae65bd container client-container: <nil>
  STEP: delete the pod @ 04/19/24 15:56:24.552
  E0419 15:56:24.558875      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:56:24.588290 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9384" for this suite. @ 04/19/24 15:56:24.603
• [4.222 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:92
  STEP: Creating a kubernetes client @ 04/19/24 15:56:24.622
  I0419 15:56:24.622592 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename downward-api @ 04/19/24 15:56:24.627
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:56:24.673
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:56:24.685
  STEP: Creating a pod to test downward api env vars @ 04/19/24 15:56:24.693
  E0419 15:56:25.559062      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:26.559342      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:27.559621      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:28.560050      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 15:56:28.748
  I0419 15:56:28.759583 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod downward-api-f936467f-c51c-440d-ba62-73a3d04a7858 container dapi-container: <nil>
  STEP: delete the pod @ 04/19/24 15:56:28.781
  I0419 15:56:28.830134 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4998" for this suite. @ 04/19/24 15:56:28.843
• [4.246 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should create and stop a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:342
  STEP: Creating a kubernetes client @ 04/19/24 15:56:28.875
  I0419 15:56:28.875445 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename kubectl @ 04/19/24 15:56:28.878
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:56:28.949
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:56:28.954
  STEP: creating a replication controller @ 04/19/24 15:56:28.96
  I0419 15:56:28.960777 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-8875 create -f -'
  I0419 15:56:29.360660 14 builder.go:146] stderr: ""
  I0419 15:56:29.360734 14 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 04/19/24 15:56:29.36
  I0419 15:56:29.361174 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-8875 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  E0419 15:56:29.562317      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:56:29.571459 14 builder.go:146] stderr: ""
  I0419 15:56:29.571541 14 builder.go:147] stdout: "update-demo-nautilus-99sw6 update-demo-nautilus-zpn5v "
  I0419 15:56:29.571891 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-8875 get pods update-demo-nautilus-99sw6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0419 15:56:29.734342 14 builder.go:146] stderr: ""
  I0419 15:56:29.734448 14 builder.go:147] stdout: ""
  I0419 15:56:29.734495 14 kubectl.go:2501] update-demo-nautilus-99sw6 is created but not running
  E0419 15:56:30.562609      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:31.562766      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:32.562929      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:33.563679      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:34.563865      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:56:34.735681 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-8875 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0419 15:56:34.917022 14 builder.go:146] stderr: ""
  I0419 15:56:34.917110 14 builder.go:147] stdout: "update-demo-nautilus-99sw6 update-demo-nautilus-zpn5v "
  I0419 15:56:34.917635 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-8875 get pods update-demo-nautilus-99sw6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0419 15:56:35.067788 14 builder.go:146] stderr: ""
  I0419 15:56:35.067862 14 builder.go:147] stdout: ""
  I0419 15:56:35.067880 14 kubectl.go:2501] update-demo-nautilus-99sw6 is created but not running
  E0419 15:56:35.564481      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:36.564648      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:37.565027      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:38.565735      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:39.565964      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:56:40.069063 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-8875 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0419 15:56:40.263459 14 builder.go:146] stderr: ""
  I0419 15:56:40.263551 14 builder.go:147] stdout: "update-demo-nautilus-99sw6 update-demo-nautilus-zpn5v "
  I0419 15:56:40.264383 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-8875 get pods update-demo-nautilus-99sw6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0419 15:56:40.430833 14 builder.go:146] stderr: ""
  I0419 15:56:40.430921 14 builder.go:147] stdout: ""
  I0419 15:56:40.430962 14 kubectl.go:2501] update-demo-nautilus-99sw6 is created but not running
  E0419 15:56:40.566180      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:41.566441      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:42.566892      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:43.567728      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:44.568140      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:56:45.431994 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-8875 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  E0419 15:56:45.569188      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:56:45.630989 14 builder.go:146] stderr: ""
  I0419 15:56:45.631081 14 builder.go:147] stdout: "update-demo-nautilus-99sw6 update-demo-nautilus-zpn5v "
  I0419 15:56:45.631573 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-8875 get pods update-demo-nautilus-99sw6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0419 15:56:45.785566 14 builder.go:146] stderr: ""
  I0419 15:56:45.785639 14 builder.go:147] stdout: "true"
  I0419 15:56:45.786030 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-8875 get pods update-demo-nautilus-99sw6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0419 15:56:45.929495 14 builder.go:146] stderr: ""
  I0419 15:56:45.929583 14 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0419 15:56:45.929618 14 kubectl.go:2392] validating pod update-demo-nautilus-99sw6
  I0419 15:56:45.949383 14 kubectl.go:2412] got data: {
    "image": "nautilus.jpg"
  }

  I0419 15:56:45.949527 14 kubectl.go:2417] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0419 15:56:45.949579 14 kubectl.go:2519] update-demo-nautilus-99sw6 is verified up and running
  I0419 15:56:45.949877 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-8875 get pods update-demo-nautilus-zpn5v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0419 15:56:46.119171 14 builder.go:146] stderr: ""
  I0419 15:56:46.119322 14 builder.go:147] stdout: "true"
  I0419 15:56:46.119969 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-8875 get pods update-demo-nautilus-zpn5v -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0419 15:56:46.270138 14 builder.go:146] stderr: ""
  I0419 15:56:46.270224 14 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0419 15:56:46.270254 14 kubectl.go:2392] validating pod update-demo-nautilus-zpn5v
  I0419 15:56:46.295999 14 kubectl.go:2412] got data: {
    "image": "nautilus.jpg"
  }

  I0419 15:56:46.296160 14 kubectl.go:2417] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0419 15:56:46.296195 14 kubectl.go:2519] update-demo-nautilus-zpn5v is verified up and running
  STEP: using delete to clean up resources @ 04/19/24 15:56:46.296
  I0419 15:56:46.296739 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-8875 delete --grace-period=0 --force -f -'
  I0419 15:56:46.462127 14 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0419 15:56:46.462239 14 builder.go:147] stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  I0419 15:56:46.462839 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-8875 get rc,svc -l name=update-demo --no-headers'
  E0419 15:56:46.570013      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:56:46.712526 14 builder.go:146] stderr: "No resources found in kubectl-8875 namespace.\n"
  I0419 15:56:46.712733 14 builder.go:147] stdout: ""
  I0419 15:56:46.714716 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-8875 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  I0419 15:56:46.980048 14 builder.go:146] stderr: ""
  I0419 15:56:46.980129 14 builder.go:147] stdout: ""
  I0419 15:56:46.980634 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8875" for this suite. @ 04/19/24 15:56:47.009
• [18.152 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update mutating webhook configurations with match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:766
  STEP: Creating a kubernetes client @ 04/19/24 15:56:47.028
  I0419 15:56:47.028193 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename webhook @ 04/19/24 15:56:47.035
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:56:47.064
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:56:47.076
  STEP: Setting up server cert @ 04/19/24 15:56:47.145
  E0419 15:56:47.570033      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 15:56:47.97
  STEP: Deploying the webhook pod @ 04/19/24 15:56:47.992
  STEP: Wait for the deployment to be ready @ 04/19/24 15:56:48.018
  I0419 15:56:48.034738 14 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0419 15:56:48.571163      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:49.571804      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 15:56:50.062
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 15:56:50.083
  E0419 15:56:50.572356      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:56:51.083482 14 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a mutating webhook with match conditions @ 04/19/24 15:56:51.108
  STEP: verifying the mutating webhook match conditions @ 04/19/24 15:56:51.153
  STEP: updating the mutating webhook match conditions @ 04/19/24 15:56:51.165
  STEP: verifying the mutating webhook match conditions @ 04/19/24 15:56:51.192
  I0419 15:56:51.309403 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-241" for this suite. @ 04/19/24 15:56:51.328
  STEP: Destroying namespace "webhook-markers-4640" for this suite. @ 04/19/24 15:56:51.367
• [4.350 seconds]
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:110
  STEP: Creating a kubernetes client @ 04/19/24 15:56:51.379
  I0419 15:56:51.379322 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename emptydir @ 04/19/24 15:56:51.383
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:56:51.413
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:56:51.419
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 04/19/24 15:56:51.425
  E0419 15:56:51.572464      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:52.572834      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:53.573332      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:54.573450      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 15:56:55.476
  I0419 15:56:55.486165 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-593429e3-44fd-4360-93e2-620143625b19 container test-container: <nil>
  STEP: delete the pod @ 04/19/24 15:56:55.51
  I0419 15:56:55.546048 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4240" for this suite. @ 04/19/24 15:56:55.557
  E0419 15:56:55.573506      14 retrywatcher.go:129] "Watch failed" err="context canceled"
• [4.198 seconds]
------------------------------
SS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:134
  STEP: Creating a kubernetes client @ 04/19/24 15:56:55.577
  I0419 15:56:55.577849 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename kubelet-test @ 04/19/24 15:56:55.58
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:56:55.617
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:56:55.622
  I0419 15:56:55.704137 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-8164" for this suite. @ 04/19/24 15:56:55.714
• [0.152 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:646
  STEP: Creating a kubernetes client @ 04/19/24 15:56:55.73
  I0419 15:56:55.730562 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename webhook @ 04/19/24 15:56:55.733
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:56:55.758
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:56:55.764
  STEP: Setting up server cert @ 04/19/24 15:56:55.817
  E0419 15:56:56.575366      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 15:56:57.481
  STEP: Deploying the webhook pod @ 04/19/24 15:56:57.49
  STEP: Wait for the deployment to be ready @ 04/19/24 15:56:57.508
  I0419 15:56:57.519632 14 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0419 15:56:57.576686      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:58.577385      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 15:56:59.552
  E0419 15:56:59.578409      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 15:56:59.58
  E0419 15:57:00.578974      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:57:00.581387 14 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 04/19/24 15:57:00.777
  STEP: Creating a configMap that should be mutated @ 04/19/24 15:57:00.816
  STEP: Deleting the collection of validation webhooks @ 04/19/24 15:57:00.871
  STEP: Creating a configMap that should not be mutated @ 04/19/24 15:57:01.041
  I0419 15:57:01.170110 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4903" for this suite. @ 04/19/24 15:57:01.181
  STEP: Destroying namespace "webhook-markers-3062" for this suite. @ 04/19/24 15:57:01.198
• [5.482 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:106
  STEP: Creating a kubernetes client @ 04/19/24 15:57:01.213
  I0419 15:57:01.213835 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename runtimeclass @ 04/19/24 15:57:01.217
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:57:01.274
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:57:01.286
  I0419 15:57:01.376703 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-9654" for this suite. @ 04/19/24 15:57:01.384
• [0.195 seconds]
------------------------------
SS
------------------------------
[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:348
  STEP: Creating a kubernetes client @ 04/19/24 15:57:01.408
  I0419 15:57:01.408841 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename disruption @ 04/19/24 15:57:01.412
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:57:01.451
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:57:01.455
  STEP: Creating a pdb that targets all three pods in a test replica set @ 04/19/24 15:57:01.459
  STEP: Waiting for the pdb to be processed @ 04/19/24 15:57:01.466
  E0419 15:57:01.580051      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:02.580944      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: First trying to evict a pod which shouldn't be evictable @ 04/19/24 15:57:03.495
  STEP: Waiting for all pods to be running @ 04/19/24 15:57:03.495
  I0419 15:57:03.505088 14 disruption.go:567] pods: 0 < 3
  E0419 15:57:03.581831      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:04.582584      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 04/19/24 15:57:05.504
  STEP: Updating the pdb to allow a pod to be evicted @ 04/19/24 15:57:05.525
  STEP: Waiting for the pdb to be processed @ 04/19/24 15:57:05.553
  E0419 15:57:05.582497      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:06.583143      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 04/19/24 15:57:07.567
  STEP: Waiting for all pods to be running @ 04/19/24 15:57:07.567
  STEP: Waiting for the pdb to observed all healthy pods @ 04/19/24 15:57:07.578
  E0419 15:57:07.583541      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Patching the pdb to disallow a pod to be evicted @ 04/19/24 15:57:07.643
  STEP: Waiting for the pdb to be processed @ 04/19/24 15:57:07.728
  STEP: Waiting for all pods to be running @ 04/19/24 15:57:07.736
  I0419 15:57:07.747057 14 disruption.go:578] running pods: 2 < 3
  E0419 15:57:08.584343      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:09.584956      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 04/19/24 15:57:09.746
  STEP: Deleting the pdb to allow a pod to be evicted @ 04/19/24 15:57:09.773
  STEP: Waiting for the pdb to be deleted @ 04/19/24 15:57:09.787
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 04/19/24 15:57:09.793
  STEP: Waiting for all pods to be running @ 04/19/24 15:57:09.793
  I0419 15:57:09.834978 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-1334" for this suite. @ 04/19/24 15:57:09.867
• [8.512 seconds]
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Update Demo should scale a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:355
  STEP: Creating a kubernetes client @ 04/19/24 15:57:09.921
  I0419 15:57:09.921475 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename kubectl @ 04/19/24 15:57:09.924
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:57:09.993
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:57:09.998
  STEP: creating a replication controller @ 04/19/24 15:57:10.005
  I0419 15:57:10.006856 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-9083 create -f -'
  I0419 15:57:10.354928 14 builder.go:146] stderr: ""
  I0419 15:57:10.355064 14 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 04/19/24 15:57:10.355
  I0419 15:57:10.355607 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-9083 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0419 15:57:10.566134 14 builder.go:146] stderr: ""
  I0419 15:57:10.566235 14 builder.go:147] stdout: "update-demo-nautilus-bbctg update-demo-nautilus-rj9lk "
  I0419 15:57:10.566413 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-9083 get pods update-demo-nautilus-bbctg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  E0419 15:57:10.585307      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:57:10.737571 14 builder.go:146] stderr: ""
  I0419 15:57:10.737659 14 builder.go:147] stdout: ""
  I0419 15:57:10.737689 14 kubectl.go:2501] update-demo-nautilus-bbctg is created but not running
  E0419 15:57:11.585892      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:12.586730      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:13.587039      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:14.587376      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:15.587436      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:57:15.738208 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-9083 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0419 15:57:15.919853 14 builder.go:146] stderr: ""
  I0419 15:57:15.919942 14 builder.go:147] stdout: "update-demo-nautilus-bbctg update-demo-nautilus-rj9lk "
  I0419 15:57:15.920199 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-9083 get pods update-demo-nautilus-bbctg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0419 15:57:16.074283 14 builder.go:146] stderr: ""
  I0419 15:57:16.074375 14 builder.go:147] stdout: "true"
  I0419 15:57:16.074650 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-9083 get pods update-demo-nautilus-bbctg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0419 15:57:16.229305 14 builder.go:146] stderr: ""
  I0419 15:57:16.229376 14 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0419 15:57:16.229402 14 kubectl.go:2392] validating pod update-demo-nautilus-bbctg
  I0419 15:57:16.242349 14 kubectl.go:2412] got data: {
    "image": "nautilus.jpg"
  }

  I0419 15:57:16.242467 14 kubectl.go:2417] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0419 15:57:16.242502 14 kubectl.go:2519] update-demo-nautilus-bbctg is verified up and running
  I0419 15:57:16.242699 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-9083 get pods update-demo-nautilus-rj9lk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0419 15:57:16.391360 14 builder.go:146] stderr: ""
  I0419 15:57:16.391430 14 builder.go:147] stdout: "true"
  I0419 15:57:16.391624 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-9083 get pods update-demo-nautilus-rj9lk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0419 15:57:16.577766 14 builder.go:146] stderr: ""
  I0419 15:57:16.577843 14 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0419 15:57:16.577869 14 kubectl.go:2392] validating pod update-demo-nautilus-rj9lk
  E0419 15:57:16.588524      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:57:16.592310 14 kubectl.go:2412] got data: {
    "image": "nautilus.jpg"
  }

  I0419 15:57:16.592402 14 kubectl.go:2417] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0419 15:57:16.592427 14 kubectl.go:2519] update-demo-nautilus-rj9lk is verified up and running
  STEP: scaling down the replication controller @ 04/19/24 15:57:16.592
  I0419 15:57:16.607634 14 kubectl.go:324] scanned /root for discovery docs: <nil>
  I0419 15:57:16.608374 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-9083 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
  E0419 15:57:17.588663      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:57:17.826996 14 builder.go:146] stderr: ""
  I0419 15:57:17.827096 14 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 04/19/24 15:57:17.827
  I0419 15:57:17.827886 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-9083 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0419 15:57:18.014884 14 builder.go:146] stderr: ""
  I0419 15:57:18.014963 14 builder.go:147] stdout: "update-demo-nautilus-bbctg "
  I0419 15:57:18.015327 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-9083 get pods update-demo-nautilus-bbctg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0419 15:57:18.164170 14 builder.go:146] stderr: ""
  I0419 15:57:18.164244 14 builder.go:147] stdout: "true"
  I0419 15:57:18.164945 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-9083 get pods update-demo-nautilus-bbctg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0419 15:57:18.319473 14 builder.go:146] stderr: ""
  I0419 15:57:18.320182 14 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0419 15:57:18.320250 14 kubectl.go:2392] validating pod update-demo-nautilus-bbctg
  I0419 15:57:18.343313 14 kubectl.go:2412] got data: {
    "image": "nautilus.jpg"
  }

  I0419 15:57:18.343435 14 kubectl.go:2417] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0419 15:57:18.343641 14 kubectl.go:2519] update-demo-nautilus-bbctg is verified up and running
  STEP: scaling up the replication controller @ 04/19/24 15:57:18.343
  I0419 15:57:18.355022 14 kubectl.go:324] scanned /root for discovery docs: <nil>
  I0419 15:57:18.355409 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-9083 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
  E0419 15:57:18.589596      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:57:19.564064 14 builder.go:146] stderr: ""
  I0419 15:57:19.564218 14 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 04/19/24 15:57:19.564
  I0419 15:57:19.565290 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-9083 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  E0419 15:57:19.590412      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:57:19.739170 14 builder.go:146] stderr: ""
  I0419 15:57:19.739251 14 builder.go:147] stdout: "update-demo-nautilus-bbctg update-demo-nautilus-r4zvb "
  I0419 15:57:19.739760 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-9083 get pods update-demo-nautilus-bbctg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0419 15:57:19.897190 14 builder.go:146] stderr: ""
  I0419 15:57:19.897269 14 builder.go:147] stdout: "true"
  I0419 15:57:19.897856 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-9083 get pods update-demo-nautilus-bbctg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0419 15:57:20.049607 14 builder.go:146] stderr: ""
  I0419 15:57:20.049770 14 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0419 15:57:20.049799 14 kubectl.go:2392] validating pod update-demo-nautilus-bbctg
  I0419 15:57:20.060367 14 kubectl.go:2412] got data: {
    "image": "nautilus.jpg"
  }

  I0419 15:57:20.060704 14 kubectl.go:2417] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0419 15:57:20.060851 14 kubectl.go:2519] update-demo-nautilus-bbctg is verified up and running
  I0419 15:57:20.061312 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-9083 get pods update-demo-nautilus-r4zvb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0419 15:57:20.220335 14 builder.go:146] stderr: ""
  I0419 15:57:20.220420 14 builder.go:147] stdout: "true"
  I0419 15:57:20.220819 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-9083 get pods update-demo-nautilus-r4zvb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0419 15:57:20.382907 14 builder.go:146] stderr: ""
  I0419 15:57:20.383002 14 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0419 15:57:20.383029 14 kubectl.go:2392] validating pod update-demo-nautilus-r4zvb
  I0419 15:57:20.401182 14 kubectl.go:2412] got data: {
    "image": "nautilus.jpg"
  }

  I0419 15:57:20.401488 14 kubectl.go:2417] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0419 15:57:20.401522 14 kubectl.go:2519] update-demo-nautilus-r4zvb is verified up and running
  STEP: using delete to clean up resources @ 04/19/24 15:57:20.401
  I0419 15:57:20.401958 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-9083 delete --grace-period=0 --force -f -'
  I0419 15:57:20.554097 14 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0419 15:57:20.554171 14 builder.go:147] stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  I0419 15:57:20.554496 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-9083 get rc,svc -l name=update-demo --no-headers'
  E0419 15:57:20.590472      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:57:20.786768 14 builder.go:146] stderr: "No resources found in kubectl-9083 namespace.\n"
  I0419 15:57:20.786862 14 builder.go:147] stdout: ""
  I0419 15:57:20.789835 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-9083 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  I0419 15:57:21.015454 14 builder.go:146] stderr: ""
  I0419 15:57:21.015670 14 builder.go:147] stdout: ""
  I0419 15:57:21.016247 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9083" for this suite. @ 04/19/24 15:57:21.034
• [11.123 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:85
  STEP: Creating a kubernetes client @ 04/19/24 15:57:21.049
  I0419 15:57:21.050242 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename pod-network-test @ 04/19/24 15:57:21.053
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:57:21.084
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:57:21.089
  STEP: Performing setup for networking test in namespace pod-network-test-3525 @ 04/19/24 15:57:21.096
  STEP: creating a selector @ 04/19/24 15:57:21.096
  STEP: Creating the service pods in kubernetes @ 04/19/24 15:57:21.096
  I0419 15:57:21.096501 14 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0419 15:57:21.591089      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:22.591867      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:23.591985      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:24.593378      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:25.592695      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:26.593125      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:27.599679      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:28.597891      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:29.598353      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:30.598836      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:31.599968      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:32.604576      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:33.603795      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:34.604508      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:35.605047      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:36.605809      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:37.606275      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:38.607303      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:39.607467      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:40.607607      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:41.608622      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:42.608533      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:43.608835      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:44.609814      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:45.609907      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:46.610509      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:47.611451      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:48.612184      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:49.612775      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:50.613672      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:51.614467      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:52.615191      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:53.615923      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:54.616296      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:55.617201      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:56.617506      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:57.618492      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:58.618437      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:59.618737      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:00.619728      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:01.619944      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:02.620015      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 04/19/24 15:58:03.432
  E0419 15:58:03.621876      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:04.622253      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:58:05.477414 14 utils.go:779] Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  I0419 15:58:05.477500 14 networking.go:42] Breadth first check of 10.233.64.45 on host 192.168.121.38...
  I0419 15:58:05.483815 14 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.87:9080/dial?request=hostname&protocol=http&host=10.233.64.45&port=8083&tries=1'] Namespace:pod-network-test-3525 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0419 15:58:05.483909 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 15:58:05.485951 14 exec_util.go:62] ExecWithOptions: Clientset creation
  I0419 15:58:05.486254 14 exec_util.go:79] ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-3525/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.87%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.64.45%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  E0419 15:58:05.622527      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:58:05.687519 14 utils.go:331] Waiting for responses: map[]
  I0419 15:58:05.688145 14 utils.go:335] reached 10.233.64.45 after 0/1 tries
  I0419 15:58:05.688398 14 networking.go:42] Breadth first check of 10.233.65.37 on host 192.168.121.197...
  I0419 15:58:05.697602 14 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.87:9080/dial?request=hostname&protocol=http&host=10.233.65.37&port=8083&tries=1'] Namespace:pod-network-test-3525 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0419 15:58:05.697999 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 15:58:05.700005 14 exec_util.go:62] ExecWithOptions: Clientset creation
  I0419 15:58:05.700303 14 exec_util.go:79] ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-3525/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.87%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.65.37%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I0419 15:58:05.839820 14 utils.go:331] Waiting for responses: map[]
  I0419 15:58:05.839890 14 utils.go:335] reached 10.233.65.37 after 0/1 tries
  I0419 15:58:05.839914 14 networking.go:42] Breadth first check of 10.233.66.86 on host 192.168.121.127...
  I0419 15:58:05.849301 14 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.87:9080/dial?request=hostname&protocol=http&host=10.233.66.86&port=8083&tries=1'] Namespace:pod-network-test-3525 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0419 15:58:05.849624 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 15:58:05.852100 14 exec_util.go:62] ExecWithOptions: Clientset creation
  I0419 15:58:05.852554 14 exec_util.go:79] ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-3525/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.87%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.66.86%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I0419 15:58:05.971790 14 utils.go:331] Waiting for responses: map[]
  I0419 15:58:05.971866 14 utils.go:335] reached 10.233.66.86 after 0/1 tries
  I0419 15:58:05.971901 14 networking.go:53] Going to retry 0 out of 3 pods....
  I0419 15:58:05.972119 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-3525" for this suite. @ 04/19/24 15:58:05.982
• [44.953 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:86
  STEP: Creating a kubernetes client @ 04/19/24 15:58:06.003
  I0419 15:58:06.003042 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename projected @ 04/19/24 15:58:06.006
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:58:06.066
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:58:06.072
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 15:58:06.081
  E0419 15:58:06.622871      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:07.623556      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:08.623981      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:09.624232      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 15:58:10.129
  I0419 15:58:10.140507 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod downwardapi-volume-5b452b4b-0517-4987-a436-5ef99aee9ee7 container client-container: <nil>
  STEP: delete the pod @ 04/19/24 15:58:10.163
  I0419 15:58:10.211536 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7457" for this suite. @ 04/19/24 15:58:10.226
• [4.244 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] VolumeAttachment Conformance should run through the lifecycle of a VolumeAttachment [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/volume_attachment.go:57
  STEP: Creating a kubernetes client @ 04/19/24 15:58:10.253
  I0419 15:58:10.253425 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename volumeattachment @ 04/19/24 15:58:10.258
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:58:10.297
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:58:10.305
  STEP: Create VolumeAttachment "va-e2e-lmvtg" on node "eipo9quoh3ef-1" @ 04/19/24 15:58:10.328
  STEP: Get VolumeAttachment "va-e2e-lmvtg" on node "eipo9quoh3ef-1" @ 04/19/24 15:58:10.342
  STEP: Patch VolumeAttachment "va-e2e-lmvtg" on node "eipo9quoh3ef-1" @ 04/19/24 15:58:10.35
  STEP: List VolumeAttachments with "va-e2e-lmvtg=patched" label @ 04/19/24 15:58:10.368
  STEP: Delete VolumeAttachment "va-e2e-lmvtg" on node "eipo9quoh3ef-1" @ 04/19/24 15:58:10.377
  STEP: Confirm deletion of VolumeAttachment "va-e2e-lmvtg" on node "eipo9quoh3ef-1" @ 04/19/24 15:58:10.394
  STEP: Create VolumeAttachment "va-e2e-72fjv" on node "eipo9quoh3ef-2" @ 04/19/24 15:58:10.424
  STEP: Update the VolumeAttachment "va-e2e-72fjv" on node "eipo9quoh3ef-2" with label "va-e2e=updated" @ 04/19/24 15:58:10.436
  STEP: Create VolumeAttachment "va-e2e-x655k" on node "eipo9quoh3ef-1" @ 04/19/24 15:58:10.465
  STEP: Update the VolumeAttachment "va-e2e-x655k" on node "eipo9quoh3ef-1" with label "va-e2e=updated" @ 04/19/24 15:58:10.478
  STEP: DeleteCollection of VolumeAttachments with "va-e2e=updated" label @ 04/19/24 15:58:10.498
  STEP: Confirm deleteCollection of VolumeAttachments with "va-e2e=updated" label @ 04/19/24 15:58:10.532
  I0419 15:58:10.542999 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "volumeattachment-843" for this suite. @ 04/19/24 15:58:10.557
• [0.322 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:818
  STEP: Creating a kubernetes client @ 04/19/24 15:58:10.583
  I0419 15:58:10.583903 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename gc @ 04/19/24 15:58:10.592
  E0419 15:58:10.624667      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:58:10.629
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:58:10.637
  I0419 15:58:10.773332 14 garbage_collector.go:840] pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"94ad0326-7c71-42c2-9ac6-5829d1075ec0", Controller:(*bool)(0xc00349dda6), BlockOwnerDeletion:(*bool)(0xc00349dda7)}}
  I0419 15:58:10.802882 14 garbage_collector.go:844] pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"8a9df1ad-b583-4e8e-9624-4e7b1ac181af", Controller:(*bool)(0xc003158056), BlockOwnerDeletion:(*bool)(0xc003158057)}}
  I0419 15:58:10.817642 14 garbage_collector.go:848] pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"9a8c3273-b213-4973-8d1f-284b11105eac", Controller:(*bool)(0xc0031582ea), BlockOwnerDeletion:(*bool)(0xc0031582eb)}}
  E0419 15:58:11.625252      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:12.625844      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:13.626061      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:14.626902      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:15.627047      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:58:15.843428 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-4439" for this suite. @ 04/19/24 15:58:15.855
• [5.281 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:469
  STEP: Creating a kubernetes client @ 04/19/24 15:58:15.868
  I0419 15:58:15.868992 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename sched-pred @ 04/19/24 15:58:15.871
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:58:15.907
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:58:15.911
  I0419 15:58:15.916931 14 helper.go:121] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0419 15:58:15.928539 14 util.go:400] Waiting for terminating namespaces to be deleted...
  I0419 15:58:15.934585 14 predicates.go:121] 
  Logging pods the apiserver thinks is on node eipo9quoh3ef-1 before test
  I0419 15:58:15.948761 14 predicates.go:887] kube-addon-manager-eipo9quoh3ef-1 from kube-system started at 2024-04-19 15:40:13 +0000 UTC (1 container statuses recorded)
  I0419 15:58:15.948854 14 predicates.go:889] 	Container kube-addon-manager ready: true, restart count 1
  I0419 15:58:15.948956 14 predicates.go:887] kube-apiserver-eipo9quoh3ef-1 from kube-system started at 2024-04-19 15:40:13 +0000 UTC (1 container statuses recorded)
  I0419 15:58:15.949109 14 predicates.go:889] 	Container kube-apiserver ready: true, restart count 1
  I0419 15:58:15.949220 14 predicates.go:887] kube-controller-manager-eipo9quoh3ef-1 from kube-system started at 2024-04-19 15:40:13 +0000 UTC (1 container statuses recorded)
  I0419 15:58:15.949291 14 predicates.go:889] 	Container kube-controller-manager ready: true, restart count 1
  I0419 15:58:15.949313 14 predicates.go:887] kube-flannel-ds-nk72d from kube-system started at 2024-04-19 15:44:46 +0000 UTC (1 container statuses recorded)
  I0419 15:58:15.949330 14 predicates.go:889] 	Container kube-flannel ready: true, restart count 0
  I0419 15:58:15.949390 14 predicates.go:887] kube-proxy-fpxst from kube-system started at 2024-04-19 15:44:45 +0000 UTC (1 container statuses recorded)
  I0419 15:58:15.949409 14 predicates.go:889] 	Container kube-proxy ready: true, restart count 0
  I0419 15:58:15.949425 14 predicates.go:887] kube-scheduler-eipo9quoh3ef-1 from kube-system started at 2024-04-19 15:40:13 +0000 UTC (1 container statuses recorded)
  I0419 15:58:15.949485 14 predicates.go:889] 	Container kube-scheduler ready: true, restart count 1
  I0419 15:58:15.949506 14 predicates.go:887] sonobuoy-systemd-logs-daemon-set-946d96f11a954c8b-87528 from sonobuoy started at 2024-04-19 15:45:05 +0000 UTC (2 container statuses recorded)
  I0419 15:58:15.949563 14 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0419 15:58:15.949580 14 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  I0419 15:58:15.949596 14 predicates.go:121] 
  Logging pods the apiserver thinks is on node eipo9quoh3ef-2 before test
  I0419 15:58:15.962328 14 predicates.go:887] coredns-7db6d8ff4d-2k6mj from kube-system started at 2024-04-19 15:44:44 +0000 UTC (1 container statuses recorded)
  I0419 15:58:15.962406 14 predicates.go:889] 	Container coredns ready: true, restart count 0
  I0419 15:58:15.962488 14 predicates.go:887] kube-addon-manager-eipo9quoh3ef-2 from kube-system started at 2024-04-19 15:34:39 +0000 UTC (1 container statuses recorded)
  I0419 15:58:15.962520 14 predicates.go:889] 	Container kube-addon-manager ready: true, restart count 1
  I0419 15:58:15.962571 14 predicates.go:887] kube-apiserver-eipo9quoh3ef-2 from kube-system started at 2024-04-19 15:34:39 +0000 UTC (1 container statuses recorded)
  I0419 15:58:15.962617 14 predicates.go:889] 	Container kube-apiserver ready: true, restart count 1
  I0419 15:58:15.962679 14 predicates.go:887] kube-controller-manager-eipo9quoh3ef-2 from kube-system started at 2024-04-19 15:34:39 +0000 UTC (1 container statuses recorded)
  I0419 15:58:15.962699 14 predicates.go:889] 	Container kube-controller-manager ready: true, restart count 1
  I0419 15:58:15.962716 14 predicates.go:887] kube-flannel-ds-nw295 from kube-system started at 2024-04-19 15:44:46 +0000 UTC (1 container statuses recorded)
  I0419 15:58:15.962775 14 predicates.go:889] 	Container kube-flannel ready: true, restart count 0
  I0419 15:58:15.962794 14 predicates.go:887] kube-proxy-thxpg from kube-system started at 2024-04-19 15:44:45 +0000 UTC (1 container statuses recorded)
  I0419 15:58:15.962848 14 predicates.go:889] 	Container kube-proxy ready: true, restart count 0
  I0419 15:58:15.962870 14 predicates.go:887] kube-scheduler-eipo9quoh3ef-2 from kube-system started at 2024-04-19 15:34:39 +0000 UTC (1 container statuses recorded)
  I0419 15:58:15.962885 14 predicates.go:889] 	Container kube-scheduler ready: true, restart count 1
  I0419 15:58:15.962956 14 predicates.go:887] sonobuoy-systemd-logs-daemon-set-946d96f11a954c8b-bhgtx from sonobuoy started at 2024-04-19 15:45:05 +0000 UTC (2 container statuses recorded)
  I0419 15:58:15.962973 14 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0419 15:58:15.963025 14 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  I0419 15:58:15.963043 14 predicates.go:121] 
  Logging pods the apiserver thinks is on node eipo9quoh3ef-3 before test
  I0419 15:58:15.974732 14 predicates.go:887] coredns-7db6d8ff4d-bcl67 from kube-system started at 2024-04-19 15:44:44 +0000 UTC (1 container statuses recorded)
  I0419 15:58:15.974781 14 predicates.go:889] 	Container coredns ready: true, restart count 0
  I0419 15:58:15.974804 14 predicates.go:887] kube-flannel-ds-p5c44 from kube-system started at 2024-04-19 15:44:46 +0000 UTC (1 container statuses recorded)
  I0419 15:58:15.974820 14 predicates.go:889] 	Container kube-flannel ready: true, restart count 0
  I0419 15:58:15.974838 14 predicates.go:887] kube-proxy-nh75b from kube-system started at 2024-04-19 15:44:45 +0000 UTC (1 container statuses recorded)
  I0419 15:58:15.974855 14 predicates.go:889] 	Container kube-proxy ready: true, restart count 0
  I0419 15:58:15.974881 14 predicates.go:887] sonobuoy from sonobuoy started at 2024-04-19 15:45:04 +0000 UTC (1 container statuses recorded)
  I0419 15:58:15.974898 14 predicates.go:889] 	Container kube-sonobuoy ready: true, restart count 0
  I0419 15:58:15.974916 14 predicates.go:887] sonobuoy-e2e-job-154f7ff9c64444f9 from sonobuoy started at 2024-04-19 15:45:05 +0000 UTC (2 container statuses recorded)
  I0419 15:58:15.974943 14 predicates.go:889] 	Container e2e ready: true, restart count 0
  I0419 15:58:15.974958 14 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0419 15:58:15.974983 14 predicates.go:887] sonobuoy-systemd-logs-daemon-set-946d96f11a954c8b-hhhbm from sonobuoy started at 2024-04-19 15:45:05 +0000 UTC (2 container statuses recorded)
  I0419 15:58:15.975001 14 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0419 15:58:15.975044 14 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 04/19/24 15:58:15.975
  E0419 15:58:16.628057      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:17.629031      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 04/19/24 15:58:18.015
  STEP: Trying to apply a random label on the found node. @ 04/19/24 15:58:18.045
  STEP: verifying the node has the label kubernetes.io/e2e-a3ce346e-30cb-400e-9841-632e1cda767f 42 @ 04/19/24 15:58:18.078
  STEP: Trying to relaunch the pod, now with labels. @ 04/19/24 15:58:18.088
  E0419 15:58:18.629156      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:19.629922      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-a3ce346e-30cb-400e-9841-632e1cda767f off the node eipo9quoh3ef-3 @ 04/19/24 15:58:20.135
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-a3ce346e-30cb-400e-9841-632e1cda767f @ 04/19/24 15:58:20.194
  I0419 15:58:20.203252 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-4220" for this suite. @ 04/19/24 15:58:20.215
• [4.363 seconds]
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:108
  STEP: Creating a kubernetes client @ 04/19/24 15:58:20.231
  I0419 15:58:20.231809 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename pod-network-test @ 04/19/24 15:58:20.238
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:58:20.275
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:58:20.282
  STEP: Performing setup for networking test in namespace pod-network-test-2280 @ 04/19/24 15:58:20.292
  STEP: creating a selector @ 04/19/24 15:58:20.292
  STEP: Creating the service pods in kubernetes @ 04/19/24 15:58:20.292
  I0419 15:58:20.292623 14 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0419 15:58:20.630342      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:21.631410      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:22.632765      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:23.633026      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:24.634415      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:25.635212      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:26.636204      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:27.637123      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:28.637176      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:29.638547      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:30.639164      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:31.639523      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:32.639777      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:33.640409      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:34.641579      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:35.641923      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:36.642430      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:37.642745      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:38.643121      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:39.643462      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:40.644565      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:41.645415      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 04/19/24 15:58:42.558
  E0419 15:58:42.645091      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:43.646061      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:44.646083      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:58:44.648830 14 utils.go:779] Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  I0419 15:58:44.650116 14 utils.go:472] Going to poll 10.233.64.46 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  I0419 15:58:44.659134 14 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.64.46:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2280 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0419 15:58:44.660267 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 15:58:44.665499 14 exec_util.go:62] ExecWithOptions: Clientset creation
  I0419 15:58:44.666799 14 exec_util.go:79] ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-2280/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.64.46%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  I0419 15:58:44.868582 14 utils.go:489] Found all 1 expected endpoints: [netserver-0]
  I0419 15:58:44.868659 14 utils.go:472] Going to poll 10.233.65.38 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  I0419 15:58:44.876410 14 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.65.38:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2280 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0419 15:58:44.876789 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 15:58:44.879188 14 exec_util.go:62] ExecWithOptions: Clientset creation
  I0419 15:58:44.879701 14 exec_util.go:79] ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-2280/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.65.38%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  I0419 15:58:45.024326 14 utils.go:489] Found all 1 expected endpoints: [netserver-1]
  I0419 15:58:45.024758 14 utils.go:472] Going to poll 10.233.66.91 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  I0419 15:58:45.031989 14 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.66.91:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2280 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0419 15:58:45.032058 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 15:58:45.033622 14 exec_util.go:62] ExecWithOptions: Clientset creation
  I0419 15:58:45.033755 14 exec_util.go:79] ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-2280/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.66.91%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  I0419 15:58:45.166679 14 utils.go:489] Found all 1 expected endpoints: [netserver-2]
  I0419 15:58:45.167498 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-2280" for this suite. @ 04/19/24 15:58:45.18
• [24.968 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:70
  STEP: Creating a kubernetes client @ 04/19/24 15:58:45.202
  I0419 15:58:45.202724 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename replication-controller @ 04/19/24 15:58:45.206
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:58:45.242
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:58:45.247
  STEP: Creating replication controller my-hostname-basic-5cd205d5-a9be-4ee2-947f-1acce15e5d12 @ 04/19/24 15:58:45.252
  I0419 15:58:45.271065 14 resource.go:87] Pod name my-hostname-basic-5cd205d5-a9be-4ee2-947f-1acce15e5d12: Found 0 pods out of 1
  E0419 15:58:45.646923      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:46.647684      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:47.647613      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:48.648049      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:49.650970      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:58:50.304408 14 resource.go:87] Pod name my-hostname-basic-5cd205d5-a9be-4ee2-947f-1acce15e5d12: Found 1 pods out of 1
  I0419 15:58:50.305963 14 rc.go:507] Ensuring all pods for ReplicationController "my-hostname-basic-5cd205d5-a9be-4ee2-947f-1acce15e5d12" are running
  I0419 15:58:50.329687 14 rc.go:523] Pod "my-hostname-basic-5cd205d5-a9be-4ee2-947f-1acce15e5d12-5p6xz" is running and ready(conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-19 15:58:46 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-19 15:58:45 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-19 15:58:46 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-19 15:58:46 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-19 15:58:45 +0000 UTC Reason: Message:}])
  I0419 15:58:50.329770 14 rc.go:531] Trying to dial the pod
  STEP: trying to dial each unique pod @ 04/19/24 15:58:50.329
  I0419 15:58:50.417462 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-3478" for this suite. @ 04/19/24 15:58:50.433
• [5.253 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to create a functioning NodePort service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1284
  STEP: Creating a kubernetes client @ 04/19/24 15:58:50.456
  I0419 15:58:50.456916 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename services @ 04/19/24 15:58:50.462
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:58:50.525
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:58:50.535
  STEP: creating service nodeport-test with type=NodePort in namespace services-4875 @ 04/19/24 15:58:50.54
  E0419 15:58:50.655838      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating replication controller nodeport-test in namespace services-4875 @ 04/19/24 15:58:50.66
  I0419 15:58:50.672361      14 runners.go:198] Created replication controller with name: nodeport-test, namespace: services-4875, replica count: 2
  E0419 15:58:51.656397      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:52.656425      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:53.657458      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:58:53.725199      14 runners.go:198] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0419 15:58:53.725532 14 resource.go:361] Creating new exec pod
  E0419 15:58:54.657720      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:55.658144      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:56.658286      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:58:56.781025 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-4875 exec execpodskmdf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  I0419 15:58:57.124051 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  I0419 15:58:57.124142 14 builder.go:147] stdout: ""
  E0419 15:58:57.658545      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:58:57.780425 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-4875 exec execpodskmdf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  I0419 15:58:58.166536 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  I0419 15:58:58.166612 14 builder.go:147] stdout: "nodeport-test-6dc66"
  I0419 15:58:58.167353 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-4875 exec execpodskmdf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.63.157 80'
  I0419 15:58:58.451832 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.63.157 80\nConnection to 10.233.63.157 80 port [tcp/http] succeeded!\n"
  I0419 15:58:58.451914 14 builder.go:147] stdout: "nodeport-test-6dc66"
  I0419 15:58:58.452416 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-4875 exec execpodskmdf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.197 32024'
  E0419 15:58:58.659413      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:58:58.722232 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.197 32024\nConnection to 192.168.121.197 32024 port [tcp/*] succeeded!\n"
  I0419 15:58:58.722324 14 builder.go:147] stdout: ""
  I0419 15:58:59.453611 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-4875 exec execpodskmdf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.197 32024'
  E0419 15:58:59.669300      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:58:59.776117 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.197 32024\nConnection to 192.168.121.197 32024 port [tcp/*] succeeded!\n"
  I0419 15:58:59.776200 14 builder.go:147] stdout: ""
  I0419 15:59:00.453706 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-4875 exec execpodskmdf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.197 32024'
  E0419 15:59:00.670549      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:59:00.818295 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.197 32024\nConnection to 192.168.121.197 32024 port [tcp/*] succeeded!\n"
  I0419 15:59:00.818544 14 builder.go:147] stdout: "nodeport-test-kdwzx"
  I0419 15:59:00.819235 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-4875 exec execpodskmdf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.127 32024'
  I0419 15:59:01.127490 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.127 32024\nConnection to 192.168.121.127 32024 port [tcp/*] succeeded!\n"
  I0419 15:59:01.127581 14 builder.go:147] stdout: "nodeport-test-6dc66"
  I0419 15:59:01.127806 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4875" for this suite. @ 04/19/24 15:59:01.145
• [10.709 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance] [sig-architecture, Conformance]
k8s.io/kubernetes/test/e2e/architecture/conformance.go:39
  STEP: Creating a kubernetes client @ 04/19/24 15:59:01.165
  I0419 15:59:01.166017 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename conformance-tests @ 04/19/24 15:59:01.168
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:59:01.214
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:59:01.219
  STEP: Getting node addresses @ 04/19/24 15:59:01.225
  I0419 15:59:01.225405 14 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  I0419 15:59:01.238483 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "conformance-tests-921" for this suite. @ 04/19/24 15:59:01.247
• [0.094 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:259
  STEP: Creating a kubernetes client @ 04/19/24 15:59:01.264
  I0419 15:59:01.265174 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename aggregateddiscovery @ 04/19/24 15:59:01.269
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:59:01.299
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:59:01.303
  I0419 15:59:01.320110 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-7905" for this suite. @ 04/19/24 15:59:01.33
• [0.082 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:332
  STEP: Creating a kubernetes client @ 04/19/24 15:59:01.347
  I0419 15:59:01.347551 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename statefulset @ 04/19/24 15:59:01.35
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:59:01.396
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:59:01.402
  STEP: Creating service test in namespace statefulset-4846 @ 04/19/24 15:59:01.408
  STEP: Creating a new StatefulSet @ 04/19/24 15:59:01.429
  I0419 15:59:01.457532 14 wait.go:40] Found 0 stateful pods, waiting for 3
  E0419 15:59:01.671143      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:02.670799      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:03.670889      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:04.671203      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:05.671806      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:06.671760      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:07.672117      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:08.672779      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:09.672871      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:10.673262      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:59:11.466947 14 wait.go:50] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I0419 15:59:11.467263 14 wait.go:50] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I0419 15:59:11.467476 14 wait.go:50] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 04/19/24 15:59:11.496
  I0419 15:59:11.538359 14 statefulset.go:2241] Updating stateful set ss2
  STEP: Creating a new revision @ 04/19/24 15:59:11.539
  E0419 15:59:11.674310      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:12.674596      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:13.674932      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:14.675858      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:15.676741      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:16.677414      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:17.677503      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:18.677917      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:19.679144      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:20.680172      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Not applying an update when the partition is greater than the number of replicas @ 04/19/24 15:59:21.577
  STEP: Performing a canary update @ 04/19/24 15:59:21.577
  I0419 15:59:21.610002 14 statefulset.go:2241] Updating stateful set ss2
  I0419 15:59:21.660430 14 wait.go:74] Waiting for Pod statefulset-4846/ss2-2 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0419 15:59:21.680974      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:22.681321      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:23.682568      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:24.683466      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:25.683921      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:26.684431      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:27.685348      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:28.686366      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:29.687044      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:30.687517      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Restoring Pods to the correct revision when they are deleted @ 04/19/24 15:59:31.643
  E0419 15:59:31.688159      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:59:31.716781 14 wait.go:40] Found 1 stateful pods, waiting for 3
  E0419 15:59:32.690514      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:33.690011      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:34.695093      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:35.693385      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:36.695171      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:37.695218      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:38.696389      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:39.697176      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:40.697517      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:41.698311      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:59:41.723992 14 wait.go:50] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I0419 15:59:41.724144 14 wait.go:50] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I0419 15:59:41.724206 14 wait.go:50] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Performing a phased rolling update @ 04/19/24 15:59:41.74
  I0419 15:59:41.776067 14 statefulset.go:2241] Updating stateful set ss2
  I0419 15:59:41.810935 14 wait.go:74] Waiting for Pod statefulset-4846/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0419 15:59:42.698792      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:43.699743      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:44.700731      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:45.701203      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:46.702038      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:47.702076      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:48.702708      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:49.702902      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:50.703086      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:51.703239      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:59:51.820362 14 statefulset.go:2241] Updating stateful set ss2
  I0419 15:59:51.849874 14 wait.go:56] Waiting for StatefulSet statefulset-4846/ss2 to complete update
  I0419 15:59:51.850210 14 wait.go:63] Waiting for Pod statefulset-4846/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0419 15:59:52.703715      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:53.704565      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:54.704717      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:55.705671      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:56.706375      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:57.707319      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:58.707999      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:59.708818      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:00.709194      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:01.710202      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:00:01.834912 14 wait.go:56] Waiting for StatefulSet statefulset-4846/ss2 to complete update
  E0419 16:00:02.710530      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:03.711071      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:04.711238      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:05.711576      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:06.711694      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:07.712013      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:08.712311      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:09.712573      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:10.713460      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:11.713741      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:00:11.846339 14 statefulset.go:135] Deleting all statefulset in ns statefulset-4846
  I0419 16:00:11.857923 14 rest.go:150] Scaling statefulset ss2 to 0
  E0419 16:00:12.714763      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:13.715781      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:14.716120      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:15.716347      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:16.716588      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:17.717022      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:18.718101      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:19.718225      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:20.718482      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:21.718921      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:00:21.904321 14 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0419 16:00:21.914269 14 rest.go:88] Deleting statefulset ss2
  I0419 16:00:21.947582 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-4846" for this suite. @ 04/19/24 16:00:21.96
• [80.634 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:305
  STEP: Creating a kubernetes client @ 04/19/24 16:00:21.983
  I0419 16:00:21.983987 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename namespaces @ 04/19/24 16:00:21.989
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:00:22.021
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:00:22.025
  STEP: Read namespace status @ 04/19/24 16:00:22.031
  I0419 16:00:22.042432 14 namespace.go:318] Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
  STEP: Patch namespace status @ 04/19/24 16:00:22.043
  I0419 16:00:22.057083 14 namespace.go:338] Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
  STEP: Update namespace status @ 04/19/24 16:00:22.057
  I0419 16:00:22.079914 14 namespace.go:363] Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
  I0419 16:00:22.080134 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-3276" for this suite. @ 04/19/24 16:00:22.103
• [0.135 seconds]
------------------------------
S
------------------------------
[sig-instrumentation] Events should manage the lifecycle of an event [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/core_events.go:58
  STEP: Creating a kubernetes client @ 04/19/24 16:00:22.118
  I0419 16:00:22.118938 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename events @ 04/19/24 16:00:22.123
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:00:22.16
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:00:22.165
  STEP: creating a test event @ 04/19/24 16:00:22.172
  STEP: listing all events in all namespaces @ 04/19/24 16:00:22.183
  STEP: patching the test event @ 04/19/24 16:00:22.206
  STEP: fetching the test event @ 04/19/24 16:00:22.22
  STEP: updating the test event @ 04/19/24 16:00:22.227
  STEP: getting the test event @ 04/19/24 16:00:22.244
  STEP: deleting the test event @ 04/19/24 16:00:22.251
  STEP: listing all events in all namespaces @ 04/19/24 16:00:22.264
  I0419 16:00:22.298360 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-7310" for this suite. @ 04/19/24 16:00:22.308
• [0.204 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should delete a collection of pod templates [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:123
  STEP: Creating a kubernetes client @ 04/19/24 16:00:22.327
  I0419 16:00:22.327145 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename podtemplate @ 04/19/24 16:00:22.329
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:00:22.361
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:00:22.37
  STEP: Create set of pod templates @ 04/19/24 16:00:22.375
  I0419 16:00:22.389043 14 podtemplates.go:143] created test-podtemplate-1
  I0419 16:00:22.400193 14 podtemplates.go:143] created test-podtemplate-2
  I0419 16:00:22.408596 14 podtemplates.go:143] created test-podtemplate-3
  STEP: get a list of pod templates with a label in the current namespace @ 04/19/24 16:00:22.409
  STEP: delete collection of pod templates @ 04/19/24 16:00:22.427
  I0419 16:00:22.427510 14 podtemplates.go:158] requesting DeleteCollection of pod templates
  STEP: check that the list of pod templates matches the requested quantity @ 04/19/24 16:00:22.463
  I0419 16:00:22.463782 14 podtemplates.go:219] requesting list of pod templates to confirm quantity
  I0419 16:00:22.471327 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-4507" for this suite. @ 04/19/24 16:00:22.483
• [0.171 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:125
  STEP: Creating a kubernetes client @ 04/19/24 16:00:22.499
  I0419 16:00:22.499896 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename secrets @ 04/19/24 16:00:22.507
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:00:22.545
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:00:22.55
  STEP: Creating secret with name secret-test-6e2daad7-1f6a-4784-9850-5f402ca91055 @ 04/19/24 16:00:22.558
  STEP: Creating a pod to test consume secrets @ 04/19/24 16:00:22.567
  E0419 16:00:22.719934      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:23.720782      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:24.720834      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:25.721506      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:00:26.616
  I0419 16:00:26.629534 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-secrets-6584c5e9-5e64-4cab-86a7-09acf7f2bf36 container secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/24 16:00:26.665
  I0419 16:00:26.703793 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8377" for this suite. @ 04/19/24 16:00:26.719
  E0419 16:00:26.721422      14 retrywatcher.go:129] "Watch failed" err="context canceled"
• [4.240 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:164
  STEP: Creating a kubernetes client @ 04/19/24 16:00:26.743
  I0419 16:00:26.743312 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename projected @ 04/19/24 16:00:26.747
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:00:26.798
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:00:26.806
  STEP: Creating the pod @ 04/19/24 16:00:26.816
  E0419 16:00:27.721492      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:28.721914      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:00:29.441906 14 pod_client.go:141] Successfully updated pod "annotationupdate10e3abbe-b8af-4154-8f0b-e2cf51c5b685"
  E0419 16:00:29.723054      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:30.723869      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:31.725332      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:32.725894      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:00:33.510337 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9216" for this suite. @ 04/19/24 16:00:33.525
• [6.798 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should release no longer matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:104
  STEP: Creating a kubernetes client @ 04/19/24 16:00:33.542
  I0419 16:00:33.542739 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename replication-controller @ 04/19/24 16:00:33.553
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:00:33.613
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:00:33.624
  STEP: Given a ReplicationController is created @ 04/19/24 16:00:33.634
  STEP: When the matched label of one of its pods change @ 04/19/24 16:00:33.647
  I0419 16:00:33.654993 14 resource.go:87] Pod name pod-release: Found 0 pods out of 1
  E0419 16:00:33.726685      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:34.727268      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:35.728002      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:36.728325      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:37.728472      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:00:38.666102 14 resource.go:87] Pod name pod-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 04/19/24 16:00:38.697
  E0419 16:00:38.728439      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:00:39.726332 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0419 16:00:39.728766      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "replication-controller-1623" for this suite. @ 04/19/24 16:00:39.741
• [6.218 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:199
  STEP: Creating a kubernetes client @ 04/19/24 16:00:39.761
  I0419 16:00:39.761868 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename container-probe @ 04/19/24 16:00:39.764
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:00:39.821
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:00:39.84
  STEP: Creating pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367 @ 04/19/24 16:00:39.848
  E0419 16:00:40.729765      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:41.730263      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/19/24 16:00:41.887
  I0419 16:00:41.903305 14 container_probe.go:1749] Initial restart count of pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 is 0
  I0419 16:00:41.917665 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:00:42.730057      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:43.730437      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:00:43.931180 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:00:44.730922      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:45.730704      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:00:45.947704 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:00:46.731329      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:47.731607      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:00:47.961741 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:00:48.731810      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:49.732545      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:00:49.985442 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:00:50.733129      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:51.733460      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:00:51.993897 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:00:52.733615      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:53.733837      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:00:54.003361 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:00:54.734416      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:55.734668      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:00:56.014259 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:00:56.735004      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:57.735246      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:00:58.022170 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:00:58.735416      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:59.736253      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:01:00.034955 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:01:00.737581      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:01.743348      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:01:02.045564 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  I0419 16:01:02.045702 14 container_probe.go:1763] Restart count of pod container-probe-9367/liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 is now 1 (20.141751091s elapsed)
  E0419 16:01:02.743413      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:03.743659      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:01:04.055619 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:01:04.743757      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:05.744132      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:01:06.063313 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:01:06.744252      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:07.744547      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:01:08.072393 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:01:08.745366      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:09.745986      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:01:10.083737 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:01:10.747049      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:11.747545      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:01:12.094965 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:01:12.747500      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:13.749539      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:01:14.102417 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:01:14.748867      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:15.749287      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:01:16.123699 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:01:16.749567      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:17.750883      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:01:18.132720 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:01:18.750839      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:19.751582      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:01:20.145402 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:01:20.753563      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:21.760469      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:01:22.162079 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  I0419 16:01:22.162265 14 container_probe.go:1763] Restart count of pod container-probe-9367/liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 is now 2 (40.258311713s elapsed)
  E0419 16:01:22.759706      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:23.761472      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:01:24.172403 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:01:24.760466      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:25.762369      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:01:26.181927 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:01:26.761992      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:27.762485      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:01:28.194075 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:01:28.763490      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:29.765333      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:01:30.206693 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:01:30.764465      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:31.765660      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:01:32.219652 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:01:32.765752      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:33.766088      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:01:34.226942 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:01:34.766454      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:35.767436      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:01:36.238867 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:01:36.767933      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:37.768142      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:01:38.248408 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:01:38.768451      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:39.768812      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:01:40.259112 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:01:40.769369      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:41.769684      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:01:42.267638 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  I0419 16:01:42.267740 14 container_probe.go:1763] Restart count of pod container-probe-9367/liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 is now 3 (1m0.363779096s elapsed)
  E0419 16:01:42.770219      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:43.770892      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:01:44.278276 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:01:44.771865      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:45.773054      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:01:46.285837 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:01:46.773567      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:47.773919      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:01:48.297473 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:01:48.774326      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:49.775275      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:01:50.306179 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:01:50.775557      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:51.775992      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:01:52.321190 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:01:52.776131      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:53.777241      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:01:54.330440 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:01:54.778454      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:55.778700      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:01:56.342875 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:01:56.779686      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:57.780942      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:01:58.350600 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:01:58.782063      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:59.782012      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:02:00.356602 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:02:00.782294      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:01.782535      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:02:02.364379 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  I0419 16:02:02.364466 14 container_probe.go:1763] Restart count of pod container-probe-9367/liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 is now 4 (1m20.460526345s elapsed)
  E0419 16:02:02.783468      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:03.783822      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:02:04.373685 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:02:04.783972      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:05.784494      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:02:06.384484 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:02:06.785068      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:07.785733      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:02:08.394496 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:02:08.787837      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:09.787848      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:02:10.401032 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:02:10.788196      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:11.789154      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:02:12.412613 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:02:12.789320      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:13.790282      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:02:14.424218 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:02:14.790553      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:15.790629      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:02:16.432769 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:02:16.791432      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:17.791804      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:02:18.443928 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:02:18.792198      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:19.792470      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:02:20.456305 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:02:20.794393      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:21.794621      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:02:22.465314 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:02:22.794832      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:23.794847      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:02:24.476704 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:02:24.795109      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:25.795925      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:02:26.485545 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:02:26.796580      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:27.796766      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:02:28.495273 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:02:28.797586      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:29.798350      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:02:30.503145 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:02:30.801205      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:31.801523      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:02:32.514358 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:02:32.802276      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:33.802644      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:02:34.520855 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:02:34.802747      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:35.803109      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:02:36.530310 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:02:36.803821      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:37.805017      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:02:38.543396 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:02:38.805791      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:39.805928      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:02:40.553672 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:02:40.806103      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:41.806358      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:02:42.562576 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:02:42.806926      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:43.807716      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:02:44.589777 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:02:44.807880      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:45.808194      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:02:46.597104 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:02:46.808656      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:47.809183      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:02:48.608969 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:02:48.809935      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:49.810106      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:02:50.618795 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:02:50.810852      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:51.811911      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:02:52.631076 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:02:52.812140      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:53.813341      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:02:54.640035 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:02:54.814440      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:55.814291      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:02:56.650991 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:02:56.814684      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:57.814977      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:02:58.662118 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:02:58.815951      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:59.816780      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:03:00.674312 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:03:00.817342      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:01.818451      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:03:02.683556 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:03:02.819399      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:03.819629      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:03:04.693995 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:03:04.820727      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:05.821454      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:03:06.703988 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  E0419 16:03:06.821531      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:07.822170      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:03:08.716338 14 container_probe.go:1759] Get pod liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 in namespace container-probe-9367
  I0419 16:03:08.716612 14 container_probe.go:1763] Restart count of pod container-probe-9367/liveness-8637d073-96b6-47fc-b3a8-2c59e676e509 is now 5 (2m26.812663414s elapsed)
  STEP: deleting the pod @ 04/19/24 16:03:08.718
  I0419 16:03:08.753538 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-9367" for this suite. @ 04/19/24 16:03:08.768
• [149.024 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should fail to create secret due to empty secret key [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:142
  STEP: Creating a kubernetes client @ 04/19/24 16:03:08.79
  I0419 16:03:08.790988 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename secrets @ 04/19/24 16:03:08.797
  E0419 16:03:08.822166      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:03:08.858
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:03:08.869
  STEP: Creating projection with secret that has name secret-emptykey-test-08c3e20e-f2df-4d38-a428-0b9295569a16 @ 04/19/24 16:03:08.879
  I0419 16:03:08.883945 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-5364" for this suite. @ 04/19/24 16:03:08.894
• [0.149 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:51
  STEP: Creating a kubernetes client @ 04/19/24 16:03:08.942
  I0419 16:03:08.942792 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename crd-watch @ 04/19/24 16:03:08.946
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:03:08.972
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:03:08.98
  I0419 16:03:08.985777 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  E0419 16:03:09.822950      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:10.824092      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating first CR  @ 04/19/24 16:03:11.695
  I0419 16:03:11.706983 14 watch.go:431] Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-19T16:03:11Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-19T16:03:11Z]] name:name1 resourceVersion:10555 uid:08cd8360-8e38-422d-9d8e-abe95a1deca7] num:map[num1:9223372036854775807 num2:1000000]]}
  E0419 16:03:11.824818      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:12.825493      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:13.825547      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:14.825789      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:15.826841      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:16.827079      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:17.828358      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:18.828500      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:19.829634      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:20.830534      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating second CR @ 04/19/24 16:03:21.707
  I0419 16:03:21.723944 14 watch.go:431] Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-19T16:03:21Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-19T16:03:21Z]] name:name2 resourceVersion:10587 uid:d1919120-35aa-47df-8aad-43f9f083b130] num:map[num1:9223372036854775807 num2:1000000]]}
  E0419 16:03:21.831303      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:22.833012      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:23.832731      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:24.833350      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:25.834290      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:26.834453      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:27.835379      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:28.835766      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:29.836086      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:30.836390      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Modifying first CR @ 04/19/24 16:03:31.724
  I0419 16:03:31.741361 14 watch.go:431] Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-19T16:03:11Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-19T16:03:31Z]] name:name1 resourceVersion:10605 uid:08cd8360-8e38-422d-9d8e-abe95a1deca7] num:map[num1:9223372036854775807 num2:1000000]]}
  E0419 16:03:31.836529      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:32.837370      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:33.837679      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:34.838067      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:35.838374      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:36.838465      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:37.838856      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:38.839110      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:39.839546      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:40.840395      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Modifying second CR @ 04/19/24 16:03:41.741
  I0419 16:03:41.760586 14 watch.go:431] Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-19T16:03:21Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-19T16:03:41Z]] name:name2 resourceVersion:10622 uid:d1919120-35aa-47df-8aad-43f9f083b130] num:map[num1:9223372036854775807 num2:1000000]]}
  E0419 16:03:41.840945      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:42.841149      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:43.842193      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:44.842400      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:45.842732      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:46.843214      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:47.843493      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:48.844360      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:49.844355      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:50.845325      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting first CR @ 04/19/24 16:03:51.761
  I0419 16:03:51.786110 14 watch.go:431] Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-19T16:03:11Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-19T16:03:31Z]] name:name1 resourceVersion:10640 uid:08cd8360-8e38-422d-9d8e-abe95a1deca7] num:map[num1:9223372036854775807 num2:1000000]]}
  E0419 16:03:51.846388      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:52.846578      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:53.846900      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:54.847298      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:55.847606      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:56.848767      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:57.849014      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:58.849077      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:59.849540      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:00.849733      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting second CR @ 04/19/24 16:04:01.786
  I0419 16:04:01.810270 14 watch.go:431] Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-19T16:03:21Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-19T16:03:41Z]] name:name2 resourceVersion:10658 uid:d1919120-35aa-47df-8aad-43f9f083b130] num:map[num1:9223372036854775807 num2:1000000]]}
  E0419 16:04:01.849880      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:02.850035      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:03.850844      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:04.851123      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:05.851504      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:06.851597      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:07.851921      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:08.852201      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:09.852529      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:10.852829      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:11.853622      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:04:12.367867 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-watch-294" for this suite. @ 04/19/24 16:04:12.39
• [63.473 seconds]
------------------------------
S
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:612
  STEP: Creating a kubernetes client @ 04/19/24 16:04:12.416
  I0419 16:04:12.416630 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename security-context-test @ 04/19/24 16:04:12.42
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:04:12.469
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:04:12.474
  E0419 16:04:12.854656      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:13.855213      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:14.855182      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:15.856331      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:16.856654      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:17.857613      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:18.858190      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:19.858807      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:04:20.611709 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-3325" for this suite. @ 04/19/24 16:04:20.626
• [8.229 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should delete a collection of pods [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:846
  STEP: Creating a kubernetes client @ 04/19/24 16:04:20.655
  I0419 16:04:20.656115 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename pods @ 04/19/24 16:04:20.662
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:04:20.701
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:04:20.708
  STEP: Create set of pods @ 04/19/24 16:04:20.716
  I0419 16:04:20.740837 14 pods.go:871] created test-pod-1
  I0419 16:04:20.759201 14 pods.go:871] created test-pod-2
  I0419 16:04:20.780198 14 pods.go:871] created test-pod-3
  STEP: waiting for all 3 pods to be running @ 04/19/24 16:04:20.781
  E0419 16:04:20.859846      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:21.860585      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:22.861470      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:23.862546      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:24.862725      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting for all pods to be deleted @ 04/19/24 16:04:24.951
  I0419 16:04:24.958000 14 pods.go:1140] Pod quantity 3 is different from expected quantity 0
  E0419 16:04:25.862883      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:04:25.963639 14 pods.go:1140] Pod quantity 2 is different from expected quantity 0
  E0419 16:04:26.863565      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:04:26.964020 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-9678" for this suite. @ 04/19/24 16:04:26.975
• [6.337 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:199
  STEP: Creating a kubernetes client @ 04/19/24 16:04:26.992
  I0419 16:04:26.992856 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/19/24 16:04:27
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:04:27.048
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:04:27.054
  STEP: fetching the /apis discovery document @ 04/19/24 16:04:27.06
  STEP: finding the apiextensions.k8s.io API group in the /apis discovery document @ 04/19/24 16:04:27.063
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document @ 04/19/24 16:04:27.063
  STEP: fetching the /apis/apiextensions.k8s.io discovery document @ 04/19/24 16:04:27.063
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document @ 04/19/24 16:04:27.065
  STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document @ 04/19/24 16:04:27.066
  STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document @ 04/19/24 16:04:27.069
  I0419 16:04:27.069529 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-1802" for this suite. @ 04/19/24 16:04:27.082
• [0.103 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:96
  STEP: Creating a kubernetes client @ 04/19/24 16:04:27.096
  I0419 16:04:27.096790 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename pod-network-test @ 04/19/24 16:04:27.099
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:04:27.13
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:04:27.136
  STEP: Performing setup for networking test in namespace pod-network-test-7177 @ 04/19/24 16:04:27.144
  STEP: creating a selector @ 04/19/24 16:04:27.144
  STEP: Creating the service pods in kubernetes @ 04/19/24 16:04:27.145
  I0419 16:04:27.145230 14 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0419 16:04:27.863842      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:28.864946      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:29.865958      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:30.866699      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:31.867286      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:32.867575      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:33.867987      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:34.868251      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:35.869009      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:36.870144      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:37.870336      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:38.870577      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 04/19/24 16:04:39.34
  E0419 16:04:39.870651      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:40.871562      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:04:41.379343 14 utils.go:779] Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  I0419 16:04:41.379448 14 networking.go:42] Breadth first check of 10.233.64.50 on host 192.168.121.38...
  I0419 16:04:41.388252 14 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.109:9080/dial?request=hostname&protocol=udp&host=10.233.64.50&port=8081&tries=1'] Namespace:pod-network-test-7177 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0419 16:04:41.388652 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 16:04:41.391316 14 exec_util.go:62] ExecWithOptions: Clientset creation
  I0419 16:04:41.391885 14 exec_util.go:79] ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-7177/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.109%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.64.50%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I0419 16:04:41.571881 14 utils.go:331] Waiting for responses: map[]
  I0419 16:04:41.571967 14 utils.go:335] reached 10.233.64.50 after 0/1 tries
  I0419 16:04:41.572295 14 networking.go:42] Breadth first check of 10.233.65.42 on host 192.168.121.197...
  I0419 16:04:41.578175 14 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.109:9080/dial?request=hostname&protocol=udp&host=10.233.65.42&port=8081&tries=1'] Namespace:pod-network-test-7177 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0419 16:04:41.578231 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 16:04:41.581123 14 exec_util.go:62] ExecWithOptions: Clientset creation
  I0419 16:04:41.581586 14 exec_util.go:79] ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-7177/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.109%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.65.42%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I0419 16:04:41.686188 14 utils.go:331] Waiting for responses: map[]
  I0419 16:04:41.686348 14 utils.go:335] reached 10.233.65.42 after 0/1 tries
  I0419 16:04:41.686374 14 networking.go:42] Breadth first check of 10.233.66.108 on host 192.168.121.127...
  I0419 16:04:41.695861 14 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.109:9080/dial?request=hostname&protocol=udp&host=10.233.66.108&port=8081&tries=1'] Namespace:pod-network-test-7177 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0419 16:04:41.695922 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 16:04:41.697608 14 exec_util.go:62] ExecWithOptions: Clientset creation
  I0419 16:04:41.697747 14 exec_util.go:79] ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-7177/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.109%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.66.108%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I0419 16:04:41.804708 14 utils.go:331] Waiting for responses: map[]
  I0419 16:04:41.804784 14 utils.go:335] reached 10.233.66.108 after 0/1 tries
  I0419 16:04:41.804807 14 networking.go:53] Going to retry 0 out of 3 pods....
  I0419 16:04:41.805032 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-7177" for this suite. @ 04/19/24 16:04:41.814
• [14.733 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:531
  STEP: Creating a kubernetes client @ 04/19/24 16:04:41.84
  I0419 16:04:41.840399 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename security-context-test @ 04/19/24 16:04:41.843
  E0419 16:04:41.871993      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:04:41.883
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:04:41.889
  E0419 16:04:42.873216      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:43.874267      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:44.874749      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:45.874973      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:04:45.963979 14 security_context.go:538] Got logs for pod "busybox-privileged-false-c8a404e0-f5ff-4d8b-9daf-f48502819c90": "ip: RTNETLINK answers: Operation not permitted\n"
  I0419 16:04:45.965061 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-2164" for this suite. @ 04/19/24 16:04:45.979
• [4.156 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/persistent_volumes.go:430
  STEP: Creating a kubernetes client @ 04/19/24 16:04:46.005
  I0419 16:04:46.005917 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename pv @ 04/19/24 16:04:46.011
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:04:46.067
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:04:46.077
  STEP: Creating initial PV and PVC @ 04/19/24 16:04:46.084
  I0419 16:04:46.084951 14 pv.go:390] Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-2861" @ 04/19/24 16:04:46.125
  STEP: Listing PVCs in namespace "pv-2861" @ 04/19/24 16:04:46.138
  STEP: Patching the PV "pv-2861-cx6bl" @ 04/19/24 16:04:46.149
  STEP: Patching the PVC "pvc-bm9vn" @ 04/19/24 16:04:46.173
  STEP: Getting PV "pv-2861-cx6bl" @ 04/19/24 16:04:46.19
  STEP: Getting PVC "pvc-bm9vn" @ 04/19/24 16:04:46.202
  STEP: Deleting PVC "pvc-bm9vn" @ 04/19/24 16:04:46.213
  STEP: Confirm deletion of PVC "pvc-bm9vn" @ 04/19/24 16:04:46.247
  E0419 16:04:46.875664      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:47.876469      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting PV "pv-2861-cx6bl" @ 04/19/24 16:04:48.264
  STEP: Confirm deletion of PV "pv-2861-cx6bl" @ 04/19/24 16:04:48.285
  E0419 16:04:48.876755      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:49.876827      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating another PV & PVC @ 04/19/24 16:04:50.309
  I0419 16:04:50.309572 14 pv.go:390] Creating a PV followed by a PVC
  STEP: Updating the PV "pv-2861-xqj5h" @ 04/19/24 16:04:50.344
  STEP: Updating the PVC "pvc-twhhz" @ 04/19/24 16:04:50.411
  STEP: Listing PVCs in all namespaces with the labelSelector: "pvc-twhhz=updated" @ 04/19/24 16:04:50.432
  STEP: Deleting PVC "pvc-twhhz" via DeleteCollection @ 04/19/24 16:04:50.441
  STEP: Confirm deletion of PVC "pvc-twhhz" @ 04/19/24 16:04:50.46
  E0419 16:04:50.877242      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:51.877970      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting PV "pv-2861-xqj5h" via DeleteCollection @ 04/19/24 16:04:52.481
  STEP: Confirm deletion of PV "pv-2861-xqj5h" @ 04/19/24 16:04:52.498
  E0419 16:04:52.881567      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:53.881777      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:04:54.517929 14 persistent_volumes.go:407] AfterEach: deleting 1 PVCs and 1 PVs...
  I0419 16:04:54.518069 14 pv.go:201] Deleting PersistentVolumeClaim "pvc-twhhz"
  I0419 16:04:54.528514 14 pv.go:189] Deleting PersistentVolume "pv-2861-xqj5h"
  I0419 16:04:54.541853 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-2861" for this suite. @ 04/19/24 16:04:54.56
• [8.576 seconds]
------------------------------
[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:41
  STEP: Creating a kubernetes client @ 04/19/24 16:04:54.582
  I0419 16:04:54.582522 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename containers @ 04/19/24 16:04:54.587
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:04:54.635
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:04:54.641
  E0419 16:04:54.882682      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:55.882484      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:04:56.716728 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-8686" for this suite. @ 04/19/24 16:04:56.726
• [2.172 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:902
  STEP: Creating a kubernetes client @ 04/19/24 16:04:56.757
  I0419 16:04:56.757528 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename statefulset @ 04/19/24 16:04:56.761
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:04:56.79
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:04:56.795
  STEP: Creating service test in namespace statefulset-3773 @ 04/19/24 16:04:56.802
  STEP: Creating statefulset ss in namespace statefulset-3773 @ 04/19/24 16:04:56.813
  I0419 16:04:56.838492 14 wait.go:40] Found 0 stateful pods, waiting for 1
  E0419 16:04:56.883035      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:57.883593      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:58.883820      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:59.884562      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:00.884001      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:01.884300      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:02.884712      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:03.885046      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:04.885191      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:05.886799      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:05:06.847431 14 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: getting scale subresource @ 04/19/24 16:05:06.869
  STEP: updating a scale subresource @ 04/19/24 16:05:06.878
  E0419 16:05:06.887019      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the statefulset Spec.Replicas was modified @ 04/19/24 16:05:06.895
  STEP: Patch a scale subresource @ 04/19/24 16:05:06.908
  STEP: verifying the statefulset Spec.Replicas was modified @ 04/19/24 16:05:06.939
  I0419 16:05:06.962806 14 statefulset.go:135] Deleting all statefulset in ns statefulset-3773
  I0419 16:05:06.982047 14 rest.go:150] Scaling statefulset ss to 0
  E0419 16:05:07.885903      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:08.886193      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:09.887402      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:10.887483      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:11.887667      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:12.888475      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:13.888590      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:14.889031      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:15.889105      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:16.889778      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:05:17.042829 14 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0419 16:05:17.051560 14 rest.go:88] Deleting statefulset ss
  I0419 16:05:17.073067 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-3773" for this suite. @ 04/19/24 16:05:17.084
• [20.339 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:241
  STEP: Creating a kubernetes client @ 04/19/24 16:05:17.098
  I0419 16:05:17.098683 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename configmap @ 04/19/24 16:05:17.101
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:05:17.127
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:05:17.133
  STEP: Creating configMap with name cm-test-opt-del-c90f03e7-9027-4bfa-b75c-9c6a9b38baab @ 04/19/24 16:05:17.15
  STEP: Creating configMap with name cm-test-opt-upd-5d232e7f-59e0-4a02-a40a-958c09edfa77 @ 04/19/24 16:05:17.157
  STEP: Creating the pod @ 04/19/24 16:05:17.164
  E0419 16:05:17.890287      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:18.891443      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:19.892483      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:20.893802      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-c90f03e7-9027-4bfa-b75c-9c6a9b38baab @ 04/19/24 16:05:21.263
  STEP: Updating configmap cm-test-opt-upd-5d232e7f-59e0-4a02-a40a-958c09edfa77 @ 04/19/24 16:05:21.282
  STEP: Creating configMap with name cm-test-opt-create-4e2e603e-6265-44cf-bc86-1d64233231a5 @ 04/19/24 16:05:21.295
  STEP: waiting to observe update in volume @ 04/19/24 16:05:21.305
  E0419 16:05:21.893873      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:22.894108      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:23.895218      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:24.895462      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:25.896576      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:26.897808      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:27.898308      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:28.898679      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:29.899635      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:30.900013      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:31.900067      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:32.900310      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:33.901506      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:34.901808      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:35.901940      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:36.902612      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:37.902856      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:38.903268      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:39.903874      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:40.904355      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:41.905127      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:42.905530      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:43.906244      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:44.906929      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:45.907669      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:46.908365      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:47.908825      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:48.909096      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:49.909350      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:50.910561      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:51.911094      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:52.911895      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:53.912646      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:54.913018      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:55.913726      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:56.914863      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:57.915751      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:58.915901      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:59.916988      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:00.917332      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:01.918276      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:02.918642      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:03.918687      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:04.919313      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:05.919375      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:06.920457      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:07.920759      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:08.921291      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:09.921928      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:10.922847      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:11.923354      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:12.923741      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:13.924234      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:14.924851      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:15.925069      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:16.925223      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:17.926088      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:18.927230      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:19.927321      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:20.927637      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:21.928715      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:22.929067      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:23.929288      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:24.930309      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:25.931266      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:26.931812      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:27.931982      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:28.932599      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:29.933012      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:30.933277      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:31.933420      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:32.933976      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:33.934233      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:34.934583      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:35.934699      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:36.935241      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:37.936272      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:38.936519      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:39.936950      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:06:40.220091 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3534" for this suite. @ 04/19/24 16:06:40.232
• [83.147 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/persistent_volumes.go:669
  STEP: Creating a kubernetes client @ 04/19/24 16:06:40.248
  I0419 16:06:40.248346 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename pv @ 04/19/24 16:06:40.252
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:06:40.279
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:06:40.285
  STEP: Creating initial PV and PVC @ 04/19/24 16:06:40.292
  I0419 16:06:40.293110 14 pv.go:390] Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-1557" @ 04/19/24 16:06:40.318
  STEP: Listing PVCs in namespace "pv-1557" @ 04/19/24 16:06:40.323
  STEP: Reading "pvc-mps8d" Status @ 04/19/24 16:06:40.329
  STEP: Reading "pv-1557-7jn6t" Status @ 04/19/24 16:06:40.339
  STEP: Patching "pvc-mps8d" Status @ 04/19/24 16:06:40.35
  STEP: Patching "pv-1557-7jn6t" Status @ 04/19/24 16:06:40.37
  STEP: Updating "pvc-mps8d" Status @ 04/19/24 16:06:40.382
  STEP: Updating "pv-1557-7jn6t" Status @ 04/19/24 16:06:40.4
  I0419 16:06:40.414027 14 persistent_volumes.go:407] AfterEach: deleting 1 PVCs and 1 PVs...
  I0419 16:06:40.414436 14 pv.go:201] Deleting PersistentVolumeClaim "pvc-mps8d"
  I0419 16:06:40.425391 14 pv.go:189] Deleting PersistentVolume "pv-1557-7jn6t"
  I0419 16:06:40.438730 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-1557" for this suite. @ 04/19/24 16:06:40.449
• [0.215 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:403
  STEP: Creating a kubernetes client @ 04/19/24 16:06:40.464
  I0419 16:06:40.464280 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename webhook @ 04/19/24 16:06:40.467
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:06:40.496
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:06:40.501
  STEP: Setting up server cert @ 04/19/24 16:06:40.55
  E0419 16:06:40.937751      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 16:06:41.299
  STEP: Deploying the webhook pod @ 04/19/24 16:06:41.318
  STEP: Wait for the deployment to be ready @ 04/19/24 16:06:41.338
  I0419 16:06:41.362736 14 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0419 16:06:41.938992      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:42.939220      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 16:06:43.389
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 16:06:43.419
  E0419 16:06:43.939332      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:06:44.420440 14 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a validating webhook configuration @ 04/19/24 16:06:44.446
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/19/24 16:06:44.493
  STEP: Updating a validating webhook configuration's rules to not include the create operation @ 04/19/24 16:06:44.514
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/19/24 16:06:44.541
  STEP: Patching a validating webhook configuration's rules to include the create operation @ 04/19/24 16:06:44.571
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/19/24 16:06:44.592
  I0419 16:06:44.698121 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6023" for this suite. @ 04/19/24 16:06:44.708
  STEP: Destroying namespace "webhook-markers-966" for this suite. @ 04/19/24 16:06:44.719
• [4.275 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:108
  STEP: Creating a kubernetes client @ 04/19/24 16:06:44.748
  I0419 16:06:44.748520 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename container-probe @ 04/19/24 16:06:44.752
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:06:44.777
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:06:44.783
  E0419 16:06:44.939877      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:45.940316      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:46.941089      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:47.941671      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:48.942108      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:49.942262      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:50.943486      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:51.944823      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:52.944187      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:53.944989      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:54.945265      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:55.946280      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:56.953033      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:57.952679      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:58.953364      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:59.953568      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:00.953836      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:01.954785      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:02.954960      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:03.955420      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:04.955662      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:05.956317      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:06.959750      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:07.957755      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:08.957570      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:09.957859      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:10.958163      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:11.958563      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:12.958984      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:13.959678      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:14.959671      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:15.959869      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:16.959975      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:17.960265      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:18.961156      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:19.961534      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:20.962072      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:21.962838      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:22.963503      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:23.963439      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:24.963957      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:25.964365      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:26.964491      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:27.964680      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:28.965028      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:29.965653      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:30.966939      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:31.966298      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:32.966750      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:33.966970      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:34.967686      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:35.968405      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:36.968457      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:37.969635      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:38.969326      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:39.970324      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:40.971274      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:41.972505      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:42.972976      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:43.972773      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:07:44.817334 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-6303" for this suite. @ 04/19/24 16:07:44.836
• [60.122 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:301
  STEP: Creating a kubernetes client @ 04/19/24 16:07:44.875
  I0419 16:07:44.875685 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename var-expansion @ 04/19/24 16:07:44.883
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:07:44.947
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:07:44.952
  STEP: creating the pod @ 04/19/24 16:07:44.961
  E0419 16:07:44.973474      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting for pod running @ 04/19/24 16:07:44.977
  E0419 16:07:45.974198      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:46.974905      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating a file in subpath @ 04/19/24 16:07:46.998
  I0419 16:07:47.009512 14 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-6827 PodName:var-expansion-19145a87-1611-4db8-8d94-9219ab918039 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0419 16:07:47.010746 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 16:07:47.014543 14 exec_util.go:62] ExecWithOptions: Clientset creation
  I0419 16:07:47.014775 14 exec_util.go:79] ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/var-expansion-6827/pods/var-expansion-19145a87-1611-4db8-8d94-9219ab918039/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: test for file in mounted path @ 04/19/24 16:07:47.19
  I0419 16:07:47.201793 14 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-6827 PodName:var-expansion-19145a87-1611-4db8-8d94-9219ab918039 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0419 16:07:47.201904 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 16:07:47.205172 14 exec_util.go:62] ExecWithOptions: Clientset creation
  I0419 16:07:47.205442 14 exec_util.go:79] ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/var-expansion-6827/pods/var-expansion-19145a87-1611-4db8-8d94-9219ab918039/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: updating the annotation value @ 04/19/24 16:07:47.338
  I0419 16:07:47.903947 14 pod_client.go:141] Successfully updated pod "var-expansion-19145a87-1611-4db8-8d94-9219ab918039"
  STEP: waiting for annotated pod running @ 04/19/24 16:07:47.904
  STEP: deleting the pod gracefully @ 04/19/24 16:07:47.912
  I0419 16:07:47.912444 14 delete.go:62] Deleting pod "var-expansion-19145a87-1611-4db8-8d94-9219ab918039" in namespace "var-expansion-6827"
  I0419 16:07:47.927738 14 delete.go:70] Wait up to 5m0s for pod "var-expansion-19145a87-1611-4db8-8d94-9219ab918039" to be fully deleted
  E0419 16:07:47.975294      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:48.976069      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:49.976651      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:50.977410      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:51.977346      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:52.978307      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:53.979249      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:54.979774      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:55.979675      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:56.979987      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:57.980743      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:58.981071      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:59.981095      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:00.981309      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:01.983771      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:02.983494      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:03.983942      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:04.984161      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:05.984299      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:06.984997      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:07.985169      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:08.985530      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:09.986725      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:10.987145      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:11.988597      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:12.988831      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:13.989326      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:14.989360      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:15.989450      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:16.989534      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:17.989709      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:18.989977      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:19.990100      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:08:20.120447 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-6827" for this suite. @ 04/19/24 16:08:20.132
• [35.273 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:572
  STEP: Creating a kubernetes client @ 04/19/24 16:08:20.152
  I0419 16:08:20.152210 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename webhook @ 04/19/24 16:08:20.157
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:08:20.209
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:08:20.218
  STEP: Setting up server cert @ 04/19/24 16:08:20.273
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 16:08:20.809
  STEP: Deploying the webhook pod @ 04/19/24 16:08:20.834
  STEP: Wait for the deployment to be ready @ 04/19/24 16:08:20.875
  I0419 16:08:20.895697 14 deployment.go:222] new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0419 16:08:20.991427      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:21.991848      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 16:08:22.925
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 16:08:22.964
  E0419 16:08:22.992427      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:08:23.964515 14 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  E0419 16:08:23.992631      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Listing all of the created validation webhooks @ 04/19/24 16:08:24.088
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/19/24 16:08:24.16
  STEP: Deleting the collection of validation webhooks @ 04/19/24 16:08:24.21
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/19/24 16:08:24.294
  I0419 16:08:24.543290 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4628" for this suite. @ 04/19/24 16:08:24.555
  STEP: Destroying namespace "webhook-markers-39" for this suite. @ 04/19/24 16:08:24.566
• [4.425 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:232
  STEP: Creating a kubernetes client @ 04/19/24 16:08:24.579
  I0419 16:08:24.579826 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename container-runtime @ 04/19/24 16:08:24.583
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:08:24.612
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:08:24.618
  STEP: create the container @ 04/19/24 16:08:24.624
  W0419 16:08:24.639925      14 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 04/19/24 16:08:24.64
  E0419 16:08:24.992796      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:25.993429      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:26.993974      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 04/19/24 16:08:27.675
  STEP: the container should be terminated @ 04/19/24 16:08:27.684
  STEP: the termination message should be set @ 04/19/24 16:08:27.685
  I0419 16:08:27.686761 14 runtime.go:167] Expected: &{} to match Container's Termination Message:  --
  STEP: delete the container @ 04/19/24 16:08:27.688
  I0419 16:08:27.727146 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-5786" for this suite. @ 04/19/24 16:08:27.74
• [3.181 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:88
  STEP: Creating a kubernetes client @ 04/19/24 16:08:27.763
  I0419 16:08:27.763696 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename projected @ 04/19/24 16:08:27.769
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:08:27.835
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:08:27.845
  STEP: Creating projection with secret that has name projected-secret-test-map-bd512644-5d8b-40e6-a8ba-cdf5033d24ff @ 04/19/24 16:08:27.85
  STEP: Creating a pod to test consume secrets @ 04/19/24 16:08:27.859
  E0419 16:08:27.993896      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:28.994963      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:29.995091      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:30.995405      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:08:31.927
  I0419 16:08:31.935651 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-projected-secrets-bbe9b943-cf80-41e2-8ddb-f5ffc44fa911 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/24 16:08:31.967
  E0419 16:08:31.995996      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:08:32.002858 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4818" for this suite. @ 04/19/24 16:08:32.011
• [4.264 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:97
  STEP: Creating a kubernetes client @ 04/19/24 16:08:32.031
  I0419 16:08:32.031050 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename secrets @ 04/19/24 16:08:32.033
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:08:32.07
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:08:32.074
  STEP: creating secret secrets-3230/secret-test-48d53127-291d-4314-ba87-efa0f06cc241 @ 04/19/24 16:08:32.078
  STEP: Creating a pod to test consume secrets @ 04/19/24 16:08:32.089
  E0419 16:08:32.996463      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:33.996739      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:34.997343      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:35.997487      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:08:36.128
  I0419 16:08:36.137831 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-configmaps-3cedbeec-6384-4634-a5e9-6be1c605b3c2 container env-test: <nil>
  STEP: delete the pod @ 04/19/24 16:08:36.153
  I0419 16:08:36.183315 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3230" for this suite. @ 04/19/24 16:08:36.19
• [4.172 seconds]
------------------------------
SS
------------------------------
[sig-apps] ReplicationController should adopt matching pods on creation [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:95
  STEP: Creating a kubernetes client @ 04/19/24 16:08:36.204
  I0419 16:08:36.204912 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename replication-controller @ 04/19/24 16:08:36.207
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:08:36.238
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:08:36.243
  STEP: Given a Pod with a 'name' label pod-adoption is created @ 04/19/24 16:08:36.248
  E0419 16:08:36.998362      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:37.998703      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When a replication controller with a matching selector is created @ 04/19/24 16:08:38.292
  STEP: Then the orphan pod is adopted @ 04/19/24 16:08:38.31
  E0419 16:08:38.998995      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:08:39.332186 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-8193" for this suite. @ 04/19/24 16:08:39.346
• [3.158 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support --unix-socket=/path [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1858
  STEP: Creating a kubernetes client @ 04/19/24 16:08:39.365
  I0419 16:08:39.365128 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename kubectl @ 04/19/24 16:08:39.369
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:08:39.407
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:08:39.416
  STEP: Starting the proxy @ 04/19/24 16:08:39.425
  I0419 16:08:39.428193 14 util.go:592] Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-3707 proxy --unix-socket=/tmp/kubectl-proxy-unix2160798601/test'
  STEP: retrieving proxy /api/ output @ 04/19/24 16:08:39.58
  I0419 16:08:39.583544 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3707" for this suite. @ 04/19/24 16:08:39.595
• [0.244 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:86
  STEP: Creating a kubernetes client @ 04/19/24 16:08:39.61
  I0419 16:08:39.611034 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename downward-api @ 04/19/24 16:08:39.613
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:08:39.643
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:08:39.65
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 16:08:39.658
  E0419 16:08:39.999659      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:40.999828      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:42.000955      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:43.001109      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:08:43.703
  I0419 16:08:43.714569 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod downwardapi-volume-7f27b36f-b555-4b7e-8cfe-ab2d09808aac container client-container: <nil>
  STEP: delete the pod @ 04/19/24 16:08:43.732
  I0419 16:08:43.776700 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-655" for this suite. @ 04/19/24 16:08:43.793
• [4.213 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Ingress API should support creating Ingress API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/ingress.go:55
  STEP: Creating a kubernetes client @ 04/19/24 16:08:43.826
  I0419 16:08:43.826430 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename ingress @ 04/19/24 16:08:43.832
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:08:43.882
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:08:43.888
  STEP: getting /apis @ 04/19/24 16:08:43.903
  STEP: getting /apis/networking.k8s.io @ 04/19/24 16:08:43.914
  STEP: getting /apis/networking.k8s.iov1 @ 04/19/24 16:08:43.917
  STEP: creating @ 04/19/24 16:08:43.919
  STEP: getting @ 04/19/24 16:08:43.948
  STEP: listing @ 04/19/24 16:08:43.954
  STEP: watching @ 04/19/24 16:08:43.961
  I0419 16:08:43.962187 14 ingress.go:186] starting watch
  STEP: cluster-wide listing @ 04/19/24 16:08:43.965
  STEP: cluster-wide watching @ 04/19/24 16:08:43.971
  I0419 16:08:43.971705 14 ingress.go:198] starting watch
  STEP: patching @ 04/19/24 16:08:43.974
  STEP: updating @ 04/19/24 16:08:43.989
  E0419 16:08:44.001122      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:08:44.008619 14 ingress.go:221] waiting for watch events with expected annotations
  I0419 16:08:44.008729 14 ingress.go:234] saw patched and updated annotations
  STEP: patching /status @ 04/19/24 16:08:44.009
  STEP: updating /status @ 04/19/24 16:08:44.021
  STEP: get /status @ 04/19/24 16:08:44.038
  STEP: deleting @ 04/19/24 16:08:44.046
  STEP: deleting a collection @ 04/19/24 16:08:44.089
  I0419 16:08:44.127396 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingress-7374" for this suite. @ 04/19/24 16:08:44.134
• [0.326 seconds]
------------------------------
SSS
------------------------------
[sig-apps] Deployment deployment should support rollover [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:132
  STEP: Creating a kubernetes client @ 04/19/24 16:08:44.152
  I0419 16:08:44.152859 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename deployment @ 04/19/24 16:08:44.156
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:08:44.192
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:08:44.197
  I0419 16:08:44.220556 14 resource.go:87] Pod name rollover-pod: Found 0 pods out of 1
  E0419 16:08:45.001185      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:46.001874      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:47.001944      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:48.002139      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:49.002244      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:08:49.232168 14 resource.go:87] Pod name rollover-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/19/24 16:08:49.232
  I0419 16:08:49.232671 14 deployment.go:911] Waiting for pods owned by replica set "test-rollover-controller" to become ready
  E0419 16:08:50.002712      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:51.003520      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:08:51.243982 14 deployment.go:921] Creating deployment "test-rollover-deployment"
  I0419 16:08:51.268573 14 deployment.go:934] Make sure deployment "test-rollover-deployment" performs scaling operations
  E0419 16:08:52.003970      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:53.004865      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:08:53.290001 14 deployment.go:939] Check revision of new replica set for deployment "test-rollover-deployment"
  I0419 16:08:53.309882 14 deployment.go:943] Ensure that both replica sets have 1 created replica
  I0419 16:08:53.335639 14 deployment.go:952] Rollover old replica sets for deployment "test-rollover-deployment" with new image update
  I0419 16:08:53.366495 14 deployment.go:313] Updating deployment test-rollover-deployment
  I0419 16:08:53.367037 14 deployment.go:961] Wait deployment "test-rollover-deployment" to be observed by the deployment controller
  E0419 16:08:54.005322      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:55.006349      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:08:55.392063 14 deployment.go:966] Wait for revision update of deployment "test-rollover-deployment" to 2
  I0419 16:08:55.416571 14 deployment.go:970] Make sure deployment "test-rollover-deployment" is complete
  I0419 16:08:55.437246 14 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I0419 16:08:55.437571 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 8, 51, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 8, 51, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 8, 54, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 8, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-679c966bdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 16:08:56.007344      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:57.007545      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:08:57.460249 14 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I0419 16:08:57.460835 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 8, 51, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 8, 51, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 8, 54, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 8, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-679c966bdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 16:08:58.008213      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:59.008521      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:08:59.458568 14 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I0419 16:08:59.458741 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 8, 51, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 8, 51, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 8, 54, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 8, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-679c966bdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 16:09:00.008565      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:01.009575      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:09:01.457150 14 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I0419 16:09:01.457643 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 8, 51, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 8, 51, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 8, 54, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 8, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-679c966bdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 16:09:02.009911      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:03.010678      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:09:03.462080 14 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I0419 16:09:03.462784 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 8, 51, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 8, 51, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 8, 54, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 8, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-679c966bdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 16:09:04.010795      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:05.011063      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:09:05.461983 14 deployment.go:94] 
  I0419 16:09:05.462170 14 deployment.go:974] Ensure that both old replica sets have no replicas
  I0419 16:09:05.487243 14 deployment.go:633] Deployment "test-rollover-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6068",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5c5f871a-d960-4d94-9865-13ba449793cf",
      ResourceVersion: (string) (len=5) "12033",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849139731,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139733,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000040  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000050  2c 22 66 3a 70 72 6f 67  72 65 73 73 44 65 61 64  |,"f:progressDead|
              00000060  6c 69 6e 65 53 65 63 6f  6e 64 73 22 3a 7b 7d 2c  |lineSeconds":{},|
              00000070  22 66 3a 72 65 70 6c 69  63 61 73 22 3a 7b 7d 2c  |"f:replicas":{},|
              00000080  22 66 3a 72 65 76 69 73  69 6f 6e 48 69 73 74 6f  |"f:revisionHisto|
              00000090  72 79 4c 69 6d 69 74 22  3a 7b 7d 2c 22 66 3a 73  |ryLimit":{},"f:s|
              000000a0  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 73  |elector":{},"f:s|
              000000b0  74 72 61 74 65 67 79 22  3a 7b 22 66 3a 72 6f 6c  |trategy":{"f:rol|
              000000c0  6c 69 6e 67 55 70 64 61  74 65 22 3a 7b 22 2e 22  |lingUpdate":{"."|
              000000d0  3a 7b 7d 2c 22 66 3a 6d  61 78 53 75 72 67 65 22  |:{},"f:maxSurge"|
              000000e0  3a 7b 7d 2c 22 66 3a 6d  61 78 55 6e 61 76 61 69  |:{},"f:maxUnavai|
              000000f0  6c 61 62 6c 65 22 3a 7b  7d 7d 2c 22 66 3a 74 79  |lable":{}},"f:ty|
              00000100  70 65 22 3a 7b 7d 7d 2c  22 66 3a 74 65 6d 70 6c  |pe":{}},"f:templ|
              00000110  61 74 65 22 3a 7b 22 66  3a 6d 65 74 61 64 61 74  |ate":{"f:metadat|
              00000120  61 22 3a 7b 22 66 3a 6c  61 62 65 6c 73 22 3a 7b  |a":{"f:labels":{|
              00000130  22 2e 22 3a 7b 7d 2c 22  66 3a 6e 61 6d 65 22 3a  |".":{},"f:name":|
              00000140  7b 7d 7d 7d 2c 22 66 3a  73 70 65 63 22 3a 7b 22  |{}}},"f:spec":{"|
              00000150  66 3a 63 6f 6e 74 61 69  6e 65 72 73 22 3a 7b 22  |f:containers":{"|
              00000160  6b 3a 7b 5c 22 6e 61 6d  65 5c 22 3a 5c 22 61 67  |k:{\"name\":\"ag|
              00000170  6e 68 6f 73 74 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |nhost\"}":{".":{|
              00000180  7d 2c 22 66 3a 69 6d 61  67 65 22 3a 7b 7d 2c 22  |},"f:image":{},"|
              00000190  66 3a 69 6d 61 67 65 50  75 6c 6c 50 6f 6c 69 63  |f:imagePullPolic|
              000001a0  79 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |y":{},"f:name":{|
              000001b0  7d 2c 22 66 3a 72 65 73  6f 75 72 63 65 73 22 3a  |},"f:resources":|
              000001c0  7b 7d 2c 22 66 3a 73 65  63 75 72 69 74 79 43 6f  |{},"f:securityCo|
              000001d0  6e 74 65 78 74 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ntext":{},"f:ter|
              000001e0  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000001f0  61 74 68 22 3a 7b 7d 2c  22 66 3a 74 65 72 6d 69  |ath":{},"f:termi|
              00000200  6e 61 74 69 6f 6e 4d 65  73 73 61 67 65 50 6f 6c  |nationMessagePol|
              00000210  69 63 79 22 3a 7b 7d 7d  7d 2c 22 66 3a 64 6e 73  |icy":{}}},"f:dns|
              00000220  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 72 65  |Policy":{},"f:re|
              00000230  73 74 61 72 74 50 6f 6c  69 63 79 22 3a 7b 7d 2c  |startPolicy":{},|
              00000240  22 66 3a 73 63 68 65 64  75 6c 65 72 4e 61 6d 65  |"f:schedulerName|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 47 72 61 63 65 50  |erminationGraceP|
              00000280  65 72 69 6f 64 53 65 63  6f 6e 64 73 22 3a 7b 7d  |eriodSeconds":{}|
              00000290  7d 7d 7d 7d                                       |}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139744,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 0,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 1,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 10,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139731,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139731,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139744,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139731,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=77) "ReplicaSet \"test-rollover-deployment-679c966bdf\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0419 16:09:05.508051 14 deployment.go:39] New ReplicaSet "test-rollover-deployment-679c966bdf" of Deployment "test-rollover-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-679c966bdf",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6068",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d2a56c4a-b564-4110-b33e-eecea5c18c9a",
      ResourceVersion: (string) (len=5) "12023",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849139733,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "679c966bdf"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "5c5f871a-d960-4d94-9865-13ba449793cf",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139733,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=806) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 35 63 35 66 38 37  31 61 2d 64 39 36 30 2d  |\"5c5f871a-d960-|
              00000120  34 64 39 34 2d 39 38 36  35 2d 31 33 62 61 34 34  |4d94-9865-13ba44|
              00000130  39 37 39 33 63 66 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |9793cf\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  61 67 6e 68 6f 73 74 5c  22 7d 22 3a 7b 22 2e 22  |agnhost\"}":{"."|
              00000210  3a 7b 7d 2c 22 66 3a 69  6d 61 67 65 22 3a 7b 7d  |:{},"f:image":{}|
              00000220  2c 22 66 3a 69 6d 61 67  65 50 75 6c 6c 50 6f 6c  |,"f:imagePullPol|
              00000230  69 63 79 22 3a 7b 7d 2c  22 66 3a 6e 61 6d 65 22  |icy":{},"f:name"|
              00000240  3a 7b 7d 2c 22 66 3a 72  65 73 6f 75 72 63 65 73  |:{},"f:resources|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 4d 65 73 73 61 67  |erminationMessag|
              00000280  65 50 61 74 68 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ePath":{},"f:ter|
              00000290  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000002a0  6f 6c 69 63 79 22 3a 7b  7d 7d 7d 2c 22 66 3a 64  |olicy":{}}},"f:d|
              000002b0  6e 73 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |nsPolicy":{},"f:|
              000002c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000002d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000002e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000002f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000300  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000310  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000320  7b 7d 7d 7d 7d 7d                                 |{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139744,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "679c966bdf"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "679c966bdf"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0419 16:09:05.528470 14 deployment.go:44] All old ReplicaSets of Deployment "test-rollover-deployment":
  I0419 16:09:05.529380 14 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6068",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0e2e0582-af6e-4ed6-93e8-fda5bac31a8e",
      ResourceVersion: (string) (len=5) "12032",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849139724,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=2) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "5c5f871a-d960-4d94-9865-13ba449793cf",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139724,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=467) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  73 65 6c 65 63 74 6f 72  |ec":{"f:selector|
              00000050  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000060  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000070  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000080  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000090  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000a0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000b0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000c0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000d0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000e0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              000000f0  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000100  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000110  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000120  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000130  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000140  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000150  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000160  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000170  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000180  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              00000190  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001a0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001b0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001c0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001d0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139744,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=249) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 7d 2c 22 66  3a 6f 77 6e 65 72 52 65  |":{}},"f:ownerRe|
              00000090  66 65 72 65 6e 63 65 73  22 3a 7b 22 2e 22 3a 7b  |ferences":{".":{|
              000000a0  7d 2c 22 6b 3a 7b 5c 22  75 69 64 5c 22 3a 5c 22  |},"k:{\"uid\":\"|
              000000b0  35 63 35 66 38 37 31 61  2d 64 39 36 30 2d 34 64  |5c5f871a-d960-4d|
              000000c0  39 34 2d 39 38 36 35 2d  31 33 62 61 34 34 39 37  |94-9865-13ba4497|
              000000d0  39 33 63 66 5c 22 7d 22  3a 7b 7d 7d 7d 2c 22 66  |93cf\"}":{}}},"f|
              000000e0  3a 73 70 65 63 22 3a 7b  22 66 3a 72 65 70 6c 69  |:spec":{"f:repli|
              000000f0  63 61 73 22 3a 7b 7d 7d  7d                       |cas":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139744,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0419 16:09:05.537452 14 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-65bd487b4b",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6068",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "176f898b-f62c-418a-9a16-42d0289a3706",
      ResourceVersion: (string) (len=5) "11991",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849139731,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "65bd487b4b"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "5c5f871a-d960-4d94-9865-13ba449793cf",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139733,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=810) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 35 63 35 66 38 37  31 61 2d 64 39 36 30 2d  |\"5c5f871a-d960-|
              00000120  34 64 39 34 2d 39 38 36  35 2d 31 33 62 61 34 34  |4d94-9865-13ba44|
              00000130  39 37 39 33 63 66 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |9793cf\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  72 65 64 69 73 2d 73 6c  61 76 65 5c 22 7d 22 3a  |redis-slave\"}":|
              00000210  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000220  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000230  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000240  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000250  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000260  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000270  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000280  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              00000290  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000002a0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000002b0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000002c0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000002d0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000002e0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              000002f0  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000300  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000310  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000320  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139733,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "65bd487b4b"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "65bd487b4b"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=11) "redis-slave",
              Image: (string) (len=47) "gcr.io/google_samples/gb-redisslave:nonexistent",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0419 16:09:05.566893 14 deployment.go:67] Pod "test-rollover-deployment-679c966bdf-mhmg4" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rollover-deployment-679c966bdf-mhmg4",
      GenerateName: (string) (len=36) "test-rollover-deployment-679c966bdf-",
      Namespace: (string) (len=15) "deployment-6068",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "23c388e4-5dc4-45d3-bc88-ac047823f57b",
      ResourceVersion: (string) (len=5) "12003",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849139733,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "679c966bdf"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=35) "test-rollover-deployment-679c966bdf",
          UID: (types.UID) (len=36) "d2a56c4a-b564-4110-b33e-eecea5c18c9a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139733,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 32  61 35 36 63 34 61 2d 62  |d\":\"d2a56c4a-b|
              00000090  35 36 34 2d 34 31 31 30  2d 62 33 33 65 2d 65 65  |564-4110-b33e-ee|
              000000a0  63 65 61 35 63 31 38 63  39 61 5c 22 7d 22 3a 7b  |cea5c18c9a\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139734,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 36 2e  31 32 33 5c 22 7d 22 3a  |.233.66.123\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-tbbxj",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-tbbxj",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "eipo9quoh3ef-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139734,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139733,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139734,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139734,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139733,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.127",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.127"
        }
      },
      PodIP: (string) (len=13) "10.233.66.123",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.66.123"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849139733,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63849139734,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:c9997bf8d2e223d7d2a0078dcfb11a653e9b16cf09418829ec03e1d57ca9628a",
          ContainerID: (string) (len=72) "cri-o://9b04e87942adacaf7ae59ceb5aed6d127623a98c0b92ee8be7a258e42e80fa90",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0419 16:09:05.570524 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-6068" for this suite. @ 04/19/24 16:09:05.582
• [21.441 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:46
  STEP: Creating a kubernetes client @ 04/19/24 16:09:05.594
  I0419 16:09:05.594346 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename downward-api @ 04/19/24 16:09:05.597
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:09:05.633
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:09:05.638
  STEP: Creating a pod to test downward api env vars @ 04/19/24 16:09:05.645
  E0419 16:09:06.011605      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:07.012720      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:09:07.68
  I0419 16:09:07.690966 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod downward-api-24a85f38-f061-480b-84c6-02c7b87d3634 container dapi-container: <nil>
  STEP: delete the pod @ 04/19/24 16:09:07.723
  I0419 16:09:07.767717 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4766" for this suite. @ 04/19/24 16:09:07.784
• [2.214 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate everything except 'skip-me' configmaps [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:866
  STEP: Creating a kubernetes client @ 04/19/24 16:09:07.809
  I0419 16:09:07.809837 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename webhook @ 04/19/24 16:09:07.815
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:09:07.855
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:09:07.861
  STEP: Setting up server cert @ 04/19/24 16:09:07.905
  E0419 16:09:08.012623      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 16:09:08.79
  STEP: Deploying the webhook pod @ 04/19/24 16:09:08.813
  STEP: Wait for the deployment to be ready @ 04/19/24 16:09:08.844
  I0419 16:09:08.887196 14 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0419 16:09:09.013246      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:10.013999      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:09:10.907103 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 16, 9, 8, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 9, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 9, 9, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 9, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-6b869959d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 16:09:11.014524      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:12.015543      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 16:09:12.966
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 16:09:12.993
  E0419 16:09:13.017321      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:09:13.994938 14 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a mutating webhook with match conditions @ 04/19/24 16:09:14.018
  E0419 16:09:14.018701      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the configmap with a random name @ 04/19/24 16:09:14.081
  STEP: verify the configmap is mutated @ 04/19/24 16:09:14.125
  STEP: create the configmap with 'skip-me' name @ 04/19/24 16:09:14.126
  I0419 16:09:14.276466 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4146" for this suite. @ 04/19/24 16:09:14.286
  STEP: Destroying namespace "webhook-markers-262" for this suite. @ 04/19/24 16:09:14.3
• [6.504 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:164
  STEP: Creating a kubernetes client @ 04/19/24 16:09:14.318
  I0419 16:09:14.318626 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename downward-api @ 04/19/24 16:09:14.324
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:09:14.357
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:09:14.362
  STEP: Creating the pod @ 04/19/24 16:09:14.367
  E0419 16:09:15.019433      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:16.020414      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:09:16.958143 14 pod_client.go:141] Successfully updated pod "annotationupdatef39bb1db-3b1b-4fc1-9f03-f133709f0ce6"
  E0419 16:09:17.021421      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:18.022843      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:19.022741      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:20.022927      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:21.023818      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:09:21.027433 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7682" for this suite. @ 04/19/24 16:09:21.041
• [6.742 seconds]
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl logs logs should be able to retrieve and filter logs [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/logs.go:114
  STEP: Creating a kubernetes client @ 04/19/24 16:09:21.062
  I0419 16:09:21.062857 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename kubectl-logs @ 04/19/24 16:09:21.066
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:09:21.108
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:09:21.113
  STEP: creating an pod @ 04/19/24 16:09:21.122
  I0419 16:09:21.123495 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-logs-1827 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.47 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
  I0419 16:09:21.331321 14 builder.go:146] stderr: ""
  I0419 16:09:21.331836 14 builder.go:147] stdout: "pod/logs-generator created\n"
  STEP: Waiting for log generator to start. @ 04/19/24 16:09:21.332
  I0419 16:09:21.334257 14 resource.go:413] Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
  E0419 16:09:22.023924      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:23.024306      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:09:23.351955 14 resource.go:435] Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
  STEP: checking for a matching strings @ 04/19/24 16:09:23.352
  I0419 16:09:23.352989 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-logs-1827 logs logs-generator logs-generator'
  I0419 16:09:23.549033 14 builder.go:146] stderr: ""
  I0419 16:09:23.549164 14 builder.go:147] stdout: "I0419 16:09:22.017629       1 logs_generator.go:76] 0 POST /api/v1/namespaces/kube-system/pods/27tg 354\nI0419 16:09:22.217100       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/jkk8 264\nI0419 16:09:22.417797       1 logs_generator.go:76] 2 POST /api/v1/namespaces/ns/pods/9n8 320\nI0419 16:09:22.617378       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/fsb6 513\nI0419 16:09:22.816976       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/kube-system/pods/cc5 515\nI0419 16:09:23.017497       1 logs_generator.go:76] 5 POST /api/v1/namespaces/default/pods/6dt 387\nI0419 16:09:23.217046       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/vr6 286\nI0419 16:09:23.417629       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/tdz 363\n"
  STEP: limiting log lines @ 04/19/24 16:09:23.549
  I0419 16:09:23.549801 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-logs-1827 logs logs-generator logs-generator --tail=1'
  I0419 16:09:23.767288 14 builder.go:146] stderr: ""
  I0419 16:09:23.767448 14 builder.go:147] stdout: "I0419 16:09:23.617016       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/kube-system/pods/4px 475\n"
  I0419 16:09:23.767490 14 logs.go:127] got output "I0419 16:09:23.617016       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/kube-system/pods/4px 475\n"
  STEP: limiting log bytes @ 04/19/24 16:09:23.767
  I0419 16:09:23.768109 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-logs-1827 logs logs-generator logs-generator --limit-bytes=1'
  I0419 16:09:23.953505 14 builder.go:146] stderr: ""
  I0419 16:09:23.953775 14 builder.go:147] stdout: "I"
  I0419 16:09:23.953802 14 logs.go:133] got output "I"
  STEP: exposing timestamps @ 04/19/24 16:09:23.953
  I0419 16:09:23.954228 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-logs-1827 logs logs-generator logs-generator --tail=1 --timestamps'
  E0419 16:09:24.024849      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:09:24.116002 14 builder.go:146] stderr: ""
  I0419 16:09:24.116090 14 builder.go:147] stdout: "2024-04-19T16:09:24.016985406Z I0419 16:09:24.016911       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/ns/pods/fdcv 323\n"
  I0419 16:09:24.116117 14 logs.go:139] got output "2024-04-19T16:09:24.016985406Z I0419 16:09:24.016911       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/ns/pods/fdcv 323\n"
  STEP: restricting to a time range @ 04/19/24 16:09:24.116
  E0419 16:09:25.025325      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:26.025459      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:09:26.616807 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-logs-1827 logs logs-generator logs-generator --since=1s'
  I0419 16:09:26.825302 14 builder.go:146] stderr: ""
  I0419 16:09:26.825391 14 builder.go:147] stdout: "I0419 16:09:26.017223       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/59jb 494\nI0419 16:09:26.217670       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/pwh4 377\nI0419 16:09:26.417209       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/kube-system/pods/4dj 231\nI0419 16:09:26.617812       1 logs_generator.go:76] 23 POST /api/v1/namespaces/ns/pods/6h5h 536\nI0419 16:09:26.818317       1 logs_generator.go:76] 24 GET /api/v1/namespaces/kube-system/pods/q86 228\n"
  I0419 16:09:26.826374 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-logs-1827 logs logs-generator logs-generator --since=24h'
  E0419 16:09:27.026319      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:09:27.041662 14 builder.go:146] stderr: ""
  I0419 16:09:27.041813 14 builder.go:147] stdout: "I0419 16:09:22.017629       1 logs_generator.go:76] 0 POST /api/v1/namespaces/kube-system/pods/27tg 354\nI0419 16:09:22.217100       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/jkk8 264\nI0419 16:09:22.417797       1 logs_generator.go:76] 2 POST /api/v1/namespaces/ns/pods/9n8 320\nI0419 16:09:22.617378       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/fsb6 513\nI0419 16:09:22.816976       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/kube-system/pods/cc5 515\nI0419 16:09:23.017497       1 logs_generator.go:76] 5 POST /api/v1/namespaces/default/pods/6dt 387\nI0419 16:09:23.217046       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/vr6 286\nI0419 16:09:23.417629       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/tdz 363\nI0419 16:09:23.617016       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/kube-system/pods/4px 475\nI0419 16:09:23.818536       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/ns/pods/xp44 444\nI0419 16:09:24.016911       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/ns/pods/fdcv 323\nI0419 16:09:24.217489       1 logs_generator.go:76] 11 POST /api/v1/namespaces/default/pods/xtb 268\nI0419 16:09:24.417339       1 logs_generator.go:76] 12 GET /api/v1/namespaces/kube-system/pods/wp7v 355\nI0419 16:09:24.617943       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/default/pods/rbrf 533\nI0419 16:09:24.817557       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/default/pods/7x42 513\nI0419 16:09:25.017073       1 logs_generator.go:76] 15 POST /api/v1/namespaces/kube-system/pods/8sp8 444\nI0419 16:09:25.217625       1 logs_generator.go:76] 16 GET /api/v1/namespaces/default/pods/pfh5 204\nI0419 16:09:25.417170       1 logs_generator.go:76] 17 POST /api/v1/namespaces/ns/pods/96kd 579\nI0419 16:09:25.617728       1 logs_generator.go:76] 18 POST /api/v1/namespaces/kube-system/pods/ft4c 369\nI0419 16:09:25.817429       1 logs_generator.go:76] 19 POST /api/v1/namespaces/ns/pods/4mj 585\nI0419 16:09:26.017223       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/59jb 494\nI0419 16:09:26.217670       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/pwh4 377\nI0419 16:09:26.417209       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/kube-system/pods/4dj 231\nI0419 16:09:26.617812       1 logs_generator.go:76] 23 POST /api/v1/namespaces/ns/pods/6h5h 536\nI0419 16:09:26.818317       1 logs_generator.go:76] 24 GET /api/v1/namespaces/kube-system/pods/q86 228\nI0419 16:09:27.017897       1 logs_generator.go:76] 25 GET /api/v1/namespaces/default/pods/z25 329\n"
  I0419 16:09:27.042227 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-logs-1827 delete pod logs-generator'
  I0419 16:09:27.757014 14 builder.go:146] stderr: ""
  I0419 16:09:27.757112 14 builder.go:147] stdout: "pod \"logs-generator\" deleted\n"
  I0419 16:09:27.757333 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-logs-1827" for this suite. @ 04/19/24 16:09:27.767
• [6.722 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:335
  STEP: Creating a kubernetes client @ 04/19/24 16:09:27.784
  I0419 16:09:27.784926 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename init-container @ 04/19/24 16:09:27.787
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:09:27.828
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:09:27.832
  STEP: creating the pod @ 04/19/24 16:09:27.839
  I0419 16:09:27.840058 14 init_container.go:374] PodSpec: initContainers in spec.initContainers
  E0419 16:09:28.027734      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:29.027565      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:30.028530      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:31.029099      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:32.029646      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:33.030460      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:34.030907      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:35.031133      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:36.031440      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:37.031711      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:38.033356      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:39.034246      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:40.034181      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:41.034669      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:42.035685      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:43.036502      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:44.036510      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:45.037476      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:46.037699      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:47.038623      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:48.039664      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:49.039997      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:50.040316      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:51.040607      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:52.047278      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:53.051736      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:54.048113      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:55.049128      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:56.049222      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:57.049492      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:58.051044      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:59.049836      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:00.050574      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:01.050848      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:02.051178      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:03.051654      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:04.051800      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:05.053045      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:06.053130      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:07.053845      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:10:07.884474 14 init_container.go:432] init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-6a3fd8fd-4a70-49d1-b08e-df7fe9c2a18c", GenerateName:"", Namespace:"init-container-4831", SelfLink:"", UID:"2fcc42ce-54b4-4e67-b06d-2f30b52b37f2", ResourceVersion:"12353", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 9, 27, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"840003052"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 9, 27, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004082b10), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 10, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004082b40), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-dwnwm", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc004fd8f00), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-dwnwm", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-dwnwm", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.9", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-dwnwm", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0029ddee0), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"eipo9quoh3ef-3", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0032c7a80), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0029ddf70)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0029ddf90)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0029ddf98), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0029ddf9c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc004a185a0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil), SchedulingGates:[]v1.PodSchedulingGate(nil), ResourceClaims:[]v1.PodResourceClaim(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"PodReadyToStartContainers", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.April, 19, 16, 9, 28, 0, time.Local), Reason:"", Message:""}, v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.April, 19, 16, 9, 27, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.April, 19, 16, 9, 27, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.April, 19, 16, 9, 27, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.April, 19, 16, 9, 27, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.121.127", HostIPs:[]v1.HostIP{v1.HostIP{IP:"192.168.121.127"}}, PodIP:"10.233.66.128", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.233.66.128"}}, StartTime:time.Date(2024, time.April, 19, 16, 9, 27, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0004f3b90)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0004f3d50)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9", ContainerID:"cri-o://3f09bd5daef409062e6294e9c875fb53962c72f972edd6c2b88311e84c9b0060", Started:(*bool)(0xc0028c403f), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil), VolumeMounts:[]v1.VolumeMountStatus(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc004fd8f60), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"", ContainerID:"", Started:(*bool)(0xc0028c4045), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil), VolumeMounts:[]v1.VolumeMountStatus(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc004fd8f40), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.9", ImageID:"", ContainerID:"", Started:(*bool)(0xc0028c4014), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil), VolumeMounts:[]v1.VolumeMountStatus(nil)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil), Resize:"", ResourceClaimStatuses:[]v1.PodResourceClaimStatus(nil)}}
  I0419 16:10:07.885906 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-4831" for this suite. @ 04/19/24 16:10:07.896
• [40.131 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/flowcontrol.go:270
  STEP: Creating a kubernetes client @ 04/19/24 16:10:07.916
  I0419 16:10:07.916684 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename apf @ 04/19/24 16:10:07.927
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:10:07.964
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:10:07.972
  STEP: getting /apis @ 04/19/24 16:10:07.978
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 04/19/24 16:10:07.989
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 04/19/24 16:10:07.992
  STEP: creating @ 04/19/24 16:10:07.995
  STEP: getting @ 04/19/24 16:10:08.029
  STEP: listing @ 04/19/24 16:10:08.044
  E0419 16:10:08.054195      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: watching @ 04/19/24 16:10:08.054
  I0419 16:10:08.054837 14 flowcontrol.go:394] starting watch
  STEP: patching @ 04/19/24 16:10:08.056
  STEP: updating @ 04/19/24 16:10:08.066
  I0419 16:10:08.081898 14 flowcontrol.go:422] waiting for watch events with expected annotations
  STEP: getting /status @ 04/19/24 16:10:08.082
  STEP: patching /status @ 04/19/24 16:10:08.089
  STEP: updating /status @ 04/19/24 16:10:08.098
  STEP: deleting @ 04/19/24 16:10:08.153
  STEP: deleting a collection @ 04/19/24 16:10:08.176
  I0419 16:10:08.215636 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-491" for this suite. @ 04/19/24 16:10:08.225
• [0.322 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should complete a service status lifecycle [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3345
  STEP: Creating a kubernetes client @ 04/19/24 16:10:08.239
  I0419 16:10:08.239566 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename services @ 04/19/24 16:10:08.242
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:10:08.269
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:10:08.275
  STEP: creating a Service @ 04/19/24 16:10:08.289
  STEP: watching for the Service to be added @ 04/19/24 16:10:08.319
  I0419 16:10:08.323168 14 service.go:3397] Found Service test-service-crg4c in namespace services-9938 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 32258}]
  I0419 16:10:08.323219 14 service.go:3404] Service test-service-crg4c created
  STEP: Getting /status @ 04/19/24 16:10:08.323
  I0419 16:10:08.329592 14 service.go:3415] Service test-service-crg4c has LoadBalancer: {[]}
  STEP: patching the ServiceStatus @ 04/19/24 16:10:08.329
  STEP: watching for the Service to be patched @ 04/19/24 16:10:08.344
  I0419 16:10:08.348013 14 service.go:3438] observed Service test-service-crg4c in namespace services-9938 with annotations: map[] & LoadBalancer: {[]}
  I0419 16:10:08.348658 14 service.go:3441] Found Service test-service-crg4c in namespace services-9938 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  0xc004dd3920 []}]}
  I0419 16:10:08.349825 14 service.go:3448] Service test-service-crg4c has service status patched
  STEP: updating the ServiceStatus @ 04/19/24 16:10:08.35
  I0419 16:10:08.367859 14 service.go:3468] updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Service to be updated @ 04/19/24 16:10:08.369
  I0419 16:10:08.373392 14 service.go:3479] Observed Service test-service-crg4c in namespace services-9938 with annotations: map[] & Conditions: {[]}
  I0419 16:10:08.373823 14 service.go:3494] Observed event: &Service{ObjectMeta:{test-service-crg4c  services-9938  bd863f16-24f1-4ba3-99d1-7123de93db96 12381 0 2024-04-19 16:10:08 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2024-04-19 16:10:08 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:allocateLoadBalancerNodePorts":{},"f:externalTrafficPolicy":{},"f:internalTrafficPolicy":{},"f:loadBalancerClass":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2024-04-19 16:10:08 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:32258,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.233.41.36,Type:LoadBalancer,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:Cluster,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.233.41.36],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:*true,LoadBalancerClass:*example.com/internal-vip,InternalTrafficPolicy:*Cluster,TrafficDistribution:nil,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,IPMode:*VIP,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
  I0419 16:10:08.373922 14 service.go:3486] Found Service test-service-crg4c in namespace services-9938 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0419 16:10:08.373964 14 service.go:3498] Service test-service-crg4c has service status updated
  STEP: patching the service @ 04/19/24 16:10:08.373
  STEP: watching for the Service to be patched @ 04/19/24 16:10:08.396
  I0419 16:10:08.399646 14 service.go:3521] observed Service test-service-crg4c in namespace services-9938 with labels: map[test-service-static:true]
  I0419 16:10:08.400297 14 service.go:3521] observed Service test-service-crg4c in namespace services-9938 with labels: map[test-service-static:true]
  I0419 16:10:08.400931 14 service.go:3521] observed Service test-service-crg4c in namespace services-9938 with labels: map[test-service-static:true]
  I0419 16:10:08.401493 14 service.go:3524] Found Service test-service-crg4c in namespace services-9938 with labels: map[test-service:patched test-service-static:true]
  I0419 16:10:08.402043 14 service.go:3531] Service test-service-crg4c patched
  STEP: deleting the service @ 04/19/24 16:10:08.402
  STEP: watching for the Service to be deleted @ 04/19/24 16:10:08.432
  I0419 16:10:08.435638 14 service.go:3555] Observed event: ADDED
  I0419 16:10:08.435732 14 service.go:3555] Observed event: MODIFIED
  I0419 16:10:08.436041 14 service.go:3555] Observed event: MODIFIED
  I0419 16:10:08.436391 14 service.go:3555] Observed event: MODIFIED
  I0419 16:10:08.436622 14 service.go:3551] Found Service test-service-crg4c in namespace services-9938 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
  I0419 16:10:08.436691 14 service.go:3560] Service test-service-crg4c deleted
  I0419 16:10:08.437407 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9938" for this suite. @ 04/19/24 16:10:08.447
• [0.219 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:64
  STEP: Creating a kubernetes client @ 04/19/24 16:10:08.467
  I0419 16:10:08.468037 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename field-validation @ 04/19/24 16:10:08.47
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:10:08.499
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:10:08.503
  STEP: apply creating a deployment @ 04/19/24 16:10:08.509
  I0419 16:10:08.536224 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-5117" for this suite. @ 04/19/24 16:10:08.545
• [0.089 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:345
  STEP: Creating a kubernetes client @ 04/19/24 16:10:08.557
  I0419 16:10:08.557446 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename pods @ 04/19/24 16:10:08.563
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:10:08.597
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:10:08.604
  STEP: creating the pod @ 04/19/24 16:10:08.611
  STEP: submitting the pod to kubernetes @ 04/19/24 16:10:08.613
  E0419 16:10:09.054460      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:10.054991      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 04/19/24 16:10:10.652
  STEP: updating the pod @ 04/19/24 16:10:10.66
  E0419 16:10:11.056588      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:10:11.198475 14 pod_client.go:141] Successfully updated pod "pod-update-b3ca4ffb-5b72-4427-9cc9-d62fd3847fad"
  STEP: verifying the updated pod is in kubernetes @ 04/19/24 16:10:11.209
  I0419 16:10:11.219043 14 pods.go:391] Pod update OK
  I0419 16:10:11.220020 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-9848" for this suite. @ 04/19/24 16:10:11.23
• [2.691 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:141
  STEP: Creating a kubernetes client @ 04/19/24 16:10:11.249
  I0419 16:10:11.249177 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename disruption @ 04/19/24 16:10:11.253
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:10:11.297
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:10:11.304
  STEP: Waiting for the pdb to be processed @ 04/19/24 16:10:11.321
  E0419 16:10:12.056000      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:13.056470      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 04/19/24 16:10:13.369
  I0419 16:10:13.380344 14 disruption.go:578] running pods: 0 < 3
  E0419 16:10:14.055978      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:15.056305      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:10:15.388839 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-172" for this suite. @ 04/19/24 16:10:15.402
• [4.169 seconds]
------------------------------
S
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:178
  STEP: Creating a kubernetes client @ 04/19/24 16:10:15.418
  I0419 16:10:15.418706 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename init-container @ 04/19/24 16:10:15.424
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:10:15.471
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:10:15.482
  STEP: creating the pod @ 04/19/24 16:10:15.492
  I0419 16:10:15.492805 14 init_container.go:213] PodSpec: initContainers in spec.initContainers
  E0419 16:10:16.056972      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:17.056844      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:18.058079      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:19.058926      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:20.058903      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:10:20.130328 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-3830" for this suite. @ 04/19/24 16:10:20.143
• [4.740 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1079
  STEP: Creating a kubernetes client @ 04/19/24 16:10:20.166
  I0419 16:10:20.166927 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename kubectl @ 04/19/24 16:10:20.169
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:10:20.211
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:10:20.217
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 04/19/24 16:10:20.227
  I0419 16:10:20.228795 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-9845 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  I0419 16:10:20.466581 14 builder.go:146] stderr: ""
  I0419 16:10:20.467447 14 builder.go:147] stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: replace the image in the pod with server-side dry-run @ 04/19/24 16:10:20.467
  I0419 16:10:20.468257 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-9845 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.36.1-1"}]}} --dry-run=server'
  I0419 16:10:20.727748 14 builder.go:146] stderr: ""
  I0419 16:10:20.728110 14 builder.go:147] stdout: "pod/e2e-test-httpd-pod patched\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 04/19/24 16:10:20.728
  I0419 16:10:20.748723 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-9845 delete pods e2e-test-httpd-pod'
  E0419 16:10:21.059525      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:22.059683      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:23.060433      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:10:23.167662 14 builder.go:146] stderr: ""
  I0419 16:10:23.167788 14 builder.go:147] stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  I0419 16:10:23.168133 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9845" for this suite. @ 04/19/24 16:10:23.178
• [3.028 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:132
  STEP: Creating a kubernetes client @ 04/19/24 16:10:23.194
  I0419 16:10:23.194384 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename projected @ 04/19/24 16:10:23.197
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:10:23.23
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:10:23.236
  STEP: Creating the pod @ 04/19/24 16:10:23.245
  E0419 16:10:24.060712      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:25.061916      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:10:25.847356 14 pod_client.go:141] Successfully updated pod "labelsupdatead54420f-50f3-4b51-ba43-cdfdc25d5ea1"
  E0419 16:10:26.062058      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:27.062755      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:10:27.886886 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-510" for this suite. @ 04/19/24 16:10:27.938
• [4.757 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:219
  STEP: Creating a kubernetes client @ 04/19/24 16:10:27.959
  I0419 16:10:27.959951 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename downward-api @ 04/19/24 16:10:27.963
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:10:28.005
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:10:28.024
  STEP: Creating a pod to test downward api env vars @ 04/19/24 16:10:28.033
  E0419 16:10:28.063398      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:29.064091      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:30.063592      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:31.064420      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:32.066357      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:10:32.082
  I0419 16:10:32.089703 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod downward-api-f991a4ac-d059-48b0-a91c-763ce45049eb container dapi-container: <nil>
  STEP: delete the pod @ 04/19/24 16:10:32.107
  I0419 16:10:32.141226 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4252" for this suite. @ 04/19/24 16:10:32.151
• [4.209 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:47
  STEP: Creating a kubernetes client @ 04/19/24 16:10:32.174
  I0419 16:10:32.174568 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename secrets @ 04/19/24 16:10:32.179
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:10:32.203
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:10:32.209
  STEP: Creating secret with name secret-test-4cfbe55d-e335-4b08-89af-4784f84587b9 @ 04/19/24 16:10:32.214
  STEP: Creating a pod to test consume secrets @ 04/19/24 16:10:32.222
  E0419 16:10:33.064576      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:34.065330      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:35.065233      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:36.065389      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:10:36.258
  I0419 16:10:36.265334 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-secrets-ab101fed-5c20-4123-9c95-af08feba2a8d container secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/24 16:10:36.279
  I0419 16:10:36.317003 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3660" for this suite. @ 04/19/24 16:10:36.332
• [4.179 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:216
  STEP: Creating a kubernetes client @ 04/19/24 16:10:36.357
  I0419 16:10:36.358073 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename container-runtime @ 04/19/24 16:10:36.363
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:10:36.404
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:10:36.415
  STEP: create the container @ 04/19/24 16:10:36.426
  W0419 16:10:36.449440      14 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Failed @ 04/19/24 16:10:36.45
  E0419 16:10:37.065308      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:38.065804      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 04/19/24 16:10:38.495
  STEP: the container should be terminated @ 04/19/24 16:10:38.505
  STEP: the termination message should be set @ 04/19/24 16:10:38.506
  I0419 16:10:38.507264 14 runtime.go:167] Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 04/19/24 16:10:38.508
  I0419 16:10:38.544129 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-3015" for this suite. @ 04/19/24 16:10:38.561
• [2.227 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:172
  STEP: Creating a kubernetes client @ 04/19/24 16:10:38.589
  I0419 16:10:38.589218 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename discovery @ 04/19/24 16:10:38.593
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:10:38.638
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:10:38.643
  STEP: Setting up server cert @ 04/19/24 16:10:38.652
  E0419 16:10:39.065949      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Requesting APIResourceList from "/api/v1" @ 04/19/24 16:10:39.356
  STEP: Requesting APIResourceList from "/apis/admissionregistration.k8s.io/v1" @ 04/19/24 16:10:39.361
  STEP: Requesting APIResourceList from "/apis/apiextensions.k8s.io/v1" @ 04/19/24 16:10:39.363
  STEP: Requesting APIResourceList from "/apis/apiregistration.k8s.io/v1" @ 04/19/24 16:10:39.366
  STEP: Requesting APIResourceList from "/apis/apps/v1" @ 04/19/24 16:10:39.369
  STEP: Requesting APIResourceList from "/apis/authentication.k8s.io/v1" @ 04/19/24 16:10:39.372
  STEP: Requesting APIResourceList from "/apis/authorization.k8s.io/v1" @ 04/19/24 16:10:39.375
  STEP: Requesting APIResourceList from "/apis/autoscaling/v1" @ 04/19/24 16:10:39.378
  STEP: Requesting APIResourceList from "/apis/autoscaling/v2" @ 04/19/24 16:10:39.381
  STEP: Requesting APIResourceList from "/apis/batch/v1" @ 04/19/24 16:10:39.384
  STEP: Requesting APIResourceList from "/apis/certificates.k8s.io/v1" @ 04/19/24 16:10:39.388
  STEP: Requesting APIResourceList from "/apis/coordination.k8s.io/v1" @ 04/19/24 16:10:39.391
  STEP: Requesting APIResourceList from "/apis/discovery.k8s.io/v1" @ 04/19/24 16:10:39.395
  STEP: Requesting APIResourceList from "/apis/events.k8s.io/v1" @ 04/19/24 16:10:39.399
  STEP: Requesting APIResourceList from "/apis/networking.k8s.io/v1" @ 04/19/24 16:10:39.402
  STEP: Requesting APIResourceList from "/apis/node.k8s.io/v1" @ 04/19/24 16:10:39.406
  STEP: Requesting APIResourceList from "/apis/policy/v1" @ 04/19/24 16:10:39.409
  STEP: Requesting APIResourceList from "/apis/scheduling.k8s.io/v1" @ 04/19/24 16:10:39.413
  STEP: Requesting APIResourceList from "/apis/storage.k8s.io/v1" @ 04/19/24 16:10:39.417
  I0419 16:10:39.421971 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-537" for this suite. @ 04/19/24 16:10:39.434
• [0.863 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:751
  STEP: Creating a kubernetes client @ 04/19/24 16:10:39.455
  I0419 16:10:39.455148 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename statefulset @ 04/19/24 16:10:39.459
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:10:39.501
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:10:39.512
  STEP: Creating service test in namespace statefulset-5207 @ 04/19/24 16:10:39.523
  STEP: Creating stateful set ss in namespace statefulset-5207 @ 04/19/24 16:10:39.537
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5207 @ 04/19/24 16:10:39.554
  I0419 16:10:39.567964 14 wait.go:40] Found 0 stateful pods, waiting for 1
  E0419 16:10:40.068345      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:41.068194      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:42.068525      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:43.069534      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:44.070052      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:45.071098      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:46.071952      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:47.072245      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:48.072272      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:49.072558      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:10:49.566866 14 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod @ 04/19/24 16:10:49.567
  I0419 16:10:49.575054 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=statefulset-5207 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0419 16:10:49.944601 14 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0419 16:10:49.944717 14 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0419 16:10:49.944758 14 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0419 16:10:49.958251 14 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E0419 16:10:50.072772      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:51.073167      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:52.073488      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:53.074253      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:54.074856      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:55.075043      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:56.075181      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:57.076022      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:58.076390      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:59.076567      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:10:59.958078 14 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0419 16:10:59.958275 14 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I0419 16:10:59.991135 14 resource.go:168] POD   NODE            PHASE    GRACE  CONDITIONS
  I0419 16:10:59.991796 14 resource.go:175] ss-0  eipo9quoh3ef-3  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:10:41 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:10:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:10:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:10:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:10:39 +0000 UTC  }]
  I0419 16:10:59.992166 14 resource.go:178] 
  I0419 16:10:59.992515 14 statefulset.go:2147] StatefulSet ss has not reached scale 3, at 1
  E0419 16:11:00.077240      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:11:01.005794 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 8.989478324s
  E0419 16:11:01.078158      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:11:02.017203 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 7.97713534s
  E0419 16:11:02.078400      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:11:03.033722 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 6.965148621s
  E0419 16:11:03.079107      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:11:04.047946 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 5.948705698s
  E0419 16:11:04.080129      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:11:05.060247 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 4.934552417s
  E0419 16:11:05.080803      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:11:06.075796 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 3.922078746s
  E0419 16:11:06.080858      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:07.081016      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:11:07.089371 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 2.906943686s
  E0419 16:11:08.081437      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:11:08.098742 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 1.893576938s
  E0419 16:11:09.081968      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:11:09.113911 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 883.774293ms
  E0419 16:11:10.081972      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5207 @ 04/19/24 16:11:10.115
  I0419 16:11:10.128081 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=statefulset-5207 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0419 16:11:10.440747 14 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0419 16:11:10.440830 14 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0419 16:11:10.440857 14 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0419 16:11:10.441410 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=statefulset-5207 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0419 16:11:10.735851 14 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  I0419 16:11:10.735933 14 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0419 16:11:10.735957 14 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0419 16:11:10.736333 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=statefulset-5207 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0419 16:11:11.064862 14 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  I0419 16:11:11.065051 14 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0419 16:11:11.065098 14 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0419 16:11:11.075641 14 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I0419 16:11:11.075782 14 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  I0419 16:11:11.075845 14 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Scale down will not halt with unhealthy stateful pod @ 04/19/24 16:11:11.075
  E0419 16:11:11.082206      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:11:11.085058 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=statefulset-5207 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0419 16:11:11.362071 14 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0419 16:11:11.362163 14 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0419 16:11:11.362400 14 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0419 16:11:11.362720 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=statefulset-5207 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0419 16:11:11.663297 14 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0419 16:11:11.663915 14 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0419 16:11:11.663946 14 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0419 16:11:11.664208 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=statefulset-5207 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0419 16:11:11.951508 14 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0419 16:11:11.952012 14 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0419 16:11:11.952139 14 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0419 16:11:11.952204 14 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I0419 16:11:11.965355 14 wait.go:114] Waiting for statefulset status.readyReplicas to become 0, currently 3
  E0419 16:11:12.082434      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:13.082675      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:14.083006      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:15.084110      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:16.083699      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:17.083828      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:18.084073      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:19.084422      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:20.084627      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:21.084841      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:11:21.975753 14 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0419 16:11:21.976328 14 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  I0419 16:11:21.976812 14 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  I0419 16:11:22.016522 14 resource.go:168] POD   NODE            PHASE    GRACE  CONDITIONS
  I0419 16:11:22.016694 14 resource.go:175] ss-0  eipo9quoh3ef-3  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:10:41 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:10:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:11:11 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:11:11 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:10:39 +0000 UTC  }]
  I0419 16:11:22.016773 14 resource.go:175] ss-1  eipo9quoh3ef-1  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:11:01 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:11:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:11:12 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:11:12 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:11:00 +0000 UTC  }]
  I0419 16:11:22.016848 14 resource.go:175] ss-2  eipo9quoh3ef-2  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:11:01 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:11:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:11:12 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:11:12 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:11:00 +0000 UTC  }]
  I0419 16:11:22.016939 14 resource.go:178] 
  I0419 16:11:22.016976 14 statefulset.go:2147] StatefulSet ss has not reached scale 0, at 3
  E0419 16:11:22.086089      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:11:23.023145 14 resource.go:168] POD   NODE            PHASE      GRACE  CONDITIONS
  I0419 16:11:23.023279 14 resource.go:175] ss-1  eipo9quoh3ef-1  Succeeded  30s    [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:11:22 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:11:00 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:11:12 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:11:12 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:11:00 +0000 UTC  }]
  I0419 16:11:23.023304 14 resource.go:178] 
  I0419 16:11:23.023325 14 statefulset.go:2147] StatefulSet ss has not reached scale 0, at 1
  E0419 16:11:23.087019      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:11:24.035247 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 0 for another 7.981707673s
  E0419 16:11:24.087952      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:11:25.042462 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 0 for another 6.969706502s
  E0419 16:11:25.088595      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:11:26.049977 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 0 for another 5.961845374s
  E0419 16:11:26.089225      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:11:27.062180 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 0 for another 4.954733516s
  E0419 16:11:27.090347      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:11:28.071368 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 0 for another 3.94214597s
  E0419 16:11:28.090696      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:11:29.085233 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 0 for another 2.933212045s
  E0419 16:11:29.091671      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:30.092774      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:11:30.094684 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 0 for another 1.919131715s
  E0419 16:11:31.093340      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:11:31.103539 14 statefulset.go:2152] Verifying statefulset ss doesn't scale past 0 for another 909.799233ms
  E0419 16:11:32.093694      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5207 @ 04/19/24 16:11:32.105
  I0419 16:11:32.112589 14 rest.go:150] Scaling statefulset ss to 0
  I0419 16:11:32.130991 14 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0419 16:11:32.138268 14 statefulset.go:135] Deleting all statefulset in ns statefulset-5207
  I0419 16:11:32.146080 14 rest.go:150] Scaling statefulset ss to 0
  I0419 16:11:32.166833 14 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0419 16:11:32.173257 14 rest.go:88] Deleting statefulset ss
  I0419 16:11:32.201348 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-5207" for this suite. @ 04/19/24 16:11:32.212
• [52.774 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should provide secure master service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:779
  STEP: Creating a kubernetes client @ 04/19/24 16:11:32.236
  I0419 16:11:32.236444 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename services @ 04/19/24 16:11:32.239
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:11:32.272
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:11:32.276
  I0419 16:11:32.291722 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1315" for this suite. @ 04/19/24 16:11:32.298
• [0.073 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:209
  STEP: Creating a kubernetes client @ 04/19/24 16:11:32.309
  I0419 16:11:32.310033 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename downward-api @ 04/19/24 16:11:32.312
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:11:32.343
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:11:32.348
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 16:11:32.354
  E0419 16:11:33.094345      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:34.094599      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:35.095701      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:36.096401      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:11:36.408
  I0419 16:11:36.416945 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod downwardapi-volume-85387c33-fe5b-46d4-b305-fb8a29f40df4 container client-container: <nil>
  STEP: delete the pod @ 04/19/24 16:11:36.435
  I0419 16:11:36.463894 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9818" for this suite. @ 04/19/24 16:11:36.473
• [4.182 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:273
  STEP: Creating a kubernetes client @ 04/19/24 16:11:36.498
  I0419 16:11:36.498497 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename webhook @ 04/19/24 16:11:36.501
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:11:36.533
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:11:36.541
  STEP: Setting up server cert @ 04/19/24 16:11:36.608
  E0419 16:11:37.097120      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:38.097877      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 16:11:38.129
  STEP: Deploying the webhook pod @ 04/19/24 16:11:38.151
  STEP: Wait for the deployment to be ready @ 04/19/24 16:11:38.173
  I0419 16:11:38.189369 14 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0419 16:11:39.098117      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:40.098392      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 16:11:40.221
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 16:11:40.256
  E0419 16:11:41.098959      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:11:41.257917 14 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 04/19/24 16:11:41.274
  I0419 16:11:41.323858 14 webhook.go:2672] Waiting for webhook configuration to be ready...
  STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 04/19/24 16:11:41.444
  STEP: Creating a dummy validating-webhook-configuration object @ 04/19/24 16:11:41.471
  STEP: Deleting the validating-webhook-configuration, which should be possible to remove @ 04/19/24 16:11:41.486
  STEP: Creating a dummy mutating-webhook-configuration object @ 04/19/24 16:11:41.506
  STEP: Deleting the mutating-webhook-configuration, which should be possible to remove @ 04/19/24 16:11:41.519
  I0419 16:11:41.667544 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5553" for this suite. @ 04/19/24 16:11:41.673
  STEP: Destroying namespace "webhook-markers-1714" for this suite. @ 04/19/24 16:11:41.694
• [5.207 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:61
  STEP: Creating a kubernetes client @ 04/19/24 16:11:41.705
  I0419 16:11:41.705688 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename containers @ 04/19/24 16:11:41.708
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:11:41.738
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:11:41.744
  STEP: Creating a pod to test override arguments @ 04/19/24 16:11:41.75
  E0419 16:11:42.117307      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:43.108504      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:11:43.787
  I0419 16:11:43.799547 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod client-containers-f6e56c92-7c33-4e13-a706-5e5ac441fdc6 container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/24 16:11:43.827
  I0419 16:11:43.885764 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-2397" for this suite. @ 04/19/24 16:11:43.893
• [2.200 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:205
  STEP: Creating a kubernetes client @ 04/19/24 16:11:43.905
  I0419 16:11:43.905761 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename daemonsets @ 04/19/24 16:11:43.908
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:11:43.942
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:11:43.948
  I0419 16:11:43.993121 14 daemon_set.go:208] Creating daemon "daemon-set" with a node selector
  STEP: Initially, daemon pods should not be running on any nodes. @ 04/19/24 16:11:44.005
  I0419 16:11:44.012668 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0419 16:11:44.013104 14 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Change node label to blue, check that daemon pod is launched. @ 04/19/24 16:11:44.013
  I0419 16:11:44.071111 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0419 16:11:44.071180 14 fixtures.go:130] Node eipo9quoh3ef-1 is running 0 daemon pod, expected 1
  E0419 16:11:44.109589      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:11:45.077063 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0419 16:11:45.077167 14 fixtures.go:130] Node eipo9quoh3ef-1 is running 0 daemon pod, expected 1
  E0419 16:11:45.110354      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:11:46.078281 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0419 16:11:46.079346 14 fixtures.go:135] Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Update the node label to green, and wait for daemons to be unscheduled @ 04/19/24 16:11:46.088
  E0419 16:11:46.110266      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:11:46.147635 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0419 16:11:46.147718 14 fixtures.go:135] Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
  E0419 16:11:47.111423      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:11:47.153709 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0419 16:11:47.153794 14 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate @ 04/19/24 16:11:47.153
  I0419 16:11:47.181198 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0419 16:11:47.181613 14 fixtures.go:130] Node eipo9quoh3ef-1 is running 0 daemon pod, expected 1
  E0419 16:11:48.111416      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:11:48.182617 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0419 16:11:48.182739 14 fixtures.go:130] Node eipo9quoh3ef-1 is running 0 daemon pod, expected 1
  E0419 16:11:49.111944      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:11:49.187321 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0419 16:11:49.187766 14 fixtures.go:135] Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 04/19/24 16:11:49.205
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2083, will wait for the garbage collector to delete the pods @ 04/19/24 16:11:49.205
  I0419 16:11:49.281014 14 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 13.247517ms
  I0419 16:11:49.383839 14 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 102.799932ms
  E0419 16:11:50.112390      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:11:50.493679 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0419 16:11:50.494499 14 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0419 16:11:50.503383 14 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"13237"},"items":null}

  I0419 16:11:50.511856 14 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"13237"},"items":null}

  I0419 16:11:50.570361 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-2083" for this suite. @ 04/19/24 16:11:50.58
• [6.688 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:57
  STEP: Creating a kubernetes client @ 04/19/24 16:11:50.594
  I0419 16:11:50.594274 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename secrets @ 04/19/24 16:11:50.596
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:11:50.643
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:11:50.648
  STEP: Creating secret with name secret-test-eef7a2a9-a24c-4753-b191-0778b3b66930 @ 04/19/24 16:11:50.655
  STEP: Creating a pod to test consume secrets @ 04/19/24 16:11:50.664
  E0419 16:11:51.112609      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:52.113171      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:53.113485      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:54.113849      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:11:54.718
  I0419 16:11:54.727323 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-secrets-23b00abd-ac14-4a5d-9338-c28d23a9e47d container secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/24 16:11:54.751
  I0419 16:11:54.800851 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9891" for this suite. @ 04/19/24 16:11:54.81
• [4.232 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] IngressClass API should support creating IngressClass API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/ingressclass.go:268
  STEP: Creating a kubernetes client @ 04/19/24 16:11:54.826
  I0419 16:11:54.826546 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename ingressclass @ 04/19/24 16:11:54.829
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:11:54.867
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:11:54.873
  STEP: getting /apis @ 04/19/24 16:11:54.878
  STEP: getting /apis/networking.k8s.io @ 04/19/24 16:11:54.888
  STEP: getting /apis/networking.k8s.iov1 @ 04/19/24 16:11:54.89
  STEP: creating @ 04/19/24 16:11:54.892
  STEP: getting @ 04/19/24 16:11:54.92
  STEP: listing @ 04/19/24 16:11:54.925
  STEP: watching @ 04/19/24 16:11:54.931
  I0419 16:11:54.931381 14 ingressclass.go:348] starting watch
  STEP: patching @ 04/19/24 16:11:54.933
  STEP: updating @ 04/19/24 16:11:54.943
  I0419 16:11:54.952811 14 ingressclass.go:364] waiting for watch events with expected annotations
  I0419 16:11:54.953395 14 ingressclass.go:377] saw patched and updated annotations
  STEP: deleting @ 04/19/24 16:11:54.954
  STEP: deleting a collection @ 04/19/24 16:11:54.978
  I0419 16:11:55.011858 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingressclass-3054" for this suite. @ 04/19/24 16:11:55.02
• [0.209 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1793
  STEP: Creating a kubernetes client @ 04/19/24 16:11:55.039
  I0419 16:11:55.039163 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename kubectl @ 04/19/24 16:11:55.042
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:11:55.078
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:11:55.082
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 04/19/24 16:11:55.087
  I0419 16:11:55.089038 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-1622 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  E0419 16:11:55.114590      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:11:55.270656 14 builder.go:146] stderr: ""
  I0419 16:11:55.270748 14 builder.go:147] stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod is running @ 04/19/24 16:11:55.27
  E0419 16:11:56.115309      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:57.116039      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:58.116985      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:59.117214      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:00.118476      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 04/19/24 16:12:00.323
  I0419 16:12:00.323470 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-1622 get pod e2e-test-httpd-pod -o json'
  I0419 16:12:00.476728 14 builder.go:146] stderr: ""
  I0419 16:12:00.476991 14 builder.go:147] stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2024-04-19T16:11:55Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-1622\",\n        \"resourceVersion\": \"13306\",\n        \"uid\": \"fdff175c-2f20-4b18-bc9b-88bc004e8718\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-8bmrd\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"eipo9quoh3ef-3\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-8bmrd\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-04-19T16:11:56Z\",\n                \"status\": \"True\",\n                \"type\": \"PodReadyToStartContainers\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-04-19T16:11:55Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-04-19T16:11:56Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-04-19T16:11:56Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-04-19T16:11:55Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"cri-o://9ae04d957001626150de37b4a5954b10e10a319aa7f4d1436e10ac7313748fc8\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2024-04-19T16:11:55Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.121.127\",\n        \"hostIPs\": [\n            {\n                \"ip\": \"192.168.121.127\"\n            }\n        ],\n        \"phase\": \"Running\",\n        \"podIP\": \"10.233.66.143\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.233.66.143\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2024-04-19T16:11:55Z\"\n    }\n}\n"
  STEP: replace the image in the pod @ 04/19/24 16:12:00.477
  I0419 16:12:00.477509 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-1622 replace -f -'
  I0419 16:12:00.791871 14 builder.go:146] stderr: ""
  I0419 16:12:00.791965 14 builder.go:147] stdout: "pod/e2e-test-httpd-pod replaced\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.36.1-1 @ 04/19/24 16:12:00.792
  I0419 16:12:00.808132 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-1622 delete pods e2e-test-httpd-pod'
  E0419 16:12:01.119431      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:02.119733      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:12:02.752678 14 builder.go:146] stderr: ""
  I0419 16:12:02.752765 14 builder.go:147] stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  I0419 16:12:02.753401 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1622" for this suite. @ 04/19/24 16:12:02.764
• [7.740 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:137
  STEP: Creating a kubernetes client @ 04/19/24 16:12:02.779
  I0419 16:12:02.779210 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 04/19/24 16:12:02.781
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:12:02.812
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:12:02.817
  STEP: create the container to handle the HTTPGet hook request. @ 04/19/24 16:12:02.829
  E0419 16:12:03.119947      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:04.120069      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 04/19/24 16:12:04.879
  E0419 16:12:05.121299      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:06.121563      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 04/19/24 16:12:06.934
  STEP: delete the pod with lifecycle hook @ 04/19/24 16:12:06.994
  E0419 16:12:07.122401      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:08.122751      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:12:09.030334 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-2769" for this suite. @ 04/19/24 16:12:09.047
• [6.285 seconds]
------------------------------
S
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:154
  STEP: Creating a kubernetes client @ 04/19/24 16:12:09.065
  I0419 16:12:09.065912 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 04/19/24 16:12:09.07
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:12:09.112
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:12:09.12
  E0419 16:12:09.124065      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the container to handle the HTTPGet hook request. @ 04/19/24 16:12:09.139
  E0419 16:12:10.124172      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:11.125035      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 04/19/24 16:12:11.199
  E0419 16:12:12.125446      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:13.125875      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 04/19/24 16:12:13.252
  E0419 16:12:14.126166      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:15.126510      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 04/19/24 16:12:15.291
  I0419 16:12:15.335971 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-9582" for this suite. @ 04/19/24 16:12:15.348
• [6.301 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:176
  STEP: Creating a kubernetes client @ 04/19/24 16:12:15.372
  I0419 16:12:15.372760 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename configmap @ 04/19/24 16:12:15.376
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:12:15.426
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:12:15.432
  STEP: Creating configMap with name configmap-test-upd-ab99b3bc-bf90-448c-b5ca-b9bbd6ef2750 @ 04/19/24 16:12:15.446
  STEP: Creating the pod @ 04/19/24 16:12:15.457
  E0419 16:12:16.127430      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:17.127681      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for pod with text data @ 04/19/24 16:12:17.499
  STEP: Waiting for pod with binary data @ 04/19/24 16:12:17.513
  I0419 16:12:17.523770 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2167" for this suite. @ 04/19/24 16:12:17.53
• [2.169 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:177
  STEP: Creating a kubernetes client @ 04/19/24 16:12:17.549
  I0419 16:12:17.550090 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename crd-webhook @ 04/19/24 16:12:17.552
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:12:17.6
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:12:17.605
  STEP: Setting up server cert @ 04/19/24 16:12:17.609
  E0419 16:12:18.128128      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:19.128740      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 04/19/24 16:12:19.225
  STEP: Deploying the custom resource conversion webhook pod @ 04/19/24 16:12:19.254
  STEP: Wait for the deployment to be ready @ 04/19/24 16:12:19.282
  I0419 16:12:19.304537 14 deployment.go:222] deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E0419 16:12:20.129330      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:21.129794      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 16:12:21.332
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 16:12:21.352
  E0419 16:12:22.130073      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:12:22.353414 14 util.go:427] Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  I0419 16:12:22.369794 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  E0419 16:12:23.129941      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:24.130651      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:25.131257      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 04/19/24 16:12:25.22
  STEP: Create a v2 custom resource @ 04/19/24 16:12:25.271
  STEP: List CRs in v1 @ 04/19/24 16:12:25.492
  STEP: List CRs in v2 @ 04/19/24 16:12:25.505
  E0419 16:12:26.132047      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:12:26.165475 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-8427" for this suite. @ 04/19/24 16:12:26.18
• [8.662 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should delete a collection of services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3572
  STEP: Creating a kubernetes client @ 04/19/24 16:12:26.236
  I0419 16:12:26.236772 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename services @ 04/19/24 16:12:26.239
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:12:26.27
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:12:26.275
  STEP: creating a collection of services @ 04/19/24 16:12:26.281
  I0419 16:12:26.281388 14 service.go:3608] Creating e2e-svc-a-jk9l2
  I0419 16:12:26.302375 14 service.go:3608] Creating e2e-svc-b-tdm2z
  I0419 16:12:26.320487 14 service.go:3608] Creating e2e-svc-c-4tgsx
  STEP: deleting service collection @ 04/19/24 16:12:26.349
  I0419 16:12:26.404385 14 service.go:3643] Collection of services has been deleted
  I0419 16:12:26.404579 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2298" for this suite. @ 04/19/24 16:12:26.413
• [0.194 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:528
  STEP: Creating a kubernetes client @ 04/19/24 16:12:26.427
  I0419 16:12:26.427035 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename container-probe @ 04/19/24 16:12:26.431
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:12:26.463
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:12:26.467
  STEP: Creating pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637 @ 04/19/24 16:12:26.473
  E0419 16:12:27.132530      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:28.133391      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/19/24 16:12:28.504
  I0419 16:12:28.510281 14 container_probe.go:1749] Initial restart count of pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 is 0
  I0419 16:12:28.515146 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:12:29.133539      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:30.133851      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:12:30.528223 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:12:31.134046      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:32.134058      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:12:32.541552 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:12:33.135448      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:34.135947      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:12:34.554160 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:12:35.137204      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:36.137798      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:12:36.563613 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:12:37.138085      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:38.138613      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:12:38.575792 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:12:39.138861      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:40.139115      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:12:40.592361 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:12:41.140167      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:42.140953      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:12:42.602715 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:12:43.141311      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:44.141639      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:12:44.614029 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:12:45.142196      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:46.142834      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:12:46.625537 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:12:47.143331      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:48.144049      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:12:48.635666 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:12:49.144226      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:50.144566      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:12:50.647610 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:12:51.144686      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:52.145239      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:12:52.657160 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:12:53.145476      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:54.146531      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:12:54.668522 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:12:55.146999      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:56.147195      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:12:56.677573 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:12:57.147349      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:58.147702      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:12:58.688236 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:12:59.148035      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:00.149243      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:13:00.700578 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:13:01.149924      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:02.150754      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:13:02.712452 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:13:03.151354      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:04.152411      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:13:04.726164 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:13:05.153735      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:06.153940      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:13:06.743729 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:13:07.154263      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:08.154481      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:13:08.754878 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:13:09.155409      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:10.155877      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:13:10.764428 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:13:11.156445      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:12.157323      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:13:12.778201 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:13:13.158952      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:14.158119      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:13:14.788621 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:13:15.158311      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:16.158647      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:13:16.801145 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:13:17.159870      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:18.162218      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:13:18.813372 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:13:19.161099      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:20.161457      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:13:20.825601 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:13:21.162657      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:22.162520      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:13:22.837698 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:13:23.163201      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:24.164259      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:13:24.862921 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:13:25.164434      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:26.165205      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:13:26.876798 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:13:27.165791      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:28.166872      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:13:28.887898 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:13:29.167718      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:30.169067      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:13:30.904525 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:13:31.169453      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:32.170112      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:13:32.944812 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:13:33.171194      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:34.171482      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:13:34.957244 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:13:35.171554      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:36.171923      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:13:36.967974 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:13:37.172168      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:38.172480      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:13:38.979701 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:13:39.172833      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:40.174073      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:13:40.989558 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:13:41.174709      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:42.175595      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:13:43.001703 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:13:43.175952      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:44.176287      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:13:45.011353 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:13:45.176871      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:46.178078      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:13:47.029182 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:13:47.178595      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:48.179817      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:13:49.039058 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:13:49.180484      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:50.180853      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:13:51.053639 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:13:51.181500      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:52.181794      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:13:53.063000 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:13:53.182314      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:54.183251      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:13:55.075455 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:13:55.183903      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:56.184385      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:13:57.087820 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:13:57.184256      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:58.185354      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:13:59.102004 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:13:59.185678      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:00.186098      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:14:01.112727 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:14:01.186947      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:02.187801      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:14:03.124572 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:14:03.188504      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:04.188803      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:14:05.138971 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:14:05.189600      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:06.190500      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:14:07.160575 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:14:07.190861      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:08.191393      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:14:09.172571 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:14:09.191541      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:10.192406      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:14:11.183195 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:14:11.193563      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:12.193730      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:14:13.193570 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:14:13.194370      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:14.194634      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:15.195943      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:14:15.204301 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:14:16.196168      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:17.198225      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:14:17.217141 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:14:18.197554      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:19.197862      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:14:19.228335 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:14:20.198501      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:21.199468      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:14:21.239645 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:14:22.199829      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:23.199967      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:14:23.248778 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:14:24.201879      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:25.205257      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:14:25.263398 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:14:26.202805      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:27.203657      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:14:27.273624 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:14:28.203499      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:29.203643      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:14:29.289334 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:14:30.204386      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:31.204594      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:14:31.298345 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:14:32.204817      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:33.205220      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:14:33.310552 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:14:34.205932      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:35.205986      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:14:35.318998 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:14:36.206557      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:37.206615      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:14:37.333834 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:14:38.207240      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:39.207448      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:14:39.344529 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:14:40.208866      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:41.208827      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:14:41.356048 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:14:42.209343      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:43.209620      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:14:43.366838 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:14:44.210889      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:45.211325      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:14:45.380447 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:14:46.211285      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:47.212090      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:14:47.396783 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:14:48.212580      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:49.213845      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:14:49.411901 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:14:50.215032      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:51.216203      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:14:51.424759 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:14:52.216538      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:53.216729      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:14:53.439554 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:14:54.216925      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:55.217474      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:14:55.448614 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:14:56.218538      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:57.219056      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:14:57.463836 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:14:58.219357      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:59.219668      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:14:59.476263 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:15:00.220238      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:01.220433      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:15:01.486022 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:15:02.220831      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:03.221437      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:15:03.497690 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:15:04.221720      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:05.223047      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:15:05.509523 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:15:06.223376      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:07.223886      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:15:07.521837 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:15:08.224342      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:09.227312      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:15:09.534676 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:15:10.228220      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:11.227815      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:15:11.547360 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:15:12.228624      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:13.229242      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:15:13.556432 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:15:14.229638      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:15.230008      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:15:15.567696 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:15:16.230535      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:17.230698      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:15:17.577271 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:15:18.231819      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:19.231991      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:15:19.590280 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:15:20.236474      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:21.234180      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:15:21.603900 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:15:22.234218      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:23.234585      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:15:23.615709 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:15:24.234990      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:25.237462      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:15:25.635173 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:15:26.236987      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:27.237400      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:15:27.647119 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:15:28.237984      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:29.241513      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:15:29.658046 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:15:30.240385      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:31.240723      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:15:31.666737 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:15:32.241271      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:33.241443      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:15:33.678520 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:15:34.241527      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:35.241918      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:15:35.690847 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:15:36.243108      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:37.242940      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:15:37.704953 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:15:38.243289      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:39.243517      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:15:39.714139 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:15:40.243700      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:41.243929      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:15:41.726045 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:15:42.245007      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:43.245311      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:15:43.738637 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:15:44.245495      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:45.245637      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:15:45.752153 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:15:46.246444      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:47.247372      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:15:47.764640 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:15:48.248019      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:49.249150      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:15:49.778263 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:15:50.249611      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:51.250738      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:15:51.789561 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:15:52.251019      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:53.252047      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:15:53.802444 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:15:54.252974      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:55.253360      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:15:55.813219 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:15:56.254379      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:57.255260      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:15:57.825996 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:15:58.255758      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:59.255874      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:15:59.835902 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:16:00.256267      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:01.256976      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:16:01.854154 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:16:02.257240      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:03.257316      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:16:03.897626 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:16:04.258225      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:05.258815      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:16:05.907379 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:16:06.258977      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:07.259985      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:16:07.917512 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:16:08.260974      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:09.261403      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:16:09.929692 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:16:10.261989      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:11.262611      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:16:11.939736 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:16:12.263368      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:13.264161      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:16:13.950780 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:16:14.264844      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:15.265513      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:16:15.958031 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:16:16.265717      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:17.266474      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:16:17.969695 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:16:18.266568      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:19.267027      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:16:19.985758 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:16:20.267290      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:21.268287      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:16:21.997644 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:16:22.269331      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:23.269783      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:16:24.008643 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:16:24.270176      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:25.270438      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:16:26.019642 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:16:26.271037      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:27.271306      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:16:28.031924 14 container_probe.go:1759] Get pod test-grpc-65f13032-ddb0-4751-88de-f92519873b88 in namespace container-probe-2637
  E0419 16:16:28.273014      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:29.272789      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 04/19/24 16:16:30.035
  I0419 16:16:30.071889 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-2637" for this suite. @ 04/19/24 16:16:30.087
• [243.683 seconds]
------------------------------
[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:223
  STEP: Creating a kubernetes client @ 04/19/24 16:16:30.113
  I0419 16:16:30.114574 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename downward-api @ 04/19/24 16:16:30.123
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:16:30.16
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:16:30.166
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 16:16:30.174
  E0419 16:16:30.272799      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:31.274739      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:32.274829      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:33.274509      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:16:34.221
  I0419 16:16:34.232036 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod downwardapi-volume-3a5279fd-a75a-484f-a1c2-408e8435b46a container client-container: <nil>
  E0419 16:16:34.275557      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod @ 04/19/24 16:16:34.279
  I0419 16:16:34.332232 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-98" for this suite. @ 04/19/24 16:16:34.35
• [4.260 seconds]
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:67
  STEP: Creating a kubernetes client @ 04/19/24 16:16:34.372
  I0419 16:16:34.372777 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename projected @ 04/19/24 16:16:34.378
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:16:34.431
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:16:34.439
  STEP: Creating projection with secret that has name projected-secret-test-d3a7c9d2-9f6b-409c-8b4c-81b86010ffc5 @ 04/19/24 16:16:34.454
  STEP: Creating a pod to test consume secrets @ 04/19/24 16:16:34.47
  E0419 16:16:35.274997      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:36.275788      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:37.275914      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:38.277440      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:16:38.528
  I0419 16:16:38.543397 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-projected-secrets-372ed5dc-e0f6-4df2-a1b2-e133ba4f6c4f container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/24 16:16:38.563
  I0419 16:16:38.609365 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6862" for this suite. @ 04/19/24 16:16:38.624
• [4.270 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:144
  STEP: Creating a kubernetes client @ 04/19/24 16:16:38.643
  I0419 16:16:38.643610 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename replicaset @ 04/19/24 16:16:38.654
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:16:38.693
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:16:38.698
  STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota @ 04/19/24 16:16:38.706
  I0419 16:16:38.726266 14 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  E0419 16:16:39.278357      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:40.279421      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:41.281131      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:42.281791      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:43.282749      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:16:43.739134 14 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/19/24 16:16:43.739
  STEP: getting scale subresource @ 04/19/24 16:16:43.739
  STEP: updating a scale subresource @ 04/19/24 16:16:43.749
  STEP: verifying the replicaset Spec.Replicas was modified @ 04/19/24 16:16:43.768
  STEP: Patch a scale subresource @ 04/19/24 16:16:43.784
  I0419 16:16:43.838250 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-8958" for this suite. @ 04/19/24 16:16:43.849
• [5.243 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve a basic endpoint from pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:789
  STEP: Creating a kubernetes client @ 04/19/24 16:16:43.894
  I0419 16:16:43.894534 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename services @ 04/19/24 16:16:43.897
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:16:43.929
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:16:43.936
  STEP: creating service endpoint-test2 in namespace services-5247 @ 04/19/24 16:16:43.943
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5247 to expose endpoints map[] @ 04/19/24 16:16:43.969
  I0419 16:16:43.992042 14 service.go:4258] successfully validated that service endpoint-test2 in namespace services-5247 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-5247 @ 04/19/24 16:16:43.992
  E0419 16:16:44.282865      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:45.283285      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5247 to expose endpoints map[pod1:[80]] @ 04/19/24 16:16:46.044
  I0419 16:16:46.080540 14 service.go:4258] successfully validated that service endpoint-test2 in namespace services-5247 exposes endpoints map[pod1:[80]]
  STEP: Checking if the Service forwards traffic to pod1 @ 04/19/24 16:16:46.081
  I0419 16:16:46.082773 14 resource.go:361] Creating new exec pod
  E0419 16:16:46.284424      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:47.284543      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:48.285173      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:16:49.123055 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-5247 exec execpod2ts4b -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  E0419 16:16:49.287755      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:16:49.521727 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  I0419 16:16:49.521843 14 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0419 16:16:49.522440 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-5247 exec execpod2ts4b -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.2.36 80'
  I0419 16:16:49.851316 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.2.36 80\nConnection to 10.233.2.36 80 port [tcp/http] succeeded!\n"
  I0419 16:16:49.851427 14 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Creating pod pod2 in namespace services-5247 @ 04/19/24 16:16:49.851
  E0419 16:16:50.288465      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:51.289045      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5247 to expose endpoints map[pod1:[80] pod2:[80]] @ 04/19/24 16:16:51.902
  I0419 16:16:51.933375 14 service.go:4258] successfully validated that service endpoint-test2 in namespace services-5247 exposes endpoints map[pod1:[80] pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod1 and pod2 @ 04/19/24 16:16:51.933
  E0419 16:16:52.290096      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:16:52.935893 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-5247 exec execpod2ts4b -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  I0419 16:16:53.266154 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  I0419 16:16:53.266272 14 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0419 16:16:53.266759 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-5247 exec execpod2ts4b -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.2.36 80'
  E0419 16:16:53.290514      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:16:53.607792 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.2.36 80\nConnection to 10.233.2.36 80 port [tcp/http] succeeded!\n"
  I0419 16:16:53.607925 14 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-5247 @ 04/19/24 16:16:53.608
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5247 to expose endpoints map[pod2:[80]] @ 04/19/24 16:16:53.634
  I0419 16:16:53.679459 14 service.go:4258] successfully validated that service endpoint-test2 in namespace services-5247 exposes endpoints map[pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod2 @ 04/19/24 16:16:53.679
  E0419 16:16:54.291722      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:16:54.682051 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-5247 exec execpod2ts4b -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  I0419 16:16:55.015483 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  I0419 16:16:55.015798 14 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0419 16:16:55.016188 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-5247 exec execpod2ts4b -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.2.36 80'
  E0419 16:16:55.291871      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:16:55.346205 14 builder.go:146] stderr: "+ nc -v -t -w 2 10.233.2.36 80\n+ echo hostName\nConnection to 10.233.2.36 80 port [tcp/http] succeeded!\n"
  I0419 16:16:55.346292 14 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod2 in namespace services-5247 @ 04/19/24 16:16:55.346
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5247 to expose endpoints map[] @ 04/19/24 16:16:55.377
  I0419 16:16:55.423244 14 service.go:4258] successfully validated that service endpoint-test2 in namespace services-5247 exposes endpoints map[]
  I0419 16:16:55.455598 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5247" for this suite. @ 04/19/24 16:16:55.465
• [11.582 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:1015
  STEP: Creating a kubernetes client @ 04/19/24 16:16:55.476
  I0419 16:16:55.476935 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename resourcequota @ 04/19/24 16:16:55.48
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:16:55.515
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:16:55.519
  STEP: Creating resourceQuota "e2e-rq-status-5rs7b" @ 04/19/24 16:16:55.535
  I0419 16:16:55.551690 14 resource_quota.go:1051] Resource quota "e2e-rq-status-5rs7b" reports spec: hard cpu limit of 500m
  I0419 16:16:55.552013 14 resource_quota.go:1053] Resource quota "e2e-rq-status-5rs7b" reports spec: hard memory limit of 500Mi
  STEP: Updating resourceQuota "e2e-rq-status-5rs7b" /status @ 04/19/24 16:16:55.552
  STEP: Confirm /status for "e2e-rq-status-5rs7b" resourceQuota via watch @ 04/19/24 16:16:55.57
  I0419 16:16:55.573695 14 resource_quota.go:1080] observed resourceQuota "e2e-rq-status-5rs7b" in namespace "resourcequota-2478" with hard status: v1.ResourceList(nil)
  I0419 16:16:55.574091 14 resource_quota.go:1083] Found resourceQuota "e2e-rq-status-5rs7b" in namespace "resourcequota-2478" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  I0419 16:16:55.574172 14 resource_quota.go:1090] ResourceQuota "e2e-rq-status-5rs7b" /status was updated
  STEP: Patching hard spec values for cpu & memory @ 04/19/24 16:16:55.581
  I0419 16:16:55.592584 14 resource_quota.go:1101] Resource quota "e2e-rq-status-5rs7b" reports spec: hard cpu limit of 1
  I0419 16:16:55.592681 14 resource_quota.go:1102] Resource quota "e2e-rq-status-5rs7b" reports spec: hard memory limit of 1Gi
  STEP: Patching "e2e-rq-status-5rs7b" /status @ 04/19/24 16:16:55.592
  STEP: Confirm /status for "e2e-rq-status-5rs7b" resourceQuota via watch @ 04/19/24 16:16:55.604
  I0419 16:16:55.607904 14 resource_quota.go:1124] observed resourceQuota "e2e-rq-status-5rs7b" in namespace "resourcequota-2478" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  I0419 16:16:55.608076 14 resource_quota.go:1127] Found resourceQuota "e2e-rq-status-5rs7b" in namespace "resourcequota-2478" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
  I0419 16:16:55.608230 14 resource_quota.go:1134] ResourceQuota "e2e-rq-status-5rs7b" /status was patched
  STEP: Get "e2e-rq-status-5rs7b" /status @ 04/19/24 16:16:55.608
  I0419 16:16:55.623200 14 resource_quota.go:1145] Resourcequota "e2e-rq-status-5rs7b" reports status: hard cpu of 1
  I0419 16:16:55.623288 14 resource_quota.go:1147] Resourcequota "e2e-rq-status-5rs7b" reports status: hard memory of 1Gi
  STEP: Repatching "e2e-rq-status-5rs7b" /status before checking Spec is unchanged @ 04/19/24 16:16:55.629
  I0419 16:16:55.642554 14 resource_quota.go:1167] Resourcequota "e2e-rq-status-5rs7b" reports status: hard cpu of 2
  I0419 16:16:55.642697 14 resource_quota.go:1169] Resourcequota "e2e-rq-status-5rs7b" reports status: hard memory of 2Gi
  I0419 16:16:55.646438 14 resource_quota.go:1181] Found resourceQuota "e2e-rq-status-5rs7b" in namespace "resourcequota-2478" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}
  I0419 16:16:55.652190 14 resource_quota.go:1212] ResourceQuota "e2e-rq-status-5rs7b" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5rs7b", GenerateName:"", Namespace:"resourcequota-2478", SelfLink:"", UID:"0efebe94-b9f9-4b0a-96fa-bcb56b554d22", ResourceVersion:"14250", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5rs7b"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00124e258), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00124e2b8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00124e360), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:16:56.293129      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:57.293806      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:58.294553      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:59.295018      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:00.295109      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:17:00.660745 14 resource_quota.go:1212] ResourceQuota "e2e-rq-status-5rs7b" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5rs7b", GenerateName:"", Namespace:"resourcequota-2478", SelfLink:"", UID:"0efebe94-b9f9-4b0a-96fa-bcb56b554d22", ResourceVersion:"14250", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5rs7b"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000508e70), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000508eb8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000508ee8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:17:01.295368      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:02.296145      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:03.297208      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:04.297004      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:05.297605      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:17:05.657971 14 resource_quota.go:1212] ResourceQuota "e2e-rq-status-5rs7b" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5rs7b", GenerateName:"", Namespace:"resourcequota-2478", SelfLink:"", UID:"0efebe94-b9f9-4b0a-96fa-bcb56b554d22", ResourceVersion:"14250", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5rs7b"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000509188), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0005091b8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000509200), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:17:06.298951      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:07.299166      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:08.300083      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:09.300365      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:10.301041      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:17:10.655947 14 resource_quota.go:1212] ResourceQuota "e2e-rq-status-5rs7b" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5rs7b", GenerateName:"", Namespace:"resourcequota-2478", SelfLink:"", UID:"0efebe94-b9f9-4b0a-96fa-bcb56b554d22", ResourceVersion:"14250", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5rs7b"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00124e7f8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00124e840), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00124e8a0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:17:11.301129      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:12.301413      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:13.303709      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:14.304082      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:15.304465      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:17:15.657037 14 resource_quota.go:1212] ResourceQuota "e2e-rq-status-5rs7b" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5rs7b", GenerateName:"", Namespace:"resourcequota-2478", SelfLink:"", UID:"0efebe94-b9f9-4b0a-96fa-bcb56b554d22", ResourceVersion:"14250", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5rs7b"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00124ebe8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00124ec60), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00124ecd8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:17:16.304634      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:17.304720      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:18.304855      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:19.305265      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:20.306419      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:17:20.659178 14 resource_quota.go:1212] ResourceQuota "e2e-rq-status-5rs7b" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5rs7b", GenerateName:"", Namespace:"resourcequota-2478", SelfLink:"", UID:"0efebe94-b9f9-4b0a-96fa-bcb56b554d22", ResourceVersion:"14250", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5rs7b"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00124ef18), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00124ef78), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00124efa8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:17:21.306847      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:22.307591      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:23.308156      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:24.308529      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:25.308585      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:17:25.656632 14 resource_quota.go:1212] ResourceQuota "e2e-rq-status-5rs7b" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5rs7b", GenerateName:"", Namespace:"resourcequota-2478", SelfLink:"", UID:"0efebe94-b9f9-4b0a-96fa-bcb56b554d22", ResourceVersion:"14250", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5rs7b"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000509608), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000509650), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0005096b0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:17:26.309175      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:27.309802      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:28.311481      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:29.311286      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:30.311577      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:17:30.654336 14 resource_quota.go:1212] ResourceQuota "e2e-rq-status-5rs7b" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5rs7b", GenerateName:"", Namespace:"resourcequota-2478", SelfLink:"", UID:"0efebe94-b9f9-4b0a-96fa-bcb56b554d22", ResourceVersion:"14250", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5rs7b"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00124f728), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00124f890), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00124f8c0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:17:31.312507      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:32.312594      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:33.313082      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:34.313391      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:35.313634      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:17:35.660637 14 resource_quota.go:1212] ResourceQuota "e2e-rq-status-5rs7b" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5rs7b", GenerateName:"", Namespace:"resourcequota-2478", SelfLink:"", UID:"0efebe94-b9f9-4b0a-96fa-bcb56b554d22", ResourceVersion:"14250", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5rs7b"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00124fe48), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00124fea8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00124fed8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:17:36.314109      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:37.314957      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:38.315770      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:39.316036      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:40.316438      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:17:40.657791 14 resource_quota.go:1212] ResourceQuota "e2e-rq-status-5rs7b" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5rs7b", GenerateName:"", Namespace:"resourcequota-2478", SelfLink:"", UID:"0efebe94-b9f9-4b0a-96fa-bcb56b554d22", ResourceVersion:"14250", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5rs7b"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0005099c8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0005099f8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000509a58), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:17:41.316948      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:42.317831      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:43.317690      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:44.318002      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:45.318853      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:17:45.657125 14 resource_quota.go:1212] ResourceQuota "e2e-rq-status-5rs7b" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5rs7b", GenerateName:"", Namespace:"resourcequota-2478", SelfLink:"", UID:"0efebe94-b9f9-4b0a-96fa-bcb56b554d22", ResourceVersion:"14250", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5rs7b"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004f122b8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004f12330), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004f12360), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:17:46.319133      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:47.320346      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:48.321043      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:49.321154      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:50.321938      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:17:50.655751 14 resource_quota.go:1212] ResourceQuota "e2e-rq-status-5rs7b" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5rs7b", GenerateName:"", Namespace:"resourcequota-2478", SelfLink:"", UID:"0efebe94-b9f9-4b0a-96fa-bcb56b554d22", ResourceVersion:"14250", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5rs7b"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000509d28), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000509d88), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000509db8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:17:51.322164      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:52.322621      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:53.322983      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:54.323114      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:55.323421      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:17:55.656269 14 resource_quota.go:1212] ResourceQuota "e2e-rq-status-5rs7b" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5rs7b", GenerateName:"", Namespace:"resourcequota-2478", SelfLink:"", UID:"0efebe94-b9f9-4b0a-96fa-bcb56b554d22", ResourceVersion:"14250", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5rs7b"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004f126a8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004f126f0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004f12738), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:17:56.324035      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:57.324379      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:58.324961      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:59.325747      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:00.325733      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:18:00.661266 14 resource_quota.go:1212] ResourceQuota "e2e-rq-status-5rs7b" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5rs7b", GenerateName:"", Namespace:"resourcequota-2478", SelfLink:"", UID:"0efebe94-b9f9-4b0a-96fa-bcb56b554d22", ResourceVersion:"14250", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5rs7b"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d020c0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d021c8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d02210), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:18:01.325894      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:02.326204      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:03.326779      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:04.327935      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:05.328198      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:18:05.656743 14 resource_quota.go:1212] ResourceQuota "e2e-rq-status-5rs7b" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5rs7b", GenerateName:"", Namespace:"resourcequota-2478", SelfLink:"", UID:"0efebe94-b9f9-4b0a-96fa-bcb56b554d22", ResourceVersion:"14250", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5rs7b"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d024e0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d02528), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d02570), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:18:06.328503      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:07.328688      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:08.329583      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:09.330448      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:10.331764      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:18:10.653559 14 resource_quota.go:1212] ResourceQuota "e2e-rq-status-5rs7b" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5rs7b", GenerateName:"", Namespace:"resourcequota-2478", SelfLink:"", UID:"0efebe94-b9f9-4b0a-96fa-bcb56b554d22", ResourceVersion:"14250", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5rs7b"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d028d0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d02930), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d02990), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:18:11.332327      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:12.332989      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:13.333424      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:14.333735      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:15.333987      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:18:15.658155 14 resource_quota.go:1212] ResourceQuota "e2e-rq-status-5rs7b" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5rs7b", GenerateName:"", Namespace:"resourcequota-2478", SelfLink:"", UID:"0efebe94-b9f9-4b0a-96fa-bcb56b554d22", ResourceVersion:"14250", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5rs7b"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004f12c48), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004f12cc0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004f12cf0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:18:16.334218      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:17.335083      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:18.335894      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:19.336758      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:20.337077      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:18:20.658183 14 resource_quota.go:1212] ResourceQuota "e2e-rq-status-5rs7b" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5rs7b", GenerateName:"", Namespace:"resourcequota-2478", SelfLink:"", UID:"0efebe94-b9f9-4b0a-96fa-bcb56b554d22", ResourceVersion:"14250", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5rs7b"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004f12ed0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004f12f00), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004f12f60), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:18:21.337244      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:22.338127      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:23.339154      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:24.339486      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:25.339448      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:18:25.660712 14 resource_quota.go:1212] ResourceQuota "e2e-rq-status-5rs7b" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5rs7b", GenerateName:"", Namespace:"resourcequota-2478", SelfLink:"", UID:"0efebe94-b9f9-4b0a-96fa-bcb56b554d22", ResourceVersion:"14250", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5rs7b"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d02f78), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d02fc0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d02ff0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:18:26.339795      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:27.340796      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:28.343357      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:29.343483      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:30.343867      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:18:30.654407 14 resource_quota.go:1212] ResourceQuota "e2e-rq-status-5rs7b" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5rs7b", GenerateName:"", Namespace:"resourcequota-2478", SelfLink:"", UID:"0efebe94-b9f9-4b0a-96fa-bcb56b554d22", ResourceVersion:"14250", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5rs7b"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d021c8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d02210), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d02258), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:18:31.344086      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:32.344386      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:33.344739      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:34.345650      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:35.345886      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:18:35.658099 14 resource_quota.go:1212] ResourceQuota "e2e-rq-status-5rs7b" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5rs7b", GenerateName:"", Namespace:"resourcequota-2478", SelfLink:"", UID:"0efebe94-b9f9-4b0a-96fa-bcb56b554d22", ResourceVersion:"14250", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5rs7b"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d02558), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d025a0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d02648), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:18:36.347563      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:37.347444      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:38.348486      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:39.348680      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:40.348981      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:18:40.659157 14 resource_quota.go:1212] ResourceQuota "e2e-rq-status-5rs7b" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5rs7b", GenerateName:"", Namespace:"resourcequota-2478", SelfLink:"", UID:"0efebe94-b9f9-4b0a-96fa-bcb56b554d22", ResourceVersion:"14250", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5rs7b"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d02990), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d02a20), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d02ac8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:18:41.349306      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:42.350252      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:43.350761      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:44.351048      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:45.351373      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:18:45.658945 14 resource_quota.go:1212] ResourceQuota "e2e-rq-status-5rs7b" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5rs7b", GenerateName:"", Namespace:"resourcequota-2478", SelfLink:"", UID:"0efebe94-b9f9-4b0a-96fa-bcb56b554d22", ResourceVersion:"14250", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5rs7b"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d02db0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d02e40), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d02e70), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:18:46.351812      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:47.352137      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:48.352819      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:49.352940      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:50.353487      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:18:50.654781 14 resource_quota.go:1212] ResourceQuota "e2e-rq-status-5rs7b" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5rs7b", GenerateName:"", Namespace:"resourcequota-2478", SelfLink:"", UID:"0efebe94-b9f9-4b0a-96fa-bcb56b554d22", ResourceVersion:"14250", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5rs7b"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d031a0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d031d0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d03230), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:18:51.354191      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:52.354623      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:53.354785      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:54.355383      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:55.356126      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:18:55.656504 14 resource_quota.go:1212] ResourceQuota "e2e-rq-status-5rs7b" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5rs7b", GenerateName:"", Namespace:"resourcequota-2478", SelfLink:"", UID:"0efebe94-b9f9-4b0a-96fa-bcb56b554d22", ResourceVersion:"14250", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5rs7b"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d034e8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d03518), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 16, 55, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d03590), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:18:56.357169      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:57.357906      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:58.358640      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:59.358899      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:00.359193      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:19:00.658728 14 resource_quota.go:1209] ResourceQuota "e2e-rq-status-5rs7b" Spec was unchanged and /status reset
  I0419 16:19:00.660744 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2478" for this suite. @ 04/19/24 16:19:00.677
• [125.223 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount an API token into pods [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:80
  STEP: Creating a kubernetes client @ 04/19/24 16:19:00.707
  I0419 16:19:00.707727 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename svcaccounts @ 04/19/24 16:19:00.71
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:19:00.767
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:19:00.773
  E0419 16:19:01.359572      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:02.360444      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: reading a file in the container @ 04/19/24 16:19:02.817
  I0419 16:19:02.817871 14 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2948 pod-service-account-68439c7d-bb56-4ae6-87e5-b037392d6068 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
  STEP: reading a file in the container @ 04/19/24 16:19:03.123
  I0419 16:19:03.125445 14 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2948 pod-service-account-68439c7d-bb56-4ae6-87e5-b037392d6068 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
  E0419 16:19:03.360647      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: reading a file in the container @ 04/19/24 16:19:03.433
  I0419 16:19:03.434211 14 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2948 pod-service-account-68439c7d-bb56-4ae6-87e5-b037392d6068 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
  I0419 16:19:03.749385 14 service_accounts.go:114] Got root ca configmap in namespace "svcaccounts-2948"
  I0419 16:19:03.753750 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-2948" for this suite. @ 04/19/24 16:19:03.762
• [3.066 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:158
  STEP: Creating a kubernetes client @ 04/19/24 16:19:03.774
  I0419 16:19:03.774051 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename runtimeclass @ 04/19/24 16:19:03.776
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:19:03.82
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:19:03.825
  STEP: Deleting RuntimeClass runtimeclass-2692-delete-me @ 04/19/24 16:19:03.846
  STEP: Waiting for the RuntimeClass to disappear @ 04/19/24 16:19:03.9
  I0419 16:19:03.918740 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-2692" for this suite. @ 04/19/24 16:19:03.925
• [0.160 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:210
  STEP: Creating a kubernetes client @ 04/19/24 16:19:03.935
  I0419 16:19:03.935233 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename emptydir @ 04/19/24 16:19:03.937
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:19:03.961
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:19:03.966
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 04/19/24 16:19:03.971
  E0419 16:19:04.360702      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:05.361037      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:19:06.001
  I0419 16:19:06.007367 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-41271c55-6033-4619-8fcb-59cf39951bc3 container test-container: <nil>
  STEP: delete the pod @ 04/19/24 16:19:06.035
  I0419 16:19:06.055374 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9067" for this suite. @ 04/19/24 16:19:06.061
• [2.136 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:195
  STEP: Creating a kubernetes client @ 04/19/24 16:19:06.071
  I0419 16:19:06.071964 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/19/24 16:19:06.075
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:19:06.11
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:19:06.115
  I0419 16:19:06.122601 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  E0419 16:19:06.362049      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:07.362111      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 04/19/24 16:19:07.935
  I0419 16:19:07.936295 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=crd-publish-openapi-2257 --namespace=crd-publish-openapi-2257 create -f -'
  I0419 16:19:08.261304 14 builder.go:146] stderr: ""
  I0419 16:19:08.261433 14 builder.go:147] stdout: "e2e-test-crd-publish-openapi-1661-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  I0419 16:19:08.261832 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=crd-publish-openapi-2257 --namespace=crd-publish-openapi-2257 delete e2e-test-crd-publish-openapi-1661-crds test-cr'
  E0419 16:19:08.362907      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:19:08.561762 14 builder.go:146] stderr: ""
  I0419 16:19:08.562358 14 builder.go:147] stdout: "e2e-test-crd-publish-openapi-1661-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  I0419 16:19:08.562826 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=crd-publish-openapi-2257 --namespace=crd-publish-openapi-2257 apply -f -'
  I0419 16:19:08.769141 14 builder.go:146] stderr: ""
  I0419 16:19:08.769546 14 builder.go:147] stdout: "e2e-test-crd-publish-openapi-1661-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  I0419 16:19:08.770020 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=crd-publish-openapi-2257 --namespace=crd-publish-openapi-2257 delete e2e-test-crd-publish-openapi-1661-crds test-cr'
  I0419 16:19:09.021030 14 builder.go:146] stderr: ""
  I0419 16:19:09.021110 14 builder.go:147] stdout: "e2e-test-crd-publish-openapi-1661-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 04/19/24 16:19:09.021
  I0419 16:19:09.021531 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=crd-publish-openapi-2257 explain e2e-test-crd-publish-openapi-1661-crds'
  I0419 16:19:09.200924 14 builder.go:146] stderr: ""
  I0419 16:19:09.201069 14 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-unknown-at-root.example.com\nKIND:       e2e-test-crd-publish-openapi-1661-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties at root for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E0419 16:19:09.363933      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:10.365011      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:19:10.970201 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-2257" for this suite. @ 04/19/24 16:19:10.997
• [4.941 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:386
  STEP: Creating a kubernetes client @ 04/19/24 16:19:11.016
  I0419 16:19:11.016582 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename secrets @ 04/19/24 16:19:11.021
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:19:11.05
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:19:11.055
  I0419 16:19:11.143879 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-894" for this suite. @ 04/19/24 16:19:11.15
• [0.149 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:142
  STEP: Creating a kubernetes client @ 04/19/24 16:19:11.168
  I0419 16:19:11.168162 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename crd-webhook @ 04/19/24 16:19:11.171
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:19:11.193
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:19:11.197
  STEP: Setting up server cert @ 04/19/24 16:19:11.203
  E0419 16:19:11.365264      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 04/19/24 16:19:12.172
  STEP: Deploying the custom resource conversion webhook pod @ 04/19/24 16:19:12.192
  STEP: Wait for the deployment to be ready @ 04/19/24 16:19:12.224
  I0419 16:19:12.253028 14 deployment.go:222] deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E0419 16:19:12.366587      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:13.367169      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 16:19:14.285
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 16:19:14.323
  E0419 16:19:14.367692      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:19:15.323690 14 util.go:427] Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  I0419 16:19:15.341814 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  E0419 16:19:15.369444      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:16.370528      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:17.370447      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 04/19/24 16:19:18.127
  STEP: v2 custom resource should be converted @ 04/19/24 16:19:18.136
  E0419 16:19:18.370816      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:19:18.778771 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-4041" for this suite. @ 04/19/24 16:19:18.809
• [7.655 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:137
  STEP: Creating a kubernetes client @ 04/19/24 16:19:18.827
  I0419 16:19:18.827705 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename dns @ 04/19/24 16:19:18.831
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:19:18.849
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:19:18.854
  STEP: Creating a test headless service @ 04/19/24 16:19:18.858
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5044.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5044.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5044.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5044.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5044.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-5044.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5044.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-5044.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5044.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-5044.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5044.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-5044.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 6.45.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.45.6_udp@PTR;check="$$(dig +tcp +noall +answer +search 6.45.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.45.6_tcp@PTR;sleep 1; done
   @ 04/19/24 16:19:18.891
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5044.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5044.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5044.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5044.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5044.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-5044.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5044.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-5044.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5044.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-5044.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5044.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-5044.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 6.45.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.45.6_udp@PTR;check="$$(dig +tcp +noall +answer +search 6.45.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.45.6_tcp@PTR;sleep 1; done
   @ 04/19/24 16:19:18.892
  STEP: creating a pod to probe DNS @ 04/19/24 16:19:18.892
  STEP: submitting the pod to kubernetes @ 04/19/24 16:19:18.892
  E0419 16:19:19.371091      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:20.371944      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:21.372345      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:22.372490      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:23.374305      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:24.374373      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:25.375354      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:26.375506      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:27.375684      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:28.376163      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:29.377236      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:30.377425      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:31.377672      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:32.377799      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:33.381542      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:34.382662      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:35.383518      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:36.385228      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:37.385604      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:38.386104      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/19/24 16:19:39.018
  STEP: looking for the results for each expected name from probers @ 04/19/24 16:19:39.026
  I0419 16:19:39.047637 14 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-5044.svc.cluster.local from pod dns-5044/dns-test-c7b05024-e565-4932-8192-e86282fdc613: the server could not find the requested resource (get pods dns-test-c7b05024-e565-4932-8192-e86282fdc613)
  I0419 16:19:39.060826 14 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-5044.svc.cluster.local from pod dns-5044/dns-test-c7b05024-e565-4932-8192-e86282fdc613: the server could not find the requested resource (get pods dns-test-c7b05024-e565-4932-8192-e86282fdc613)
  I0419 16:19:39.071855 14 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5044.svc.cluster.local from pod dns-5044/dns-test-c7b05024-e565-4932-8192-e86282fdc613: the server could not find the requested resource (get pods dns-test-c7b05024-e565-4932-8192-e86282fdc613)
  I0419 16:19:39.082841 14 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5044.svc.cluster.local from pod dns-5044/dns-test-c7b05024-e565-4932-8192-e86282fdc613: the server could not find the requested resource (get pods dns-test-c7b05024-e565-4932-8192-e86282fdc613)
  I0419 16:19:39.147224 14 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-5044.svc.cluster.local from pod dns-5044/dns-test-c7b05024-e565-4932-8192-e86282fdc613: the server could not find the requested resource (get pods dns-test-c7b05024-e565-4932-8192-e86282fdc613)
  I0419 16:19:39.166553 14 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-5044.svc.cluster.local from pod dns-5044/dns-test-c7b05024-e565-4932-8192-e86282fdc613: the server could not find the requested resource (get pods dns-test-c7b05024-e565-4932-8192-e86282fdc613)
  I0419 16:19:39.177337 14 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5044.svc.cluster.local from pod dns-5044/dns-test-c7b05024-e565-4932-8192-e86282fdc613: the server could not find the requested resource (get pods dns-test-c7b05024-e565-4932-8192-e86282fdc613)
  I0419 16:19:39.188560 14 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5044.svc.cluster.local from pod dns-5044/dns-test-c7b05024-e565-4932-8192-e86282fdc613: the server could not find the requested resource (get pods dns-test-c7b05024-e565-4932-8192-e86282fdc613)
  I0419 16:19:39.228822 14 dns_common.go:489] Lookups using dns-5044/dns-test-c7b05024-e565-4932-8192-e86282fdc613 failed for: [wheezy_udp@dns-test-service.dns-5044.svc.cluster.local wheezy_tcp@dns-test-service.dns-5044.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5044.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5044.svc.cluster.local jessie_udp@dns-test-service.dns-5044.svc.cluster.local jessie_tcp@dns-test-service.dns-5044.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5044.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5044.svc.cluster.local]

  I0419 16:19:39.273159 14 dns_common.go:495] Pod client logs for webserver: 
  I0419 16:19:39.288742 14 dns_common.go:495] Pod client logs for querier: 
  I0419 16:19:39.304694 14 dns_common.go:495] Pod client logs for jessie-querier: 
  E0419 16:19:39.386724      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:40.387820      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:41.388800      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:42.389255      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:43.389755      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:19:44.037095 14 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-5044.svc.cluster.local from pod dns-5044/dns-test-c7b05024-e565-4932-8192-e86282fdc613: the server could not find the requested resource (get pods dns-test-c7b05024-e565-4932-8192-e86282fdc613)
  I0419 16:19:44.049181 14 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-5044.svc.cluster.local from pod dns-5044/dns-test-c7b05024-e565-4932-8192-e86282fdc613: the server could not find the requested resource (get pods dns-test-c7b05024-e565-4932-8192-e86282fdc613)
  I0419 16:19:44.058917 14 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5044.svc.cluster.local from pod dns-5044/dns-test-c7b05024-e565-4932-8192-e86282fdc613: the server could not find the requested resource (get pods dns-test-c7b05024-e565-4932-8192-e86282fdc613)
  I0419 16:19:44.067829 14 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5044.svc.cluster.local from pod dns-5044/dns-test-c7b05024-e565-4932-8192-e86282fdc613: the server could not find the requested resource (get pods dns-test-c7b05024-e565-4932-8192-e86282fdc613)
  I0419 16:19:44.115808 14 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-5044.svc.cluster.local from pod dns-5044/dns-test-c7b05024-e565-4932-8192-e86282fdc613: the server could not find the requested resource (get pods dns-test-c7b05024-e565-4932-8192-e86282fdc613)
  I0419 16:19:44.124311 14 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-5044.svc.cluster.local from pod dns-5044/dns-test-c7b05024-e565-4932-8192-e86282fdc613: the server could not find the requested resource (get pods dns-test-c7b05024-e565-4932-8192-e86282fdc613)
  I0419 16:19:44.133694 14 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5044.svc.cluster.local from pod dns-5044/dns-test-c7b05024-e565-4932-8192-e86282fdc613: the server could not find the requested resource (get pods dns-test-c7b05024-e565-4932-8192-e86282fdc613)
  I0419 16:19:44.145818 14 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5044.svc.cluster.local from pod dns-5044/dns-test-c7b05024-e565-4932-8192-e86282fdc613: the server could not find the requested resource (get pods dns-test-c7b05024-e565-4932-8192-e86282fdc613)
  I0419 16:19:44.186445 14 dns_common.go:489] Lookups using dns-5044/dns-test-c7b05024-e565-4932-8192-e86282fdc613 failed for: [wheezy_udp@dns-test-service.dns-5044.svc.cluster.local wheezy_tcp@dns-test-service.dns-5044.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5044.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5044.svc.cluster.local jessie_udp@dns-test-service.dns-5044.svc.cluster.local jessie_tcp@dns-test-service.dns-5044.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5044.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5044.svc.cluster.local]

  I0419 16:19:44.207257 14 dns_common.go:495] Pod client logs for webserver: 
  I0419 16:19:44.221272 14 dns_common.go:495] Pod client logs for querier: 
  I0419 16:19:44.238917 14 dns_common.go:495] Pod client logs for jessie-querier: 
  E0419 16:19:44.390554      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:45.391186      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:46.391222      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:47.391977      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:48.392648      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:19:49.040321 14 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-5044.svc.cluster.local from pod dns-5044/dns-test-c7b05024-e565-4932-8192-e86282fdc613: the server could not find the requested resource (get pods dns-test-c7b05024-e565-4932-8192-e86282fdc613)
  I0419 16:19:49.052666 14 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-5044.svc.cluster.local from pod dns-5044/dns-test-c7b05024-e565-4932-8192-e86282fdc613: the server could not find the requested resource (get pods dns-test-c7b05024-e565-4932-8192-e86282fdc613)
  I0419 16:19:49.063789 14 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5044.svc.cluster.local from pod dns-5044/dns-test-c7b05024-e565-4932-8192-e86282fdc613: the server could not find the requested resource (get pods dns-test-c7b05024-e565-4932-8192-e86282fdc613)
  I0419 16:19:49.074981 14 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5044.svc.cluster.local from pod dns-5044/dns-test-c7b05024-e565-4932-8192-e86282fdc613: the server could not find the requested resource (get pods dns-test-c7b05024-e565-4932-8192-e86282fdc613)
  I0419 16:19:49.126255 14 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-5044.svc.cluster.local from pod dns-5044/dns-test-c7b05024-e565-4932-8192-e86282fdc613: the server could not find the requested resource (get pods dns-test-c7b05024-e565-4932-8192-e86282fdc613)
  I0419 16:19:49.139513 14 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-5044.svc.cluster.local from pod dns-5044/dns-test-c7b05024-e565-4932-8192-e86282fdc613: the server could not find the requested resource (get pods dns-test-c7b05024-e565-4932-8192-e86282fdc613)
  I0419 16:19:49.154988 14 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5044.svc.cluster.local from pod dns-5044/dns-test-c7b05024-e565-4932-8192-e86282fdc613: the server could not find the requested resource (get pods dns-test-c7b05024-e565-4932-8192-e86282fdc613)
  I0419 16:19:49.168555 14 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5044.svc.cluster.local from pod dns-5044/dns-test-c7b05024-e565-4932-8192-e86282fdc613: the server could not find the requested resource (get pods dns-test-c7b05024-e565-4932-8192-e86282fdc613)
  I0419 16:19:49.209841 14 dns_common.go:489] Lookups using dns-5044/dns-test-c7b05024-e565-4932-8192-e86282fdc613 failed for: [wheezy_udp@dns-test-service.dns-5044.svc.cluster.local wheezy_tcp@dns-test-service.dns-5044.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5044.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5044.svc.cluster.local jessie_udp@dns-test-service.dns-5044.svc.cluster.local jessie_tcp@dns-test-service.dns-5044.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5044.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5044.svc.cluster.local]

  I0419 16:19:49.227068 14 dns_common.go:495] Pod client logs for webserver: 
  I0419 16:19:49.242517 14 dns_common.go:495] Pod client logs for querier: 
  I0419 16:19:49.260523 14 dns_common.go:495] Pod client logs for jessie-querier: 
  E0419 16:19:49.392994      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:50.393679      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:51.394569      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:52.395193      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:53.394892      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:19:54.176647 14 dns_common.go:527] DNS probes using dns-5044/dns-test-c7b05024-e565-4932-8192-e86282fdc613 succeeded

  STEP: deleting the pod @ 04/19/24 16:19:54.177
  STEP: deleting the test service @ 04/19/24 16:19:54.228
  STEP: deleting the test headless service @ 04/19/24 16:19:54.278
  I0419 16:19:54.313841 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-5044" for this suite. @ 04/19/24 16:19:54.324
• [35.507 seconds]
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:793
  STEP: Creating a kubernetes client @ 04/19/24 16:19:54.335
  I0419 16:19:54.335341 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename statefulset @ 04/19/24 16:19:54.339
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:19:54.359
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:19:54.365
  STEP: Creating service test in namespace statefulset-6512 @ 04/19/24 16:19:54.371
  STEP: Looking for a node to schedule stateful set and pod @ 04/19/24 16:19:54.38
  E0419 16:19:54.395926      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating pod with conflicting port in namespace statefulset-6512 @ 04/19/24 16:19:54.398
  STEP: Waiting until pod test-pod will start running in namespace statefulset-6512 @ 04/19/24 16:19:54.414
  E0419 16:19:55.396090      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:56.396364      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating statefulset with conflicting port in namespace statefulset-6512 @ 04/19/24 16:19:56.438
  STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-6512 @ 04/19/24 16:19:56.453
  I0419 16:19:56.486714 14 statefulset.go:866] Observed stateful pod in namespace: statefulset-6512, name: ss-0, uid: 9735f7fb-2b72-46aa-82c1-b1578dcf57b3, status phase: Pending. Waiting for statefulset controller to delete.
  I0419 16:19:56.525415 14 statefulset.go:866] Observed stateful pod in namespace: statefulset-6512, name: ss-0, uid: 9735f7fb-2b72-46aa-82c1-b1578dcf57b3, status phase: Failed. Waiting for statefulset controller to delete.
  I0419 16:19:56.597432 14 statefulset.go:866] Observed stateful pod in namespace: statefulset-6512, name: ss-0, uid: 9735f7fb-2b72-46aa-82c1-b1578dcf57b3, status phase: Failed. Waiting for statefulset controller to delete.
  I0419 16:19:56.604996 14 statefulset.go:860] Observed delete event for stateful pod ss-0 in namespace statefulset-6512
  STEP: Removing pod with conflicting port in namespace statefulset-6512 @ 04/19/24 16:19:56.605
  STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-6512 and will be in running state @ 04/19/24 16:19:56.665
  E0419 16:19:57.396560      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:58.396745      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:19:58.715333 14 statefulset.go:135] Deleting all statefulset in ns statefulset-6512
  I0419 16:19:58.724699 14 rest.go:150] Scaling statefulset ss to 0
  E0419 16:19:59.397083      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:00.397608      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:01.398087      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:02.398470      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:03.398950      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:04.399185      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:05.400009      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:06.400234      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:07.400667      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:08.401102      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:20:08.768419 14 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0419 16:20:08.777238 14 rest.go:88] Deleting statefulset ss
  I0419 16:20:08.817605 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-6512" for this suite. @ 04/19/24 16:20:08.828
• [14.507 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery request for CRDs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:194
  STEP: Creating a kubernetes client @ 04/19/24 16:20:08.843
  I0419 16:20:08.843973 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename aggregateddiscovery @ 04/19/24 16:20:08.846
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:20:08.874
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:20:08.878
  I0419 16:20:08.885200 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  E0419 16:20:09.401288      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:10.401424      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:11.402146      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:20:12.122388 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-1572" for this suite. @ 04/19/24 16:20:12.135
• [3.315 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:274
  STEP: Creating a kubernetes client @ 04/19/24 16:20:12.159
  I0419 16:20:12.159860 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename namespaces @ 04/19/24 16:20:12.163
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:20:12.196
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:20:12.208
  STEP: creating a Namespace @ 04/19/24 16:20:12.22
  STEP: patching the Namespace @ 04/19/24 16:20:12.249
  STEP: get the Namespace and ensuring it has the label @ 04/19/24 16:20:12.262
  I0419 16:20:12.267114 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-3851" for this suite. @ 04/19/24 16:20:12.278
  STEP: Destroying namespace "nspatchtest-9fd64e7d-a66b-431e-9096-b7fa25b499ea-2154" for this suite. @ 04/19/24 16:20:12.29
• [0.140 seconds]
------------------------------
SSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:156
  STEP: Creating a kubernetes client @ 04/19/24 16:20:12.302
  I0419 16:20:12.302421 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename var-expansion @ 04/19/24 16:20:12.304
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:20:12.328
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:20:12.333
  E0419 16:20:12.401936      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:13.402803      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:20:14.377009 14 delete.go:62] Deleting pod "var-expansion-f750c522-3b75-43f4-b2cc-e921334d55f1" in namespace "var-expansion-7507"
  I0419 16:20:14.389650 14 delete.go:70] Wait up to 5m0s for pod "var-expansion-f750c522-3b75-43f4-b2cc-e921334d55f1" to be fully deleted
  E0419 16:20:14.403741      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:15.404052      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:16.404781      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:20:16.410157 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-7507" for this suite. @ 04/19/24 16:20:16.425
• [4.145 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:286
  STEP: Creating a kubernetes client @ 04/19/24 16:20:16.471
  I0419 16:20:16.471987 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename proxy @ 04/19/24 16:20:16.475
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:20:16.549
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:20:16.556
  I0419 16:20:16.563510 14 proxy.go:293] Creating pod...
  E0419 16:20:17.405159      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:18.405383      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:20:18.596074 14 proxy.go:317] Creating service...
  I0419 16:20:18.624014 14 proxy.go:354] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-1522/pods/agnhost/proxy/some/path/with/DELETE
  I0419 16:20:18.650848 14 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0419 16:20:18.650970 14 proxy.go:354] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-1522/pods/agnhost/proxy/some/path/with/GET
  I0419 16:20:18.659094 14 proxy.go:530] http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  I0419 16:20:18.659266 14 proxy.go:354] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-1522/pods/agnhost/proxy/some/path/with/HEAD
  I0419 16:20:18.668432 14 proxy.go:517] http.Client request:HEAD | StatusCode:200
  I0419 16:20:18.668494 14 proxy.go:354] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-1522/pods/agnhost/proxy/some/path/with/OPTIONS
  I0419 16:20:18.674738 14 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0419 16:20:18.674802 14 proxy.go:354] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-1522/pods/agnhost/proxy/some/path/with/PATCH
  I0419 16:20:18.680624 14 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0419 16:20:18.680689 14 proxy.go:354] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-1522/pods/agnhost/proxy/some/path/with/POST
  I0419 16:20:18.685961 14 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0419 16:20:18.686022 14 proxy.go:354] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-1522/pods/agnhost/proxy/some/path/with/PUT
  I0419 16:20:18.693323 14 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0419 16:20:18.693381 14 proxy.go:365] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-1522/services/test-service/proxy/some/path/with/DELETE
  I0419 16:20:18.701202 14 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0419 16:20:18.701265 14 proxy.go:365] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-1522/services/test-service/proxy/some/path/with/GET
  I0419 16:20:18.709548 14 proxy.go:530] http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  I0419 16:20:18.709604 14 proxy.go:365] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-1522/services/test-service/proxy/some/path/with/HEAD
  I0419 16:20:18.717782 14 proxy.go:517] http.Client request:HEAD | StatusCode:200
  I0419 16:20:18.717832 14 proxy.go:365] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-1522/services/test-service/proxy/some/path/with/OPTIONS
  I0419 16:20:18.726107 14 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0419 16:20:18.726194 14 proxy.go:365] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-1522/services/test-service/proxy/some/path/with/PATCH
  I0419 16:20:18.735003 14 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0419 16:20:18.735058 14 proxy.go:365] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-1522/services/test-service/proxy/some/path/with/POST
  I0419 16:20:18.743566 14 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0419 16:20:18.743623 14 proxy.go:365] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-1522/services/test-service/proxy/some/path/with/PUT
  I0419 16:20:18.751656 14 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0419 16:20:18.752169 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-1522" for this suite. @ 04/19/24 16:20:18.76
• [2.303 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:261
  STEP: Creating a kubernetes client @ 04/19/24 16:20:18.777
  I0419 16:20:18.777845 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename webhook @ 04/19/24 16:20:18.781
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:20:18.859
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:20:18.866
  STEP: Setting up server cert @ 04/19/24 16:20:18.912
  E0419 16:20:19.405552      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 16:20:19.552
  STEP: Deploying the webhook pod @ 04/19/24 16:20:19.572
  STEP: Wait for the deployment to be ready @ 04/19/24 16:20:19.601
  I0419 16:20:19.625496 14 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0419 16:20:20.407097      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:21.407594      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 16:20:21.657
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 16:20:21.681
  E0419 16:20:22.408016      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:20:22.681860 14 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating pod webhook via the AdmissionRegistration API @ 04/19/24 16:20:22.708
  STEP: create a pod that should be updated by the webhook @ 04/19/24 16:20:22.765
  I0419 16:20:22.923480 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2829" for this suite. @ 04/19/24 16:20:22.935
  STEP: Destroying namespace "webhook-markers-2217" for this suite. @ 04/19/24 16:20:22.947
• [4.182 seconds]
------------------------------
SS
------------------------------
[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:420
  STEP: Creating a kubernetes client @ 04/19/24 16:20:22.961
  I0419 16:20:22.961234 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename job @ 04/19/24 16:20:22.964
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:20:22.988
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:20:22.994
  STEP: Creating Indexed job @ 04/19/24 16:20:23
  STEP: Ensuring job reaches completions @ 04/19/24 16:20:23.012
  E0419 16:20:23.409205      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:24.409701      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:25.410118      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:26.410316      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:27.411709      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:28.411972      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:29.412548      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:30.412757      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring pods with index for job exist @ 04/19/24 16:20:31.024
  I0419 16:20:31.041715 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-2477" for this suite. @ 04/19/24 16:20:31.053
• [8.108 seconds]
------------------------------
S
------------------------------
[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:108
  STEP: Creating a kubernetes client @ 04/19/24 16:20:31.071
  I0419 16:20:31.071941 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename disruption @ 04/19/24 16:20:31.076
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:20:31.113
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:20:31.119
  STEP: creating the pdb @ 04/19/24 16:20:31.129
  STEP: Waiting for the pdb to be processed @ 04/19/24 16:20:31.145
  E0419 16:20:31.413873      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:32.414403      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: updating the pdb @ 04/19/24 16:20:33.155
  STEP: Waiting for the pdb to be processed @ 04/19/24 16:20:33.176
  E0419 16:20:33.414868      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:34.415487      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching the pdb @ 04/19/24 16:20:35.185
  STEP: Waiting for the pdb to be processed @ 04/19/24 16:20:35.213
  E0419 16:20:35.416364      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:36.417025      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be deleted @ 04/19/24 16:20:37.242
  I0419 16:20:37.251995 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-7210" for this suite. @ 04/19/24 16:20:37.265
• [6.209 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:397
  STEP: Creating a kubernetes client @ 04/19/24 16:20:37.284
  I0419 16:20:37.284925 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename resourcequota @ 04/19/24 16:20:37.287
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:20:37.317
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:20:37.322
  STEP: Counting existing ResourceQuota @ 04/19/24 16:20:37.328
  E0419 16:20:37.418161      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:38.419089      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:39.419830      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:40.420229      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:41.420987      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 04/19/24 16:20:42.337
  STEP: Ensuring resource quota status is calculated @ 04/19/24 16:20:42.358
  E0419 16:20:42.421977      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:43.422841      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ReplicationController @ 04/19/24 16:20:44.368
  STEP: Ensuring resource quota status captures replication controller creation @ 04/19/24 16:20:44.397
  E0419 16:20:44.424097      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:45.424187      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicationController @ 04/19/24 16:20:46.41
  E0419 16:20:46.425615      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota status released usage @ 04/19/24 16:20:46.427
  E0419 16:20:47.426055      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:48.426762      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:20:48.438298 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-999" for this suite. @ 04/19/24 16:20:48.451
• [11.186 seconds]
------------------------------
SS
------------------------------
[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:132
  STEP: Creating a kubernetes client @ 04/19/24 16:20:48.471
  I0419 16:20:48.471359 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename downward-api @ 04/19/24 16:20:48.475
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:20:48.508
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:20:48.515
  STEP: Creating the pod @ 04/19/24 16:20:48.522
  E0419 16:20:49.426853      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:50.427228      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:20:51.128107 14 pod_client.go:141] Successfully updated pod "labelsupdate544f6a03-bfd3-4ea4-b959-028145ec0b10"
  E0419 16:20:51.427849      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:52.428212      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:20:53.182503 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1838" for this suite. @ 04/19/24 16:20:53.193
• [4.738 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:285
  STEP: Creating a kubernetes client @ 04/19/24 16:20:53.21
  I0419 16:20:53.210659 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename webhook @ 04/19/24 16:20:53.213
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:20:53.245
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:20:53.25
  STEP: Setting up server cert @ 04/19/24 16:20:53.289
  E0419 16:20:53.428756      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 16:20:54.063
  STEP: Deploying the webhook pod @ 04/19/24 16:20:54.08
  STEP: Wait for the deployment to be ready @ 04/19/24 16:20:54.1
  I0419 16:20:54.117151 14 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0419 16:20:54.429463      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:55.430489      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 16:20:56.159
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 16:20:56.195
  E0419 16:20:56.430314      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:20:57.196751 14 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0419 16:20:57.214843 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  E0419 16:20:57.431601      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-773-crds.webhook.example.com via the AdmissionRegistration API @ 04/19/24 16:20:57.746
  STEP: Creating a custom resource that should be mutated by the webhook @ 04/19/24 16:20:57.792
  E0419 16:20:58.432095      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:59.432306      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:00.434105      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:21:00.531094 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3407" for this suite. @ 04/19/24 16:21:00.545
  STEP: Destroying namespace "webhook-markers-5649" for this suite. @ 04/19/24 16:21:00.564
• [7.374 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:400
  STEP: Creating a kubernetes client @ 04/19/24 16:21:00.586
  I0419 16:21:00.587041 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename namespaces @ 04/19/24 16:21:00.591
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:21:00.624
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:21:00.63
  STEP: Creating namespace "e2e-ns-xxqlf" @ 04/19/24 16:21:00.637
  I0419 16:21:00.664074 14 namespace.go:411] Namespace "e2e-ns-xxqlf-8731" has []v1.FinalizerName{"kubernetes"}
  STEP: Adding e2e finalizer to namespace "e2e-ns-xxqlf-8731" @ 04/19/24 16:21:00.664
  I0419 16:21:00.686004 14 namespace.go:434] Namespace "e2e-ns-xxqlf-8731" has []v1.FinalizerName{"kubernetes", "e2e.example.com/fakeFinalizer"}
  STEP: Removing e2e finalizer from namespace "e2e-ns-xxqlf-8731" @ 04/19/24 16:21:00.686
  I0419 16:21:00.702887 14 namespace.go:463] Namespace "e2e-ns-xxqlf-8731" has []v1.FinalizerName{"kubernetes"}
  I0419 16:21:00.704049 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-3665" for this suite. @ 04/19/24 16:21:00.715
  STEP: Destroying namespace "e2e-ns-xxqlf-8731" for this suite. @ 04/19/24 16:21:00.729
• [0.155 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version should find the server version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/server_version.go:41
  STEP: Creating a kubernetes client @ 04/19/24 16:21:00.757
  I0419 16:21:00.758536 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename server-version @ 04/19/24 16:21:00.77
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:21:00.797
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:21:00.804
  STEP: Request ServerVersion @ 04/19/24 16:21:00.813
  STEP: Confirm major version @ 04/19/24 16:21:00.815
  I0419 16:21:00.816275 14 server_version.go:52] Major version: 1
  STEP: Confirm minor version @ 04/19/24 16:21:00.816
  I0419 16:21:00.816856 14 server_version.go:58] cleanMinorVersion: 30
  I0419 16:21:00.817370 14 server_version.go:62] Minor version: 30
  I0419 16:21:00.817826 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "server-version-6003" for this suite. @ 04/19/24 16:21:00.829
• [0.091 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment should validate Deployment Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:489
  STEP: Creating a kubernetes client @ 04/19/24 16:21:00.85
  I0419 16:21:00.850512 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename deployment @ 04/19/24 16:21:00.853
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:21:00.875
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:21:00.881
  STEP: creating a Deployment @ 04/19/24 16:21:00.893
  I0419 16:21:00.893292 14 deployment.go:507] Creating simple deployment test-deployment-wpslg
  I0419 16:21:00.935179 14 deployment.go:222] deployment "test-deployment-wpslg" doesn't have the required revision set
  E0419 16:21:01.433658      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:02.434699      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Getting /status @ 04/19/24 16:21:02.975
  I0419 16:21:02.987471 14 deployment.go:532] Deployment test-deployment-wpslg has Conditions: [{Available True 2024-04-19 16:21:01 +0000 UTC 2024-04-19 16:21:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2024-04-19 16:21:01 +0000 UTC 2024-04-19 16:21:00 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wpslg-c8586b885" has successfully progressed.}]
  STEP: updating Deployment Status @ 04/19/24 16:21:02.987
  I0419 16:21:03.012992 14 deployment.go:552] updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 21, 1, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 21, 1, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 21, 1, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 21, 0, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-wpslg-c8586b885\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Deployment status to be updated @ 04/19/24 16:21:03.013
  I0419 16:21:03.021830 14 deployment.go:579] Observed &Deployment event: ADDED
  I0419 16:21:03.021976 14 deployment.go:575] Observed Deployment test-deployment-wpslg in namespace deployment-3162 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-19 16:21:00 +0000 UTC 2024-04-19 16:21:00 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-wpslg-c8586b885"}
  I0419 16:21:03.022320 14 deployment.go:579] Observed &Deployment event: MODIFIED
  I0419 16:21:03.022433 14 deployment.go:575] Observed Deployment test-deployment-wpslg in namespace deployment-3162 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-19 16:21:00 +0000 UTC 2024-04-19 16:21:00 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-wpslg-c8586b885"}
  I0419 16:21:03.022477 14 deployment.go:575] Observed Deployment test-deployment-wpslg in namespace deployment-3162 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-04-19 16:21:00 +0000 UTC 2024-04-19 16:21:00 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0419 16:21:03.022794 14 deployment.go:579] Observed &Deployment event: MODIFIED
  I0419 16:21:03.023477 14 deployment.go:575] Observed Deployment test-deployment-wpslg in namespace deployment-3162 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-04-19 16:21:00 +0000 UTC 2024-04-19 16:21:00 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0419 16:21:03.023537 14 deployment.go:575] Observed Deployment test-deployment-wpslg in namespace deployment-3162 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-19 16:21:00 +0000 UTC 2024-04-19 16:21:00 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-wpslg-c8586b885" is progressing.}
  I0419 16:21:03.024693 14 deployment.go:579] Observed &Deployment event: MODIFIED
  I0419 16:21:03.025220 14 deployment.go:575] Observed Deployment test-deployment-wpslg in namespace deployment-3162 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-04-19 16:21:01 +0000 UTC 2024-04-19 16:21:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0419 16:21:03.025565 14 deployment.go:575] Observed Deployment test-deployment-wpslg in namespace deployment-3162 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-19 16:21:01 +0000 UTC 2024-04-19 16:21:00 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wpslg-c8586b885" has successfully progressed.}
  I0419 16:21:03.026213 14 deployment.go:579] Observed &Deployment event: MODIFIED
  I0419 16:21:03.026662 14 deployment.go:575] Observed Deployment test-deployment-wpslg in namespace deployment-3162 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-04-19 16:21:01 +0000 UTC 2024-04-19 16:21:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0419 16:21:03.026750 14 deployment.go:575] Observed Deployment test-deployment-wpslg in namespace deployment-3162 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-19 16:21:01 +0000 UTC 2024-04-19 16:21:00 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wpslg-c8586b885" has successfully progressed.}
  I0419 16:21:03.027096 14 deployment.go:572] Found Deployment test-deployment-wpslg in namespace deployment-3162 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0419 16:21:03.028085 14 deployment.go:583] Deployment test-deployment-wpslg has an updated status
  STEP: patching the Statefulset Status @ 04/19/24 16:21:03.028
  I0419 16:21:03.028748 14 deployment.go:587] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I0419 16:21:03.048595 14 deployment.go:591] Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Deployment status to be patched @ 04/19/24 16:21:03.048
  I0419 16:21:03.056086 14 deployment.go:616] Observed &Deployment event: ADDED
  I0419 16:21:03.056281 14 deployment.go:612] Observed deployment test-deployment-wpslg in namespace deployment-3162 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-19 16:21:00 +0000 UTC 2024-04-19 16:21:00 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-wpslg-c8586b885"}
  I0419 16:21:03.057436 14 deployment.go:616] Observed &Deployment event: MODIFIED
  I0419 16:21:03.058586 14 deployment.go:612] Observed deployment test-deployment-wpslg in namespace deployment-3162 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-19 16:21:00 +0000 UTC 2024-04-19 16:21:00 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-wpslg-c8586b885"}
  I0419 16:21:03.058706 14 deployment.go:612] Observed deployment test-deployment-wpslg in namespace deployment-3162 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-04-19 16:21:00 +0000 UTC 2024-04-19 16:21:00 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0419 16:21:03.059729 14 deployment.go:616] Observed &Deployment event: MODIFIED
  I0419 16:21:03.060388 14 deployment.go:612] Observed deployment test-deployment-wpslg in namespace deployment-3162 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-04-19 16:21:00 +0000 UTC 2024-04-19 16:21:00 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0419 16:21:03.060475 14 deployment.go:612] Observed deployment test-deployment-wpslg in namespace deployment-3162 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-19 16:21:00 +0000 UTC 2024-04-19 16:21:00 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-wpslg-c8586b885" is progressing.}
  I0419 16:21:03.061754 14 deployment.go:616] Observed &Deployment event: MODIFIED
  I0419 16:21:03.061906 14 deployment.go:612] Observed deployment test-deployment-wpslg in namespace deployment-3162 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-04-19 16:21:01 +0000 UTC 2024-04-19 16:21:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0419 16:21:03.062577 14 deployment.go:612] Observed deployment test-deployment-wpslg in namespace deployment-3162 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-19 16:21:01 +0000 UTC 2024-04-19 16:21:00 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wpslg-c8586b885" has successfully progressed.}
  I0419 16:21:03.063954 14 deployment.go:616] Observed &Deployment event: MODIFIED
  I0419 16:21:03.064653 14 deployment.go:612] Observed deployment test-deployment-wpslg in namespace deployment-3162 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-04-19 16:21:01 +0000 UTC 2024-04-19 16:21:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0419 16:21:03.065345 14 deployment.go:612] Observed deployment test-deployment-wpslg in namespace deployment-3162 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-19 16:21:01 +0000 UTC 2024-04-19 16:21:00 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wpslg-c8586b885" has successfully progressed.}
  I0419 16:21:03.065427 14 deployment.go:612] Observed deployment test-deployment-wpslg in namespace deployment-3162 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0419 16:21:03.067648 14 deployment.go:616] Observed &Deployment event: MODIFIED
  I0419 16:21:03.067803 14 deployment.go:609] Found deployment test-deployment-wpslg in namespace deployment-3162 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
  I0419 16:21:03.068952 14 deployment.go:620] Deployment test-deployment-wpslg has a patched status
  I0419 16:21:03.080652 14 deployment.go:633] Deployment "test-deployment-wpslg":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=21) "test-deployment-wpslg",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3162",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f3a07980-1ebd-4ea1-9bb9-1607907b6134",
      ResourceVersion: (string) (len=5) "15438",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140460,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140460,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=657) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              00000030  6e 61 6d 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |name":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  70 72 6f 67 72 65 73 73  |ec":{"f:progress|
              00000050  44 65 61 64 6c 69 6e 65  53 65 63 6f 6e 64 73 22  |DeadlineSeconds"|
              00000060  3a 7b 7d 2c 22 66 3a 72  65 70 6c 69 63 61 73 22  |:{},"f:replicas"|
              00000070  3a 7b 7d 2c 22 66 3a 72  65 76 69 73 69 6f 6e 48  |:{},"f:revisionH|
              00000080  69 73 74 6f 72 79 4c 69  6d 69 74 22 3a 7b 7d 2c  |istoryLimit":{},|
              00000090  22 66 3a 73 65 6c 65 63  74 6f 72 22 3a 7b 7d 2c  |"f:selector":{},|
              000000a0  22 66 3a 73 74 72 61 74  65 67 79 22 3a 7b 22 66  |"f:strategy":{"f|
              000000b0  3a 72 6f 6c 6c 69 6e 67  55 70 64 61 74 65 22 3a  |:rollingUpdate":|
              000000c0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6d 61 78 53 75  |{".":{},"f:maxSu|
              000000d0  72 67 65 22 3a 7b 7d 2c  22 66 3a 6d 61 78 55 6e  |rge":{},"f:maxUn|
              000000e0  61 76 61 69 6c 61 62 6c  65 22 3a 7b 7d 7d 2c 22  |available":{}},"|
              000000f0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 66 3a 74  |f:type":{}},"f:t|
              00000100  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000110  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              00000120  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 65 32  |s":{".":{},"f:e2|
              00000130  65 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |e":{},"f:name":{|
              00000140  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              00000150  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000160  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              00000170  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              00000180  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000190  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              000001a0  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              000001b0  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              000001c0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000001d0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000001e0  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000210  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000220  69 63 79 22 3a 7b 7d 2c  22 66 3a 72 65 73 74 61  |icy":{},"f:resta|
              00000230  72 74 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |rtPolicy":{},"f:|
              00000240  73 63 68 65 64 75 6c 65  72 4e 61 6d 65 22 3a 7b  |schedulerName":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 47  72 61 63 65 50 65 72 69  |inationGracePeri|
              00000280  6f 64 53 65 63 6f 6e 64  73 22 3a 7b 7d 7d 7d 7d  |odSeconds":{}}}}|
              00000290  7d                                                |}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140463,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=147) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 53 74 61 74  |{\"type\":\"Stat|
              00000030  75 73 50 61 74 63 68 65  64 5c 22 7d 22 3a 7b 22  |usPatched\"}":{"|
              00000040  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |.":{},"f:lastTra|
              00000050  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000060  22 66 3a 6c 61 73 74 55  70 64 61 74 65 54 69 6d  |"f:lastUpdateTim|
              00000070  65 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |e":{},"f:status"|
              00000080  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000090  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140463,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=373) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 50 72 6f  |:{\"type\":\"Pro|
              000000a0  67 72 65 73 73 69 6e 67  5c 22 7d 22 3a 7b 22 2e  |gressing\"}":{".|
              000000b0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000000c0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000000d0  66 3a 6c 61 73 74 55 70  64 61 74 65 54 69 6d 65  |f:lastUpdateTime|
              000000e0  22 3a 7b 7d 2c 22 66 3a  6d 65 73 73 61 67 65 22  |":{},"f:message"|
              000000f0  3a 7b 7d 2c 22 66 3a 72  65 61 73 6f 6e 22 3a 7b  |:{},"f:reason":{|
              00000100  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              00000110  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              00000120  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000130  69 6f 6e 22 3a 7b 7d 2c  22 66 3a 72 65 61 64 79  |ion":{},"f:ready|
              00000140  52 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |Replicas":{},"f:|
              00000150  72 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |replicas":{},"f:|
              00000160  75 70 64 61 74 65 64 52  65 70 6c 69 63 61 73 22  |updatedReplicas"|
              00000170  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=3) "e2e": (string) (len=7) "testing"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=13) "StatusPatched",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140463,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140463,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "FoundNewReplicaSet",
          Message: (string) (len=55) "Found new replica set \"test-deployment-wpslg-c8586b885\""
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0419 16:21:03.121985 14 deployment.go:39] New ReplicaSet "test-deployment-wpslg-c8586b885" of Deployment "test-deployment-wpslg":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "test-deployment-wpslg-c8586b885",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3162",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b5f19056-4e8f-4dc1-b745-d456018e3a71",
      ResourceVersion: (string) (len=5) "15432",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140460,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "c8586b885"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=21) "test-deployment-wpslg",
          UID: (types.UID) (len=36) "f3a07980-1ebd-4ea1-9bb9-1607907b6134",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140460,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=803) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              000000d0  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 70 6f 64 2d  |name":{},"f:pod-|
              000000e0  74 65 6d 70 6c 61 74 65  2d 68 61 73 68 22 3a 7b  |template-hash":{|
              000000f0  7d 7d 2c 22 66 3a 6f 77  6e 65 72 52 65 66 65 72  |}},"f:ownerRefer|
              00000100  65 6e 63 65 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |ences":{".":{},"|
              00000110  6b 3a 7b 5c 22 75 69 64  5c 22 3a 5c 22 66 33 61  |k:{\"uid\":\"f3a|
              00000120  30 37 39 38 30 2d 31 65  62 64 2d 34 65 61 31 2d  |07980-1ebd-4ea1-|
              00000130  39 62 62 39 2d 31 36 30  37 39 30 37 62 36 31 33  |9bb9-1607907b613|
              00000140  34 5c 22 7d 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |4\"}":{}}},"f:sp|
              00000150  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000160  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000180  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000190  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              000001a0  3a 7b 7d 2c 22 66 3a 65  32 65 22 3a 7b 7d 2c 22  |:{},"f:e2e":{},"|
              000001b0  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 70 6f  |f:name":{},"f:po|
              000001c0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001d0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000001e0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000001f0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              00000200  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              00000210  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000220  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000230  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000240  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000280  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000290  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              000002a0  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              000002b0  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              000002c0  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              000002d0  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000002e0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000002f0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              00000300  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              00000310  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              00000320  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140461,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=3) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=9) "c8586b885"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=3) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=9) "c8586b885"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0419 16:21:03.134293 14 deployment.go:67] Pod "test-deployment-wpslg-c8586b885-gw6xg" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "test-deployment-wpslg-c8586b885-gw6xg",
      GenerateName: (string) (len=32) "test-deployment-wpslg-c8586b885-",
      Namespace: (string) (len=15) "deployment-3162",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "fbdd4b2d-2d1a-44cc-807e-320210cda9e0",
      ResourceVersion: (string) (len=5) "15431",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140460,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "c8586b885"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "test-deployment-wpslg-c8586b885",
          UID: (types.UID) (len=36) "b5f19056-4e8f-4dc1-b745-d456018e3a71",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140460,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=548) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 65 32 65 22 3a 7b 7d  |.":{},"f:e2e":{}|
              00000040  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000050  70 6f 64 2d 74 65 6d 70  6c 61 74 65 2d 68 61 73  |pod-template-has|
              00000060  68 22 3a 7b 7d 7d 2c 22  66 3a 6f 77 6e 65 72 52  |h":{}},"f:ownerR|
              00000070  65 66 65 72 65 6e 63 65  73 22 3a 7b 22 2e 22 3a  |eferences":{".":|
              00000080  7b 7d 2c 22 6b 3a 7b 5c  22 75 69 64 5c 22 3a 5c  |{},"k:{\"uid\":\|
              00000090  22 62 35 66 31 39 30 35  36 2d 34 65 38 66 2d 34  |"b5f19056-4e8f-4|
              000000a0  64 63 31 2d 62 37 34 35  2d 64 34 35 36 30 31 38  |dc1-b745-d456018|
              000000b0  65 33 61 37 31 5c 22 7d  22 3a 7b 7d 7d 7d 2c 22  |e3a71\"}":{}}},"|
              000000c0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000d0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              000000e0  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              000000f0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000100  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000110  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000120  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000130  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 73 65  |ources":{},"f:se|
              00000140  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000150  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000160  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000170  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000180  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000190  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              000001a0  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              000001b0  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              000001c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000200  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000210  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000220  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140461,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 36 2e  31 36 36 5c 22 7d 22 3a  |.233.66.166\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-wd6mr",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-wd6mr",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "eipo9quoh3ef-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140461,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140460,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140461,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140461,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140460,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.127",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.127"
        }
      },
      PodIP: (string) (len=13) "10.233.66.166",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.66.166"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140460,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63849140461,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://977249c44ea01c8aef4287ef6757b807bfc1faac35b2933ec5d1a5c6af49551a",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0419 16:21:03.147891 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-3162" for this suite. @ 04/19/24 16:21:03.16
• [2.322 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replace and Patch tests [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:155
  STEP: Creating a kubernetes client @ 04/19/24 16:21:03.173
  I0419 16:21:03.173605 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename replicaset @ 04/19/24 16:21:03.177
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:21:03.2
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:21:03.208
  I0419 16:21:03.236191 14 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  E0419 16:21:03.434869      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:04.435396      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:05.435638      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:06.435881      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:07.435960      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:21:08.247430 14 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/19/24 16:21:08.248
  STEP: Scaling up "test-rs" replicaset @ 04/19/24 16:21:08.248
  I0419 16:21:08.275924 14 replicaset.go:44] Updating replica set "test-rs"
  STEP: patching the ReplicaSet @ 04/19/24 16:21:08.276
  I0419 16:21:08.301383 14 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-6143 with ReadyReplicas 1, AvailableReplicas 1
  I0419 16:21:08.322498 14 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-6143 with ReadyReplicas 1, AvailableReplicas 1
  I0419 16:21:08.390529 14 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-6143 with ReadyReplicas 1, AvailableReplicas 1
  I0419 16:21:08.402120 14 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-6143 with ReadyReplicas 1, AvailableReplicas 1
  E0419 16:21:08.437409      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:09.437950      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:21:09.609339 14 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-6143 with ReadyReplicas 2, AvailableReplicas 2
  E0419 16:21:10.438599      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:21:10.811185 14 replica_set.go:545] observed Replicaset test-rs in namespace replicaset-6143 with ReadyReplicas 3 found true
  I0419 16:21:10.811664 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-6143" for this suite. @ 04/19/24 16:21:10.83
• [7.672 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:164
  STEP: Creating a kubernetes client @ 04/19/24 16:21:10.854
  I0419 16:21:10.854802 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename disruption @ 04/19/24 16:21:10.862
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:21:10.897
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:21:10.904
  STEP: Waiting for the pdb to be processed @ 04/19/24 16:21:10.926
  STEP: Updating PodDisruptionBudget status @ 04/19/24 16:21:10.936
  STEP: Waiting for all pods to be running @ 04/19/24 16:21:10.952
  I0419 16:21:10.961907 14 disruption.go:578] running pods: 0 < 1
  E0419 16:21:11.438265      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:12.440588      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 04/19/24 16:21:12.961
  STEP: Waiting for the pdb to be processed @ 04/19/24 16:21:12.987
  STEP: Patching PodDisruptionBudget status @ 04/19/24 16:21:13.01
  STEP: Waiting for the pdb to be processed @ 04/19/24 16:21:13.031
  I0419 16:21:13.048320 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-5485" for this suite. @ 04/19/24 16:21:13.06
• [2.223 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:75
  STEP: Creating a kubernetes client @ 04/19/24 16:21:13.077
  I0419 16:21:13.077897 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename configmap @ 04/19/24 16:21:13.082
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:21:13.118
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:21:13.124
  STEP: Creating configMap with name configmap-test-volume-0d2d2ba8-022e-43a6-8774-ba2e8d261f25 @ 04/19/24 16:21:13.131
  STEP: Creating a pod to test consume configMaps @ 04/19/24 16:21:13.139
  E0419 16:21:13.441572      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:14.442232      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:15.442831      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:16.442707      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:21:17.177
  I0419 16:21:17.184820 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-configmaps-935f1172-064f-45f5-8901-2aea2f8d6845 container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/24 16:21:17.199
  I0419 16:21:17.223937 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1239" for this suite. @ 04/19/24 16:21:17.234
• [4.173 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Deployment deployment should support proportional scaling [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:160
  STEP: Creating a kubernetes client @ 04/19/24 16:21:17.252
  I0419 16:21:17.252658 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename deployment @ 04/19/24 16:21:17.258
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:21:17.297
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:21:17.301
  I0419 16:21:17.309238 14 deployment.go:1196] Creating deployment "webserver-deployment"
  I0419 16:21:17.328644 14 deployment.go:1200] Waiting for observed generation 1
  E0419 16:21:17.443826      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:18.444135      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:21:19.342163 14 deployment.go:1205] Waiting for all required pods to come up
  I0419 16:21:19.351950 14 resource.go:87] Pod name httpd: Found 10 pods out of 10
  STEP: ensuring each pod is running @ 04/19/24 16:21:19.352
  E0419 16:21:19.445473      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:20.445671      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:21:21.377861 14 deployment.go:1209] Waiting for deployment "webserver-deployment" to complete
  I0419 16:21:21.393549 14 deployment.go:1218] Updating deployment "webserver-deployment" with a non-existent image
  I0419 16:21:21.417733 14 deployment.go:313] Updating deployment webserver-deployment
  I0419 16:21:21.418409 14 deployment.go:1224] Waiting for observed generation 2
  E0419 16:21:21.446660      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:22.447303      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:21:23.444224 14 deployment.go:1234] Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
  E0419 16:21:23.448049      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:21:23.455637 14 deployment.go:1239] Waiting for the first rollout's replicaset to have .spec.replicas = 8
  I0419 16:21:23.465573 14 deployment.go:1244] Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  I0419 16:21:23.495777 14 deployment.go:1258] Verifying that the second rollout's replicaset has .status.availableReplicas = 0
  I0419 16:21:23.496537 14 deployment.go:1263] Waiting for the second rollout's replicaset to have .spec.replicas = 5
  I0419 16:21:23.505389 14 deployment.go:1268] Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  I0419 16:21:23.523163 14 deployment.go:1275] Verifying that deployment "webserver-deployment" has minimum required number of available replicas
  I0419 16:21:23.523365 14 deployment.go:1283] Scaling up the deployment "webserver-deployment" from 10 to 30
  I0419 16:21:23.550412 14 deployment.go:313] Updating deployment webserver-deployment
  I0419 16:21:23.551035 14 deployment.go:1289] Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
  I0419 16:21:23.578632 14 deployment.go:1297] Verifying that first rollout's replicaset has .spec.replicas = 20
  I0419 16:21:23.594895 14 deployment.go:1303] Verifying that second rollout's replicaset has .spec.replicas = 13
  I0419 16:21:23.621772 14 deployment.go:633] Deployment "webserver-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=20) "webserver-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2e1a50f1-646d-4bf7-aea1-0474ab08386e",
      ResourceVersion: (string) (len=5) "15838",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140477,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=541) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 6e 61  |licas":{},"f:una|
              000001f0  76 61 69 6c 61 62 6c 65  52 65 70 6c 69 63 61 73  |vailableReplicas|
              00000200  22 3a 7b 7d 2c 22 66 3a  75 70 64 61 74 65 64 52  |":{},"f:updatedR|
              00000210  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140483,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=635) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000160  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000170  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000180  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000190  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              000001a0  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001b0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001c0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001d0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001e0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001f0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              00000200  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000210  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000220  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000230  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000270  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(30),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 2,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 3,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 13,
      UpdatedReplicas: (int32) 5,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      UnavailableReplicas: (int32) 5,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140480,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140480,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=60) "ReplicaSet \"webserver-deployment-67c89d485c\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0419 16:21:23.666549 14 deployment.go:39] New ReplicaSet "webserver-deployment-67c89d485c" of Deployment "webserver-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-67c89d485c",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4b18aaec-038a-4bc5-afe8-a596d6deea3b",
      ResourceVersion: (string) (len=5) "15844",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140481,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "2e1a50f1-646d-4bf7-aea1-0474ab08386e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140483,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 32 65 31 61 35 30  66 31 2d 36 34 36 64 2d  |\"2e1a50f1-646d-|
              00000120  34 62 66 37 2d 61 65 61  31 2d 30 34 37 34 61 62  |4bf7-aea1-0474ab|
              00000130  30 38 33 38 36 65 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |08386e\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(13),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 5,
      FullyLabeledReplicas: (int32) 5,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0419 16:21:23.668495 14 deployment.go:44] All old ReplicaSets of Deployment "webserver-deployment":
  I0419 16:21:23.669035 14 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-77db57d8df",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "bb0f79f4-8723-4946-affd-528d3efd7d3a",
      ResourceVersion: (string) (len=5) "15839",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140477,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "2e1a50f1-646d-4bf7-aea1-0474ab08386e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140483,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 32 65 31 61 35 30  66 31 2d 36 34 36 64 2d  |\"2e1a50f1-646d-|
              00000120  34 62 66 37 2d 61 65 61  31 2d 30 34 37 34 61 62  |4bf7-aea1-0474ab|
              00000130  30 38 33 38 36 65 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |08386e\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(20),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 8,
      FullyLabeledReplicas: (int32) 8,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0419 16:21:23.718323 14 deployment.go:67] Pod "webserver-deployment-67c89d485c-7c4pb" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-67c89d485c-7c4pb",
      GenerateName: (string) (len=32) "webserver-deployment-67c89d485c-",
      Namespace: (string) (len=15) "deployment-7995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8655a278-be9e-4bec-86a6-205e07c93278",
      ResourceVersion: (string) (len=5) "15792",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140481,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-67c89d485c",
          UID: (types.UID) (len=36) "4b18aaec-038a-4bc5-afe8-a596d6deea3b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 62  31 38 61 61 65 63 2d 30  |d\":\"4b18aaec-0|
              00000090  33 38 61 2d 34 62 63 35  2d 61 66 65 38 2d 61 35  |38a-4bc5-afe8-a5|
              000000a0  39 36 64 36 64 65 65 61  33 62 5c 22 7d 22 3a 7b  |96d6deea3b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-7zgcf",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-7zgcf",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "eipo9quoh3ef-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.38",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.38"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140481,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0419 16:21:23.725390 14 deployment.go:67] Pod "webserver-deployment-67c89d485c-bgf49" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-67c89d485c-bgf49",
      GenerateName: (string) (len=32) "webserver-deployment-67c89d485c-",
      Namespace: (string) (len=15) "deployment-7995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8a1fc673-c224-4aaf-bbcc-42c36d3e57f2",
      ResourceVersion: (string) (len=5) "15801",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140481,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-67c89d485c",
          UID: (types.UID) (len=36) "4b18aaec-038a-4bc5-afe8-a596d6deea3b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 62  31 38 61 61 65 63 2d 30  |d\":\"4b18aaec-0|
              00000090  33 38 61 2d 34 62 63 35  2d 61 66 65 38 2d 61 35  |38a-4bc5-afe8-a5|
              000000a0  39 36 64 36 64 65 65 61  33 62 5c 22 7d 22 3a 7b  |96d6deea3b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-4b26g",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-4b26g",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "eipo9quoh3ef-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.197",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.197"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140481,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0419 16:21:23.732172 14 deployment.go:67] Pod "webserver-deployment-67c89d485c-c5z57" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-67c89d485c-c5z57",
      GenerateName: (string) (len=32) "webserver-deployment-67c89d485c-",
      Namespace: (string) (len=15) "deployment-7995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "aac93d2f-1dee-40e9-a527-b1481bb36eae",
      ResourceVersion: (string) (len=5) "15852",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140483,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-67c89d485c",
          UID: (types.UID) (len=36) "4b18aaec-038a-4bc5-afe8-a596d6deea3b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140483,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 62  31 38 61 61 65 63 2d 30  |d\":\"4b18aaec-0|
              00000090  33 38 61 2d 34 62 63 35  2d 61 66 65 38 2d 61 35  |38a-4bc5-afe8-a5|
              000000a0  39 36 64 36 64 65 65 61  33 62 5c 22 7d 22 3a 7b  |96d6deea3b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-qjkg8",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-qjkg8",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0419 16:21:23.735785 14 deployment.go:67] Pod "webserver-deployment-67c89d485c-cj9v6" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-67c89d485c-cj9v6",
      GenerateName: (string) (len=32) "webserver-deployment-67c89d485c-",
      Namespace: (string) (len=15) "deployment-7995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4715194a-473f-4779-9417-0c66504f8605",
      ResourceVersion: (string) (len=5) "15795",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140481,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-67c89d485c",
          UID: (types.UID) (len=36) "4b18aaec-038a-4bc5-afe8-a596d6deea3b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 62  31 38 61 61 65 63 2d 30  |d\":\"4b18aaec-0|
              00000090  33 38 61 2d 34 62 63 35  2d 61 66 65 38 2d 61 35  |38a-4bc5-afe8-a5|
              000000a0  39 36 64 36 64 65 65 61  33 62 5c 22 7d 22 3a 7b  |96d6deea3b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-xk6rm",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-xk6rm",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "eipo9quoh3ef-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.127",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.127"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140481,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0419 16:21:23.746688 14 deployment.go:67] Pod "webserver-deployment-67c89d485c-fkt4p" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-67c89d485c-fkt4p",
      GenerateName: (string) (len=32) "webserver-deployment-67c89d485c-",
      Namespace: (string) (len=15) "deployment-7995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f8170f3f-b8e9-4e4e-854d-f680cbcd889c",
      ResourceVersion: (string) (len=5) "15848",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140483,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-67c89d485c",
          UID: (types.UID) (len=36) "4b18aaec-038a-4bc5-afe8-a596d6deea3b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140483,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 62  31 38 61 61 65 63 2d 30  |d\":\"4b18aaec-0|
              00000090  33 38 61 2d 34 62 63 35  2d 61 66 65 38 2d 61 35  |38a-4bc5-afe8-a5|
              000000a0  39 36 64 36 64 65 65 61  33 62 5c 22 7d 22 3a 7b  |96d6deea3b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-b9hh6",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-b9hh6",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0419 16:21:23.758190 14 deployment.go:67] Pod "webserver-deployment-67c89d485c-rj4jj" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-67c89d485c-rj4jj",
      GenerateName: (string) (len=32) "webserver-deployment-67c89d485c-",
      Namespace: (string) (len=15) "deployment-7995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "48fe8d3b-47fc-4548-b634-b5abffe88b95",
      ResourceVersion: (string) (len=5) "15816",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140481,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-67c89d485c",
          UID: (types.UID) (len=36) "4b18aaec-038a-4bc5-afe8-a596d6deea3b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 62  31 38 61 61 65 63 2d 30  |d\":\"4b18aaec-0|
              00000090  33 38 61 2d 34 62 63 35  2d 61 66 65 38 2d 61 35  |38a-4bc5-afe8-a5|
              000000a0  39 36 64 36 64 65 65 61  33 62 5c 22 7d 22 3a 7b  |96d6deea3b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-x8q6b",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-x8q6b",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "eipo9quoh3ef-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.127",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.127"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140481,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0419 16:21:23.762991 14 deployment.go:67] Pod "webserver-deployment-67c89d485c-wj6xk" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-67c89d485c-wj6xk",
      GenerateName: (string) (len=32) "webserver-deployment-67c89d485c-",
      Namespace: (string) (len=15) "deployment-7995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8b67d460-ae7d-4ed3-9844-d4527a5ff913",
      ResourceVersion: (string) (len=5) "15856",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140483,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-67c89d485c",
          UID: (types.UID) (len=36) "4b18aaec-038a-4bc5-afe8-a596d6deea3b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140483,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 62  31 38 61 61 65 63 2d 30  |d\":\"4b18aaec-0|
              00000090  33 38 61 2d 34 62 63 35  2d 61 66 65 38 2d 61 35  |38a-4bc5-afe8-a5|
              000000a0  39 36 64 36 64 65 65 61  33 62 5c 22 7d 22 3a 7b  |96d6deea3b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-kh844",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-kh844",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0419 16:21:23.793664 14 deployment.go:67] Pod "webserver-deployment-67c89d485c-wxrn9" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-67c89d485c-wxrn9",
      GenerateName: (string) (len=32) "webserver-deployment-67c89d485c-",
      Namespace: (string) (len=15) "deployment-7995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6d34eadf-7e49-44c9-a40e-ba3b1e3627a2",
      ResourceVersion: (string) (len=5) "15819",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140481,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-67c89d485c",
          UID: (types.UID) (len=36) "4b18aaec-038a-4bc5-afe8-a596d6deea3b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 62  31 38 61 61 65 63 2d 30  |d\":\"4b18aaec-0|
              00000090  33 38 61 2d 34 62 63 35  2d 61 66 65 38 2d 61 35  |38a-4bc5-afe8-a5|
              000000a0  39 36 64 36 64 65 65 61  33 62 5c 22 7d 22 3a 7b  |96d6deea3b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-h97cm",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-h97cm",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "eipo9quoh3ef-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.38",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.38"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140481,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0419 16:21:23.807442 14 deployment.go:67] Pod "webserver-deployment-77db57d8df-6mndd" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-6mndd",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-7995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1184def2-3756-420f-85cd-d01bfc92042c",
      ResourceVersion: (string) (len=5) "15857",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140483,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "bb0f79f4-8723-4946-affd-528d3efd7d3a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140483,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 62  30 66 37 39 66 34 2d 38  |d\":\"bb0f79f4-8|
              00000090  37 32 33 2d 34 39 34 36  2d 61 66 66 64 2d 35 32  |723-4946-affd-52|
              000000a0  38 64 33 65 66 64 37 64  33 61 5c 22 7d 22 3a 7b  |8d3efd7d3a\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-t5jb2",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-t5jb2",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0419 16:21:23.818091 14 deployment.go:67] Pod "webserver-deployment-77db57d8df-8q9jg" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-8q9jg",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-7995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b5af6cc3-95c9-47d4-a3d6-8e0304f22833",
      ResourceVersion: (string) (len=5) "15767",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140477,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "bb0f79f4-8723-4946-affd-528d3efd7d3a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 62  30 66 37 39 66 34 2d 38  |d\":\"bb0f79f4-8|
              00000090  37 32 33 2d 34 39 34 36  2d 61 66 66 64 2d 35 32  |723-4946-affd-52|
              000000a0  38 64 33 65 66 64 37 64  33 61 5c 22 7d 22 3a 7b  |8d3efd7d3a\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140480,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 35 2e  35 30 5c 22 7d 22 3a 7b  |.233.65.50\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-4lggd",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-4lggd",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "eipo9quoh3ef-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140480,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140480,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140480,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.197",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.197"
        }
      },
      PodIP: (string) (len=12) "10.233.65.50",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.65.50"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140477,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63849140480,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://803c575310d6ee3f0c17cac98d9f49de0682c9b593ee88d240a625eb68b49a4d",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0419 16:21:23.834261 14 deployment.go:67] Pod "webserver-deployment-77db57d8df-b62rg" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-b62rg",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-7995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "28985c7f-5723-4049-a219-529c7ca1ba5f",
      ResourceVersion: (string) (len=5) "15850",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140483,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "bb0f79f4-8723-4946-affd-528d3efd7d3a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140483,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 62  30 66 37 39 66 34 2d 38  |d\":\"bb0f79f4-8|
              00000090  37 32 33 2d 34 39 34 36  2d 61 66 66 64 2d 35 32  |723-4946-affd-52|
              000000a0  38 64 33 65 66 64 37 64  33 61 5c 22 7d 22 3a 7b  |8d3efd7d3a\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-72bwf",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-72bwf",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0419 16:21:23.838345 14 deployment.go:67] Pod "webserver-deployment-77db57d8df-bws8q" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-bws8q",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-7995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5cad6485-16e2-40ae-8276-f3b0dae052f2",
      ResourceVersion: (string) (len=5) "15762",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140477,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "bb0f79f4-8723-4946-affd-528d3efd7d3a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 62  30 66 37 39 66 34 2d 38  |d\":\"bb0f79f4-8|
              00000090  37 32 33 2d 34 39 34 36  2d 61 66 66 64 2d 35 32  |723-4946-affd-52|
              000000a0  38 64 33 65 66 64 37 64  33 61 5c 22 7d 22 3a 7b  |8d3efd7d3a\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140480,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 35 2e  34 39 5c 22 7d 22 3a 7b  |.233.65.49\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-99zt6",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-99zt6",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "eipo9quoh3ef-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140480,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140480,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140480,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.197",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.197"
        }
      },
      PodIP: (string) (len=12) "10.233.65.49",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.65.49"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140477,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63849140480,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://b7962b605c6a38503d061bc9a96536e8bdb07dc901fe881258a8d23dc5e03cc0",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0419 16:21:23.853618 14 deployment.go:67] Pod "webserver-deployment-77db57d8df-h2z2q" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-h2z2q",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-7995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7a82954c-edae-4634-9467-adc89a8d7550",
      ResourceVersion: (string) (len=5) "15859",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140483,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "bb0f79f4-8723-4946-affd-528d3efd7d3a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140483,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 62  30 66 37 39 66 34 2d 38  |d\":\"bb0f79f4-8|
              00000090  37 32 33 2d 34 39 34 36  2d 61 66 66 64 2d 35 32  |723-4946-affd-52|
              000000a0  38 64 33 65 66 64 37 64  33 61 5c 22 7d 22 3a 7b  |8d3efd7d3a\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140483,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-lckxm",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-lckxm",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "eipo9quoh3ef-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140483,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140483,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140483,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140483,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140483,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.127",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.127"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140483,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0419 16:21:23.864790 14 deployment.go:67] Pod "webserver-deployment-77db57d8df-jhspm" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-jhspm",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-7995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "40d7ac71-f307-4a9c-a572-c5b67a3c43a6",
      ResourceVersion: (string) (len=5) "15743",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140477,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "bb0f79f4-8723-4946-affd-528d3efd7d3a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 62  30 66 37 39 66 34 2d 38  |d\":\"bb0f79f4-8|
              00000090  37 32 33 2d 34 39 34 36  2d 61 66 66 64 2d 35 32  |723-4946-affd-52|
              000000a0  38 64 33 65 66 64 37 64  33 61 5c 22 7d 22 3a 7b  |8d3efd7d3a\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140479,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 34 2e  36 33 5c 22 7d 22 3a 7b  |.233.64.63\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-ncvhf",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-ncvhf",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "eipo9quoh3ef-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140479,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140479,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140479,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.38",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.38"
        }
      },
      PodIP: (string) (len=12) "10.233.64.63",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.64.63"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140477,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63849140479,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://576a425d29460f8e767eab76fe814dbe58212db310562e3fd223c65c4393fde3",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0419 16:21:23.943368 14 deployment.go:67] Pod "webserver-deployment-77db57d8df-k86w9" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-k86w9",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-7995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d593a644-ce4d-4b77-9e14-80d1b339b1de",
      ResourceVersion: (string) (len=5) "15849",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140483,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "bb0f79f4-8723-4946-affd-528d3efd7d3a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140483,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 62  30 66 37 39 66 34 2d 38  |d\":\"bb0f79f4-8|
              00000090  37 32 33 2d 34 39 34 36  2d 61 66 66 64 2d 35 32  |723-4946-affd-52|
              000000a0  38 64 33 65 66 64 37 64  33 61 5c 22 7d 22 3a 7b  |8d3efd7d3a\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-4q2tn",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-4q2tn",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0419 16:21:23.965019 14 deployment.go:67] Pod "webserver-deployment-77db57d8df-lffsq" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-lffsq",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-7995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "464f4216-34ff-4f61-b0c6-f45f8b68b778",
      ResourceVersion: (string) (len=5) "15764",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140477,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "bb0f79f4-8723-4946-affd-528d3efd7d3a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 62  30 66 37 39 66 34 2d 38  |d\":\"bb0f79f4-8|
              00000090  37 32 33 2d 34 39 34 36  2d 61 66 66 64 2d 35 32  |723-4946-affd-52|
              000000a0  38 64 33 65 66 64 37 64  33 61 5c 22 7d 22 3a 7b  |8d3efd7d3a\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140480,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 35 2e  34 38 5c 22 7d 22 3a 7b  |.233.65.48\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-7cxsz",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-7cxsz",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "eipo9quoh3ef-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140480,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140480,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140480,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.197",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.197"
        }
      },
      PodIP: (string) (len=12) "10.233.65.48",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.65.48"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140477,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63849140480,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://2550d3db597a49f2297ef208e1ef102da43237fdd498ec73c211a7dd431c94ad",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0419 16:21:23.976182 14 deployment.go:67] Pod "webserver-deployment-77db57d8df-mkxq2" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-mkxq2",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-7995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9b728994-04a5-46d6-b253-85d2ec10f99d",
      ResourceVersion: (string) (len=5) "15746",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140477,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "bb0f79f4-8723-4946-affd-528d3efd7d3a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 62  30 66 37 39 66 34 2d 38  |d\":\"bb0f79f4-8|
              00000090  37 32 33 2d 34 39 34 36  2d 61 66 66 64 2d 35 32  |723-4946-affd-52|
              000000a0  38 64 33 65 66 64 37 64  33 61 5c 22 7d 22 3a 7b  |8d3efd7d3a\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140479,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 34 2e  36 32 5c 22 7d 22 3a 7b  |.233.64.62\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-vjkgq",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-vjkgq",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "eipo9quoh3ef-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140479,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140479,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140479,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.38",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.38"
        }
      },
      PodIP: (string) (len=12) "10.233.64.62",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.64.62"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140477,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63849140478,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://540db74ed7522d223b640cd3011ac141106b7c9e3a0a65c1d5db8209b0c46e67",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0419 16:21:23.983375 14 deployment.go:67] Pod "webserver-deployment-77db57d8df-nm6rs" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-nm6rs",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-7995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "db297214-9288-4491-8b8d-688a3cdc56a9",
      ResourceVersion: (string) (len=5) "15712",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140477,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "bb0f79f4-8723-4946-affd-528d3efd7d3a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 62  30 66 37 39 66 34 2d 38  |d\":\"bb0f79f4-8|
              00000090  37 32 33 2d 34 39 34 36  2d 61 66 66 64 2d 35 32  |723-4946-affd-52|
              000000a0  38 64 33 65 66 64 37 64  33 61 5c 22 7d 22 3a 7b  |8d3efd7d3a\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140478,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 34 2e  36 31 5c 22 7d 22 3a 7b  |.233.64.61\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-7zcmd",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-7zcmd",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "eipo9quoh3ef-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140478,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140478,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140478,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.38",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.38"
        }
      },
      PodIP: (string) (len=12) "10.233.64.61",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.64.61"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140477,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63849140478,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://c52e00f1a3a8a35f480452206a95b02fd65a79368fdbdfef701992ad746a0eba",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0419 16:21:23.995507 14 deployment.go:67] Pod "webserver-deployment-77db57d8df-px7s4" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-px7s4",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-7995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "709df954-0254-48b5-885f-a01f35c0588e",
      ResourceVersion: (string) (len=5) "15734",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140477,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "bb0f79f4-8723-4946-affd-528d3efd7d3a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 62  30 66 37 39 66 34 2d 38  |d\":\"bb0f79f4-8|
              00000090  37 32 33 2d 34 39 34 36  2d 61 66 66 64 2d 35 32  |723-4946-affd-52|
              000000a0  38 64 33 65 66 64 37 64  33 61 5c 22 7d 22 3a 7b  |8d3efd7d3a\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140479,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 36 2e  31 37 32 5c 22 7d 22 3a  |.233.66.172\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-57w8s",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-57w8s",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "eipo9quoh3ef-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140479,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140479,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140479,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.127",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.127"
        }
      },
      PodIP: (string) (len=13) "10.233.66.172",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.66.172"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140477,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63849140478,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://cac509e34b2e9a49f6a43c4792539a3a5e57f57aedf9e21bf26f2bbea4a683b4",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0419 16:21:24.009661 14 deployment.go:67] Pod "webserver-deployment-77db57d8df-rtsf8" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-rtsf8",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-7995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9967d4ed-7337-4d56-a9dc-a52aaae086ca",
      ResourceVersion: (string) (len=5) "15851",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140483,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "bb0f79f4-8723-4946-affd-528d3efd7d3a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140483,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 62  30 66 37 39 66 34 2d 38  |d\":\"bb0f79f4-8|
              00000090  37 32 33 2d 34 39 34 36  2d 61 66 66 64 2d 35 32  |723-4946-affd-52|
              000000a0  38 64 33 65 66 64 37 64  33 61 5c 22 7d 22 3a 7b  |8d3efd7d3a\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-9fwdz",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-9fwdz",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "eipo9quoh3ef-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140483,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0419 16:21:24.023236 14 deployment.go:67] Pod "webserver-deployment-77db57d8df-tbfbg" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-tbfbg",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-7995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "93514df1-e293-46c7-b77a-552ee55c2218",
      ResourceVersion: (string) (len=5) "15723",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140477,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "bb0f79f4-8723-4946-affd-528d3efd7d3a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 62  30 66 37 39 66 34 2d 38  |d\":\"bb0f79f4-8|
              00000090  37 32 33 2d 34 39 34 36  2d 61 66 66 64 2d 35 32  |723-4946-affd-52|
              000000a0  38 64 33 65 66 64 37 64  33 61 5c 22 7d 22 3a 7b  |8d3efd7d3a\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140478,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 36 2e  31 37 30 5c 22 7d 22 3a  |.233.66.170\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-v7qrl",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-v7qrl",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "eipo9quoh3ef-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140478,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140478,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140478,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.127",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.127"
        }
      },
      PodIP: (string) (len=13) "10.233.66.170",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.66.170"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140477,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63849140478,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://bf13c03bc012b9e48d708ab7ffa3bc8651e586d489ed3f8f717e259244b82ab6",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0419 16:21:24.028773 14 deployment.go:67] Pod "webserver-deployment-77db57d8df-twzzg" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-twzzg",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-7995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c4ca1a0c-41a0-4b32-bac1-70f4a5600666",
      ResourceVersion: (string) (len=5) "15845",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140483,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "bb0f79f4-8723-4946-affd-528d3efd7d3a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140483,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 62  30 66 37 39 66 34 2d 38  |d\":\"bb0f79f4-8|
              00000090  37 32 33 2d 34 39 34 36  2d 61 66 66 64 2d 35 32  |723-4946-affd-52|
              000000a0  38 64 33 65 66 64 37 64  33 61 5c 22 7d 22 3a 7b  |8d3efd7d3a\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-dgkvd",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-dgkvd",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0419 16:21:24.040190 14 deployment.go:67] Pod "webserver-deployment-77db57d8df-xcntv" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-xcntv",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-7995",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6ab7eebb-272f-4005-9b7d-34345ed87e4f",
      ResourceVersion: (string) (len=5) "15858",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140483,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "bb0f79f4-8723-4946-affd-528d3efd7d3a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140483,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 62  30 66 37 39 66 34 2d 38  |d\":\"bb0f79f4-8|
              00000090  37 32 33 2d 34 39 34 36  2d 61 66 66 64 2d 35 32  |723-4946-affd-52|
              000000a0  38 64 33 65 66 64 37 64  33 61 5c 22 7d 22 3a 7b  |8d3efd7d3a\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-8fdzl",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-8fdzl",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0419 16:21:24.054738 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-7995" for this suite. @ 04/19/24 16:21:24.126
• [7.060 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:60
  STEP: Creating a kubernetes client @ 04/19/24 16:21:24.314
  I0419 16:21:24.314688 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename watch @ 04/19/24 16:21:24.343
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:21:24.446
  E0419 16:21:24.447513      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:21:24.451
  STEP: creating a watch on configmaps with label A @ 04/19/24 16:21:24.463
  STEP: creating a watch on configmaps with label B @ 04/19/24 16:21:24.466
  STEP: creating a watch on configmaps with label A or B @ 04/19/24 16:21:24.469
  STEP: creating a configmap with label A and ensuring the correct watchers observe the notification @ 04/19/24 16:21:24.473
  I0419 16:21:24.490786 14 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1522  930e896e-3971-4a12-b0b3-64a756e4b948 15938 0 2024-04-19 16:21:24 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-19 16:21:24 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0419 16:21:24.491313 14 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1522  930e896e-3971-4a12-b0b3-64a756e4b948 15938 0 2024-04-19 16:21:24 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-19 16:21:24 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A and ensuring the correct watchers observe the notification @ 04/19/24 16:21:24.491
  I0419 16:21:24.520121 14 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1522  930e896e-3971-4a12-b0b3-64a756e4b948 15939 0 2024-04-19 16:21:24 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-19 16:21:24 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0419 16:21:24.520346 14 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1522  930e896e-3971-4a12-b0b3-64a756e4b948 15939 0 2024-04-19 16:21:24 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-19 16:21:24 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A again and ensuring the correct watchers observe the notification @ 04/19/24 16:21:24.52
  I0419 16:21:24.549711 14 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1522  930e896e-3971-4a12-b0b3-64a756e4b948 15941 0 2024-04-19 16:21:24 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-19 16:21:24 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0419 16:21:24.550399 14 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1522  930e896e-3971-4a12-b0b3-64a756e4b948 15941 0 2024-04-19 16:21:24 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-19 16:21:24 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap A and ensuring the correct watchers observe the notification @ 04/19/24 16:21:24.55
  I0419 16:21:24.573307 14 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1522  930e896e-3971-4a12-b0b3-64a756e4b948 15942 0 2024-04-19 16:21:24 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-19 16:21:24 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0419 16:21:24.573851 14 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1522  930e896e-3971-4a12-b0b3-64a756e4b948 15942 0 2024-04-19 16:21:24 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-19 16:21:24 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: creating a configmap with label B and ensuring the correct watchers observe the notification @ 04/19/24 16:21:24.574
  I0419 16:21:24.586656 14 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1522  c7231336-f1bf-43a1-93f0-982c53705edc 15943 0 2024-04-19 16:21:24 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-04-19 16:21:24 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0419 16:21:24.587117 14 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1522  c7231336-f1bf-43a1-93f0-982c53705edc 15943 0 2024-04-19 16:21:24 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-04-19 16:21:24 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0419 16:21:25.448686      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:26.449156      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:27.449605      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:28.450773      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:29.451252      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:30.451218      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:31.452097      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:32.452515      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:33.452778      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:34.453172      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting configmap B and ensuring the correct watchers observe the notification @ 04/19/24 16:21:34.588
  I0419 16:21:34.603979 14 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1522  c7231336-f1bf-43a1-93f0-982c53705edc 16168 0 2024-04-19 16:21:24 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-04-19 16:21:24 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0419 16:21:34.604488 14 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1522  c7231336-f1bf-43a1-93f0-982c53705edc 16168 0 2024-04-19 16:21:24 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-04-19 16:21:24 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0419 16:21:35.453777      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:36.454300      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:37.454554      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:38.454979      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:39.455812      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:40.457105      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:41.458783      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:42.460329      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:43.460648      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:44.460815      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:21:44.606645 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-1522" for this suite. @ 04/19/24 16:21:44.622
• [20.326 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:131
  STEP: Creating a kubernetes client @ 04/19/24 16:21:44.65
  I0419 16:21:44.650672 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename runtimeclass @ 04/19/24 16:21:44.657
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:21:44.687
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:21:44.696
  E0419 16:21:45.462120      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:46.465477      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:21:46.776522 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-9320" for this suite. @ 04/19/24 16:21:46.791
• [2.163 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:58
  STEP: Creating a kubernetes client @ 04/19/24 16:21:46.824
  I0419 16:21:46.824288 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename projected @ 04/19/24 16:21:46.829
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:21:46.865
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:21:46.876
  STEP: Creating configMap with name projected-configmap-test-volume-f199f703-0134-47f6-9b78-2a9fb828f917 @ 04/19/24 16:21:46.886
  STEP: Creating a pod to test consume configMaps @ 04/19/24 16:21:46.902
  E0419 16:21:47.465607      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:48.466260      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:49.468433      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:50.466984      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:21:50.952
  I0419 16:21:50.965900 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-projected-configmaps-2c73fa75-8803-466c-b2c8-c7b9807c453f container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/24 16:21:50.992
  I0419 16:21:51.031546 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9665" for this suite. @ 04/19/24 16:21:51.045
• [4.232 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:539
  STEP: Creating a kubernetes client @ 04/19/24 16:21:51.069
  I0419 16:21:51.069441 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename gc @ 04/19/24 16:21:51.074
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:21:51.103
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:21:51.112
  STEP: create the deployment @ 04/19/24 16:21:51.121
  W0419 16:21:51.134688      14 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 04/19/24 16:21:51.135
  E0419 16:21:51.472600      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the deployment @ 04/19/24 16:21:51.658
  STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs @ 04/19/24 16:21:51.67
  STEP: Gathering metrics @ 04/19/24 16:21:52.215
  I0419 16:21:52.446118 14 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0419 16:21:52.460766 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0419 16:21:52.470011      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "gc-9340" for this suite. @ 04/19/24 16:21:52.471
• [1.419 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:135
  STEP: Creating a kubernetes client @ 04/19/24 16:21:52.488
  I0419 16:21:52.488507 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename container-probe @ 04/19/24 16:21:52.491
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:21:52.518
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:21:52.523
  STEP: Creating pod busybox-692d8cca-3a89-4cd8-9468-8ce253826f8b in namespace container-probe-1034 @ 04/19/24 16:21:52.529
  E0419 16:21:53.471505      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:54.471651      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/19/24 16:21:54.568
  I0419 16:21:54.583360 14 container_probe.go:1749] Initial restart count of pod busybox-692d8cca-3a89-4cd8-9468-8ce253826f8b is 0
  I0419 16:21:54.600652 14 container_probe.go:1759] Get pod busybox-692d8cca-3a89-4cd8-9468-8ce253826f8b in namespace container-probe-1034
  E0419 16:21:55.475904      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:56.476041      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:21:56.611816 14 container_probe.go:1759] Get pod busybox-692d8cca-3a89-4cd8-9468-8ce253826f8b in namespace container-probe-1034
  E0419 16:21:57.477300      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:58.477844      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:21:58.623447 14 container_probe.go:1759] Get pod busybox-692d8cca-3a89-4cd8-9468-8ce253826f8b in namespace container-probe-1034
  E0419 16:21:59.478551      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:00.479135      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:22:00.634998 14 container_probe.go:1759] Get pod busybox-692d8cca-3a89-4cd8-9468-8ce253826f8b in namespace container-probe-1034
  E0419 16:22:01.479336      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:02.479731      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:22:02.646880 14 container_probe.go:1759] Get pod busybox-692d8cca-3a89-4cd8-9468-8ce253826f8b in namespace container-probe-1034
  E0419 16:22:03.479811      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:04.480456      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:22:04.658994 14 container_probe.go:1759] Get pod busybox-692d8cca-3a89-4cd8-9468-8ce253826f8b in namespace container-probe-1034
  E0419 16:22:05.480859      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:06.481477      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:22:06.673385 14 container_probe.go:1759] Get pod busybox-692d8cca-3a89-4cd8-9468-8ce253826f8b in namespace container-probe-1034
  E0419 16:22:07.482380      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:08.482573      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:22:08.686327 14 container_probe.go:1759] Get pod busybox-692d8cca-3a89-4cd8-9468-8ce253826f8b in namespace container-probe-1034
  E0419 16:22:09.483198      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:10.484042      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:22:10.695581 14 container_probe.go:1759] Get pod busybox-692d8cca-3a89-4cd8-9468-8ce253826f8b in namespace container-probe-1034
  E0419 16:22:11.484356      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:12.484808      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:22:12.707966 14 container_probe.go:1759] Get pod busybox-692d8cca-3a89-4cd8-9468-8ce253826f8b in namespace container-probe-1034
  E0419 16:22:13.485373      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:14.486454      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:22:14.720359 14 container_probe.go:1759] Get pod busybox-692d8cca-3a89-4cd8-9468-8ce253826f8b in namespace container-probe-1034
  E0419 16:22:15.486733      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:16.487022      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:22:16.729817 14 container_probe.go:1759] Get pod busybox-692d8cca-3a89-4cd8-9468-8ce253826f8b in namespace container-probe-1034
  E0419 16:22:17.488370      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:18.488608      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:22:18.769941 14 container_probe.go:1759] Get pod busybox-692d8cca-3a89-4cd8-9468-8ce253826f8b in namespace container-probe-1034
  E0419 16:22:19.489442      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:20.490114      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:22:20.782023 14 container_probe.go:1759] Get pod busybox-692d8cca-3a89-4cd8-9468-8ce253826f8b in namespace container-probe-1034
  E0419 16:22:21.497255      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:22.491083      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:22:22.795149 14 container_probe.go:1759] Get pod busybox-692d8cca-3a89-4cd8-9468-8ce253826f8b in namespace container-probe-1034
  E0419 16:22:23.492214      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:24.492161      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:22:24.805525 14 container_probe.go:1759] Get pod busybox-692d8cca-3a89-4cd8-9468-8ce253826f8b in namespace container-probe-1034
  E0419 16:22:25.493429      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:26.492656      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:22:26.818572 14 container_probe.go:1759] Get pod busybox-692d8cca-3a89-4cd8-9468-8ce253826f8b in namespace container-probe-1034
  E0419 16:22:27.496313      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:28.495551      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:22:28.829410 14 container_probe.go:1759] Get pod busybox-692d8cca-3a89-4cd8-9468-8ce253826f8b in namespace container-probe-1034
  E0419 16:22:29.499647      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:30.499843      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:22:30.843989 14 container_probe.go:1759] Get pod busybox-692d8cca-3a89-4cd8-9468-8ce253826f8b in namespace container-probe-1034
  E0419 16:22:31.500349      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:32.501322      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:22:32.852866 14 container_probe.go:1759] Get pod busybox-692d8cca-3a89-4cd8-9468-8ce253826f8b in namespace container-probe-1034
  E0419 16:22:33.502308      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:34.502771      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:22:34.861641 14 container_probe.go:1759] Get pod busybox-692d8cca-3a89-4cd8-9468-8ce253826f8b in namespace container-probe-1034
  E0419 16:22:35.503542      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:36.504018      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:22:36.871426 14 container_probe.go:1759] Get pod busybox-692d8cca-3a89-4cd8-9468-8ce253826f8b in namespace container-probe-1034
  E0419 16:22:37.503752      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:38.504362      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:22:38.883919 14 container_probe.go:1759] Get pod busybox-692d8cca-3a89-4cd8-9468-8ce253826f8b in namespace container-probe-1034
  E0419 16:22:39.505333      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:40.506251      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:22:40.890961 14 container_probe.go:1759] Get pod busybox-692d8cca-3a89-4cd8-9468-8ce253826f8b in namespace container-probe-1034
  E0419 16:22:41.506468      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:42.507558      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:22:42.903398 14 container_probe.go:1759] Get pod busybox-692d8cca-3a89-4cd8-9468-8ce253826f8b in namespace container-probe-1034
  E0419 16:22:43.508015      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:44.508669      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:22:44.910450 14 container_probe.go:1759] Get pod busybox-692d8cca-3a89-4cd8-9468-8ce253826f8b in namespace container-probe-1034
  I0419 16:22:44.910596 14 container_probe.go:1763] Restart count of pod container-probe-1034/busybox-692d8cca-3a89-4cd8-9468-8ce253826f8b is now 1 (50.326518099s elapsed)
  STEP: deleting the pod @ 04/19/24 16:22:44.911
  I0419 16:22:44.962062 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-1034" for this suite. @ 04/19/24 16:22:44.973
• [52.497 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:130
  STEP: Creating a kubernetes client @ 04/19/24 16:22:44.992
  I0419 16:22:44.993449 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename sched-preemption @ 04/19/24 16:22:45
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:22:45.03
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:22:45.036
  I0419 16:22:45.083139 14 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0419 16:22:45.508950      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:46.509441      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:47.510285      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:48.511020      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:49.511789      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:50.512269      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:51.512772      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:52.514153      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:53.514569      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:54.514979      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:55.515016      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:56.516203      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:57.517036      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:58.517291      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:59.517329      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:00.518661      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:01.518165      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:02.519151      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:03.519208      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:04.520148      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:05.520435      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:06.524018      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:07.524352      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:08.524611      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:09.527660      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:10.525330      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:11.526607      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:12.527425      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:13.528549      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:14.532929      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:15.537493      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:16.531308      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:17.532025      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:18.533305      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:19.533393      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:20.534603      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:21.536799      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:22.536583      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:23.536763      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:24.537182      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:25.537354      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:26.538003      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:27.538261      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:28.539532      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:29.539760      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:30.540815      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:31.541253      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:32.541966      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:33.542031      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:34.542419      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:35.542735      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:36.543299      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:37.543571      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:38.545261      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:39.544091      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:40.544683      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:41.545169      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:42.545785      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:43.545839      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:44.546147      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:23:45.094454 14 util.go:400] Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 04/19/24 16:23:45.102
  I0419 16:23:45.151797 14 preemption.go:178] Created pod: pod0-0-sched-preemption-low-priority
  I0419 16:23:45.165365 14 preemption.go:178] Created pod: pod0-1-sched-preemption-medium-priority
  I0419 16:23:45.215597 14 preemption.go:178] Created pod: pod1-0-sched-preemption-medium-priority
  I0419 16:23:45.240915 14 preemption.go:178] Created pod: pod1-1-sched-preemption-medium-priority
  I0419 16:23:45.322599 14 preemption.go:178] Created pod: pod2-0-sched-preemption-medium-priority
  I0419 16:23:45.356944 14 preemption.go:178] Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 04/19/24 16:23:45.357
  E0419 16:23:45.546739      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:46.547040      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Run a high priority pod that has same requirements as that of lower priority pod @ 04/19/24 16:23:47.412
  E0419 16:23:47.547735      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:48.547972      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:49.548778      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:50.548805      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:51.550008      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:23:51.633602 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-8619" for this suite. @ 04/19/24 16:23:51.643
• [66.665 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:190
  STEP: Creating a kubernetes client @ 04/19/24 16:23:51.667
  I0419 16:23:51.668131 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename var-expansion @ 04/19/24 16:23:51.673
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:23:51.705
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:23:51.711
  E0419 16:23:52.550925      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:53.552163      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:23:53.747026 14 delete.go:62] Deleting pod "var-expansion-f6ee1fcd-e172-46ea-9fb0-87ee852a7d95" in namespace "var-expansion-5825"
  I0419 16:23:53.773948 14 delete.go:70] Wait up to 5m0s for pod "var-expansion-f6ee1fcd-e172-46ea-9fb0-87ee852a7d95" to be fully deleted
  E0419 16:23:54.552273      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:55.553290      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:23:55.793028 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-5825" for this suite. @ 04/19/24 16:23:55.804
• [4.157 seconds]
------------------------------
[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:350
  STEP: Creating a kubernetes client @ 04/19/24 16:23:55.825
  I0419 16:23:55.825928 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename field-validation @ 04/19/24 16:23:55.83
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:23:55.854
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:23:55.86
  I0419 16:23:55.867871 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  W0419 16:23:55.870952      14 field_validation.go:423] props: &JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{spec: {  <nil>  object   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[cronSpec:{  <nil>  string   nil <nil> false <nil> false <nil> <nil> ^(\d+|\*)(/\d+)?(\s+(\d+|\*)(/\d+)?){4}$ <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} foo:{  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} ports:{  <nil>  array   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] &JSONSchemaPropsOrArray{Schema:&JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[containerPort protocol],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{containerPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostIP: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},name: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},protocol: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},},JSONSchemas:[]JSONSchemaProps{},} [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [containerPort protocol] 0xc004905280 <nil> []}] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},}
  E0419 16:23:56.553735      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:57.555148      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:58.555988      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0419 16:23:58.633466      14 warnings.go:70] unknown field "alpha"
  W0419 16:23:58.633533      14 warnings.go:70] unknown field "beta"
  W0419 16:23:58.633548      14 warnings.go:70] unknown field "delta"
  W0419 16:23:58.633569      14 warnings.go:70] unknown field "epsilon"
  W0419 16:23:58.633584      14 warnings.go:70] unknown field "gamma"
  I0419 16:23:59.221530 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-5039" for this suite. @ 04/19/24 16:23:59.236
• [3.430 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:649
  STEP: Creating a kubernetes client @ 04/19/24 16:23:59.257
  I0419 16:23:59.257315 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename svcaccounts @ 04/19/24 16:23:59.261
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:23:59.294
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:23:59.301
  STEP: creating a ServiceAccount @ 04/19/24 16:23:59.308
  STEP: watching for the ServiceAccount to be added @ 04/19/24 16:23:59.321
  STEP: patching the ServiceAccount @ 04/19/24 16:23:59.325
  STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) @ 04/19/24 16:23:59.338
  STEP: deleting the ServiceAccount @ 04/19/24 16:23:59.347
  I0419 16:23:59.375848 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-8767" for this suite. @ 04/19/24 16:23:59.385
• [0.142 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should support CronJob API operations [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:341
  STEP: Creating a kubernetes client @ 04/19/24 16:23:59.399
  I0419 16:23:59.400063 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename cronjob @ 04/19/24 16:23:59.405
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:23:59.435
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:23:59.44
  STEP: Creating a cronjob @ 04/19/24 16:23:59.451
  STEP: creating @ 04/19/24 16:23:59.451
  STEP: getting @ 04/19/24 16:23:59.463
  STEP: listing @ 04/19/24 16:23:59.47
  STEP: watching @ 04/19/24 16:23:59.479
  I0419 16:23:59.479206 14 cronjob.go:370] starting watch
  STEP: cluster-wide listing @ 04/19/24 16:23:59.481
  STEP: cluster-wide watching @ 04/19/24 16:23:59.487
  I0419 16:23:59.487644 14 cronjob.go:382] starting watch
  STEP: patching @ 04/19/24 16:23:59.49
  STEP: updating @ 04/19/24 16:23:59.503
  I0419 16:23:59.521974 14 cronjob.go:406] waiting for watch events with expected annotations
  I0419 16:23:59.522909 14 cronjob.go:420] saw patched and updated annotations
  STEP: patching /status @ 04/19/24 16:23:59.523
  STEP: updating /status @ 04/19/24 16:23:59.534
  STEP: get /status @ 04/19/24 16:23:59.552
  E0419 16:23:59.556194      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting @ 04/19/24 16:23:59.56
  STEP: deleting a collection @ 04/19/24 16:23:59.591
  I0419 16:23:59.614042 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-1805" for this suite. @ 04/19/24 16:23:59.628
• [0.244 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:117
  STEP: Creating a kubernetes client @ 04/19/24 16:23:59.654
  I0419 16:23:59.654848 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename field-validation @ 04/19/24 16:23:59.658
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:23:59.689
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:23:59.694
  STEP: apply creating a deployment @ 04/19/24 16:23:59.701
  I0419 16:23:59.726499 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-6146" for this suite. @ 04/19/24 16:23:59.734
• [0.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:185
  STEP: Creating a kubernetes client @ 04/19/24 16:23:59.752
  I0419 16:23:59.752486 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename deployment @ 04/19/24 16:23:59.757
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:23:59.782
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:23:59.788
  STEP: creating a Deployment @ 04/19/24 16:23:59.817
  STEP: waiting for Deployment to be created @ 04/19/24 16:23:59.873
  STEP: waiting for all Replicas to be Ready @ 04/19/24 16:23:59.879
  I0419 16:23:59.882329 14 deployment.go:246] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0419 16:23:59.882403 14 deployment.go:248] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0419 16:23:59.882470 14 deployment.go:246] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0419 16:23:59.882570 14 deployment.go:248] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0419 16:23:59.886862 14 deployment.go:246] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0419 16:23:59.887201 14 deployment.go:248] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0419 16:23:59.965563 14 deployment.go:246] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0419 16:23:59.965669 14 deployment.go:248] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  E0419 16:24:00.557077      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:24:00.759552 14 deployment.go:246] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  I0419 16:24:00.760129 14 deployment.go:248] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  I0419 16:24:00.981479 14 deployment.go:248] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 2 and labels map[test-deployment-static:true]
  STEP: patching the Deployment @ 04/19/24 16:24:00.981
  I0419 16:24:01.004499 14 deployment.go:290] observed event type ADDED
  STEP: waiting for Replicas to scale @ 04/19/24 16:24:01.005
  I0419 16:24:01.009672 14 deployment.go:309] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 0
  I0419 16:24:01.010018 14 deployment.go:311] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 0
  I0419 16:24:01.010374 14 deployment.go:309] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 0
  I0419 16:24:01.010665 14 deployment.go:311] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 0
  I0419 16:24:01.011017 14 deployment.go:309] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 0
  I0419 16:24:01.011321 14 deployment.go:311] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 0
  I0419 16:24:01.011650 14 deployment.go:309] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 0
  I0419 16:24:01.012032 14 deployment.go:311] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 0
  I0419 16:24:01.012440 14 deployment.go:309] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 1
  I0419 16:24:01.012833 14 deployment.go:311] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 1
  I0419 16:24:01.013271 14 deployment.go:309] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 2
  I0419 16:24:01.013634 14 deployment.go:311] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 2
  I0419 16:24:01.013935 14 deployment.go:309] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 2
  I0419 16:24:01.014280 14 deployment.go:311] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 2
  I0419 16:24:01.033266 14 deployment.go:309] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 2
  I0419 16:24:01.033698 14 deployment.go:311] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 2
  I0419 16:24:01.069923 14 deployment.go:309] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 2
  I0419 16:24:01.070485 14 deployment.go:311] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 2
  I0419 16:24:01.093288 14 deployment.go:309] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 1
  I0419 16:24:01.093802 14 deployment.go:311] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 1
  I0419 16:24:01.127057 14 deployment.go:309] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 1
  I0419 16:24:01.127442 14 deployment.go:311] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 1
  E0419 16:24:01.557724      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:24:01.793752 14 deployment.go:309] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 2
  I0419 16:24:01.794185 14 deployment.go:311] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 2
  I0419 16:24:01.846581 14 deployment.go:311] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 1
  STEP: listing Deployments @ 04/19/24 16:24:01.846
  I0419 16:24:01.860337 14 deployment.go:327] Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
  STEP: updating the Deployment @ 04/19/24 16:24:01.86
  I0419 16:24:01.883815 14 deployment.go:360] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 1
  STEP: fetching the DeploymentStatus @ 04/19/24 16:24:01.883
  I0419 16:24:01.923919 14 deployment.go:389] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0419 16:24:01.924349 14 deployment.go:389] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0419 16:24:02.015290 14 deployment.go:389] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0419 16:24:02.047000 14 deployment.go:389] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  E0419 16:24:02.558307      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:24:02.813008 14 deployment.go:389] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  I0419 16:24:02.873533 14 deployment.go:389] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  I0419 16:24:02.905417 14 deployment.go:389] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  E0419 16:24:03.559289      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:24:03.933378 14 deployment.go:389] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  STEP: patching the DeploymentStatus @ 04/19/24 16:24:03.991
  STEP: fetching the DeploymentStatus @ 04/19/24 16:24:04.014
  I0419 16:24:04.026127 14 deployment.go:449] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 1
  I0419 16:24:04.026570 14 deployment.go:449] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 1
  I0419 16:24:04.026947 14 deployment.go:449] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 1
  I0419 16:24:04.027499 14 deployment.go:449] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 1
  I0419 16:24:04.027870 14 deployment.go:449] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 2
  I0419 16:24:04.028296 14 deployment.go:449] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 2
  I0419 16:24:04.028721 14 deployment.go:449] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 2
  I0419 16:24:04.029157 14 deployment.go:449] observed Deployment test-deployment in namespace deployment-9158 with ReadyReplicas 3
  STEP: deleting the Deployment @ 04/19/24 16:24:04.029
  I0419 16:24:04.061639 14 deployment.go:475] observed event type MODIFIED
  I0419 16:24:04.062172 14 deployment.go:475] observed event type MODIFIED
  I0419 16:24:04.062624 14 deployment.go:475] observed event type MODIFIED
  I0419 16:24:04.062966 14 deployment.go:475] observed event type MODIFIED
  I0419 16:24:04.063313 14 deployment.go:475] observed event type MODIFIED
  I0419 16:24:04.063624 14 deployment.go:475] observed event type MODIFIED
  I0419 16:24:04.063959 14 deployment.go:475] observed event type MODIFIED
  I0419 16:24:04.064343 14 deployment.go:475] observed event type MODIFIED
  I0419 16:24:04.064649 14 deployment.go:475] observed event type MODIFIED
  I0419 16:24:04.065009 14 deployment.go:475] observed event type MODIFIED
  I0419 16:24:04.065414 14 deployment.go:475] observed event type MODIFIED
  I0419 16:24:04.072529 14 deployment.go:650] Log out all the ReplicaSets if there is no deployment created
  I0419 16:24:04.078804 14 deployment.go:657] ReplicaSet "test-deployment-5bf4984755":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=26) "test-deployment-5bf4984755",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9158",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1e9d0d93-a619-4ad8-8fa6-27c38d800a14",
      ResourceVersion: (string) (len=5) "16835",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140639,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "5bf4984755",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=15) "test-deployment",
          UID: (types.UID) (len=36) "27ea684e-f33f-4f82-a255-d9412ba1c293",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140641,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=827) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              000000d0  65 2d 68 61 73 68 22 3a  7b 7d 2c 22 66 3a 74 65  |e-hash":{},"f:te|
              000000e0  73 74 2d 64 65 70 6c 6f  79 6d 65 6e 74 2d 73 74  |st-deployment-st|
              000000f0  61 74 69 63 22 3a 7b 7d  7d 2c 22 66 3a 6f 77 6e  |atic":{}},"f:own|
              00000100  65 72 52 65 66 65 72 65  6e 63 65 73 22 3a 7b 22  |erReferences":{"|
              00000110  2e 22 3a 7b 7d 2c 22 6b  3a 7b 5c 22 75 69 64 5c  |.":{},"k:{\"uid\|
              00000120  22 3a 5c 22 32 37 65 61  36 38 34 65 2d 66 33 33  |":\"27ea684e-f33|
              00000130  66 2d 34 66 38 32 2d 61  32 35 35 2d 64 39 34 31  |f-4f82-a255-d941|
              00000140  32 62 61 31 63 32 39 33  5c 22 7d 22 3a 7b 7d 7d  |2ba1c293\"}":{}}|
              00000150  7d 2c 22 66 3a 73 70 65  63 22 3a 7b 22 66 3a 72  |},"f:spec":{"f:r|
              00000160  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 73  |eplicas":{},"f:s|
              00000170  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 74  |elector":{},"f:t|
              00000180  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000190  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              000001a0  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 70 6f  |s":{".":{},"f:po|
              000001b0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001c0  3a 7b 7d 2c 22 66 3a 74  65 73 74 2d 64 65 70 6c  |:{},"f:test-depl|
              000001d0  6f 79 6d 65 6e 74 2d 73  74 61 74 69 63 22 3a 7b  |oyment-static":{|
              000001e0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000200  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 74 65 73  |:{\"name\":\"tes|
              00000210  74 2d 64 65 70 6c 6f 79  6d 65 6e 74 5c 22 7d 22  |t-deployment\"}"|
              00000220  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000230  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000240  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000250  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000260  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              00000270  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              00000280  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000290  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000002a0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000002b0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000002c0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              000002d0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000002e0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000002f0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000300  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000310  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000320  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000330  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140641,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "5bf4984755",
          (string) (len=22) "test-deployment-static": (string) (len=4) "true"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "5bf4984755",
            (string) (len=22) "test-deployment-static": (string) (len=4) "true"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=15) "test-deployment",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(1),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 3,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }


  I0419 16:24:04.091196 14 deployment.go:657] ReplicaSet "test-deployment-65fbf5b65d":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=26) "test-deployment-65fbf5b65d",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9158",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "48a97884-7340-4ead-b52b-bc3322ad542d",
      ResourceVersion: (string) (len=5) "16914",
      Generation: (int64) 4,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140641,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "65fbf5b65d",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=15) "test-deployment",
          UID: (types.UID) (len=36) "27ea684e-f33f-4f82-a255-d9412ba1c293",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140643,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=827) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              000000d0  65 2d 68 61 73 68 22 3a  7b 7d 2c 22 66 3a 74 65  |e-hash":{},"f:te|
              000000e0  73 74 2d 64 65 70 6c 6f  79 6d 65 6e 74 2d 73 74  |st-deployment-st|
              000000f0  61 74 69 63 22 3a 7b 7d  7d 2c 22 66 3a 6f 77 6e  |atic":{}},"f:own|
              00000100  65 72 52 65 66 65 72 65  6e 63 65 73 22 3a 7b 22  |erReferences":{"|
              00000110  2e 22 3a 7b 7d 2c 22 6b  3a 7b 5c 22 75 69 64 5c  |.":{},"k:{\"uid\|
              00000120  22 3a 5c 22 32 37 65 61  36 38 34 65 2d 66 33 33  |":\"27ea684e-f33|
              00000130  66 2d 34 66 38 32 2d 61  32 35 35 2d 64 39 34 31  |f-4f82-a255-d941|
              00000140  32 62 61 31 63 32 39 33  5c 22 7d 22 3a 7b 7d 7d  |2ba1c293\"}":{}}|
              00000150  7d 2c 22 66 3a 73 70 65  63 22 3a 7b 22 66 3a 72  |},"f:spec":{"f:r|
              00000160  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 73  |eplicas":{},"f:s|
              00000170  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 74  |elector":{},"f:t|
              00000180  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000190  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              000001a0  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 70 6f  |s":{".":{},"f:po|
              000001b0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001c0  3a 7b 7d 2c 22 66 3a 74  65 73 74 2d 64 65 70 6c  |:{},"f:test-depl|
              000001d0  6f 79 6d 65 6e 74 2d 73  74 61 74 69 63 22 3a 7b  |oyment-static":{|
              000001e0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000200  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 74 65 73  |:{\"name\":\"tes|
              00000210  74 2d 64 65 70 6c 6f 79  6d 65 6e 74 5c 22 7d 22  |t-deployment\"}"|
              00000220  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000230  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000240  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000250  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000260  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              00000270  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              00000280  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000290  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000002a0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000002b0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000002c0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              000002d0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000002e0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000002f0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000300  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000310  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000320  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000330  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140643,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "65fbf5b65d",
          (string) (len=22) "test-deployment-static": (string) (len=4) "true"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "65fbf5b65d",
            (string) (len=22) "test-deployment-static": (string) (len=4) "true"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=15) "test-deployment",
              Image: (string) (len=25) "registry.k8s.io/pause:3.9",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(2),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 4,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }


  I0419 16:24:04.101582 14 deployment.go:669] pod: "test-deployment-65fbf5b65d-dnmc2":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-65fbf5b65d-dnmc2",
      GenerateName: (string) (len=27) "test-deployment-65fbf5b65d-",
      Namespace: (string) (len=15) "deployment-9158",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "00a597d9-12f5-42b6-92fd-0241bd705aa1",
      ResourceVersion: (string) (len=5) "16910",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140641,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140645,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      DeletionGracePeriodSeconds: (*int64)(2),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "65fbf5b65d",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=26) "test-deployment-65fbf5b65d",
          UID: (types.UID) (len=36) "48a97884-7340-4ead-b52b-bc3322ad542d",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140641,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  34 38 61 39 37 38 38 34  |uid\":\"48a97884|
              000000a0  2d 37 33 34 30 2d 34 65  61 64 2d 62 35 32 62 2d  |-7340-4ead-b52b-|
              000000b0  62 63 33 33 32 32 61 64  35 34 32 64 5c 22 7d 22  |bc3322ad542d\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140641,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 36 2e  31 39 31 5c 22 7d 22 3a  |.233.66.191\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-lw9xg",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=25) "registry.k8s.io/pause:3.9",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-lw9xg",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(2),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "eipo9quoh3ef-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140641,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140641,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140641,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140641,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140641,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.127",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.127"
        }
      },
      PodIP: (string) (len=13) "10.233.66.191",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.66.191"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140641,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63849140641,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=25) "registry.k8s.io/pause:3.9",
          ImageID: (string) (len=93) "registry.k8s.io/pause@sha256:7031c1b283388d2c2e09b57badb803c05ebed362dc88d84b480cc47f72a21097",
          ContainerID: (string) (len=72) "cri-o://6545e4a544bd131b6f7d807c7034136d6a5f70761bc26dd28c1a646737a3067b",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  I0419 16:24:04.105843 14 deployment.go:657] ReplicaSet "test-deployment-6b9f8f4d48":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=26) "test-deployment-6b9f8f4d48",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9158",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "08fd06d4-f3be-4d14-bf66-f12e832bdc6e",
      ResourceVersion: (string) (len=5) "16906",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140641,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "6b9f8f4d48",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "3",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=15) "test-deployment",
          UID: (types.UID) (len=36) "27ea684e-f33f-4f82-a255-d9412ba1c293",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140642,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=827) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              000000d0  65 2d 68 61 73 68 22 3a  7b 7d 2c 22 66 3a 74 65  |e-hash":{},"f:te|
              000000e0  73 74 2d 64 65 70 6c 6f  79 6d 65 6e 74 2d 73 74  |st-deployment-st|
              000000f0  61 74 69 63 22 3a 7b 7d  7d 2c 22 66 3a 6f 77 6e  |atic":{}},"f:own|
              00000100  65 72 52 65 66 65 72 65  6e 63 65 73 22 3a 7b 22  |erReferences":{"|
              00000110  2e 22 3a 7b 7d 2c 22 6b  3a 7b 5c 22 75 69 64 5c  |.":{},"k:{\"uid\|
              00000120  22 3a 5c 22 32 37 65 61  36 38 34 65 2d 66 33 33  |":\"27ea684e-f33|
              00000130  66 2d 34 66 38 32 2d 61  32 35 35 2d 64 39 34 31  |f-4f82-a255-d941|
              00000140  32 62 61 31 63 32 39 33  5c 22 7d 22 3a 7b 7d 7d  |2ba1c293\"}":{}}|
              00000150  7d 2c 22 66 3a 73 70 65  63 22 3a 7b 22 66 3a 72  |},"f:spec":{"f:r|
              00000160  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 73  |eplicas":{},"f:s|
              00000170  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 74  |elector":{},"f:t|
              00000180  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000190  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              000001a0  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 70 6f  |s":{".":{},"f:po|
              000001b0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001c0  3a 7b 7d 2c 22 66 3a 74  65 73 74 2d 64 65 70 6c  |:{},"f:test-depl|
              000001d0  6f 79 6d 65 6e 74 2d 73  74 61 74 69 63 22 3a 7b  |oyment-static":{|
              000001e0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000200  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 74 65 73  |:{\"name\":\"tes|
              00000210  74 2d 64 65 70 6c 6f 79  6d 65 6e 74 5c 22 7d 22  |t-deployment\"}"|
              00000220  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000230  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000240  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000250  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000260  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              00000270  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              00000280  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000290  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000002a0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000002b0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000002c0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              000002d0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000002e0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000002f0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000300  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000310  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000320  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000330  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140643,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(2),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "6b9f8f4d48",
          (string) (len=22) "test-deployment-static": (string) (len=4) "true"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "6b9f8f4d48",
            (string) (len=22) "test-deployment-static": (string) (len=4) "true"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=15) "test-deployment",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(1),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 2,
      FullyLabeledReplicas: (int32) 2,
      ReadyReplicas: (int32) 2,
      AvailableReplicas: (int32) 2,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }


  I0419 16:24:04.116364 14 deployment.go:669] pod: "test-deployment-6b9f8f4d48-7xwnt":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-6b9f8f4d48-7xwnt",
      GenerateName: (string) (len=27) "test-deployment-6b9f8f4d48-",
      Namespace: (string) (len=15) "deployment-9158",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0d280dba-e1bb-45e2-9cb9-df0e35a52f8a",
      ResourceVersion: (string) (len=5) "16925",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140642,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140645,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      DeletionGracePeriodSeconds: (*int64)(1),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "6b9f8f4d48",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=26) "test-deployment-6b9f8f4d48",
          UID: (types.UID) (len=36) "08fd06d4-f3be-4d14-bf66-f12e832bdc6e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140642,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  30 38 66 64 30 36 64 34  |uid\":\"08fd06d4|
              000000a0  2d 66 33 62 65 2d 34 64  31 34 2d 62 66 36 36 2d  |-f3be-4d14-bf66-|
              000000b0  66 31 32 65 38 33 32 62  64 63 36 65 5c 22 7d 22  |f12e832bdc6e\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140643,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 35 2e  36 30 5c 22 7d 22 3a 7b  |.233.65.60\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-bxjdx",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-bxjdx",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(1),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "eipo9quoh3ef-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140643,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140642,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140643,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140643,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140642,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.197",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.197"
        }
      },
      PodIP: (string) (len=12) "10.233.65.60",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.65.60"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140642,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63849140643,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://62eac4f94d41c2c5bf69351981712b6c16ea1b55e878150ff5c3cd4bf84b4e51",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  I0419 16:24:04.120794 14 deployment.go:669] pod: "test-deployment-6b9f8f4d48-w25pb":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-6b9f8f4d48-w25pb",
      GenerateName: (string) (len=27) "test-deployment-6b9f8f4d48-",
      Namespace: (string) (len=15) "deployment-9158",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5f33eecc-7e78-4bd7-80dc-116d28faff89",
      ResourceVersion: (string) (len=5) "16869",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140641,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=22) "test-deployment-static": (string) (len=4) "true",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6b9f8f4d48"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=26) "test-deployment-6b9f8f4d48",
          UID: (types.UID) (len=36) "08fd06d4-f3be-4d14-bf66-f12e832bdc6e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140641,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  30 38 66 64 30 36 64 34  |uid\":\"08fd06d4|
              000000a0  2d 66 33 62 65 2d 34 64  31 34 2d 62 66 36 36 2d  |-f3be-4d14-bf66-|
              000000b0  66 31 32 65 38 33 32 62  64 63 36 65 5c 22 7d 22  |f12e832bdc6e\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140642,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 36 2e  31 39 32 5c 22 7d 22 3a  |.233.66.192\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-ccsxw",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-ccsxw",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(1),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "eipo9quoh3ef-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140642,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140641,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140642,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140642,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140641,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.127",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.127"
        }
      },
      PodIP: (string) (len=13) "10.233.66.192",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.66.192"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140641,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63849140642,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://31455f2cac3a43facbd44a9b0e1ee6927bdadf6b918a1dfc861e130065e8ce59",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  I0419 16:24:04.124641 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-9158" for this suite. @ 04/19/24 16:24:04.141
• [4.411 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve multiport endpoints from pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:850
  STEP: Creating a kubernetes client @ 04/19/24 16:24:04.165
  I0419 16:24:04.165788 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename services @ 04/19/24 16:24:04.171
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:24:04.192
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:24:04.205
  STEP: creating service multi-endpoint-test in namespace services-2928 @ 04/19/24 16:24:04.211
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2928 to expose endpoints map[] @ 04/19/24 16:24:04.233
  I0419 16:24:04.259230 14 service.go:4258] successfully validated that service multi-endpoint-test in namespace services-2928 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-2928 @ 04/19/24 16:24:04.259
  E0419 16:24:04.560384      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:05.560815      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2928 to expose endpoints map[pod1:[100]] @ 04/19/24 16:24:06.311
  I0419 16:24:06.339202 14 service.go:4258] successfully validated that service multi-endpoint-test in namespace services-2928 exposes endpoints map[pod1:[100]]
  STEP: Creating pod pod2 in namespace services-2928 @ 04/19/24 16:24:06.339
  E0419 16:24:06.561108      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:07.561130      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2928 to expose endpoints map[pod1:[100] pod2:[101]] @ 04/19/24 16:24:08.375
  I0419 16:24:08.408052 14 service.go:4258] successfully validated that service multi-endpoint-test in namespace services-2928 exposes endpoints map[pod1:[100] pod2:[101]]
  STEP: Checking if the Service forwards traffic to pods @ 04/19/24 16:24:08.408
  I0419 16:24:08.408205 14 resource.go:361] Creating new exec pod
  E0419 16:24:08.561594      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:09.561899      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:10.562067      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:24:11.435017 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-2928 exec execpodn4phr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
  E0419 16:24:11.563178      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:24:11.870161 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
  I0419 16:24:11.870251 14 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0419 16:24:11.870864 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-2928 exec execpodn4phr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.49.238 80'
  I0419 16:24:12.175072 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.49.238 80\nConnection to 10.233.49.238 80 port [tcp/http] succeeded!\n"
  I0419 16:24:12.175181 14 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0419 16:24:12.175478 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-2928 exec execpodn4phr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
  I0419 16:24:12.435180 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
  I0419 16:24:12.435286 14 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0419 16:24:12.435619 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-2928 exec execpodn4phr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.49.238 81'
  E0419 16:24:12.563349      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:24:12.697214 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.49.238 81\nConnection to 10.233.49.238 81 port [tcp/*] succeeded!\n"
  I0419 16:24:12.697315 14 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-2928 @ 04/19/24 16:24:12.697
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2928 to expose endpoints map[pod2:[101]] @ 04/19/24 16:24:12.734
  E0419 16:24:13.564277      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:24:13.786338 14 service.go:4258] successfully validated that service multi-endpoint-test in namespace services-2928 exposes endpoints map[pod2:[101]]
  STEP: Deleting pod pod2 in namespace services-2928 @ 04/19/24 16:24:13.786
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2928 to expose endpoints map[] @ 04/19/24 16:24:13.818
  I0419 16:24:13.857570 14 service.go:4258] successfully validated that service multi-endpoint-test in namespace services-2928 exposes endpoints map[]
  I0419 16:24:13.947114 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2928" for this suite. @ 04/19/24 16:24:13.953
• [9.797 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:112
  STEP: Creating a kubernetes client @ 04/19/24 16:24:13.964
  I0419 16:24:13.965112 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename replicaset @ 04/19/24 16:24:13.968
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:24:13.99
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:24:13.994
  I0419 16:24:13.998915 14 replica_set.go:191] Creating ReplicaSet my-hostname-basic-b7b78312-53c7-4ff3-8231-2a02b981275c
  I0419 16:24:14.013168 14 resource.go:87] Pod name my-hostname-basic-b7b78312-53c7-4ff3-8231-2a02b981275c: Found 0 pods out of 1
  E0419 16:24:14.564678      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:15.565323      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:16.565129      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:17.565930      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:18.565810      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:24:19.026568 14 resource.go:87] Pod name my-hostname-basic-b7b78312-53c7-4ff3-8231-2a02b981275c: Found 1 pods out of 1
  I0419 16:24:19.026644 14 replica_set.go:204] Ensuring a pod for ReplicaSet "my-hostname-basic-b7b78312-53c7-4ff3-8231-2a02b981275c" is running
  I0419 16:24:19.034998 14 replica_set.go:220] Pod "my-hostname-basic-b7b78312-53c7-4ff3-8231-2a02b981275c-sg6mb" is running (conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-19 16:24:14 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-19 16:24:14 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-19 16:24:14 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-19 16:24:14 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-19 16:24:14 +0000 UTC Reason: Message:}])
  I0419 16:24:19.035057 14 replica_set.go:228] Trying to dial the pod
  STEP: trying to dial each unique pod @ 04/19/24 16:24:19.035
  I0419 16:24:19.060696 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-9715" for this suite. @ 04/19/24 16:24:19.07
• [5.118 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:110
  STEP: Creating a kubernetes client @ 04/19/24 16:24:19.084
  I0419 16:24:19.084430 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename projected @ 04/19/24 16:24:19.088
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:24:19.11
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:24:19.117
  STEP: Creating configMap with name projected-configmap-test-volume-map-df2eab6f-cb06-479a-a0ff-0318384c2090 @ 04/19/24 16:24:19.122
  STEP: Creating a pod to test consume configMaps @ 04/19/24 16:24:19.129
  E0419 16:24:19.566751      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:20.567198      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:21.567495      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:22.567990      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:24:23.178
  I0419 16:24:23.187475 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-projected-configmaps-01017777-10a7-4048-8a3b-d7ead888c958 container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/24 16:24:23.22
  I0419 16:24:23.256698 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7656" for this suite. @ 04/19/24 16:24:23.266
• [4.197 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:105
  STEP: Creating a kubernetes client @ 04/19/24 16:24:23.282
  I0419 16:24:23.282092 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename deployment @ 04/19/24 16:24:23.285
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:24:23.328
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:24:23.333
  I0419 16:24:23.340091 14 deployment.go:754] Creating replica set "test-rolling-update-controller" (going to be adopted)
  I0419 16:24:23.358009 14 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  E0419 16:24:23.568671      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:24.569464      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:25.569541      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:26.574913      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:27.573603      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:24:28.370882 14 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/19/24 16:24:28.371
  I0419 16:24:28.371720 14 deployment.go:763] Creating deployment "test-rolling-update-deployment"
  I0419 16:24:28.393178 14 deployment.go:769] Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
  I0419 16:24:28.420219 14 deployment.go:222] new replicaset for deployment "test-rolling-update-deployment" is yet to be created
  E0419 16:24:28.573417      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:29.574967      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:24:30.438540 14 deployment.go:773] Ensuring status for deployment "test-rolling-update-deployment" is the expected
  I0419 16:24:30.448682 14 deployment.go:778] Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
  I0419 16:24:30.482074 14 deployment.go:633] Deployment "test-rolling-update-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7378",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9f00d0ad-b020-4970-a98e-506c0449f70e",
      ResourceVersion: (string) (len=5) "17223",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140668,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=10) "sample-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140668,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140670,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=10) "sample-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=10) "sample-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140668,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140668,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140670,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140668,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=83) "ReplicaSet \"test-rolling-update-deployment-6f4b778cd6\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0419 16:24:30.501927 14 deployment.go:39] New ReplicaSet "test-rolling-update-deployment-6f4b778cd6" of Deployment "test-rolling-update-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rolling-update-deployment-6f4b778cd6",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7378",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7d9b0b04-003e-4365-800a-293c575a0faa",
      ResourceVersion: (string) (len=5) "17213",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140668,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6f4b778cd6"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "9f00d0ad-b020-4970-a98e-506c0449f70e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140668,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 39 66 30 30 64 30  61 64 2d 62 30 32 30 2d  |\"9f00d0ad-b020-|
              00000120  34 39 37 30 2d 61 39 38  65 2d 35 30 36 63 30 34  |4970-a98e-506c04|
              00000130  34 39 66 37 30 65 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |49f70e\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140670,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "6f4b778cd6"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "6f4b778cd6"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0419 16:24:30.505003 14 deployment.go:44] All old ReplicaSets of Deployment "test-rolling-update-deployment":
  I0419 16:24:30.505860 14 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7378",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "341c1910-aede-433d-b728-06f42d5509e2",
      ResourceVersion: (string) (len=5) "17222",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140663,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305832"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "9f00d0ad-b020-4970-a98e-506c0449f70e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140663,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=533) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  2c 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |,"f:labels":{"."|
              00000060  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000070  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              00000080  73 70 65 63 22 3a 7b 22  66 3a 73 65 6c 65 63 74  |spec":{"f:select|
              00000090  6f 72 22 3a 7b 7d 2c 22  66 3a 74 65 6d 70 6c 61  |or":{},"f:templa|
              000000a0  74 65 22 3a 7b 22 66 3a  6d 65 74 61 64 61 74 61  |te":{"f:metadata|
              000000b0  22 3a 7b 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |":{"f:labels":{"|
              000000c0  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              000000d0  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 7d 2c 22  |},"f:pod":{}}},"|
              000000e0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000f0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              00000100  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              00000110  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000120  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000130  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000140  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000150  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 74 65  |ources":{},"f:te|
              00000160  72 6d 69 6e 61 74 69 6f  6e 4d 65 73 73 61 67 65  |rminationMessage|
              00000170  50 61 74 68 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |Path":{},"f:term|
              00000180  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 6f  |inationMessagePo|
              00000190  6c 69 63 79 22 3a 7b 7d  7d 7d 2c 22 66 3a 64 6e  |licy":{}}},"f:dn|
              000001a0  73 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 72  |sPolicy":{},"f:r|
              000001b0  65 73 74 61 72 74 50 6f  6c 69 63 79 22 3a 7b 7d  |estartPolicy":{}|
              000001c0  2c 22 66 3a 73 63 68 65  64 75 6c 65 72 4e 61 6d  |,"f:schedulerNam|
              000001d0  65 22 3a 7b 7d 2c 22 66  3a 73 65 63 75 72 69 74  |e":{},"f:securit|
              000001e0  79 43 6f 6e 74 65 78 74  22 3a 7b 7d 2c 22 66 3a  |yContext":{},"f:|
              000001f0  74 65 72 6d 69 6e 61 74  69 6f 6e 47 72 61 63 65  |terminationGrace|
              00000200  50 65 72 69 6f 64 53 65  63 6f 6e 64 73 22 3a 7b  |PeriodSeconds":{|
              00000210  7d 7d 7d 7d 7d                                    |}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140670,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=242) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 64 65 70 6c 6f  79 6d 65 6e 74 2e 6b 75  |"f:deployment.ku|
              00000030  62 65 72 6e 65 74 65 73  2e 69 6f 2f 64 65 73 69  |bernetes.io/desi|
              00000040  72 65 64 2d 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |red-replicas":{}|
              00000050  2c 22 66 3a 64 65 70 6c  6f 79 6d 65 6e 74 2e 6b  |,"f:deployment.k|
              00000060  75 62 65 72 6e 65 74 65  73 2e 69 6f 2f 6d 61 78  |ubernetes.io/max|
              00000070  2d 72 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 2c 22  |-replicas":{}},"|
              00000080  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000090  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              000000a0  22 75 69 64 5c 22 3a 5c  22 39 66 30 30 64 30 61  |"uid\":\"9f00d0a|
              000000b0  64 2d 62 30 32 30 2d 34  39 37 30 2d 61 39 38 65  |d-b020-4970-a98e|
              000000c0  2d 35 30 36 63 30 34 34  39 66 37 30 65 5c 22 7d  |-506c0449f70e\"}|
              000000d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000000e0  7b 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |{"f:replicas":{}|
              000000f0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140670,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=3) "pod": (string) (len=5) "httpd",
          (string) (len=4) "name": (string) (len=10) "sample-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0419 16:24:30.523216 14 deployment.go:67] Pod "test-rolling-update-deployment-6f4b778cd6-ktbwn" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=47) "test-rolling-update-deployment-6f4b778cd6-ktbwn",
      GenerateName: (string) (len=42) "test-rolling-update-deployment-6f4b778cd6-",
      Namespace: (string) (len=15) "deployment-7378",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2b066d80-9de3-41d1-b99f-f49188f0b82b",
      ResourceVersion: (string) (len=5) "17212",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140668,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6f4b778cd6"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=41) "test-rolling-update-deployment-6f4b778cd6",
          UID: (types.UID) (len=36) "7d9b0b04-003e-4365-800a-293c575a0faa",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140668,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 37 64  39 62 30 62 30 34 2d 30  |d\":\"7d9b0b04-0|
              00000090  30 33 65 2d 34 33 36 35  2d 38 30 30 61 2d 32 39  |03e-4365-800a-29|
              000000a0  33 63 35 37 35 61 30 66  61 61 5c 22 7d 22 3a 7b  |3c575a0faa\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140670,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 36 2e  31 39 38 5c 22 7d 22 3a  |.233.66.198\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-lwcrh",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-lwcrh",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "eipo9quoh3ef-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140670,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140668,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140670,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140670,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140668,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.127",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.127"
        }
      },
      PodIP: (string) (len=13) "10.233.66.198",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.66.198"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140668,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63849140669,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:c9997bf8d2e223d7d2a0078dcfb11a653e9b16cf09418829ec03e1d57ca9628a",
          ContainerID: (string) (len=72) "cri-o://62a7abbf27b23d35677fbe799992e97c4432b17d53c7c9c6ee65612012290d50",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0419 16:24:30.539681 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-7378" for this suite. @ 04/19/24 16:24:30.553
• [7.290 seconds]
------------------------------
S
------------------------------
[sig-apps] Deployment Deployment should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:150
  STEP: Creating a kubernetes client @ 04/19/24 16:24:30.572
  I0419 16:24:30.573027 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  E0419 16:24:30.575520      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Building a namespace api object, basename deployment @ 04/19/24 16:24:30.577
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:24:30.619
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:24:30.628
  I0419 16:24:30.639963 14 deployment.go:1645] Creating simple deployment test-new-deployment
  I0419 16:24:30.687844 14 deployment.go:222] deployment "test-new-deployment" doesn't have the required revision set
  E0419 16:24:31.576213      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:32.577008      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: getting scale subresource @ 04/19/24 16:24:32.719
  STEP: updating a scale subresource @ 04/19/24 16:24:32.725
  STEP: verifying the deployment Spec.Replicas was modified @ 04/19/24 16:24:32.745
  STEP: Patch a scale subresource @ 04/19/24 16:24:32.753
  I0419 16:24:32.785544 14 deployment.go:633] Deployment "test-new-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=19) "test-new-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5076",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6dd0c8a0-8c74-4dbe-a485-13e0b3accc94",
      ResourceVersion: (string) (len=5) "17252",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140670,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)(<nil>),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=28) {
              00000000  7b 22 66 3a 73 70 65 63  22 3a 7b 22 66 3a 72 65  |{"f:spec":{"f:re|
              00000010  70 6c 69 63 61 73 22 3a  7b 7d 7d 7d              |plicas":{}}}|
            }
          }),
          Subresource: (string) (len=5) "scale"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140670,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=619) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |onds":{},"f:revi|
              00000060  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000070  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              00000090  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000a0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000b0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000c0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000d0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000e0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              000000f0  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000100  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000110  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000120  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000130  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000140  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000150  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000160  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000170  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000180  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000190  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001a0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001b0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001c0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001d0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001e0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000001f0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000200  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000210  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000220  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000230  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000240  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000250  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000260  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140672,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(4),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140672,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140672,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140672,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140670,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=72) "ReplicaSet \"test-new-deployment-77db57d8df\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0419 16:24:32.800215 14 deployment.go:39] New ReplicaSet "test-new-deployment-77db57d8df" of Deployment "test-new-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-new-deployment-77db57d8df",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5076",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1f8ab82e-07a5-457b-abf8-71d3ff20ba53",
      ResourceVersion: (string) (len=5) "17255",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140670,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=19) "test-new-deployment",
          UID: (types.UID) (len=36) "6dd0c8a0-8c74-4dbe-a485-13e0b3accc94",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140672,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 36 64 64 30 63 38  61 30 2d 38 63 37 34 2d  |\"6dd0c8a0-8c74-|
              00000120  34 64 62 65 2d 61 34 38  35 2d 31 33 65 30 62 33  |4dbe-a485-13e0b3|
              00000130  61 63 63 63 39 34 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |accc94\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140672,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(2),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0419 16:24:32.809798 14 deployment.go:67] Pod "test-new-deployment-77db57d8df-gsghr" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-77db57d8df-gsghr",
      GenerateName: (string) (len=31) "test-new-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-5076",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e602e556-5213-414b-a99d-20d194c426d3",
      ResourceVersion: (string) (len=5) "17256",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140672,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-77db57d8df",
          UID: (types.UID) (len=36) "1f8ab82e-07a5-457b-abf8-71d3ff20ba53",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140672,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 66  38 61 62 38 32 65 2d 30  |d\":\"1f8ab82e-0|
              00000090  37 61 35 2d 34 35 37 62  2d 61 62 66 38 2d 37 31  |7a5-457b-abf8-71|
              000000a0  64 33 66 66 32 30 62 61  35 33 5c 22 7d 22 3a 7b  |d3ff20ba53\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-txf45",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-txf45",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "eipo9quoh3ef-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140672,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0419 16:24:32.813926 14 deployment.go:67] Pod "test-new-deployment-77db57d8df-tcd9s" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-77db57d8df-tcd9s",
      GenerateName: (string) (len=31) "test-new-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-5076",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c4b72433-e532-4d21-b41e-dfccc11ce392",
      ResourceVersion: (string) (len=5) "17247",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140670,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-77db57d8df",
          UID: (types.UID) (len=36) "1f8ab82e-07a5-457b-abf8-71d3ff20ba53",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140670,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 66  38 61 62 38 32 65 2d 30  |d\":\"1f8ab82e-0|
              00000090  37 61 35 2d 34 35 37 62  2d 61 62 66 38 2d 37 31  |7a5-457b-abf8-71|
              000000a0  64 33 66 66 32 30 62 61  35 33 5c 22 7d 22 3a 7b  |d3ff20ba53\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140672,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 36 2e  31 39 39 5c 22 7d 22 3a  |.233.66.199\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-cbpqz",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-cbpqz",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "eipo9quoh3ef-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140672,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140670,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140672,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140672,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849140670,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.127",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.127"
        }
      },
      PodIP: (string) (len=13) "10.233.66.199",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.66.199"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849140670,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63849140671,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://dc8ba28cec5e64224c4320dbee236ebbb17a6e969668df1fe632572f57fd6061",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0419 16:24:32.818374 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-5076" for this suite. @ 04/19/24 16:24:32.842
• [2.299 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:480
  STEP: Creating a kubernetes client @ 04/19/24 16:24:32.872
  I0419 16:24:32.872816 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename gc @ 04/19/24 16:24:32.875
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:24:32.926
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:24:32.93
  STEP: create the deployment @ 04/19/24 16:24:32.94
  W0419 16:24:32.948647      14 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 04/19/24 16:24:32.948
  STEP: delete the deployment @ 04/19/24 16:24:33.457
  STEP: wait for all rs to be garbage collected @ 04/19/24 16:24:33.477
  STEP: expected 0 pods, got 2 pods @ 04/19/24 16:24:33.538
  E0419 16:24:33.576632      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 04/19/24 16:24:34.009
  I0419 16:24:34.274784 14 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0419 16:24:34.275123 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-5770" for this suite. @ 04/19/24 16:24:34.29
• [1.437 seconds]
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:130
  STEP: Creating a kubernetes client @ 04/19/24 16:24:34.309
  I0419 16:24:34.309583 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename emptydir @ 04/19/24 16:24:34.331
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:24:34.355
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:24:34.365
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 04/19/24 16:24:34.37
  E0419 16:24:34.577585      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:35.578691      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:36.579219      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:37.579743      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:24:38.407
  I0419 16:24:38.417103 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-51503747-33ab-4e0f-9f99-e9cb0fec9f77 container test-container: <nil>
  STEP: delete the pod @ 04/19/24 16:24:38.427
  I0419 16:24:38.449489 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1492" for this suite. @ 04/19/24 16:24:38.459
• [4.160 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:69
  STEP: Creating a kubernetes client @ 04/19/24 16:24:38.471
  I0419 16:24:38.471291 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename endpointslice @ 04/19/24 16:24:38.474
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:24:38.498
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:24:38.503
  I0419 16:24:38.524966 14 endpointslice.go:1045] Endpoints addresses: [192.168.121.197 192.168.121.38] , ports: [6443]
  I0419 16:24:38.525788 14 endpointslice.go:1075] EndpointSlices addresses: [192.168.121.197 192.168.121.38] , ports: [6443]
  I0419 16:24:38.527571 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-6922" for this suite. @ 04/19/24 16:24:38.536
• [0.076 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:54
  STEP: Creating a kubernetes client @ 04/19/24 16:24:38.549
  I0419 16:24:38.549085 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename podtemplate @ 04/19/24 16:24:38.552
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:24:38.572
  E0419 16:24:38.579872      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:24:38.58
  I0419 16:24:38.640391 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-5752" for this suite. @ 04/19/24 16:24:38.648
• [0.110 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:424
  STEP: Creating a kubernetes client @ 04/19/24 16:24:38.66
  I0419 16:24:38.660574 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename configmap @ 04/19/24 16:24:38.662
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:24:38.684
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:24:38.689
  STEP: Creating configMap with name configmap-test-volume-522ed72c-d69a-4a93-b66e-167e80dce891 @ 04/19/24 16:24:38.694
  STEP: Creating a pod to test consume configMaps @ 04/19/24 16:24:38.701
  E0419 16:24:39.579761      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:40.580361      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:41.581648      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:42.582374      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:24:42.743
  I0419 16:24:42.753726 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-configmaps-77986b28-de2f-4741-9721-b0781b45afee container configmap-volume-test: <nil>
  STEP: delete the pod @ 04/19/24 16:24:42.771
  I0419 16:24:42.803796 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5979" for this suite. @ 04/19/24 16:24:42.813
• [4.164 seconds]
------------------------------
SSS
------------------------------
[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2218
  STEP: Creating a kubernetes client @ 04/19/24 16:24:42.826
  I0419 16:24:42.826514 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename services @ 04/19/24 16:24:42.831
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:24:42.857
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:24:42.864
  STEP: creating service in namespace services-1966 @ 04/19/24 16:24:42.87
  STEP: creating service affinity-nodeport in namespace services-1966 @ 04/19/24 16:24:42.871
  STEP: creating replication controller affinity-nodeport in namespace services-1966 @ 04/19/24 16:24:42.901
  I0419 16:24:42.917770      14 runners.go:198] Created replication controller with name: affinity-nodeport, namespace: services-1966, replica count: 3
  E0419 16:24:43.583409      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:44.584247      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:45.584754      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:24:45.969064      14 runners.go:198] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0419 16:24:46.002021 14 resource.go:361] Creating new exec pod
  E0419 16:24:46.585221      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:47.585434      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:48.585869      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:24:49.053633 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-1966 exec execpod-affinityq7mtf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
  I0419 16:24:49.417403 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
  I0419 16:24:49.417703 14 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0419 16:24:49.418117 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-1966 exec execpod-affinityq7mtf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.49.88 80'
  E0419 16:24:49.585904      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:24:49.736454 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.49.88 80\nConnection to 10.233.49.88 80 port [tcp/http] succeeded!\n"
  I0419 16:24:49.736569 14 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0419 16:24:49.736991 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-1966 exec execpod-affinityq7mtf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.127 30246'
  I0419 16:24:50.035133 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.127 30246\nConnection to 192.168.121.127 30246 port [tcp/*] succeeded!\n"
  I0419 16:24:50.035273 14 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0419 16:24:50.036424 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-1966 exec execpod-affinityq7mtf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.38 30246'
  I0419 16:24:50.295211 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.38 30246\nConnection to 192.168.121.38 30246 port [tcp/*] succeeded!\n"
  I0419 16:24:50.295326 14 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0419 16:24:50.297359 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-1966 exec execpod-affinityq7mtf -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.38:30246/ ; done'
  E0419 16:24:50.586672      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:24:50.847158 14 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:30246/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:30246/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:30246/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:30246/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:30246/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:30246/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:30246/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:30246/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:30246/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:30246/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:30246/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:30246/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:30246/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:30246/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:30246/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:30246/\n"
  I0419 16:24:50.847279 14 builder.go:147] stdout: "\naffinity-nodeport-mjqmm\naffinity-nodeport-mjqmm\naffinity-nodeport-mjqmm\naffinity-nodeport-mjqmm\naffinity-nodeport-mjqmm\naffinity-nodeport-mjqmm\naffinity-nodeport-mjqmm\naffinity-nodeport-mjqmm\naffinity-nodeport-mjqmm\naffinity-nodeport-mjqmm\naffinity-nodeport-mjqmm\naffinity-nodeport-mjqmm\naffinity-nodeport-mjqmm\naffinity-nodeport-mjqmm\naffinity-nodeport-mjqmm\naffinity-nodeport-mjqmm"
  I0419 16:24:50.847333 14 service.go:242] Received response from host: affinity-nodeport-mjqmm
  I0419 16:24:50.847360 14 service.go:242] Received response from host: affinity-nodeport-mjqmm
  I0419 16:24:50.847385 14 service.go:242] Received response from host: affinity-nodeport-mjqmm
  I0419 16:24:50.847403 14 service.go:242] Received response from host: affinity-nodeport-mjqmm
  I0419 16:24:50.847424 14 service.go:242] Received response from host: affinity-nodeport-mjqmm
  I0419 16:24:50.847441 14 service.go:242] Received response from host: affinity-nodeport-mjqmm
  I0419 16:24:50.847458 14 service.go:242] Received response from host: affinity-nodeport-mjqmm
  I0419 16:24:50.847475 14 service.go:242] Received response from host: affinity-nodeport-mjqmm
  I0419 16:24:50.847503 14 service.go:242] Received response from host: affinity-nodeport-mjqmm
  I0419 16:24:50.847524 14 service.go:242] Received response from host: affinity-nodeport-mjqmm
  I0419 16:24:50.847541 14 service.go:242] Received response from host: affinity-nodeport-mjqmm
  I0419 16:24:50.847557 14 service.go:242] Received response from host: affinity-nodeport-mjqmm
  I0419 16:24:50.847574 14 service.go:242] Received response from host: affinity-nodeport-mjqmm
  I0419 16:24:50.847636 14 service.go:242] Received response from host: affinity-nodeport-mjqmm
  I0419 16:24:50.847653 14 service.go:242] Received response from host: affinity-nodeport-mjqmm
  I0419 16:24:50.847670 14 service.go:242] Received response from host: affinity-nodeport-mjqmm
  I0419 16:24:50.848010 14 service.go:4014] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport in namespace services-1966, will wait for the garbage collector to delete the pods @ 04/19/24 16:24:50.879
  I0419 16:24:50.949907 14 resources.go:139] Deleting ReplicationController affinity-nodeport took: 14.612095ms
  I0419 16:24:51.052302 14 resources.go:163] Terminating ReplicationController affinity-nodeport pods took: 102.396291ms
  E0419 16:24:51.587527      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:52.591740      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:53.588260      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:24:54.308418 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1966" for this suite. @ 04/19/24 16:24:54.315
• [11.501 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:697
  STEP: Creating a kubernetes client @ 04/19/24 16:24:54.328
  I0419 16:24:54.328180 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename job @ 04/19/24 16:24:54.332
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:24:54.357
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:24:54.361
  STEP: Creating a job @ 04/19/24 16:24:54.366
  STEP: Ensuring active pods == parallelism @ 04/19/24 16:24:54.377
  E0419 16:24:54.588530      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:55.589389      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Orphaning one of the Job's Pods @ 04/19/24 16:24:56.395
  E0419 16:24:56.589655      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:24:56.971607 14 pod_client.go:141] Successfully updated pod "adopt-release-7tqkg"
  STEP: Checking that the Job readopts the Pod @ 04/19/24 16:24:56.971
  E0419 16:24:57.589698      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:58.589929      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing the labels from the Job's Pod @ 04/19/24 16:24:58.993
  I0419 16:24:59.527226 14 pod_client.go:141] Successfully updated pod "adopt-release-7tqkg"
  STEP: Checking that the Job releases the Pod @ 04/19/24 16:24:59.527
  E0419 16:24:59.591141      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:00.591273      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:25:01.546831 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-4324" for this suite. @ 04/19/24 16:25:01.569
• [7.263 seconds]
------------------------------
SS
------------------------------
  E0419 16:25:01.592098      14 retrywatcher.go:129] "Watch failed" err="context canceled"
[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:251
  STEP: Creating a kubernetes client @ 04/19/24 16:25:01.593
  I0419 16:25:01.593143 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename downward-api @ 04/19/24 16:25:01.597
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:25:01.629
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:25:01.635
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 16:25:01.644
  E0419 16:25:02.592992      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:03.593455      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:04.593146      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:05.593528      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:25:05.707
  I0419 16:25:05.717787 14 output.go:196] Trying to get logs from node eipo9quoh3ef-1 pod downwardapi-volume-be33c817-1db3-4a59-8aa9-bde73b9b491a container client-container: <nil>
  STEP: delete the pod @ 04/19/24 16:25:05.756
  I0419 16:25:05.790771 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6963" for this suite. @ 04/19/24 16:25:05.805
• [4.226 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:90
  STEP: Creating a kubernetes client @ 04/19/24 16:25:05.821
  I0419 16:25:05.822084 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename configmap @ 04/19/24 16:25:05.827
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:25:05.858
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:25:05.863
  STEP: Creating configMap with name configmap-test-volume-map-d6f2a4c2-37de-4a03-8585-476f33cb3397 @ 04/19/24 16:25:05.87
  STEP: Creating a pod to test consume configMaps @ 04/19/24 16:25:05.88
  E0419 16:25:06.594236      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:07.595206      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:08.596315      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:09.597404      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:25:09.926
  I0419 16:25:09.933716 14 output.go:196] Trying to get logs from node eipo9quoh3ef-1 pod pod-configmaps-044933ab-b396-4e3d-accb-13093565a507 container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/24 16:25:09.95
  I0419 16:25:09.987892 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4642" for this suite. @ 04/19/24 16:25:10.001
• [4.192 seconds]
------------------------------
SSS
------------------------------
[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:168
  STEP: Creating a kubernetes client @ 04/19/24 16:25:10.014
  I0419 16:25:10.014744 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename downward-api @ 04/19/24 16:25:10.017
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:25:10.042
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:25:10.047
  STEP: Creating a pod to test downward api env vars @ 04/19/24 16:25:10.051
  E0419 16:25:10.597587      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:11.597915      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:12.598435      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:13.599590      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:25:14.093
  I0419 16:25:14.102167 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod downward-api-762ec529-15f3-4793-9e13-f33c7ed1e3d6 container dapi-container: <nil>
  STEP: delete the pod @ 04/19/24 16:25:14.118
  I0419 16:25:14.163664 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-507" for this suite. @ 04/19/24 16:25:14.188
• [4.194 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:263
  STEP: Creating a kubernetes client @ 04/19/24 16:25:14.209
  I0419 16:25:14.209909 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename projected @ 04/19/24 16:25:14.214
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:25:14.239
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:25:14.244
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 16:25:14.249
  E0419 16:25:14.600258      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:15.600557      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:16.600989      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:17.601881      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:25:18.302
  I0419 16:25:18.313958 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod downwardapi-volume-750afc7b-9291-4002-9f8a-a30e98558959 container client-container: <nil>
  STEP: delete the pod @ 04/19/24 16:25:18.339
  I0419 16:25:18.384476 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8288" for this suite. @ 04/19/24 16:25:18.395
• [4.207 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:146
  STEP: Creating a kubernetes client @ 04/19/24 16:25:18.424
  I0419 16:25:18.424768 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/19/24 16:25:18.429
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:25:18.469
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:25:18.476
  I0419 16:25:18.484673 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  E0419 16:25:18.602811      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:25:19.101326 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-4275" for this suite. @ 04/19/24 16:25:19.118
• [0.713 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:191
  STEP: Creating a kubernetes client @ 04/19/24 16:25:19.138
  I0419 16:25:19.138535 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename runtimeclass @ 04/19/24 16:25:19.141
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:25:19.169
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:25:19.174
  STEP: getting /apis @ 04/19/24 16:25:19.18
  STEP: getting /apis/node.k8s.io @ 04/19/24 16:25:19.19
  STEP: getting /apis/node.k8s.io/v1 @ 04/19/24 16:25:19.192
  STEP: creating @ 04/19/24 16:25:19.194
  STEP: watching @ 04/19/24 16:25:19.224
  I0419 16:25:19.224193 14 runtimeclass.go:275] starting watch
  STEP: getting @ 04/19/24 16:25:19.235
  STEP: listing @ 04/19/24 16:25:19.239
  STEP: patching @ 04/19/24 16:25:19.246
  STEP: updating @ 04/19/24 16:25:19.256
  I0419 16:25:19.264746 14 runtimeclass.go:305] waiting for watch events with expected annotations
  STEP: deleting @ 04/19/24 16:25:19.264
  STEP: deleting a collection @ 04/19/24 16:25:19.285
  I0419 16:25:19.315741 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-5652" for this suite. @ 04/19/24 16:25:19.326
• [0.201 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:371
  STEP: Creating a kubernetes client @ 04/19/24 16:25:19.34
  I0419 16:25:19.340933 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename webhook @ 04/19/24 16:25:19.343
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:25:19.372
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:25:19.377
  STEP: Setting up server cert @ 04/19/24 16:25:19.412
  E0419 16:25:19.603213      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 16:25:20.458
  STEP: Deploying the webhook pod @ 04/19/24 16:25:20.487
  STEP: Wait for the deployment to be ready @ 04/19/24 16:25:20.519
  I0419 16:25:20.546814 14 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0419 16:25:20.613335      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:21.614433      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 16:25:22.576
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 16:25:22.603
  E0419 16:25:22.606222      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:25:23.605829 14 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  E0419 16:25:23.606682      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Setting timeout (1s) shorter than webhook latency (5s) @ 04/19/24 16:25:23.619
  STEP: Registering slow webhook via the AdmissionRegistration API @ 04/19/24 16:25:23.62
  I0419 16:25:23.650108 14 webhook.go:2672] Waiting for webhook configuration to be ready...
  STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) @ 04/19/24 16:25:23.774
  E0419 16:25:24.607793      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore @ 04/19/24 16:25:24.789
  STEP: Registering slow webhook via the AdmissionRegistration API @ 04/19/24 16:25:24.79
  E0419 16:25:25.608504      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is longer than webhook latency @ 04/19/24 16:25:25.867
  STEP: Registering slow webhook via the AdmissionRegistration API @ 04/19/24 16:25:25.867
  E0419 16:25:26.608591      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:27.609010      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:28.610019      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:29.613372      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:30.612038      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is empty (defaulted to 10s in v1) @ 04/19/24 16:25:30.962
  STEP: Registering slow webhook via the AdmissionRegistration API @ 04/19/24 16:25:30.962
  E0419 16:25:31.612149      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:32.613209      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:33.613789      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:34.633423      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:35.620570      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:25:36.204366 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1924" for this suite. @ 04/19/24 16:25:36.214
  STEP: Destroying namespace "webhook-markers-1264" for this suite. @ 04/19/24 16:25:36.229
• [16.899 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:199
  STEP: Creating a kubernetes client @ 04/19/24 16:25:36.241
  I0419 16:25:36.241136 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename webhook @ 04/19/24 16:25:36.247
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:25:36.274
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:25:36.28
  STEP: Setting up server cert @ 04/19/24 16:25:36.316
  E0419 16:25:36.620494      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 16:25:37.18
  STEP: Deploying the webhook pod @ 04/19/24 16:25:37.199
  STEP: Wait for the deployment to be ready @ 04/19/24 16:25:37.227
  I0419 16:25:37.263208 14 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0419 16:25:37.625906      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:38.626090      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 16:25:39.301
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 16:25:39.329
  E0419 16:25:39.626601      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:25:40.329947 14 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 04/19/24 16:25:40.35
  STEP: create a pod that should be denied by the webhook @ 04/19/24 16:25:40.432
  STEP: create a pod that causes the webhook to hang @ 04/19/24 16:25:40.472
  E0419 16:25:40.627587      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:41.628179      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:42.630008      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:43.628531      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:44.628834      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:45.629861      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:46.630647      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:47.631571      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:48.632563      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:49.632780      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create a configmap that should be denied by the webhook @ 04/19/24 16:25:50.496
  STEP: create a configmap that should be admitted by the webhook @ 04/19/24 16:25:50.572
  STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook @ 04/19/24 16:25:50.592
  STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook @ 04/19/24 16:25:50.616
  STEP: create a namespace that bypass the webhook @ 04/19/24 16:25:50.631
  E0419 16:25:50.632804      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace @ 04/19/24 16:25:50.661
  I0419 16:25:50.772775 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6744" for this suite. @ 04/19/24 16:25:50.799
  STEP: Destroying namespace "webhook-markers-2048" for this suite. @ 04/19/24 16:25:50.824
  STEP: Destroying namespace "exempted-namespace-6257" for this suite. @ 04/19/24 16:25:50.833
• [14.603 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:184
  STEP: Creating a kubernetes client @ 04/19/24 16:25:50.853
  I0419 16:25:50.853602 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename container-probe @ 04/19/24 16:25:50.856
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:25:50.878
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:25:50.883
  STEP: Creating pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217 @ 04/19/24 16:25:50.889
  E0419 16:25:51.633398      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:52.634834      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/19/24 16:25:52.994
  I0419 16:25:53.001550 14 container_probe.go:1749] Initial restart count of pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f is 0
  I0419 16:25:53.012190 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:25:53.635502      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:54.635216      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:25:55.025748 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:25:55.635540      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:56.636303      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:25:57.037915 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:25:57.637619      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:58.637795      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:25:59.047978 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:25:59.638115      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:00.639028      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:26:01.063666 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:26:01.643840      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:02.643424      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:26:03.076342 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:26:03.644115      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:04.645020      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:26:05.087076 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:26:05.651757      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:06.648400      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:26:07.100674 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:26:07.648852      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:08.649128      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:26:09.114447 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:26:09.649508      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:10.650448      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:26:11.132079 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:26:11.653408      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:12.652286      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:26:13.148099 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:26:13.653009      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:14.653197      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:26:15.158584 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:26:15.653489      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:16.655129      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:26:17.165302 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:26:17.654118      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:18.654600      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:26:19.176601 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:26:19.654833      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:20.660931      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:26:21.192044 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:26:21.657080      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:22.656755      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:26:23.204973 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:26:23.657891      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:24.669251      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:26:25.218105 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:26:25.658488      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:26.658831      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:26:27.228219 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:26:27.659613      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:28.660073      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:26:29.239112 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:26:29.660096      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:30.660838      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:26:31.253220 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:26:31.661071      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:32.661919      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:26:33.271552 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:26:33.662573      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:34.662887      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:26:35.284999 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:26:35.663883      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:36.663787      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:26:37.298038 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:26:37.664255      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:38.664498      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:26:39.313001 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:26:39.665103      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:40.665960      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:26:41.326786 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:26:41.665802      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:42.666778      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:26:43.342583 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:26:43.667349      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:44.668045      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:26:45.354294 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:26:45.669001      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:46.669081      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:26:47.364509 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:26:47.670102      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:48.670436      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:26:49.378734 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:26:49.671470      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:50.671643      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:26:51.394188 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:26:51.672579      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:52.673150      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:26:53.405796 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:26:53.673749      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:54.674069      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:26:55.418215 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:26:55.674604      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:56.676988      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:26:57.429834 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:26:57.677042      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:58.677440      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:26:59.440538 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:26:59.677970      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:00.678808      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:27:01.450436 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:27:01.679508      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:02.679972      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:27:03.462760 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:27:03.680802      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:04.681451      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:27:05.474068 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:27:05.681836      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:06.682389      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:27:07.484658 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:27:07.682654      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:08.682948      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:27:09.492728 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:27:09.683635      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:10.684209      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:27:11.502137 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:27:11.685135      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:12.685406      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:27:13.521608 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:27:13.686798      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:14.687628      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:27:15.531357 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:27:15.688454      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:16.689276      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:27:17.541475 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:27:17.690056      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:18.691006      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:27:19.550923 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:27:19.691749      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:20.693019      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:27:21.569051 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:27:21.693196      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:22.693665      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:27:23.583449 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:27:23.694150      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:24.694502      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:27:25.595047 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:27:25.694700      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:26.695411      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:27:27.604527 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:27:27.696174      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:28.697198      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:27:29.615054 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:27:29.698275      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:30.698991      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:27:31.625793 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:27:31.699905      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:32.700242      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:27:33.637841 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:27:33.701024      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:34.701411      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:27:35.647734 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:27:35.702006      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:36.702931      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:27:37.655685 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:27:37.703860      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:38.703992      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:27:39.665082 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:27:39.704968      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:40.705923      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:27:41.675979 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:27:41.706653      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:42.706992      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:27:43.685469 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:27:43.707698      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:44.708563      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:27:45.700067 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:27:45.709145      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:46.710290      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:27:47.710081 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:27:47.710386      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:48.710682      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:49.710792      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:27:49.724835 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:27:50.711153      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:51.711941      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:27:51.736030 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:27:52.712310      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:53.712734      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:27:53.749941 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:27:54.713075      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:55.713186      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:27:55.760150 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:27:56.713443      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:57.713780      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:27:57.772139 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:27:58.714953      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:59.715121      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:27:59.780779 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:28:00.715495      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:01.715811      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:28:01.793058 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:28:02.716727      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:03.717749      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:28:03.809331 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:28:04.718522      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:05.718820      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:28:05.820387 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:28:06.719181      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:07.719236      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:28:07.828089 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:28:08.719447      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:09.720211      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:28:09.837793 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:28:10.720516      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:11.720711      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:28:11.875406 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:28:12.721119      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:13.722242      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:28:13.884591 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:28:14.722519      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:15.722800      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:28:15.895690 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:28:16.723086      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:17.723409      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:28:17.908757 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:28:18.724278      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:19.725074      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:28:19.918787 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:28:20.725289      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:21.725563      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:28:21.934672 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:28:22.726451      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:23.726515      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:28:23.945778 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:28:24.726946      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:25.728055      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:28:25.958815 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:28:26.728315      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:27.728725      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:28:27.971059 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:28:28.729874      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:29.730209      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:28:29.985642 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:28:30.730521      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:31.730632      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:28:31.997899 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:28:32.730995      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:33.731922      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:28:34.012329 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:28:34.732243      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:35.733363      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:28:36.023181 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:28:36.733638      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:37.733801      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:28:38.034621 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:28:38.734852      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:39.734995      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:28:40.045641 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:28:40.735321      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:41.736391      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:28:42.062018 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:28:42.737358      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:43.737103      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:28:44.073589 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:28:44.737688      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:45.738152      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:28:46.087922 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:28:46.738305      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:47.738615      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:28:48.101786 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:28:48.739847      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:49.740402      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:28:50.111215 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:28:50.740864      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:51.740666      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:28:52.125097 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:28:52.742078      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:53.742036      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:28:54.138064 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:28:54.743505      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:55.743513      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:28:56.152211 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:28:56.744185      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:57.744379      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:28:58.165872 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:28:58.744483      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:59.744741      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:29:00.179612 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:29:00.746601      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:01.746484      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:29:02.189817 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:29:02.747360      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:03.747029      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:29:04.202347 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:29:04.747586      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:05.748054      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:29:06.211957 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:29:06.748094      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:07.748239      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:29:08.223530 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:29:08.749190      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:09.749597      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:29:10.235440 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:29:10.749821      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:11.750028      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:29:12.246928 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:29:12.750553      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:13.750890      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:29:14.259644 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:29:14.750796      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:15.750895      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:29:16.273287 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:29:16.751512      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:17.752141      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:29:18.285725 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:29:18.752242      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:19.753423      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:29:20.302402 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:29:20.753866      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:21.754566      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:29:22.318159 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:29:22.754506      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:23.754759      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:29:24.327491 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:29:24.754897      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:25.756009      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:29:26.342078 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:29:26.755584      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:27.755760      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:29:28.354863 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:29:28.755955      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:29.756204      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:29:30.366568 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:29:30.757409      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:31.758414      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:29:32.378972 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:29:32.759212      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:33.760494      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:29:34.390084 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:29:34.759971      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:35.760579      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:29:36.403963 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:29:36.761350      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:37.761630      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:29:38.416635 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:29:38.761880      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:39.762552      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:29:40.425563 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:29:40.762668      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:41.763178      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:29:42.437975 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:29:42.764079      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:43.764339      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:29:44.449034 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:29:44.765113      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:45.765261      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:29:46.461444 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:29:46.766247      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:47.766533      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:29:48.471565 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:29:48.766654      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:49.766883      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:29:50.481970 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:29:50.767252      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:51.767630      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:29:52.496679 14 container_probe.go:1759] Get pod liveness-b1a20a01-4d46-4286-a885-c896ab28e41f in namespace container-probe-3217
  E0419 16:29:52.767655      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:53.768961      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 04/19/24 16:29:54.497
  I0419 16:29:54.578477 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-3217" for this suite. @ 04/19/24 16:29:54.588
• [243.753 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:601
  STEP: Creating a kubernetes client @ 04/19/24 16:29:54.619
  I0419 16:29:54.619477 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename job @ 04/19/24 16:29:54.63
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:29:54.704
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:29:54.712
  STEP: Creating a job @ 04/19/24 16:29:54.718
  STEP: Ensuring job reaches completions @ 04/19/24 16:29:54.732
  E0419 16:29:54.769146      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:55.770166      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:56.770641      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:57.771050      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:58.772262      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:59.772829      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:00.773235      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:01.774743      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:02.774866      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:03.775575      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:30:04.745182 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-6467" for this suite. @ 04/19/24 16:30:04.761
  E0419 16:30:04.776076      14 retrywatcher.go:129] "Watch failed" err="context canceled"
• [10.162 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:132
  STEP: Creating a kubernetes client @ 04/19/24 16:30:04.783
  I0419 16:30:04.783433 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename replicaset @ 04/19/24 16:30:04.788
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:30:04.828
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:30:04.838
  STEP: Given a Pod with a 'name' label pod-adoption-release is created @ 04/19/24 16:30:04.85
  E0419 16:30:05.777238      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:06.777685      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When a replicaset with a matching selector is created @ 04/19/24 16:30:06.904
  STEP: Then the orphan pod is adopted @ 04/19/24 16:30:06.922
  E0419 16:30:07.778611      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When the matched label of one of its pods change @ 04/19/24 16:30:07.955
  I0419 16:30:07.965052 14 resource.go:87] Pod name pod-adoption-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 04/19/24 16:30:07.992
  E0419 16:30:08.778726      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:30:09.015333 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-5549" for this suite. @ 04/19/24 16:30:09.032
• [4.275 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:168
  STEP: Creating a kubernetes client @ 04/19/24 16:30:09.066
  I0419 16:30:09.066564 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename field-validation @ 04/19/24 16:30:09.071
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:30:09.106
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:30:09.112
  I0419 16:30:09.122183 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  E0419 16:30:09.779974      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:10.780964      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:11.781711      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0419 16:30:11.918523      14 warnings.go:70] unknown field "alpha"
  W0419 16:30:11.918586      14 warnings.go:70] unknown field "beta"
  W0419 16:30:11.918598      14 warnings.go:70] unknown field "delta"
  W0419 16:30:11.918610      14 warnings.go:70] unknown field "epsilon"
  W0419 16:30:11.918620      14 warnings.go:70] unknown field "gamma"
  I0419 16:30:12.558335 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-6530" for this suite. @ 04/19/24 16:30:12.576
• [3.530 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] Servers with support for API chunking should support continue listing from the last key if the original version has been compacted away, though the list is inconsistent [Slow] [Conformance] [sig-api-machinery, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/chunking.go:144
  STEP: Creating a kubernetes client @ 04/19/24 16:30:12.597
  I0419 16:30:12.597372 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename chunking @ 04/19/24 16:30:12.601
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:30:12.652
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:30:12.66
  STEP: creating a large number of resources @ 04/19/24 16:30:12.667
  E0419 16:30:12.782107      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:13.782114      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:14.783010      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:15.783886      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:16.784425      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:17.785049      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:18.786132      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:19.787119      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:20.787445      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:21.789285      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:22.789179      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:23.792396      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:24.793058      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:25.793232      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:26.793288      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:27.794161      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:28.795021      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:29.795907      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the first page @ 04/19/24 16:30:30.321
  I0419 16:30:30.365683 14 chunking.go:163] Retrieved 40/40 results with rv 19143 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkxNDMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page until the token expires @ 04/19/24 16:30:30.365
  E0419 16:30:30.796568      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:31.796854      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:32.797306      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:33.797666      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:34.797983      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:35.798209      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:36.798772      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:37.798943      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:38.799772      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:39.800132      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:40.800640      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:41.801713      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:42.801998      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:43.802981      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:44.803242      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:45.803549      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:46.804664      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:47.805126      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:48.805259      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:49.806147      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:30:50.384799 14 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkxNDMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:30:50.807771      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:51.807828      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:52.808839      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:53.809698      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:54.810011      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:55.810178      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:56.810763      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:57.811007      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:58.812260      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:59.812428      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:00.812748      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:01.813323      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:02.813673      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:03.814017      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:04.814305      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:05.814643      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:06.815386      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:07.815770      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:08.817077      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:09.817318      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:31:10.391226 14 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkxNDMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:31:10.819056      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:11.819110      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:12.819023      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:13.820221      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:14.820591      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:15.821220      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:16.821601      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:17.822008      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:18.823057      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:19.823257      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:20.823572      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:21.823900      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:22.824162      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:23.825473      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:24.825756      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:25.826088      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:26.826650      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:27.826888      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:28.827138      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:29.827420      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:31:30.383764 14 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkxNDMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:31:30.828015      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:31.827927      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:32.828321      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:33.828584      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:34.829262      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:35.829803      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:36.830801      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:37.831359      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:38.831666      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:39.831947      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:40.832272      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:41.832587      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:42.832992      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:43.834025      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:44.834648      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:45.835446      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:46.835757      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:47.836251      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:48.836648      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:49.837209      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:31:50.384004 14 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkxNDMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:31:50.837593      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:51.838207      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:52.838748      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:53.840095      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:54.840744      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:55.840997      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:56.842025      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:57.842200      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:58.843354      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:59.843891      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:00.844468      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:01.844737      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:02.845263      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:03.846264      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:04.846677      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:05.849703      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:06.850720      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:07.850926      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:08.851052      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:09.856614      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:32:10.390812 14 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkxNDMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:32:10.854070      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:11.855145      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:12.855979      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:13.857243      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:14.857466      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:15.858238      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:16.858954      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:17.859383      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:18.859579      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:19.860549      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:20.861199      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:21.861399      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:22.862031      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:23.862897      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:24.863795      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:25.864356      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:26.864618      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:27.865222      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:28.866051      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:29.866645      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:32:30.382809 14 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkxNDMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:32:30.867116      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:31.867770      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:32.868227      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:33.869247      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:34.870068      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:35.870627      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:36.877779      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:37.878153      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:38.879184      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:39.879905      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:40.880098      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:41.880507      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:42.880755      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:43.881026      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:44.881208      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:45.881901      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:46.882492      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:47.882698      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:48.882921      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:49.883259      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:32:50.390902 14 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkxNDMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:32:50.884168      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:51.884716      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:52.886098      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:53.886202      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:54.886739      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:55.887032      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:56.887598      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:57.893340      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:58.890544      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:59.891241      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:00.891853      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:01.892396      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:02.892558      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:03.893666      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:04.894257      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:05.896222      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:06.895062      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:07.895598      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:08.896502      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:09.898617      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:33:10.384828 14 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkxNDMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:33:10.897454      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:11.897854      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:12.903598      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:13.901900      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:14.900846      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:15.901261      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:16.901544      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:17.902156      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:18.903290      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:19.904362      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:20.904528      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:21.904803      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:22.905257      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:23.905257      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:24.906312      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:25.906584      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:26.908020      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:27.908530      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:28.908205      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:29.907186      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:33:30.393127 14 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkxNDMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:33:30.907603      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:31.907768      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:32.908419      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:33.908768      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:34.909174      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:35.909223      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:36.909440      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:37.910398      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:38.911628      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:39.911991      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:40.912500      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:41.912706      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:42.913165      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:43.913179      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:44.913424      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:45.913692      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:46.914447      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:47.914599      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:48.914924      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:49.915157      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:33:50.388016 14 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkxNDMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:33:50.916178      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:51.916944      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:52.917318      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:53.918237      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:54.918755      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:55.919170      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:56.920158      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:57.920835      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:58.921144      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:59.921532      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:00.921720      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:01.922111      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:02.922483      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:03.922585      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:04.922731      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:05.923080      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:06.924059      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:07.924086      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:08.924518      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:09.924758      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:34:10.379776 14 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkxNDMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:34:10.925911      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:11.926710      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:12.926929      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:13.927684      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:14.928445      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:15.928460      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:16.929458      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:17.929635      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:18.932044      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:19.931171      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:20.931388      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:21.932484      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:22.932943      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:23.932967      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:24.933208      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:25.934950      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:26.935117      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:27.935207      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:28.936226      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:29.936540      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:34:30.387350 14 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkxNDMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:34:30.936641      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:31.937052      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:32.937349      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:33.937684      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:34.938829      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:35.938859      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:36.941215      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:37.940684      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:38.940693      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:39.940915      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:40.941189      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:41.941674      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:42.942187      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:43.946550      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:44.945524      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:45.946799      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:46.947987      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:47.949002      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:48.949975      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:49.950512      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:34:50.383022 14 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkxNDMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:34:50.951220      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:51.951691      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:52.953001      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:53.953243      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:54.954216      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:55.954314      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:56.955138      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:57.955433      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:58.955654      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:59.955889      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:00.958684      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:01.957665      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:02.959403      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:03.958334      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:04.959044      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:05.959349      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:06.960346      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:07.960729      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:08.961694      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:09.962063      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:35:10.382434 14 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkxNDMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:35:10.963120      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:11.963488      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:12.963722      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:13.963939      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:14.964853      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:15.965227      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:16.965684      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:17.966187      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:18.967177      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:19.967632      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:20.967968      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:21.968511      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:22.969132      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:23.969295      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:24.969460      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:25.969836      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:26.970029      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:27.970910      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:28.970722      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:29.971325      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:35:30.390729 14 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkxNDMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:35:30.971793      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:31.971695      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:32.972544      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:33.972726      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:34.973857      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:35.974100      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:36.974512      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:37.975204      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:38.975459      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:39.976293      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:40.977217      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:41.978226      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:42.979388      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:43.979699      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:44.980559      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:45.981639      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:46.982095      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:47.982340      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:48.982745      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:49.983593      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:35:50.387597 14 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkxNDMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:35:50.984054      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:51.985086      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:52.985485      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:53.985924      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:54.986268      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:55.986461      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:56.986926      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:57.987338      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:58.988187      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:59.988729      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:00.989143      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:01.989240      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:02.990220      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:03.990745      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:04.991626      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:05.991885      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:06.992077      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:07.993119      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:08.993286      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:09.994382      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:36:10.387121 14 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkxNDMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:36:10.995268      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:11.995361      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:12.995519      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:13.995625      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:14.995980      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:15.996260      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:16.997011      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:17.997832      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:18.998193      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:19.998753      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:20.999079      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:21.999164      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:22.999438      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:23.999645      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:24.999947      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:26.000079      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:27.000807      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:28.001146      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:29.001276      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:30.002175      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:36:30.383187 14 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkxNDMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:36:31.002855      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:32.003137      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:33.003387      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:34.003313      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:35.003564      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:36.003883      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:37.003980      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:38.005945      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:39.006911      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:40.007153      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:41.007357      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:42.007508      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:43.007860      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:44.008124      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:45.008422      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:46.008570      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:47.008753      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:48.009115      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:49.009231      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:50.009580      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:36:50.382063 14 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkxNDMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:36:51.010318      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:52.010573      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:53.010814      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:54.011065      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:55.011345      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:56.011673      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:57.013454      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:58.013120      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:59.013940      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:00.014473      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:01.015036      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:02.015401      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:03.015867      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:04.016741      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:05.017248      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:06.017643      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:07.018600      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:08.019084      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:09.020305      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:10.020700      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:37:10.386109 14 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkxNDMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:37:11.021099      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:12.021955      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:13.022586      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:14.022602      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:15.022868      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:16.023183      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:17.023484      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:18.023685      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:19.024139      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:20.024486      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:21.024560      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:22.024710      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:23.025113      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:24.025350      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:25.025490      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:26.025768      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:27.026059      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:28.026211      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:29.026578      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:30.026684      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:37:30.385120 14 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkxNDMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:37:31.027432      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:32.028437      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:33.028662      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:34.029666      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:35.030720      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:36.030696      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:37.032072      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:38.031836      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:39.032094      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:40.032811      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:41.033098      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:42.033186      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:43.033902      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:44.034355      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:45.035078      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:46.034806      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:47.035742      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:48.036056      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:49.036517      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:50.036471      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:37:50.381996 14 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkxNDMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:37:51.036649      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:52.037410      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:53.037985      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:54.038010      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:55.038464      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:56.039105      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:57.040075      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:58.040651      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:59.041490      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:00.042060      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:01.042503      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:02.043200      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:03.043826      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:04.044789      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:05.045437      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:06.045953      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:07.047147      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:08.047720      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:09.048471      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:10.049050      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:38:10.387019 14 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkxNDMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:38:11.049794      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:12.050664      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:13.050244      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:14.050610      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:15.050850      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:16.051093      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:17.051777      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:18.052174      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:19.052400      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:20.052619      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:21.052779      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:22.053175      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:23.053385      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:24.053659      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:25.053847      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:26.054259      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:27.054797      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:28.055275      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:29.055465      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:30.055848      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:38:30.384720 14 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkxNDMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:38:31.056715      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:32.056259      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:33.057096      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:34.057188      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:35.057816      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:36.058083      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:37.058940      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:38.059295      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:39.059666      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:40.059711      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:41.060510      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:42.061332      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:43.062487      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:44.062855      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:45.062818      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:46.063100      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:47.063550      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:48.063823      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:49.064014      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:50.064314      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:38:50.385938 14 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkxNDMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:38:51.065125      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:52.065480      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:53.065446      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:54.065795      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:55.066064      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:56.066285      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:57.066648      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:58.066879      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:59.067168      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:00.067308      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:01.067678      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:02.067907      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:03.068134      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:04.069151      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:05.069506      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:06.069809      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:07.070674      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:08.072030      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:09.074172      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:10.074348      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:39:10.386779 14 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkxNDMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:39:11.074738      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:12.075592      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:13.075917      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:14.076165      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:15.076366      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:16.076494      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:17.077266      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:18.078540      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:19.079371      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:20.079741      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:21.080193      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:22.080726      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:23.081365      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:24.082111      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:25.082644      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:26.083602      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:27.084039      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:28.084431      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:29.085182      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:30.085676      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:39:30.382351 14 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkxNDMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:39:31.086477      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:32.086193      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:33.086753      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:34.087484      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:35.088132      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:36.088071      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:37.089408      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:38.089567      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:39.089903      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:40.090069      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:41.090166      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:42.090520      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:43.091657      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:44.091256      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:45.091603      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:46.092026      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:47.092862      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:48.093112      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:49.093621      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:50.093722      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:39:50.395175 14 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkxNDMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:39:51.094485      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:52.094577      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:53.094896      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:54.095164      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:55.097942      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:56.098021      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:57.098874      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:58.099307      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:59.099490      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:00.100541      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:01.101608      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:02.102859      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:03.103309      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:04.104329      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:05.104762      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:06.104993      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:07.105143      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:08.105713      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:09.105949      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:10.106300      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:40:10.379396 14 chunking.go:177] got error The provided continue parameter is too old to display a consistent list result. You can start a new list without the continue parameter, or use the continue token in this response to retrieve the remainder of the results. Continuing with the provided token results in an inconsistent list - objects that were created, modified, or deleted between the time the first chunk was returned and now may show up in the list.
  I0419 16:40:10.380943 14 chunking.go:186] Retrieved inconsistent continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6LTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page again with the token received with the error message @ 04/19/24 16:40:10.382
  STEP: retrieving all remaining pages @ 04/19/24 16:40:10.406
  I0419 16:40:10.428056 14 chunking.go:221] Retrieved 40/40 results with rv 20142 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAxNDIsInN0YXJ0IjoidGVtcGxhdGUtMDExOVx1MDAwMCJ9
  I0419 16:40:10.441549 14 chunking.go:221] Retrieved 40/40 results with rv 20142 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAxNDIsInN0YXJ0IjoidGVtcGxhdGUtMDE1OVx1MDAwMCJ9
  I0419 16:40:10.460121 14 chunking.go:221] Retrieved 40/40 results with rv 20142 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAxNDIsInN0YXJ0IjoidGVtcGxhdGUtMDE5OVx1MDAwMCJ9
  I0419 16:40:10.483029 14 chunking.go:221] Retrieved 40/40 results with rv 20142 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAxNDIsInN0YXJ0IjoidGVtcGxhdGUtMDIzOVx1MDAwMCJ9
  I0419 16:40:10.500653 14 chunking.go:221] Retrieved 40/40 results with rv 20142 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAxNDIsInN0YXJ0IjoidGVtcGxhdGUtMDI3OVx1MDAwMCJ9
  I0419 16:40:10.517683 14 chunking.go:221] Retrieved 40/40 results with rv 20142 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAxNDIsInN0YXJ0IjoidGVtcGxhdGUtMDMxOVx1MDAwMCJ9
  I0419 16:40:10.531387 14 chunking.go:221] Retrieved 40/40 results with rv 20142 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAxNDIsInN0YXJ0IjoidGVtcGxhdGUtMDM1OVx1MDAwMCJ9
  I0419 16:40:10.545415 14 chunking.go:221] Retrieved 40/40 results with rv 20142 and continue 
  I0419 16:40:10.546760 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-7229" for this suite. @ 04/19/24 16:40:10.562
• [597.982 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery endpoint Accept headers [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:151
  STEP: Creating a kubernetes client @ 04/19/24 16:40:10.587
  I0419 16:40:10.588079 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename aggregateddiscovery @ 04/19/24 16:40:10.592
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:40:10.626
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:40:10.632
  I0419 16:40:10.646442 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-8888" for this suite. @ 04/19/24 16:40:10.658
• [0.085 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] PodTemplates should replace a pod template [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:177
  STEP: Creating a kubernetes client @ 04/19/24 16:40:10.673
  I0419 16:40:10.674130 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename podtemplate @ 04/19/24 16:40:10.676
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:40:10.709
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:40:10.715
  STEP: Create a pod template @ 04/19/24 16:40:10.722
  STEP: Replace a pod template @ 04/19/24 16:40:10.731
  I0419 16:40:10.747040 14 podtemplates.go:210] Found updated podtemplate annotation: "true"

  I0419 16:40:10.747306 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-9080" for this suite. @ 04/19/24 16:40:10.759
• [0.102 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:150
  STEP: Creating a kubernetes client @ 04/19/24 16:40:10.779
  I0419 16:40:10.779433 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename emptydir @ 04/19/24 16:40:10.783
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:40:10.807
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:40:10.814
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 04/19/24 16:40:10.821
  E0419 16:40:11.107615      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:12.107961      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:13.108990      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:14.109184      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:40:14.874
  I0419 16:40:14.883080 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-4da442ed-272d-4b33-9b4b-cd43357eaa95 container test-container: <nil>
  STEP: delete the pod @ 04/19/24 16:40:14.937
  I0419 16:40:14.978504 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7819" for this suite. @ 04/19/24 16:40:14.994
• [4.237 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support proxy with --port 0 [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1833
  STEP: Creating a kubernetes client @ 04/19/24 16:40:15.019
  I0419 16:40:15.019680 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename kubectl @ 04/19/24 16:40:15.023
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:40:15.062
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:40:15.069
  STEP: starting the proxy server @ 04/19/24 16:40:15.08
  I0419 16:40:15.081265 14 util.go:592] Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-7441 proxy -p 0 --disable-filter'
  E0419 16:40:15.109735      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: curling proxy /api/ output @ 04/19/24 16:40:15.221
  I0419 16:40:15.241841 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  I0419 16:40:15.245232 14 kubectl.go:2228] kubectl proxy stderr: W0419 16:40:15.220575     594 proxy.go:177] Request filter disabled, your proxy is vulnerable to XSRF attacks, please be cautious

  I0419 16:40:15.245359 14 kubectl.go:2223] kubectl proxy stdout: Starting to serve on 127.0.0.1:42971

  STEP: Destroying namespace "kubectl-7441" for this suite. @ 04/19/24 16:40:15.254
• [0.248 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected combined should project all components that make up the projection API [Projection] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_combined.go:44
  STEP: Creating a kubernetes client @ 04/19/24 16:40:15.267
  I0419 16:40:15.267522 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename projected @ 04/19/24 16:40:15.272
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:40:15.295
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:40:15.301
  STEP: Creating configMap with name configmap-projected-all-test-volume-1a42c088-6c39-4041-b1dc-eb05b5588564 @ 04/19/24 16:40:15.306
  STEP: Creating secret with name secret-projected-all-test-volume-d4d8553c-f029-420b-8e17-fe4612466a23 @ 04/19/24 16:40:15.315
  STEP: Creating a pod to test Check all projections for projected volume plugin @ 04/19/24 16:40:15.324
  E0419 16:40:16.110510      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:17.110988      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:18.111188      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:19.111139      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:40:19.363
  I0419 16:40:19.369507 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod projected-volume-2f5433fc-e653-4a0e-ab6c-64365235f37d container projected-all-volume-test: <nil>
  STEP: delete the pod @ 04/19/24 16:40:19.387
  I0419 16:40:19.424222 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7787" for this suite. @ 04/19/24 16:40:19.435
• [4.180 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should patch a pod status [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:1084
  STEP: Creating a kubernetes client @ 04/19/24 16:40:19.456
  I0419 16:40:19.457135 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename pods @ 04/19/24 16:40:19.461
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:40:19.485
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:40:19.493
  STEP: Create a pod @ 04/19/24 16:40:19.499
  E0419 16:40:20.112235      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:21.112824      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching /status @ 04/19/24 16:40:21.546
  I0419 16:40:21.565460 14 pods.go:1124] Status Message: "Patched by e2e test" and Reason: "E2E"
  I0419 16:40:21.565838 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8728" for this suite. @ 04/19/24 16:40:21.575
• [2.132 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/hostport.go:63
  STEP: Creating a kubernetes client @ 04/19/24 16:40:21.597
  I0419 16:40:21.597510 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename hostport @ 04/19/24 16:40:21.6
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:40:21.63
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:40:21.636
  STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled @ 04/19/24 16:40:21.654
  E0419 16:40:22.113710      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:23.114309      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:24.115295      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:25.115328      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:26.115758      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:27.116780      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:28.117697      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:29.118646      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:30.119432      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:31.119665      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:32.120217      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:33.120732      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 192.168.121.127 on the node which pod1 resides and expect scheduled @ 04/19/24 16:40:33.742
  E0419 16:40:34.121452      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:35.121610      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 192.168.121.127 but use UDP protocol on the node which pod2 resides @ 04/19/24 16:40:35.777
  E0419 16:40:36.121787      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:37.121985      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:38.123137      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:39.127079      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 @ 04/19/24 16:40:39.887
  I0419 16:40:39.888069 14 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 192.168.121.127 http://127.0.0.1:54323/hostname] Namespace:hostport-7199 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0419 16:40:39.888358 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 16:40:39.891766 14 exec_util.go:62] ExecWithOptions: Clientset creation
  I0419 16:40:39.892333 14 exec_util.go:79] ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-7199/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+192.168.121.127+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.121.127, port: 54323 @ 04/19/24 16:40:40.057
  I0419 16:40:40.057283 14 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://192.168.121.127:54323/hostname] Namespace:hostport-7199 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0419 16:40:40.057390 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 16:40:40.059253 14 exec_util.go:62] ExecWithOptions: Clientset creation
  I0419 16:40:40.059518 14 exec_util.go:79] ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-7199/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F192.168.121.127%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  E0419 16:40:40.127468      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.121.127, port: 54323 UDP @ 04/19/24 16:40:40.176
  I0419 16:40:40.176341 14 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 192.168.121.127 54323] Namespace:hostport-7199 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0419 16:40:40.176373 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 16:40:40.178065 14 exec_util.go:62] ExecWithOptions: Clientset creation
  I0419 16:40:40.178282 14 exec_util.go:79] ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-7199/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+192.168.121.127+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  E0419 16:40:41.129220      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:42.129967      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:43.130186      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:44.130274      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:45.130809      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:40:45.268508 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "hostport-7199" for this suite. @ 04/19/24 16:40:45.281
• [23.700 seconds]
------------------------------
SSSS
------------------------------
[sig-network] DNS should provide DNS for ExternalName services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:329
  STEP: Creating a kubernetes client @ 04/19/24 16:40:45.299
  I0419 16:40:45.299674 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename dns @ 04/19/24 16:40:45.304
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:40:45.34
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:40:45.347
  STEP: Creating a test externalName service @ 04/19/24 16:40:45.35
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6259.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-6259.svc.cluster.local; sleep 1; done
   @ 04/19/24 16:40:45.362
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6259.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-6259.svc.cluster.local; sleep 1; done
   @ 04/19/24 16:40:45.362
  STEP: creating a pod to probe DNS @ 04/19/24 16:40:45.362
  STEP: submitting the pod to kubernetes @ 04/19/24 16:40:45.362
  E0419 16:40:46.131289      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:47.131531      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:48.131336      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:49.133009      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:50.136149      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:51.134165      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:52.134653      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:53.135263      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:54.136714      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:55.136622      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:56.136820      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:57.136972      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:58.137704      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:59.138878      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:00.139243      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:01.139891      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:02.139792      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:03.140842      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/19/24 16:41:03.504
  STEP: looking for the results for each expected name from probers @ 04/19/24 16:41:03.518
  I0419 16:41:03.553501 14 dns_common.go:552] DNS probes using dns-test-9a8a9396-6db6-4fc5-974e-3e93cb95fbb0 succeeded

  STEP: changing the externalName to bar.example.com @ 04/19/24 16:41:03.554
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6259.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-6259.svc.cluster.local; sleep 1; done
   @ 04/19/24 16:41:03.588
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6259.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-6259.svc.cluster.local; sleep 1; done
   @ 04/19/24 16:41:03.589
  STEP: creating a second pod to probe DNS @ 04/19/24 16:41:03.589
  STEP: submitting the pod to kubernetes @ 04/19/24 16:41:03.589
  E0419 16:41:04.140529      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:05.140702      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/19/24 16:41:05.624
  STEP: looking for the results for each expected name from probers @ 04/19/24 16:41:05.636
  I0419 16:41:05.661564 14 dns_common.go:482] File wheezy_udp@dns-test-service-3.dns-6259.svc.cluster.local from pod  dns-6259/dns-test-96f13441-a581-4235-8561-44939a97aff8 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0419 16:41:05.671728 14 dns_common.go:482] File jessie_udp@dns-test-service-3.dns-6259.svc.cluster.local from pod  dns-6259/dns-test-96f13441-a581-4235-8561-44939a97aff8 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0419 16:41:05.672964 14 dns_common.go:489] Lookups using dns-6259/dns-test-96f13441-a581-4235-8561-44939a97aff8 failed for: [wheezy_udp@dns-test-service-3.dns-6259.svc.cluster.local jessie_udp@dns-test-service-3.dns-6259.svc.cluster.local]

  I0419 16:41:05.693192 14 dns_common.go:495] Pod client logs for webserver: 
  I0419 16:41:05.709403 14 dns_common.go:495] Pod client logs for querier: 
  I0419 16:41:05.727701 14 dns_common.go:495] Pod client logs for jessie-querier: 
  E0419 16:41:06.141856      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:07.142410      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:08.142926      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:09.142808      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:10.143774      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:41:10.647640 14 dns_common.go:482] File wheezy_udp@dns-test-service-3.dns-6259.svc.cluster.local from pod  dns-6259/dns-test-96f13441-a581-4235-8561-44939a97aff8 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0419 16:41:10.656995 14 dns_common.go:482] File jessie_udp@dns-test-service-3.dns-6259.svc.cluster.local from pod  dns-6259/dns-test-96f13441-a581-4235-8561-44939a97aff8 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0419 16:41:10.657066 14 dns_common.go:489] Lookups using dns-6259/dns-test-96f13441-a581-4235-8561-44939a97aff8 failed for: [wheezy_udp@dns-test-service-3.dns-6259.svc.cluster.local jessie_udp@dns-test-service-3.dns-6259.svc.cluster.local]

  I0419 16:41:10.668797 14 dns_common.go:495] Pod client logs for webserver: 
  I0419 16:41:10.682688 14 dns_common.go:495] Pod client logs for querier: 
  I0419 16:41:10.701493 14 dns_common.go:495] Pod client logs for jessie-querier: 
  E0419 16:41:11.144555      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:12.145307      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:13.146848      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:14.146616      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:15.153625      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:41:15.649233 14 dns_common.go:482] File wheezy_udp@dns-test-service-3.dns-6259.svc.cluster.local from pod  dns-6259/dns-test-96f13441-a581-4235-8561-44939a97aff8 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0419 16:41:15.665403 14 dns_common.go:482] File jessie_udp@dns-test-service-3.dns-6259.svc.cluster.local from pod  dns-6259/dns-test-96f13441-a581-4235-8561-44939a97aff8 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0419 16:41:15.666555 14 dns_common.go:489] Lookups using dns-6259/dns-test-96f13441-a581-4235-8561-44939a97aff8 failed for: [wheezy_udp@dns-test-service-3.dns-6259.svc.cluster.local jessie_udp@dns-test-service-3.dns-6259.svc.cluster.local]

  I0419 16:41:15.689148 14 dns_common.go:495] Pod client logs for webserver: 
  I0419 16:41:15.703429 14 dns_common.go:495] Pod client logs for querier: 
  I0419 16:41:15.720492 14 dns_common.go:495] Pod client logs for jessie-querier: 
  E0419 16:41:16.154518      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:17.154834      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:18.155076      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:19.156024      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:20.156333      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:41:20.661231 14 dns_common.go:552] DNS probes using dns-test-96f13441-a581-4235-8561-44939a97aff8 succeeded

  STEP: changing the service to type=ClusterIP @ 04/19/24 16:41:20.661
  W0419 16:41:20.713988      14 warnings.go:70] spec.externalName is ignored when spec.type is not "ExternalName"
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6259.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-6259.svc.cluster.local; sleep 1; done
   @ 04/19/24 16:41:20.715
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6259.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-6259.svc.cluster.local; sleep 1; done
   @ 04/19/24 16:41:20.716
  STEP: creating a third pod to probe DNS @ 04/19/24 16:41:20.717
  STEP: submitting the pod to kubernetes @ 04/19/24 16:41:20.727
  E0419 16:41:21.157268      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:22.157749      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/19/24 16:41:22.804
  STEP: looking for the results for each expected name from probers @ 04/19/24 16:41:22.815
  I0419 16:41:22.844335 14 dns_common.go:552] DNS probes using dns-test-fdc27898-9c67-42ed-abed-ab0acfc44b54 succeeded

  STEP: deleting the pod @ 04/19/24 16:41:22.845
  STEP: deleting the pod @ 04/19/24 16:41:22.88
  STEP: deleting the pod @ 04/19/24 16:41:22.916
  STEP: deleting the test externalName service @ 04/19/24 16:41:22.963
  I0419 16:41:23.009938 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-6259" for this suite. @ 04/19/24 16:41:23.019
• [37.732 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:875
  STEP: Creating a kubernetes client @ 04/19/24 16:41:23.038
  I0419 16:41:23.039047 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename daemonsets @ 04/19/24 16:41:23.043
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:41:23.066
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:41:23.071
  STEP: Creating simple DaemonSet "daemon-set" @ 04/19/24 16:41:23.127
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/19/24 16:41:23.139
  I0419 16:41:23.156988 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0419 16:41:23.157094 14 fixtures.go:130] Node eipo9quoh3ef-1 is running 0 daemon pod, expected 1
  E0419 16:41:23.158039      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:24.158476      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:41:24.158709 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0419 16:41:24.159202 14 fixtures.go:130] Node eipo9quoh3ef-1 is running 0 daemon pod, expected 1
  E0419 16:41:25.160693      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:41:25.169880 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0419 16:41:25.170259 14 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Getting /status @ 04/19/24 16:41:25.176
  I0419 16:41:25.195449 14 daemon_set.go:912] Daemon Set daemon-set has Conditions: []
  STEP: updating the DaemonSet Status @ 04/19/24 16:41:25.195
  I0419 16:41:25.217525 14 daemon_set.go:932] updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the daemon set status to be updated @ 04/19/24 16:41:25.217
  I0419 16:41:25.222496 14 daemon_set.go:957] Observed &DaemonSet event: ADDED
  I0419 16:41:25.222796 14 daemon_set.go:957] Observed &DaemonSet event: MODIFIED
  I0419 16:41:25.223000 14 daemon_set.go:957] Observed &DaemonSet event: MODIFIED
  I0419 16:41:25.223588 14 daemon_set.go:957] Observed &DaemonSet event: MODIFIED
  I0419 16:41:25.223832 14 daemon_set.go:957] Observed &DaemonSet event: MODIFIED
  I0419 16:41:25.223892 14 daemon_set.go:950] Found daemon set daemon-set in namespace daemonsets-6423 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0419 16:41:25.223920 14 daemon_set.go:961] Daemon set daemon-set has an updated status
  STEP: patching the DaemonSet Status @ 04/19/24 16:41:25.223
  STEP: watching for the daemon set status to be patched @ 04/19/24 16:41:25.242
  I0419 16:41:25.246768 14 daemon_set.go:1001] Observed &DaemonSet event: ADDED
  I0419 16:41:25.247588 14 daemon_set.go:1001] Observed &DaemonSet event: MODIFIED
  I0419 16:41:25.248591 14 daemon_set.go:1001] Observed &DaemonSet event: MODIFIED
  I0419 16:41:25.249359 14 daemon_set.go:1001] Observed &DaemonSet event: MODIFIED
  I0419 16:41:25.250606 14 daemon_set.go:1001] Observed &DaemonSet event: MODIFIED
  I0419 16:41:25.251100 14 daemon_set.go:997] Observed daemon set daemon-set in namespace daemonsets-6423 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0419 16:41:25.251457 14 daemon_set.go:1001] Observed &DaemonSet event: MODIFIED
  I0419 16:41:25.251811 14 daemon_set.go:994] Found daemon set daemon-set in namespace daemonsets-6423 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
  I0419 16:41:25.252431 14 daemon_set.go:1005] Daemon set daemon-set has a patched status
  STEP: Deleting DaemonSet "daemon-set" @ 04/19/24 16:41:25.262
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6423, will wait for the garbage collector to delete the pods @ 04/19/24 16:41:25.263
  I0419 16:41:25.343260 14 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 18.612166ms
  I0419 16:41:25.444524 14 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 101.217529ms
  E0419 16:41:26.164370      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:41:26.856331 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0419 16:41:26.856674 14 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0419 16:41:26.861669 14 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"20985"},"items":null}

  I0419 16:41:26.867109 14 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"20985"},"items":null}

  I0419 16:41:26.893465 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-6423" for this suite. @ 04/19/24 16:41:26.901
• [3.876 seconds]
------------------------------
SSSS
------------------------------
[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:47
  STEP: Creating a kubernetes client @ 04/19/24 16:41:26.917
  I0419 16:41:26.917496 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename configmap @ 04/19/24 16:41:26.925
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:41:26.954
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:41:26.965
  STEP: Creating configMap configmap-6561/configmap-test-b6d2c129-af75-48b0-9283-9e19d078b1eb @ 04/19/24 16:41:26.97
  STEP: Creating a pod to test consume configMaps @ 04/19/24 16:41:26.98
  E0419 16:41:27.163169      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:28.163481      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:29.164028      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:30.164423      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:41:31.035
  I0419 16:41:31.045281 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-configmaps-05387adb-6ee2-48a3-a75d-a34f10e9fd6d container env-test: <nil>
  STEP: delete the pod @ 04/19/24 16:41:31.068
  I0419 16:41:31.116090 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6561" for this suite. @ 04/19/24 16:41:31.135
• [4.238 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:215
  STEP: Creating a kubernetes client @ 04/19/24 16:41:31.161
  I0419 16:41:31.162060 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  E0419 16:41:31.165103      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Building a namespace api object, basename projected @ 04/19/24 16:41:31.167
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:41:31.196
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:41:31.203
  STEP: Creating secret with name s-test-opt-del-8ea8bb67-40c1-4ca7-904c-0f466f8770a2 @ 04/19/24 16:41:31.221
  STEP: Creating secret with name s-test-opt-upd-ca966035-d00a-41a5-bf74-444b12b63b76 @ 04/19/24 16:41:31.231
  STEP: Creating the pod @ 04/19/24 16:41:31.243
  E0419 16:41:32.165543      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:33.166003      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-8ea8bb67-40c1-4ca7-904c-0f466f8770a2 @ 04/19/24 16:41:33.362
  STEP: Updating secret s-test-opt-upd-ca966035-d00a-41a5-bf74-444b12b63b76 @ 04/19/24 16:41:33.384
  STEP: Creating secret with name s-test-opt-create-05e8c7ae-3178-4399-b27b-bfc179850c5e @ 04/19/24 16:41:33.396
  STEP: waiting to observe update in volume @ 04/19/24 16:41:33.412
  E0419 16:41:34.166479      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:35.166799      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:36.166926      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:37.168295      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:38.168801      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:39.169346      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:40.169521      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:41.170465      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:42.170190      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:43.170602      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:44.170766      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:45.171293      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:46.171538      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:47.172121      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:48.173051      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:49.173536      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:50.174746      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:51.175556      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:52.175434      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:53.175815      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:54.176669      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:55.177161      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:56.186483      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:57.186833      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:58.187318      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:59.187596      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:00.188572      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:01.189346      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:02.189501      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:03.190717      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:04.190799      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:05.192140      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:06.193518      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:07.194093      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:08.194800      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:09.194862      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:10.195628      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:11.195964      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:12.196558      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:13.196780      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:14.196787      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:15.197356      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:16.198887      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:17.198799      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:18.199865      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:19.200580      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:20.200278      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:21.200600      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:22.201346      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:23.201947      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:24.202214      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:25.202993      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:26.203142      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:27.203094      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:28.203168      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:29.203665      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:30.203531      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:31.204479      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:32.204776      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:33.205721      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:34.206117      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:35.206877      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:36.207360      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:37.208254      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:38.207857      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:39.209184      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:40.216722      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:41.217013      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:42.217297      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:43.218338      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:44.219371      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:45.219764      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:46.220393      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:47.220801      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:48.221162      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:49.221435      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:50.223040      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:51.222887      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:52.223632      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:53.225584      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:54.224087      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:55.224500      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:56.225468      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:57.226427      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:58.227433      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:59.228229      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:00.229038      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:43:00.650755 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4557" for this suite. @ 04/19/24 16:43:00.666
• [89.526 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve endpoints on same port and different protocols [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3656
  STEP: Creating a kubernetes client @ 04/19/24 16:43:00.703
  I0419 16:43:00.704062 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename services @ 04/19/24 16:43:00.709
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:43:00.75
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:43:00.761
  STEP: creating service multiprotocol-test in namespace services-6897 @ 04/19/24 16:43:00.768
  STEP: creating pod pod1 in namespace services-6897 @ 04/19/24 16:43:00.794
  STEP: Creating pod pod1 in namespace services-6897 @ 04/19/24 16:43:00.797
  E0419 16:43:01.230023      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:02.230509      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multiprotocol-test in namespace services-6897 to expose endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]] @ 04/19/24 16:43:02.854
  I0419 16:43:02.880363 14 service.go:4351] successfully validated that service multiprotocol-test in namespace services-6897 exposes endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]]
  STEP: Checking if the Service forwards traffic to the TCP and UDP port @ 04/19/24 16:43:02.88
  I0419 16:43:02.880948 14 resource.go:361] Creating new exec pod
  E0419 16:43:03.231090      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:04.231500      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:43:04.920251 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-6897 exec execpod7d7t9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.24.14 80'
  E0419 16:43:05.232196      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:43:05.275244 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.24.14 80\nConnection to 10.233.24.14 80 port [tcp/http] succeeded!\n"
  I0419 16:43:05.275332 14 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0419 16:43:05.275935 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-6897 exec execpod7d7t9 -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.233.24.14 80'
  E0419 16:43:06.233024      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:07.233583      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:08.233743      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:09.233991      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:43:09.541156 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.233.24.14 80\nConnection to 10.233.24.14 80 port [udp/*] succeeded!\n"
  I0419 16:43:09.541243 14 builder.go:147] stdout: "pod1"
  STEP: Checking if the Service forwards traffic to TCP only @ 04/19/24 16:43:09.541
  I0419 16:43:09.567424 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-6897 exec execpod7d7t9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.24.14 80'
  I0419 16:43:09.884167 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.24.14 80\nConnection to 10.233.24.14 80 port [tcp/http] succeeded!\n"
  I0419 16:43:09.884257 14 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0419 16:43:09.885048 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-6897 exec execpod7d7t9 -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.233.24.14 80'
  E0419 16:43:10.234297      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:11.234649      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:12.234954      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:13.235222      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:43:14.166874 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.233.24.14 80\nConnection to 10.233.24.14 80 port [udp/*] succeeded!\n"
  I0419 16:43:14.167017 14 builder.go:147] stdout: ""
  I0419 16:43:14.168059 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-6897 exec execpod7d7t9 -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.233.24.14 80'
  E0419 16:43:14.235976      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:15.236542      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:16.237591      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:17.237877      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:18.238735      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:43:18.511159 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.233.24.14 80\nConnection to 10.233.24.14 80 port [udp/*] succeeded!\n"
  I0419 16:43:18.511282 14 builder.go:147] stdout: ""
  STEP: Checking if the Service forwards traffic to UDP only @ 04/19/24 16:43:18.511
  I0419 16:43:18.537583 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-6897 exec execpod7d7t9 -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.233.24.14 80'
  E0419 16:43:19.239884      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:20.240249      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:21.240475      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:22.241034      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:43:22.829219 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.233.24.14 80\nConnection to 10.233.24.14 80 port [udp/*] succeeded!\n"
  I0419 16:43:22.829325 14 builder.go:147] stdout: "pod1"
  I0419 16:43:22.829711 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-6897 exec execpod7d7t9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.24.14 80'
  E0419 16:43:23.241224      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:24.241418      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:43:25.121292 14 builder.go:135] rc: 1
  I0419 16:43:25.121688 14 util.go:239] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-6897 exec execpod7d7t9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.24.14 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.233.24.14 80
  nc: connect to 10.233.24.14 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I0419 16:43:25.122189 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-6897 exec execpod7d7t9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.24.14 80'
  E0419 16:43:25.242171      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:26.242578      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:27.243589      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:43:27.403953 14 builder.go:135] rc: 1
  I0419 16:43:27.404114 14 util.go:239] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-6897 exec execpod7d7t9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.24.14 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.233.24.14 80
  nc: connect to 10.233.24.14 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I0419 16:43:27.404862 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-6897 exec execpod7d7t9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.24.14 80'
  E0419 16:43:28.244331      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:29.244445      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:43:29.727433 14 builder.go:135] rc: 1
  I0419 16:43:29.727600 14 util.go:239] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-6897 exec execpod7d7t9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.24.14 80:
  Command stdout:

  stderr:
  + nc -v -t -w 2 10.233.24.14 80
  + echo hostName
  nc: connect to 10.233.24.14 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I0419 16:43:29.728073 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6897" for this suite. @ 04/19/24 16:43:29.743
• [29.057 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csistoragecapacity.go:50
  STEP: Creating a kubernetes client @ 04/19/24 16:43:29.762
  I0419 16:43:29.762341 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename csistoragecapacity @ 04/19/24 16:43:29.766
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:43:29.803
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:43:29.81
  STEP: getting /apis @ 04/19/24 16:43:29.818
  STEP: getting /apis/storage.k8s.io @ 04/19/24 16:43:29.83
  STEP: getting /apis/storage.k8s.io/v1 @ 04/19/24 16:43:29.834
  STEP: creating @ 04/19/24 16:43:29.838
  STEP: watching @ 04/19/24 16:43:29.871
  I0419 16:43:29.871953 14 csistoragecapacity.go:143] starting watch
  STEP: getting @ 04/19/24 16:43:29.888
  STEP: listing in namespace @ 04/19/24 16:43:29.896
  STEP: listing across namespaces @ 04/19/24 16:43:29.905
  STEP: patching @ 04/19/24 16:43:29.911
  STEP: updating @ 04/19/24 16:43:29.925
  I0419 16:43:29.934592 14 csistoragecapacity.go:181] waiting for watch events with expected annotations in namespace
  I0419 16:43:29.934833 14 csistoragecapacity.go:181] waiting for watch events with expected annotations across namespace
  STEP: deleting @ 04/19/24 16:43:29.935
  STEP: deleting a collection @ 04/19/24 16:43:29.956
  I0419 16:43:29.982988 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csistoragecapacity-7705" for this suite. @ 04/19/24 16:43:29.992
• [0.242 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:237
  STEP: Creating a kubernetes client @ 04/19/24 16:43:30.019
  I0419 16:43:30.020041 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename projected @ 04/19/24 16:43:30.022
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:43:30.047
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:43:30.052
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 16:43:30.058
  E0419 16:43:30.245496      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:31.245925      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:32.246527      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:33.246362      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:43:34.111
  I0419 16:43:34.126475 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod downwardapi-volume-fb8a7462-0b50-4bab-a3fe-9cdf2bd30747 container client-container: <nil>
  STEP: delete the pod @ 04/19/24 16:43:34.146
  I0419 16:43:34.190725 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4453" for this suite. @ 04/19/24 16:43:34.204
• [4.201 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:168
  STEP: Creating a kubernetes client @ 04/19/24 16:43:34.231
  I0419 16:43:34.231878 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename cronjob @ 04/19/24 16:43:34.235
  E0419 16:43:34.247132      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:43:34.27
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:43:34.281
  STEP: Creating a ReplaceConcurrent cronjob @ 04/19/24 16:43:34.292
  STEP: Ensuring a job is scheduled @ 04/19/24 16:43:34.307
  E0419 16:43:35.247161      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:36.247608      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:37.247796      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:38.248168      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:39.248347      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:40.248501      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:41.249160      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:42.249897      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:43.250191      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:44.250186      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:45.250846      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:46.251474      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:47.251993      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:48.252813      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:49.253577      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:50.254506      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:51.255378      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:52.255111      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:53.255898      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:54.255968      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:55.256163      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:56.257088      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:57.257259      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:58.258139      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:59.258756      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:00.259842      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 04/19/24 16:44:00.317
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 04/19/24 16:44:00.326
  STEP: Ensuring the job is replaced with a new one @ 04/19/24 16:44:00.337
  E0419 16:44:01.260177      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:02.260599      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:03.261240      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:04.261558      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:05.262042      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:06.262214      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:07.263065      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:08.263375      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:09.263527      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:10.264142      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:11.264378      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:12.265295      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:13.265372      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:14.265780      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:15.265995      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:16.266648      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:17.267227      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:18.267597      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:19.267941      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:20.268753      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:21.269226      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:22.269609      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:23.269836      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:24.270817      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:25.270847      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:26.271720      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:27.272638      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:28.273389      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:29.274338      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:30.274754      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:31.275619      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:32.276013      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:33.276307      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:34.276600      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:35.276829      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:36.277258      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:37.277340      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:38.278156      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:39.278475      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:40.279543      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:41.279798      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:42.280033      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:43.280540      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:44.281195      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:45.281201      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:46.281734      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:47.282121      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:48.282943      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:49.283580      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:50.284515      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:51.284844      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:52.285209      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:53.285239      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:54.285640      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:55.285989      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:56.286665      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:57.287539      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:58.287767      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:59.288139      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:00.288195      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing cronjob @ 04/19/24 16:45:00.345
  I0419 16:45:00.366982 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-8507" for this suite. @ 04/19/24 16:45:00.377
• [86.165 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for the cluster [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:50
  STEP: Creating a kubernetes client @ 04/19/24 16:45:00.397
  I0419 16:45:00.397831 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename dns @ 04/19/24 16:45:00.408
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:45:00.446
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:45:00.452
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 04/19/24 16:45:00.459
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 04/19/24 16:45:00.459
  STEP: creating a pod to probe DNS @ 04/19/24 16:45:00.459
  STEP: submitting the pod to kubernetes @ 04/19/24 16:45:00.459
  E0419 16:45:01.288542      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:02.289287      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/19/24 16:45:02.507
  STEP: looking for the results for each expected name from probers @ 04/19/24 16:45:02.515
  I0419 16:45:02.575032 14 dns_common.go:527] DNS probes using dns-634/dns-test-b5f407c9-2edb-4440-8392-4c3ed21f2712 succeeded

  STEP: deleting the pod @ 04/19/24 16:45:02.575
  I0419 16:45:02.607778 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-634" for this suite. @ 04/19/24 16:45:02.625
• [2.242 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:948
  STEP: Creating a kubernetes client @ 04/19/24 16:45:02.648
  I0419 16:45:02.648867 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename resourcequota @ 04/19/24 16:45:02.651
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:45:02.68
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:45:02.691
  STEP: Creating a ResourceQuota @ 04/19/24 16:45:02.701
  STEP: Getting a ResourceQuota @ 04/19/24 16:45:02.71
  STEP: Listing all ResourceQuotas with LabelSelector @ 04/19/24 16:45:02.715
  STEP: Patching the ResourceQuota @ 04/19/24 16:45:02.722
  STEP: Deleting a Collection of ResourceQuotas @ 04/19/24 16:45:02.733
  STEP: Verifying the deleted ResourceQuota @ 04/19/24 16:45:02.751
  I0419 16:45:02.757334 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-7929" for this suite. @ 04/19/24 16:45:02.765
• [0.125 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:897
  STEP: Creating a kubernetes client @ 04/19/24 16:45:02.775
  I0419 16:45:02.775665 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename pods @ 04/19/24 16:45:02.781
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:45:02.803
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:45:02.807
  STEP: creating a Pod with a static label @ 04/19/24 16:45:02.829
  STEP: watching for Pod to be ready @ 04/19/24 16:45:02.843
  I0419 16:45:02.850843 14 pods.go:945] observed Pod pod-test in namespace pods-7919 in phase Pending with labels: map[test-pod-static:true] & conditions []
  I0419 16:45:02.856930 14 pods.go:945] observed Pod pod-test in namespace pods-7919 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:45:02 +0000 UTC  }]
  I0419 16:45:02.877177 14 pods.go:945] observed Pod pod-test in namespace pods-7919 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:45:02 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:45:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:45:02 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:45:02 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:45:02 +0000 UTC  }]
  E0419 16:45:03.290505      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:45:03.718659 14 pods.go:948] Found Pod pod-test in namespace pods-7919 in phase Running with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:45:03 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:45:02 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:45:03 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:45:03 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:45:02 +0000 UTC  }]
  STEP: patching the Pod with a new Label and updated data @ 04/19/24 16:45:03.729
  STEP: getting the Pod and ensuring that it's patched @ 04/19/24 16:45:03.753
  STEP: replacing the Pod's status Ready condition to False @ 04/19/24 16:45:03.764
  STEP: check the Pod again to ensure its Ready conditions are False @ 04/19/24 16:45:03.811
  STEP: deleting the Pod via a Collection with a LabelSelector @ 04/19/24 16:45:03.811
  STEP: watching for the Pod to be deleted @ 04/19/24 16:45:03.831
  I0419 16:45:03.835417 14 pods.go:1058] observed event type MODIFIED
  E0419 16:45:04.291453      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:05.292231      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:45:05.783208 14 pods.go:1058] observed event type MODIFIED
  I0419 16:45:05.914884 14 pods.go:1058] observed event type MODIFIED
  E0419 16:45:06.292761      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:45:06.787301 14 pods.go:1058] observed event type MODIFIED
  I0419 16:45:06.832022 14 pods.go:1058] observed event type MODIFIED
  I0419 16:45:06.852379 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7919" for this suite. @ 04/19/24 16:45:06.864
• [4.105 seconds]
------------------------------
SSS
------------------------------
[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/security_context.go:170
  STEP: Creating a kubernetes client @ 04/19/24 16:45:06.881
  I0419 16:45:06.881237 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename security-context @ 04/19/24 16:45:06.883
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:45:06.912
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:45:06.921
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 04/19/24 16:45:06.929
  E0419 16:45:07.293310      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:08.294429      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:45:08.963
  I0419 16:45:08.970796 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod security-context-46207b43-78d8-41e8-be78-ce0422648126 container test-container: <nil>
  STEP: delete the pod @ 04/19/24 16:45:08.998
  I0419 16:45:09.038296 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-9906" for this suite. @ 04/19/24 16:45:09.049
• [2.187 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Lease lease API should be available [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lease.go:73
  STEP: Creating a kubernetes client @ 04/19/24 16:45:09.07
  I0419 16:45:09.071090 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename lease-test @ 04/19/24 16:45:09.074
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:45:09.102
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:45:09.108
  I0419 16:45:09.218247 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "lease-test-6078" for this suite. @ 04/19/24 16:45:09.226
• [0.166 seconds]
------------------------------
SS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/certificates.go:200
  STEP: Creating a kubernetes client @ 04/19/24 16:45:09.238
  I0419 16:45:09.238438 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename certificates @ 04/19/24 16:45:09.24
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:45:09.263
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:45:09.268
  E0419 16:45:09.294582      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:10.294888      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: getting /apis @ 04/19/24 16:45:10.411
  STEP: getting /apis/certificates.k8s.io @ 04/19/24 16:45:10.42
  STEP: getting /apis/certificates.k8s.io/v1 @ 04/19/24 16:45:10.423
  STEP: creating @ 04/19/24 16:45:10.426
  STEP: getting @ 04/19/24 16:45:10.469
  STEP: listing @ 04/19/24 16:45:10.479
  STEP: watching @ 04/19/24 16:45:10.491
  I0419 16:45:10.491511 14 certificates.go:316] starting watch
  STEP: patching @ 04/19/24 16:45:10.494
  STEP: updating @ 04/19/24 16:45:10.507
  I0419 16:45:10.521706 14 certificates.go:332] waiting for watch events with expected annotations
  I0419 16:45:10.521862 14 certificates.go:345] saw patched and updated annotations
  STEP: getting /approval @ 04/19/24 16:45:10.522
  STEP: patching /approval @ 04/19/24 16:45:10.529
  STEP: updating /approval @ 04/19/24 16:45:10.539
  STEP: getting /status @ 04/19/24 16:45:10.549
  STEP: patching /status @ 04/19/24 16:45:10.556
  STEP: updating /status @ 04/19/24 16:45:10.57
  STEP: deleting @ 04/19/24 16:45:10.581
  STEP: deleting a collection @ 04/19/24 16:45:10.605
  I0419 16:45:10.633738 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "certificates-2415" for this suite. @ 04/19/24 16:45:10.643
• [1.420 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:1031
  STEP: Creating a kubernetes client @ 04/19/24 16:45:10.658
  I0419 16:45:10.658858 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename statefulset @ 04/19/24 16:45:10.661
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:45:10.688
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:45:10.695
  STEP: Creating service test in namespace statefulset-7619 @ 04/19/24 16:45:10.701
  STEP: Creating statefulset ss in namespace statefulset-7619 @ 04/19/24 16:45:10.724
  I0419 16:45:10.743668 14 wait.go:40] Found 0 stateful pods, waiting for 1
  E0419 16:45:11.295870      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:12.296959      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:13.297915      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:14.298306      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:15.299194      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:16.300105      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:17.301011      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:18.301507      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:19.301943      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:20.302265      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:45:20.746421 14 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Patch Statefulset to include a label @ 04/19/24 16:45:20.768
  STEP: Getting /status @ 04/19/24 16:45:20.801
  I0419 16:45:20.811551 14 statefulset.go:1067] StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
  STEP: updating the StatefulSet Status @ 04/19/24 16:45:20.811
  I0419 16:45:20.839491 14 statefulset.go:1087] updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the statefulset status to be updated @ 04/19/24 16:45:20.839
  I0419 16:45:20.854074 14 statefulset.go:1115] Observed &StatefulSet event: ADDED
  I0419 16:45:20.854217 14 statefulset.go:1108] Found Statefulset ss in namespace statefulset-7619 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0419 16:45:20.854266 14 statefulset.go:1119] Statefulset ss has an updated status
  STEP: patching the Statefulset Status @ 04/19/24 16:45:20.854
  I0419 16:45:20.854492 14 statefulset.go:1123] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I0419 16:45:20.869443 14 statefulset.go:1127] Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Statefulset status to be patched @ 04/19/24 16:45:20.869
  I0419 16:45:20.873655 14 statefulset.go:1152] Observed &StatefulSet event: ADDED
  I0419 16:45:20.874927 14 statefulset.go:1148] Observed Statefulset ss in namespace statefulset-7619 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0419 16:45:20.877689 14 statefulset.go:1152] Observed &StatefulSet event: MODIFIED
  I0419 16:45:20.878509 14 statefulset.go:1145] Found Statefulset ss in namespace statefulset-7619 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
  I0419 16:45:20.879798 14 statefulset.go:135] Deleting all statefulset in ns statefulset-7619
  I0419 16:45:20.891458 14 rest.go:150] Scaling statefulset ss to 0
  E0419 16:45:21.302597      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:22.303733      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:23.304956      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:24.305658      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:25.306602      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:26.306968      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:27.307104      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:28.307628      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:29.308555      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:30.309199      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:45:30.920208 14 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0419 16:45:30.931949 14 rest.go:88] Deleting statefulset ss
  I0419 16:45:30.976139 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-7619" for this suite. @ 04/19/24 16:45:30.989
• [20.343 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application should create and stop a working application [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:397
  STEP: Creating a kubernetes client @ 04/19/24 16:45:31.002
  I0419 16:45:31.002763 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename kubectl @ 04/19/24 16:45:31.005
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:45:31.027
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:45:31.035
  STEP: creating all guestbook components @ 04/19/24 16:45:31.04
  I0419 16:45:31.041309 14 kubectl.go:403] apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-replica
    labels:
      app: agnhost
      role: replica
      tier: backend
  spec:
    ports:
    - port: 6379
    selector:
      app: agnhost
      role: replica
      tier: backend

  I0419 16:45:31.051645 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-4734 create -f -'
  E0419 16:45:31.310249      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:45:31.374403 14 builder.go:146] stderr: ""
  I0419 16:45:31.374484 14 builder.go:147] stdout: "service/agnhost-replica created\n"
  I0419 16:45:31.374579 14 kubectl.go:403] apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-primary
    labels:
      app: agnhost
      role: primary
      tier: backend
  spec:
    ports:
    - port: 6379
      targetPort: 6379
    selector:
      app: agnhost
      role: primary
      tier: backend

  I0419 16:45:31.374907 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-4734 create -f -'
  I0419 16:45:31.702487 14 builder.go:146] stderr: ""
  I0419 16:45:31.702569 14 builder.go:147] stdout: "service/agnhost-primary created\n"
  I0419 16:45:31.702765 14 kubectl.go:403] apiVersion: v1
  kind: Service
  metadata:
    name: frontend
    labels:
      app: guestbook
      tier: frontend
  spec:
    # if your cluster supports it, uncomment the following to automatically create
    # an external load-balanced IP for the frontend service.
    # type: LoadBalancer
    ports:
    - port: 80
    selector:
      app: guestbook
      tier: frontend

  I0419 16:45:31.703042 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-4734 create -f -'
  I0419 16:45:32.019416 14 builder.go:146] stderr: ""
  I0419 16:45:32.019493 14 builder.go:147] stdout: "service/frontend created\n"
  I0419 16:45:32.019638 14 kubectl.go:403] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: frontend
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: guestbook
        tier: frontend
    template:
      metadata:
        labels:
          app: guestbook
          tier: frontend
      spec:
        containers:
        - name: guestbook-frontend
          image: registry.k8s.io/e2e-test-images/agnhost:2.47
          args: [ "guestbook", "--backend-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 80

  I0419 16:45:32.020098 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-4734 create -f -'
  I0419 16:45:32.304170 14 builder.go:146] stderr: ""
  I0419 16:45:32.304253 14 builder.go:147] stdout: "deployment.apps/frontend created\n"
  I0419 16:45:32.304412 14 kubectl.go:403] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-primary
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: agnhost
        role: primary
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: primary
          tier: backend
      spec:
        containers:
        - name: primary
          image: registry.k8s.io/e2e-test-images/agnhost:2.47
          args: [ "guestbook", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  I0419 16:45:32.306891 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-4734 create -f -'
  E0419 16:45:32.310517      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:45:32.549715 14 builder.go:146] stderr: ""
  I0419 16:45:32.549808 14 builder.go:147] stdout: "deployment.apps/agnhost-primary created\n"
  I0419 16:45:32.549979 14 kubectl.go:403] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-replica
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: agnhost
        role: replica
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: replica
          tier: backend
      spec:
        containers:
        - name: replica
          image: registry.k8s.io/e2e-test-images/agnhost:2.47
          args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  I0419 16:45:32.550851 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-4734 create -f -'
  I0419 16:45:32.886339 14 builder.go:146] stderr: ""
  I0419 16:45:32.886434 14 builder.go:147] stdout: "deployment.apps/agnhost-replica created\n"
  STEP: validating guestbook app @ 04/19/24 16:45:32.886
  I0419 16:45:32.886525 14 kubectl.go:2271] Waiting for all frontend pods to be Running.
  E0419 16:45:33.310738      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:34.311571      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:35.311845      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:36.312906      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:37.312951      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:45:37.938288 14 kubectl.go:2275] Waiting for frontend to serve content.
  I0419 16:45:37.970835 14 kubectl.go:2280] Trying to add a new entry to the guestbook.
  I0419 16:45:38.009904 14 kubectl.go:2285] Verifying that added entry can be retrieved.
  STEP: using delete to clean up resources @ 04/19/24 16:45:38.046
  I0419 16:45:38.047286 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-4734 delete --grace-period=0 --force -f -'
  I0419 16:45:38.272217 14 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0419 16:45:38.272340 14 builder.go:147] stdout: "service \"agnhost-replica\" force deleted\n"
  STEP: using delete to clean up resources @ 04/19/24 16:45:38.272
  I0419 16:45:38.272671 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-4734 delete --grace-period=0 --force -f -'
  E0419 16:45:38.313553      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:45:38.458001 14 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0419 16:45:38.458087 14 builder.go:147] stdout: "service \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 04/19/24 16:45:38.458
  I0419 16:45:38.458514 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-4734 delete --grace-period=0 --force -f -'
  I0419 16:45:38.631172 14 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0419 16:45:38.631261 14 builder.go:147] stdout: "service \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 04/19/24 16:45:38.631
  I0419 16:45:38.631750 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-4734 delete --grace-period=0 --force -f -'
  I0419 16:45:38.776726 14 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0419 16:45:38.776807 14 builder.go:147] stdout: "deployment.apps \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 04/19/24 16:45:38.777
  I0419 16:45:38.777320 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-4734 delete --grace-period=0 --force -f -'
  I0419 16:45:38.988031 14 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0419 16:45:38.988122 14 builder.go:147] stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 04/19/24 16:45:38.988
  I0419 16:45:38.989635 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-4734 delete --grace-period=0 --force -f -'
  I0419 16:45:39.261921 14 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0419 16:45:39.262016 14 builder.go:147] stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
  I0419 16:45:39.262192 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4734" for this suite. @ 04/19/24 16:45:39.271
• [8.292 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:113
  STEP: Creating a kubernetes client @ 04/19/24 16:45:39.296
  I0419 16:45:39.296415 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename deployment @ 04/19/24 16:45:39.312
  E0419 16:45:39.314341      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:45:39.349
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:45:39.353
  I0419 16:45:39.362959 14 deployment.go:792] Creating deployment "test-recreate-deployment"
  I0419 16:45:39.371793 14 deployment.go:798] Waiting deployment "test-recreate-deployment" to be updated to revision 1
  I0419 16:45:39.435478 14 deployment.go:802] Waiting deployment "test-recreate-deployment" to complete
  I0419 16:45:39.450069 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 45, 39, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 45, 39, 0, time.Local), Reason:"NewReplicaSetCreated", Message:"Created new replica set \"test-recreate-deployment-6b6d9cd7b6\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 16, 45, 39, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 45, 39, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
  E0419 16:45:40.314931      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:41.315439      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:45:41.461565 14 deployment.go:807] Triggering a new rollout for deployment "test-recreate-deployment"
  I0419 16:45:41.486458 14 deployment.go:313] Updating deployment test-recreate-deployment
  I0419 16:45:41.486843 14 deployment.go:814] Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
  I0419 16:45:41.673310 14 deployment.go:633] Deployment "test-recreate-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-recreate-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5395",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ac6ec766-d21a-4aaf-9943-e8c2f9e28360",
      ResourceVersion: (string) (len=5) "22121",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849141939,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849141941,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=570) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |":{"f:type":{}},|
              000000b0  22 66 3a 74 65 6d 70 6c  61 74 65 22 3a 7b 22 66  |"f:template":{"f|
              000000c0  3a 6d 65 74 61 64 61 74  61 22 3a 7b 22 66 3a 6c  |:metadata":{"f:l|
              000000d0  61 62 65 6c 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |abels":{".":{},"|
              000000e0  66 3a 6e 61 6d 65 22 3a  7b 7d 7d 7d 2c 22 66 3a  |f:name":{}}},"f:|
              000000f0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              00000100  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              00000110  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              00000120  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000130  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000140  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000150  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000160  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000170  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000180  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000190  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              000001a0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000001b0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000001c0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000001d0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000001e0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000001f0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              00000200  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000210  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000220  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000230  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849141941,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=495) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 63 6f 6e 64 69 74 69  6f 6e 73 22 3a 7b 22 2e  |:conditions":{".|
              00000070  22 3a 7b 7d 2c 22 6b 3a  7b 5c 22 74 79 70 65 5c  |":{},"k:{\"type\|
              00000080  22 3a 5c 22 41 76 61 69  6c 61 62 6c 65 5c 22 7d  |":\"Available\"}|
              00000090  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              000000a0  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              000000b0  3a 7b 7d 2c 22 66 3a 6c  61 73 74 55 70 64 61 74  |:{},"f:lastUpdat|
              000000c0  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6d 65 73  |eTime":{},"f:mes|
              000000d0  73 61 67 65 22 3a 7b 7d  2c 22 66 3a 72 65 61 73  |sage":{},"f:reas|
              000000e0  6f 6e 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |on":{},"f:status|
              000000f0  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000100  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000110  22 50 72 6f 67 72 65 73  73 69 6e 67 5c 22 7d 22  |"Progressing\"}"|
              00000120  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000130  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000140  7b 7d 2c 22 66 3a 6c 61  73 74 55 70 64 61 74 65  |{},"f:lastUpdate|
              00000150  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000160  61 67 65 22 3a 7b 7d 2c  22 66 3a 72 65 61 73 6f  |age":{},"f:reaso|
              00000170  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000180  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000190  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              000001a0  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              000001b0  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 75  |eplicas":{},"f:u|
              000001c0  6e 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |navailableReplic|
              000001d0  61 73 22 3a 7b 7d 2c 22  66 3a 75 70 64 61 74 65  |as":{},"f:update|
              000001e0  64 52 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 7d     |dReplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=8) "Recreate",
        RollingUpdate: (*v1.RollingUpdateDeployment)(<nil>)
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 1,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849141941,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849141941,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849141941,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849141939,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=64) "ReplicaSet \"test-recreate-deployment-66b65d9f8f\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0419 16:45:41.694391 14 deployment.go:39] New ReplicaSet "test-recreate-deployment-66b65d9f8f" of Deployment "test-recreate-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-recreate-deployment-66b65d9f8f",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5395",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "074ce265-fe7d-4970-b3ba-0909b61aeff5",
      ResourceVersion: (string) (len=5) "22118",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849141941,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=10) "66b65d9f8f"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "ac6ec766-d21a-4aaf-9943-e8c2f9e28360",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849141941,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 61 63 36 65 63 37  36 36 2d 64 32 31 61 2d  |\"ac6ec766-d21a-|
              00000120  34 61 61 66 2d 39 39 34  33 2d 65 38 63 32 66 39  |4aaf-9943-e8c2f9|
              00000130  65 32 38 33 36 30 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |e28360\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849141941,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=10) "66b65d9f8f"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=10) "66b65d9f8f"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0419 16:45:41.696733 14 deployment.go:44] All old ReplicaSets of Deployment "test-recreate-deployment":
  I0419 16:45:41.697447 14 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-recreate-deployment-6b6d9cd7b6",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5395",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "08ac03c0-17d2-4f3a-99f1-1792d29e989b",
      ResourceVersion: (string) (len=5) "22109",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849141939,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6b6d9cd7b6"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "ac6ec766-d21a-4aaf-9943-e8c2f9e28360",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849141941,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 61 63 36 65 63 37  36 36 2d 64 32 31 61 2d  |\"ac6ec766-d21a-|
              00000120  34 61 61 66 2d 39 39 34  33 2d 65 38 63 32 66 39  |4aaf-9943-e8c2f9|
              00000130  65 32 38 33 36 30 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |e28360\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849141941,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=10) "6b6d9cd7b6"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=10) "6b6d9cd7b6"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0419 16:45:41.706714 14 deployment.go:67] Pod "test-recreate-deployment-66b65d9f8f-5q2v6" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-recreate-deployment-66b65d9f8f-5q2v6",
      GenerateName: (string) (len=36) "test-recreate-deployment-66b65d9f8f-",
      Namespace: (string) (len=15) "deployment-5395",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "95da39a2-b817-4ea8-8e28-ab85808578e3",
      ResourceVersion: (string) (len=5) "22120",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849141941,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=10) "66b65d9f8f"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=35) "test-recreate-deployment-66b65d9f8f",
          UID: (types.UID) (len=36) "074ce265-fe7d-4970-b3ba-0909b61aeff5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849141941,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 30 37  34 63 65 32 36 35 2d 66  |d\":\"074ce265-f|
              00000090  65 37 64 2d 34 39 37 30  2d 62 33 62 61 2d 30 39  |e7d-4970-b3ba-09|
              000000a0  30 39 62 36 31 61 65 66  66 35 5c 22 7d 22 3a 7b  |09b61aeff5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849141941,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-ndn6c",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-ndn6c",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "eipo9quoh3ef-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849141941,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849141941,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849141941,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849141941,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849141941,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.127",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.127"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849141941,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0419 16:45:41.714305 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-5395" for this suite. @ 04/19/24 16:45:41.722
• [2.436 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:116
  STEP: Creating a kubernetes client @ 04/19/24 16:45:41.733
  I0419 16:45:41.733335 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename var-expansion @ 04/19/24 16:45:41.736
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:45:41.766
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:45:41.771
  STEP: Creating a pod to test substitution in volume subpath @ 04/19/24 16:45:41.777
  E0419 16:45:42.316365      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:43.317178      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:44.317120      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:45.317530      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:45:45.824
  I0419 16:45:45.833828 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod var-expansion-1c6ad726-aa9a-465c-9029-1ae0b3e64443 container dapi-container: <nil>
  STEP: delete the pod @ 04/19/24 16:45:45.861
  I0419 16:45:45.889774 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-7111" for this suite. @ 04/19/24 16:45:45.901
• [4.186 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:55
  STEP: Creating a kubernetes client @ 04/19/24 16:45:45.92
  I0419 16:45:45.920694 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename projected @ 04/19/24 16:45:45.925
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:45:45.957
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:45:45.962
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 16:45:45.97
  E0419 16:45:46.318801      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:47.319806      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:48.319637      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:49.320631      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:45:50.021
  I0419 16:45:50.030927 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod downwardapi-volume-d8fe54fe-12c6-4b8d-9f9b-010244932ecf container client-container: <nil>
  STEP: delete the pod @ 04/19/24 16:45:50.049
  I0419 16:45:50.087470 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6284" for this suite. @ 04/19/24 16:45:50.099
• [4.197 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:87
  STEP: Creating a kubernetes client @ 04/19/24 16:45:50.128
  I0419 16:45:50.128594 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename disruption @ 04/19/24 16:45:50.134
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:45:50.182
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:45:50.189
  STEP: Creating a kubernetes client @ 04/19/24 16:45:50.197
  I0419 16:45:50.197163 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename disruption-2 @ 04/19/24 16:45:50.2
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:45:50.226
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:45:50.231
  STEP: Waiting for the pdb to be processed @ 04/19/24 16:45:50.248
  E0419 16:45:50.320925      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:51.321361      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 04/19/24 16:45:52.269
  E0419 16:45:52.322314      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:53.323323      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 04/19/24 16:45:54.295
  STEP: listing a collection of PDBs across all namespaces @ 04/19/24 16:45:54.308
  STEP: listing a collection of PDBs in namespace disruption-4922 @ 04/19/24 16:45:54.318
  E0419 16:45:54.324366      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting a collection of PDBs @ 04/19/24 16:45:54.331
  STEP: Waiting for the PDB collection to be deleted @ 04/19/24 16:45:54.367
  I0419 16:45:54.375929 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2-9919" for this suite. @ 04/19/24 16:45:54.389
  I0419 16:45:54.405183 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-4922" for this suite. @ 04/19/24 16:45:54.417
• [4.303 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:160
  STEP: Creating a kubernetes client @ 04/19/24 16:45:54.433
  I0419 16:45:54.433573 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename emptydir @ 04/19/24 16:45:54.438
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:45:54.477
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:45:54.485
  STEP: Creating a pod to test emptydir volume type on node default medium @ 04/19/24 16:45:54.496
  E0419 16:45:55.324778      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:56.325613      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:57.326415      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:58.327148      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:45:58.547
  I0419 16:45:58.558185 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-7d0c3975-c3ad-4515-b383-c91dbfc00d58 container test-container: <nil>
  STEP: delete the pod @ 04/19/24 16:45:58.58
  I0419 16:45:58.626063 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9525" for this suite. @ 04/19/24 16:45:58.646
• [4.234 seconds]
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:59
  STEP: Creating a kubernetes client @ 04/19/24 16:45:58.67
  I0419 16:45:58.671553 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename subpath @ 04/19/24 16:45:58.676
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:45:58.712
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:45:58.721
  STEP: Setting up data @ 04/19/24 16:45:58.728
  STEP: Creating pod pod-subpath-test-secret-sb8s @ 04/19/24 16:45:58.754
  STEP: Creating a pod to test atomic-volume-subpath @ 04/19/24 16:45:58.755
  E0419 16:45:59.327595      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:00.327930      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:01.328427      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:02.329645      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:03.329807      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:04.330715      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:05.331292      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:06.331334      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:07.332378      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:08.333108      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:09.333719      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:10.340213      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:11.335947      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:12.336125      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:13.336636      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:14.337446      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:15.338461      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:16.338626      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:17.338793      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:18.339947      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:19.340350      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:20.340413      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:21.341448      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:22.343118      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:46:22.956
  I0419 16:46:22.967728 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-subpath-test-secret-sb8s container test-container-subpath-secret-sb8s: <nil>
  STEP: delete the pod @ 04/19/24 16:46:22.993
  STEP: Deleting pod pod-subpath-test-secret-sb8s @ 04/19/24 16:46:23.031
  I0419 16:46:23.031586 14 delete.go:62] Deleting pod "pod-subpath-test-secret-sb8s" in namespace "subpath-1358"
  I0419 16:46:23.039116 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-1358" for this suite. @ 04/19/24 16:46:23.05
• [24.399 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2240
  STEP: Creating a kubernetes client @ 04/19/24 16:46:23.073
  I0419 16:46:23.073917 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename services @ 04/19/24 16:46:23.078
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:46:23.126
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:46:23.132
  STEP: creating service in namespace services-4801 @ 04/19/24 16:46:23.137
  STEP: creating service affinity-nodeport-transition in namespace services-4801 @ 04/19/24 16:46:23.137
  STEP: creating replication controller affinity-nodeport-transition in namespace services-4801 @ 04/19/24 16:46:23.165
  I0419 16:46:23.180645      14 runners.go:198] Created replication controller with name: affinity-nodeport-transition, namespace: services-4801, replica count: 3
  E0419 16:46:23.342528      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:24.347770      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:25.343737      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:46:26.236046      14 runners.go:198] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0419 16:46:26.274082 14 resource.go:361] Creating new exec pod
  E0419 16:46:26.344104      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:27.344457      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:28.345078      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:46:29.328324 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-4801 exec execpod-affinitydblmd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
  E0419 16:46:29.345986      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:46:29.741549 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
  I0419 16:46:29.741848 14 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0419 16:46:29.742256 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-4801 exec execpod-affinitydblmd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.26.210 80'
  I0419 16:46:30.029116 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.26.210 80\nConnection to 10.233.26.210 80 port [tcp/http] succeeded!\n"
  I0419 16:46:30.029216 14 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0419 16:46:30.030982 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-4801 exec execpod-affinitydblmd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.127 32461'
  I0419 16:46:30.294948 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.127 32461\nConnection to 192.168.121.127 32461 port [tcp/*] succeeded!\n"
  I0419 16:46:30.295082 14 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0419 16:46:30.295606 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-4801 exec execpod-affinitydblmd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.197 32461'
  E0419 16:46:30.346206      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:46:30.571696 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.197 32461\nConnection to 192.168.121.197 32461 port [tcp/*] succeeded!\n"
  I0419 16:46:30.571786 14 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0419 16:46:30.598291 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-4801 exec execpod-affinitydblmd -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.38:32461/ ; done'
  I0419 16:46:31.119473 14 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:32461/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:32461/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:32461/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:32461/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:32461/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:32461/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:32461/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:32461/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:32461/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:32461/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:32461/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:32461/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:32461/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:32461/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:32461/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:32461/\n"
  I0419 16:46:31.119617 14 builder.go:147] stdout: "\naffinity-nodeport-transition-pb8lf\naffinity-nodeport-transition-jkdcx\naffinity-nodeport-transition-452bx\naffinity-nodeport-transition-452bx\naffinity-nodeport-transition-452bx\naffinity-nodeport-transition-pb8lf\naffinity-nodeport-transition-jkdcx\naffinity-nodeport-transition-452bx\naffinity-nodeport-transition-jkdcx\naffinity-nodeport-transition-pb8lf\naffinity-nodeport-transition-jkdcx\naffinity-nodeport-transition-jkdcx\naffinity-nodeport-transition-jkdcx\naffinity-nodeport-transition-452bx\naffinity-nodeport-transition-pb8lf\naffinity-nodeport-transition-452bx"
  I0419 16:46:31.119677 14 service.go:242] Received response from host: affinity-nodeport-transition-pb8lf
  I0419 16:46:31.119700 14 service.go:242] Received response from host: affinity-nodeport-transition-jkdcx
  I0419 16:46:31.119742 14 service.go:242] Received response from host: affinity-nodeport-transition-452bx
  I0419 16:46:31.119759 14 service.go:242] Received response from host: affinity-nodeport-transition-452bx
  I0419 16:46:31.119776 14 service.go:242] Received response from host: affinity-nodeport-transition-452bx
  I0419 16:46:31.119793 14 service.go:242] Received response from host: affinity-nodeport-transition-pb8lf
  I0419 16:46:31.119809 14 service.go:242] Received response from host: affinity-nodeport-transition-jkdcx
  I0419 16:46:31.119826 14 service.go:242] Received response from host: affinity-nodeport-transition-452bx
  I0419 16:46:31.119870 14 service.go:242] Received response from host: affinity-nodeport-transition-jkdcx
  I0419 16:46:31.119887 14 service.go:242] Received response from host: affinity-nodeport-transition-pb8lf
  I0419 16:46:31.119903 14 service.go:242] Received response from host: affinity-nodeport-transition-jkdcx
  I0419 16:46:31.119919 14 service.go:242] Received response from host: affinity-nodeport-transition-jkdcx
  I0419 16:46:31.119935 14 service.go:242] Received response from host: affinity-nodeport-transition-jkdcx
  I0419 16:46:31.119951 14 service.go:242] Received response from host: affinity-nodeport-transition-452bx
  I0419 16:46:31.119975 14 service.go:242] Received response from host: affinity-nodeport-transition-pb8lf
  I0419 16:46:31.119993 14 service.go:242] Received response from host: affinity-nodeport-transition-452bx
  I0419 16:46:31.154577 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-4801 exec execpod-affinitydblmd -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.38:32461/ ; done'
  E0419 16:46:31.346883      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:46:31.615077 14 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:32461/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:32461/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:32461/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:32461/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:32461/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:32461/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:32461/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:32461/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:32461/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:32461/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:32461/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:32461/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:32461/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:32461/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:32461/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.38:32461/\n"
  I0419 16:46:31.615221 14 builder.go:147] stdout: "\naffinity-nodeport-transition-jkdcx\naffinity-nodeport-transition-jkdcx\naffinity-nodeport-transition-jkdcx\naffinity-nodeport-transition-jkdcx\naffinity-nodeport-transition-jkdcx\naffinity-nodeport-transition-jkdcx\naffinity-nodeport-transition-jkdcx\naffinity-nodeport-transition-jkdcx\naffinity-nodeport-transition-jkdcx\naffinity-nodeport-transition-jkdcx\naffinity-nodeport-transition-jkdcx\naffinity-nodeport-transition-jkdcx\naffinity-nodeport-transition-jkdcx\naffinity-nodeport-transition-jkdcx\naffinity-nodeport-transition-jkdcx\naffinity-nodeport-transition-jkdcx"
  I0419 16:46:31.615282 14 service.go:242] Received response from host: affinity-nodeport-transition-jkdcx
  I0419 16:46:31.615304 14 service.go:242] Received response from host: affinity-nodeport-transition-jkdcx
  I0419 16:46:31.615321 14 service.go:242] Received response from host: affinity-nodeport-transition-jkdcx
  I0419 16:46:31.615337 14 service.go:242] Received response from host: affinity-nodeport-transition-jkdcx
  I0419 16:46:31.615355 14 service.go:242] Received response from host: affinity-nodeport-transition-jkdcx
  I0419 16:46:31.615370 14 service.go:242] Received response from host: affinity-nodeport-transition-jkdcx
  I0419 16:46:31.615386 14 service.go:242] Received response from host: affinity-nodeport-transition-jkdcx
  I0419 16:46:31.615401 14 service.go:242] Received response from host: affinity-nodeport-transition-jkdcx
  I0419 16:46:31.615430 14 service.go:242] Received response from host: affinity-nodeport-transition-jkdcx
  I0419 16:46:31.615445 14 service.go:242] Received response from host: affinity-nodeport-transition-jkdcx
  I0419 16:46:31.615461 14 service.go:242] Received response from host: affinity-nodeport-transition-jkdcx
  I0419 16:46:31.615477 14 service.go:242] Received response from host: affinity-nodeport-transition-jkdcx
  I0419 16:46:31.615492 14 service.go:242] Received response from host: affinity-nodeport-transition-jkdcx
  I0419 16:46:31.615508 14 service.go:242] Received response from host: affinity-nodeport-transition-jkdcx
  I0419 16:46:31.615524 14 service.go:242] Received response from host: affinity-nodeport-transition-jkdcx
  I0419 16:46:31.615540 14 service.go:242] Received response from host: affinity-nodeport-transition-jkdcx
  I0419 16:46:31.615704 14 service.go:4014] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-4801, will wait for the garbage collector to delete the pods @ 04/19/24 16:46:31.639
  I0419 16:46:31.719283 14 resources.go:139] Deleting ReplicationController affinity-nodeport-transition took: 15.280686ms
  I0419 16:46:31.820193 14 resources.go:163] Terminating ReplicationController affinity-nodeport-transition pods took: 100.903432ms
  E0419 16:46:32.348223      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:33.348620      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:34.349747      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:46:35.168456 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4801" for this suite. @ 04/19/24 16:46:35.175
• [12.112 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1537
  STEP: Creating a kubernetes client @ 04/19/24 16:46:35.186
  I0419 16:46:35.186807 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename services @ 04/19/24 16:46:35.189
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:46:35.221
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:46:35.226
  STEP: creating a service nodeport-service with the type=NodePort in namespace services-3919 @ 04/19/24 16:46:35.232
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 04/19/24 16:46:35.257
  STEP: creating service externalsvc in namespace services-3919 @ 04/19/24 16:46:35.257
  STEP: creating replication controller externalsvc in namespace services-3919 @ 04/19/24 16:46:35.278
  I0419 16:46:35.291343      14 runners.go:198] Created replication controller with name: externalsvc, namespace: services-3919, replica count: 2
  E0419 16:46:35.350494      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:36.351050      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:37.351289      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:46:38.345289      14 runners.go:198] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E0419 16:46:38.351546      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: changing the NodePort service to type=ExternalName @ 04/19/24 16:46:38.356
  I0419 16:46:38.421823 14 resource.go:361] Creating new exec pod
  E0419 16:46:39.352787      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:40.352992      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:46:40.466004 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-3919 exec execpod72f49 -- /bin/sh -x -c nslookup nodeport-service.services-3919.svc.cluster.local'
  I0419 16:46:40.914117 14 builder.go:146] stderr: "+ nslookup nodeport-service.services-3919.svc.cluster.local\n"
  I0419 16:46:40.915299 14 builder.go:147] stdout: "Server:\t\t10.233.0.10\nAddress:\t10.233.0.10#53\n\nnodeport-service.services-3919.svc.cluster.local\tcanonical name = externalsvc.services-3919.svc.cluster.local.\nName:\texternalsvc.services-3919.svc.cluster.local\nAddress: 10.233.45.150\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-3919, will wait for the garbage collector to delete the pods @ 04/19/24 16:46:40.928
  I0419 16:46:41.003554 14 resources.go:139] Deleting ReplicationController externalsvc took: 12.414793ms
  I0419 16:46:41.104821 14 resources.go:163] Terminating ReplicationController externalsvc pods took: 101.25968ms
  E0419 16:46:41.354004      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:42.354602      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:43.355521      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:46:43.857591 14 service.go:1548] Cleaning up the NodePort to ExternalName test service
  I0419 16:46:43.908618 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3919" for this suite. @ 04/19/24 16:46:43.923
• [8.749 seconds]
------------------------------
[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/security_context.go:135
  STEP: Creating a kubernetes client @ 04/19/24 16:46:43.937
  I0419 16:46:43.937927 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename security-context @ 04/19/24 16:46:43.94
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:46:43.968
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:46:43.973
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 04/19/24 16:46:43.979
  E0419 16:46:44.355200      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:45.355998      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:46.356208      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:47.357105      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:46:48.03
  I0419 16:46:48.040603 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod security-context-0f3b6804-5628-4dfd-b70d-7a32eb2174df container test-container: <nil>
  STEP: delete the pod @ 04/19/24 16:46:48.064
  I0419 16:46:48.113448 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-1616" for this suite. @ 04/19/24 16:46:48.128
• [4.217 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:46
  STEP: Creating a kubernetes client @ 04/19/24 16:46:48.158
  I0419 16:46:48.158442 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename projected @ 04/19/24 16:46:48.165
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:46:48.193
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:46:48.2
  STEP: Creating projection with secret that has name projected-secret-test-b24bea1d-a976-478e-91b5-f3e940bbeb85 @ 04/19/24 16:46:48.21
  STEP: Creating a pod to test consume secrets @ 04/19/24 16:46:48.223
  E0419 16:46:48.357916      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:49.358905      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:50.359432      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:51.359765      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:46:52.281
  I0419 16:46:52.294167 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-projected-secrets-ee12366f-ddaf-4863-bbdf-c5cec05a4219 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/24 16:46:52.307
  I0419 16:46:52.338338 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1078" for this suite. @ 04/19/24 16:46:52.347
  E0419 16:46:52.360132      14 retrywatcher.go:129] "Watch failed" err="context canceled"
• [4.206 seconds]
------------------------------
SSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:489
  STEP: Creating a kubernetes client @ 04/19/24 16:46:52.365
  I0419 16:46:52.365473 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename security-context-test @ 04/19/24 16:46:52.369
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:46:52.399
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:46:52.404
  E0419 16:46:53.361058      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:54.361340      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:55.361990      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:56.362796      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:46:56.458228 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-2120" for this suite. @ 04/19/24 16:46:56.474
• [4.129 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:101
  STEP: Creating a kubernetes client @ 04/19/24 16:46:56.497
  I0419 16:46:56.497798 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename proxy @ 04/19/24 16:46:56.502
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:46:56.539
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:46:56.544
  STEP: starting an echo server on multiple ports @ 04/19/24 16:46:56.578
  STEP: creating replication controller proxy-service-476cl in namespace proxy-3547 @ 04/19/24 16:46:56.578
  I0419 16:46:56.596033      14 runners.go:198] Created replication controller with name: proxy-service-476cl, namespace: proxy-3547, replica count: 1
  E0419 16:46:57.363205      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:46:57.650069      14 runners.go:198] proxy-service-476cl Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
  E0419 16:46:58.363659      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:46:58.651059      14 runners.go:198] proxy-service-476cl Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0419 16:46:58.674569 14 proxy.go:230] setup took 2.124466455s, starting test cases
  STEP: running 16 cases, 20 attempts per case, 320 total attempts @ 04/19/24 16:46:58.675
  I0419 16:46:58.703266 14 proxy.go:558] (0) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:160/proxy/: foo (200; 25.33845ms)
  I0419 16:46:58.706669 14 proxy.go:558] (0) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:162/proxy/: bar (200; 25.876638ms)
  I0419 16:46:58.707236 14 proxy.go:558] (0) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname1/proxy/: foo (200; 30.182818ms)
  I0419 16:46:58.707229 14 proxy.go:558] (0) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:160/proxy/: foo (200; 29.471713ms)
  I0419 16:46:58.722121 14 proxy.go:558] (0) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/rewriteme">test</a> (200; 41.888498ms)
  I0419 16:46:58.723222 14 proxy.go:558] (0) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname2/proxy/: bar (200; 44.756033ms)
  I0419 16:46:58.723402 14 proxy.go:558] (0) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:162/proxy/: bar (200; 40.397075ms)
  I0419 16:46:58.723519 14 proxy.go:558] (0) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/rewriteme">... (200; 40.789022ms)
  I0419 16:46:58.723625 14 proxy.go:558] (0) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/rewriteme">test<... (200; 46.053735ms)
  I0419 16:46:58.741425 14 proxy.go:558] (0) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname2/proxy/: bar (200; 63.150308ms)
  I0419 16:46:58.745737 14 proxy.go:558] (0) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname1/proxy/: foo (200; 62.873557ms)
  I0419 16:46:58.749465 14 proxy.go:558] (0) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname2/proxy/: tls qux (200; 72.84542ms)
  I0419 16:46:58.750011 14 proxy.go:558] (0) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname1/proxy/: tls baz (200; 70.71978ms)
  I0419 16:46:58.750255 14 proxy.go:558] (0) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:462/proxy/: tls qux (200; 67.66687ms)
  I0419 16:46:58.750512 14 proxy.go:558] (0) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/tlsrewritem... (200; 72.378077ms)
  I0419 16:46:58.750802 14 proxy.go:558] (0) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:460/proxy/: tls baz (200; 69.827462ms)
  I0419 16:46:58.764042 14 proxy.go:558] (1) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:162/proxy/: bar (200; 11.649395ms)
  I0419 16:46:58.764400 14 proxy.go:558] (1) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/tlsrewritem... (200; 13.35204ms)
  I0419 16:46:58.771439 14 proxy.go:558] (1) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname1/proxy/: foo (200; 20.131647ms)
  I0419 16:46:58.771847 14 proxy.go:558] (1) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/rewriteme">test</a> (200; 19.904415ms)
  I0419 16:46:58.772371 14 proxy.go:558] (1) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/rewriteme">test<... (200; 20.40673ms)
  I0419 16:46:58.773003 14 proxy.go:558] (1) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/rewriteme">... (200; 20.778798ms)
  I0419 16:46:58.773301 14 proxy.go:558] (1) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname2/proxy/: bar (200; 21.807205ms)
  I0419 16:46:58.773555 14 proxy.go:558] (1) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:160/proxy/: foo (200; 21.060451ms)
  I0419 16:46:58.773804 14 proxy.go:558] (1) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:162/proxy/: bar (200; 22.098022ms)
  I0419 16:46:58.774087 14 proxy.go:558] (1) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:160/proxy/: foo (200; 22.030763ms)
  I0419 16:46:58.774470 14 proxy.go:558] (1) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:460/proxy/: tls baz (200; 22.680074ms)
  I0419 16:46:58.776676 14 proxy.go:558] (1) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:462/proxy/: tls qux (200; 24.405666ms)
  I0419 16:46:58.776732 14 proxy.go:558] (1) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname2/proxy/: tls qux (200; 24.283113ms)
  I0419 16:46:58.777188 14 proxy.go:558] (1) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname2/proxy/: bar (200; 25.33396ms)
  I0419 16:46:58.779444 14 proxy.go:558] (1) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname1/proxy/: foo (200; 27.119038ms)
  I0419 16:46:58.779822 14 proxy.go:558] (1) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname1/proxy/: tls baz (200; 27.682575ms)
  I0419 16:46:58.789441 14 proxy.go:558] (2) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:162/proxy/: bar (200; 9.247575ms)
  I0419 16:46:58.795067 14 proxy.go:558] (2) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:162/proxy/: bar (200; 13.886099ms)
  I0419 16:46:58.799162 14 proxy.go:558] (2) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname1/proxy/: foo (200; 18.651505ms)
  I0419 16:46:58.801725 14 proxy.go:558] (2) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/rewriteme">... (200; 20.048852ms)
  I0419 16:46:58.802437 14 proxy.go:558] (2) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/tlsrewritem... (200; 20.802354ms)
  I0419 16:46:58.803460 14 proxy.go:558] (2) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:462/proxy/: tls qux (200; 21.628537ms)
  I0419 16:46:58.803916 14 proxy.go:558] (2) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname2/proxy/: bar (200; 22.609777ms)
  I0419 16:46:58.804641 14 proxy.go:558] (2) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname2/proxy/: bar (200; 23.936634ms)
  I0419 16:46:58.804942 14 proxy.go:558] (2) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:460/proxy/: tls baz (200; 24.0218ms)
  I0419 16:46:58.808452 14 proxy.go:558] (2) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/rewriteme">test</a> (200; 26.988314ms)
  I0419 16:46:58.809683 14 proxy.go:558] (2) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:160/proxy/: foo (200; 28.164552ms)
  I0419 16:46:58.809907 14 proxy.go:558] (2) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:160/proxy/: foo (200; 28.328094ms)
  I0419 16:46:58.810848 14 proxy.go:558] (2) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname1/proxy/: tls baz (200; 29.066976ms)
  I0419 16:46:58.810905 14 proxy.go:558] (2) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/rewriteme">test<... (200; 29.165778ms)
  I0419 16:46:58.811018 14 proxy.go:558] (2) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname1/proxy/: foo (200; 29.127272ms)
  I0419 16:46:58.811568 14 proxy.go:558] (2) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname2/proxy/: tls qux (200; 30.177652ms)
  I0419 16:46:58.825753 14 proxy.go:558] (3) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/tlsrewritem... (200; 13.961202ms)
  I0419 16:46:58.831448 14 proxy.go:558] (3) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:160/proxy/: foo (200; 18.832919ms)
  I0419 16:46:58.832091 14 proxy.go:558] (3) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:160/proxy/: foo (200; 19.494211ms)
  I0419 16:46:58.834805 14 proxy.go:558] (3) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/rewriteme">test<... (200; 22.244248ms)
  I0419 16:46:58.834835 14 proxy.go:558] (3) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname1/proxy/: foo (200; 22.897727ms)
  I0419 16:46:58.837677 14 proxy.go:558] (3) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/rewriteme">... (200; 24.902683ms)
  I0419 16:46:58.838070 14 proxy.go:558] (3) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:162/proxy/: bar (200; 25.816615ms)
  I0419 16:46:58.838074 14 proxy.go:558] (3) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname2/proxy/: bar (200; 25.977492ms)
  I0419 16:46:58.838151 14 proxy.go:558] (3) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:460/proxy/: tls baz (200; 25.752749ms)
  I0419 16:46:58.838181 14 proxy.go:558] (3) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/rewriteme">test</a> (200; 25.972529ms)
  I0419 16:46:58.838217 14 proxy.go:558] (3) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:462/proxy/: tls qux (200; 25.550493ms)
  I0419 16:46:58.838664 14 proxy.go:558] (3) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:162/proxy/: bar (200; 25.836216ms)
  I0419 16:46:58.838699 14 proxy.go:558] (3) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname1/proxy/: foo (200; 25.781552ms)
  I0419 16:46:58.838722 14 proxy.go:558] (3) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname1/proxy/: tls baz (200; 26.000995ms)
  I0419 16:46:58.839649 14 proxy.go:558] (3) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname2/proxy/: bar (200; 27.181908ms)
  I0419 16:46:58.840293 14 proxy.go:558] (3) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname2/proxy/: tls qux (200; 27.313745ms)
  I0419 16:46:58.856943 14 proxy.go:558] (4) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/rewriteme">test<... (200; 14.293503ms)
  I0419 16:46:58.858225 14 proxy.go:558] (4) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:460/proxy/: tls baz (200; 15.537884ms)
  I0419 16:46:58.860232 14 proxy.go:558] (4) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/tlsrewritem... (200; 17.233125ms)
  I0419 16:46:58.860502 14 proxy.go:558] (4) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname2/proxy/: bar (200; 19.562339ms)
  I0419 16:46:58.860567 14 proxy.go:558] (4) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/rewriteme">test</a> (200; 18.82469ms)
  I0419 16:46:58.860614 14 proxy.go:558] (4) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:160/proxy/: foo (200; 17.774903ms)
  I0419 16:46:58.864393 14 proxy.go:558] (4) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/rewriteme">... (200; 22.153276ms)
  I0419 16:46:58.866309 14 proxy.go:558] (4) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:162/proxy/: bar (200; 24.218155ms)
  I0419 16:46:58.866433 14 proxy.go:558] (4) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname2/proxy/: bar (200; 25.88958ms)
  I0419 16:46:58.866462 14 proxy.go:558] (4) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:462/proxy/: tls qux (200; 24.149664ms)
  I0419 16:46:58.866493 14 proxy.go:558] (4) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname1/proxy/: foo (200; 24.12683ms)
  I0419 16:46:58.866519 14 proxy.go:558] (4) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname1/proxy/: foo (200; 23.927932ms)
  I0419 16:46:58.866599 14 proxy.go:558] (4) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:162/proxy/: bar (200; 24.088271ms)
  I0419 16:46:58.866629 14 proxy.go:558] (4) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname1/proxy/: tls baz (200; 24.633283ms)
  I0419 16:46:58.867007 14 proxy.go:558] (4) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:160/proxy/: foo (200; 24.098768ms)
  I0419 16:46:58.867041 14 proxy.go:558] (4) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname2/proxy/: tls qux (200; 24.250861ms)
  I0419 16:46:58.883014 14 proxy.go:558] (5) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:162/proxy/: bar (200; 13.569887ms)
  I0419 16:46:58.885322 14 proxy.go:558] (5) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:160/proxy/: foo (200; 15.242677ms)
  I0419 16:46:58.885782 14 proxy.go:558] (5) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:162/proxy/: bar (200; 16.280133ms)
  I0419 16:46:58.888522 14 proxy.go:558] (5) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:160/proxy/: foo (200; 18.57048ms)
  I0419 16:46:58.888597 14 proxy.go:558] (5) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/rewriteme">test<... (200; 18.696083ms)
  I0419 16:46:58.889861 14 proxy.go:558] (5) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/rewriteme">test</a> (200; 20.159169ms)
  I0419 16:46:58.890817 14 proxy.go:558] (5) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname2/proxy/: bar (200; 20.973993ms)
  I0419 16:46:58.891316 14 proxy.go:558] (5) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/rewriteme">... (200; 21.183454ms)
  I0419 16:46:58.891959 14 proxy.go:558] (5) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:462/proxy/: tls qux (200; 21.503605ms)
  I0419 16:46:58.892111 14 proxy.go:558] (5) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname2/proxy/: tls qux (200; 22.4874ms)
  I0419 16:46:58.894460 14 proxy.go:558] (5) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname1/proxy/: foo (200; 24.267357ms)
  I0419 16:46:58.897165 14 proxy.go:558] (5) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:460/proxy/: tls baz (200; 27.373435ms)
  I0419 16:46:58.897387 14 proxy.go:558] (5) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/tlsrewritem... (200; 27.628438ms)
  I0419 16:46:58.897737 14 proxy.go:558] (5) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname1/proxy/: tls baz (200; 27.42951ms)
  I0419 16:46:58.898051 14 proxy.go:558] (5) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname2/proxy/: bar (200; 27.797581ms)
  I0419 16:46:58.898114 14 proxy.go:558] (5) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname1/proxy/: foo (200; 27.759313ms)
  I0419 16:46:58.910130 14 proxy.go:558] (6) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/tlsrewritem... (200; 11.845371ms)
  I0419 16:46:58.913078 14 proxy.go:558] (6) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/rewriteme">... (200; 14.012922ms)
  I0419 16:46:58.914197 14 proxy.go:558] (6) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname2/proxy/: bar (200; 15.477767ms)
  I0419 16:46:58.915254 14 proxy.go:558] (6) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname1/proxy/: tls baz (200; 16.361298ms)
  I0419 16:46:58.915229 14 proxy.go:558] (6) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:462/proxy/: tls qux (200; 15.996424ms)
  I0419 16:46:58.919566 14 proxy.go:558] (6) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:160/proxy/: foo (200; 18.766899ms)
  I0419 16:46:58.919859 14 proxy.go:558] (6) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/rewriteme">test<... (200; 19.286105ms)
  I0419 16:46:58.920493 14 proxy.go:558] (6) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:162/proxy/: bar (200; 20.979269ms)
  I0419 16:46:58.920632 14 proxy.go:558] (6) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/rewriteme">test</a> (200; 20.817853ms)
  I0419 16:46:58.922477 14 proxy.go:558] (6) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:460/proxy/: tls baz (200; 22.318579ms)
  I0419 16:46:58.922908 14 proxy.go:558] (6) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:162/proxy/: bar (200; 22.953603ms)
  I0419 16:46:58.923664 14 proxy.go:558] (6) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname1/proxy/: foo (200; 25.11592ms)
  I0419 16:46:58.922928 14 proxy.go:558] (6) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:160/proxy/: foo (200; 21.876429ms)
  I0419 16:46:58.924431 14 proxy.go:558] (6) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname2/proxy/: tls qux (200; 24.767715ms)
  I0419 16:46:58.924431 14 proxy.go:558] (6) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname1/proxy/: foo (200; 25.050434ms)
  I0419 16:46:58.924685 14 proxy.go:558] (6) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname2/proxy/: bar (200; 24.323087ms)
  I0419 16:46:58.951485 14 proxy.go:558] (7) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:160/proxy/: foo (200; 25.969467ms)
  I0419 16:46:58.953223 14 proxy.go:558] (7) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:160/proxy/: foo (200; 27.820751ms)
  I0419 16:46:58.953470 14 proxy.go:558] (7) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:162/proxy/: bar (200; 28.236294ms)
  I0419 16:46:58.953507 14 proxy.go:558] (7) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/rewriteme">... (200; 27.652436ms)
  I0419 16:46:58.953582 14 proxy.go:558] (7) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/rewriteme">test</a> (200; 28.25603ms)
  I0419 16:46:58.953606 14 proxy.go:558] (7) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/rewriteme">test<... (200; 27.903897ms)
  I0419 16:46:58.958523 14 proxy.go:558] (7) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname2/proxy/: bar (200; 32.463269ms)
  I0419 16:46:58.953624 14 proxy.go:558] (7) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:460/proxy/: tls baz (200; 27.346795ms)
  I0419 16:46:58.953661 14 proxy.go:558] (7) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:462/proxy/: tls qux (200; 27.739799ms)
  I0419 16:46:58.953697 14 proxy.go:558] (7) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/tlsrewritem... (200; 28.125514ms)
  I0419 16:46:58.953994 14 proxy.go:558] (7) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:162/proxy/: bar (200; 27.789383ms)
  I0419 16:46:58.954043 14 proxy.go:558] (7) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname1/proxy/: foo (200; 28.057759ms)
  I0419 16:46:58.954063 14 proxy.go:558] (7) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname1/proxy/: tls baz (200; 28.283602ms)
  I0419 16:46:58.954091 14 proxy.go:558] (7) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname2/proxy/: tls qux (200; 28.871503ms)
  I0419 16:46:58.954123 14 proxy.go:558] (7) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname2/proxy/: bar (200; 28.476808ms)
  I0419 16:46:58.954413 14 proxy.go:558] (7) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname1/proxy/: foo (200; 28.290778ms)
  I0419 16:46:58.976155 14 proxy.go:558] (8) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:160/proxy/: foo (200; 11.683184ms)
  I0419 16:46:58.976540 14 proxy.go:558] (8) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname2/proxy/: tls qux (200; 12.445838ms)
  I0419 16:46:58.976833 14 proxy.go:558] (8) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/rewriteme">test<... (200; 12.540318ms)
  I0419 16:46:58.978136 14 proxy.go:558] (8) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:160/proxy/: foo (200; 13.509082ms)
  I0419 16:46:58.980226 14 proxy.go:558] (8) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:462/proxy/: tls qux (200; 14.493374ms)
  I0419 16:46:58.983967 14 proxy.go:558] (8) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:460/proxy/: tls baz (200; 17.167948ms)
  I0419 16:46:58.984046 14 proxy.go:558] (8) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname1/proxy/: tls baz (200; 18.634045ms)
  I0419 16:46:58.984081 14 proxy.go:558] (8) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:162/proxy/: bar (200; 17.517005ms)
  I0419 16:46:58.985103 14 proxy.go:558] (8) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname2/proxy/: bar (200; 19.84869ms)
  I0419 16:46:58.985200 14 proxy.go:558] (8) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/rewriteme">test</a> (200; 18.750769ms)
  I0419 16:46:58.985969 14 proxy.go:558] (8) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:162/proxy/: bar (200; 19.259987ms)
  I0419 16:46:58.986060 14 proxy.go:558] (8) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/tlsrewritem... (200; 21.235233ms)
  I0419 16:46:58.986209 14 proxy.go:558] (8) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname1/proxy/: foo (200; 21.282201ms)
  I0419 16:46:58.986541 14 proxy.go:558] (8) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/rewriteme">... (200; 20.96661ms)
  I0419 16:46:58.988401 14 proxy.go:558] (8) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname2/proxy/: bar (200; 23.330252ms)
  I0419 16:46:58.989455 14 proxy.go:558] (8) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname1/proxy/: foo (200; 22.796971ms)
  I0419 16:46:59.005192 14 proxy.go:558] (9) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:160/proxy/: foo (200; 14.468673ms)
  I0419 16:46:59.005394 14 proxy.go:558] (9) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/rewriteme">... (200; 15.242305ms)
  I0419 16:46:59.005604 14 proxy.go:558] (9) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:462/proxy/: tls qux (200; 15.350417ms)
  I0419 16:46:59.009588 14 proxy.go:558] (9) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/rewriteme">test<... (200; 19.567998ms)
  I0419 16:46:59.010658 14 proxy.go:558] (9) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:162/proxy/: bar (200; 20.963746ms)
  I0419 16:46:59.011281 14 proxy.go:558] (9) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:160/proxy/: foo (200; 20.38406ms)
  I0419 16:46:59.011316 14 proxy.go:558] (9) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:162/proxy/: bar (200; 21.476337ms)
  I0419 16:46:59.011347 14 proxy.go:558] (9) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname1/proxy/: foo (200; 20.703573ms)
  I0419 16:46:59.011450 14 proxy.go:558] (9) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:460/proxy/: tls baz (200; 21.515636ms)
  I0419 16:46:59.014353 14 proxy.go:558] (9) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/rewriteme">test</a> (200; 23.519252ms)
  I0419 16:46:59.014443 14 proxy.go:558] (9) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname1/proxy/: tls baz (200; 24.349146ms)
  I0419 16:46:59.014495 14 proxy.go:558] (9) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname2/proxy/: bar (200; 24.771542ms)
  I0419 16:46:59.014993 14 proxy.go:558] (9) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/tlsrewritem... (200; 24.038926ms)
  I0419 16:46:59.016300 14 proxy.go:558] (9) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname2/proxy/: bar (200; 25.954501ms)
  I0419 16:46:59.016549 14 proxy.go:558] (9) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname2/proxy/: tls qux (200; 25.77885ms)
  I0419 16:46:59.016632 14 proxy.go:558] (9) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname1/proxy/: foo (200; 26.329543ms)
  I0419 16:46:59.030174 14 proxy.go:558] (10) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:160/proxy/: foo (200; 13.328942ms)
  I0419 16:46:59.034545 14 proxy.go:558] (10) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:162/proxy/: bar (200; 17.784904ms)
  I0419 16:46:59.041069 14 proxy.go:558] (10) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:162/proxy/: bar (200; 22.266101ms)
  I0419 16:46:59.042304 14 proxy.go:558] (10) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/rewriteme">... (200; 22.373581ms)
  I0419 16:46:59.043011 14 proxy.go:558] (10) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname2/proxy/: tls qux (200; 25.648901ms)
  I0419 16:46:59.044079 14 proxy.go:558] (10) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:160/proxy/: foo (200; 25.05954ms)
  I0419 16:46:59.044144 14 proxy.go:558] (10) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/rewriteme">test<... (200; 23.673354ms)
  I0419 16:46:59.044713 14 proxy.go:558] (10) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/rewriteme">test</a> (200; 27.170381ms)
  I0419 16:46:59.044799 14 proxy.go:558] (10) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:460/proxy/: tls baz (200; 26.879754ms)
  I0419 16:46:59.044848 14 proxy.go:558] (10) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname2/proxy/: bar (200; 25.281367ms)
  I0419 16:46:59.044957 14 proxy.go:558] (10) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:462/proxy/: tls qux (200; 25.718709ms)
  I0419 16:46:59.044994 14 proxy.go:558] (10) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/tlsrewritem... (200; 26.895865ms)
  I0419 16:46:59.045207 14 proxy.go:558] (10) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname1/proxy/: tls baz (200; 24.988091ms)
  I0419 16:46:59.047203 14 proxy.go:558] (10) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname1/proxy/: foo (200; 27.093211ms)
  I0419 16:46:59.048844 14 proxy.go:558] (10) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname2/proxy/: bar (200; 28.55999ms)
  I0419 16:46:59.049323 14 proxy.go:558] (10) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname1/proxy/: foo (200; 29.927926ms)
  I0419 16:46:59.061808 14 proxy.go:558] (11) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/rewriteme">test</a> (200; 10.921699ms)
  I0419 16:46:59.063366 14 proxy.go:558] (11) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:162/proxy/: bar (200; 12.367865ms)
  I0419 16:46:59.063732 14 proxy.go:558] (11) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:160/proxy/: foo (200; 12.817317ms)
  I0419 16:46:59.066257 14 proxy.go:558] (11) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:160/proxy/: foo (200; 14.685359ms)
  I0419 16:46:59.066858 14 proxy.go:558] (11) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/rewriteme">test<... (200; 15.699564ms)
  I0419 16:46:59.067271 14 proxy.go:558] (11) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:460/proxy/: tls baz (200; 16.229969ms)
  I0419 16:46:59.072010 14 proxy.go:558] (11) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname2/proxy/: tls qux (200; 21.188313ms)
  I0419 16:46:59.072159 14 proxy.go:558] (11) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:462/proxy/: tls qux (200; 22.33206ms)
  I0419 16:46:59.072590 14 proxy.go:558] (11) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname1/proxy/: foo (200; 22.432345ms)
  I0419 16:46:59.074090 14 proxy.go:558] (11) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname2/proxy/: bar (200; 22.920663ms)
  I0419 16:46:59.074413 14 proxy.go:558] (11) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:162/proxy/: bar (200; 23.949998ms)
  I0419 16:46:59.074827 14 proxy.go:558] (11) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname1/proxy/: foo (200; 23.625476ms)
  I0419 16:46:59.075107 14 proxy.go:558] (11) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/tlsrewritem... (200; 23.387217ms)
  I0419 16:46:59.077854 14 proxy.go:558] (11) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname2/proxy/: bar (200; 25.977192ms)
  I0419 16:46:59.078199 14 proxy.go:558] (11) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/rewriteme">... (200; 26.269645ms)
  I0419 16:46:59.078500 14 proxy.go:558] (11) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname1/proxy/: tls baz (200; 26.702867ms)
  I0419 16:46:59.087767 14 proxy.go:558] (12) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:162/proxy/: bar (200; 9.186557ms)
  I0419 16:46:59.093720 14 proxy.go:558] (12) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/rewriteme">test</a> (200; 14.807671ms)
  I0419 16:46:59.093805 14 proxy.go:558] (12) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:160/proxy/: foo (200; 14.009068ms)
  I0419 16:46:59.094917 14 proxy.go:558] (12) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/rewriteme">test<... (200; 15.384052ms)
  I0419 16:46:59.096638 14 proxy.go:558] (12) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:460/proxy/: tls baz (200; 17.403832ms)
  I0419 16:46:59.098392 14 proxy.go:558] (12) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/rewriteme">... (200; 17.254343ms)
  I0419 16:46:59.099558 14 proxy.go:558] (12) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname2/proxy/: tls qux (200; 20.794309ms)
  I0419 16:46:59.099914 14 proxy.go:558] (12) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:160/proxy/: foo (200; 20.254985ms)
  I0419 16:46:59.099970 14 proxy.go:558] (12) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:162/proxy/: bar (200; 20.883099ms)
  I0419 16:46:59.100382 14 proxy.go:558] (12) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname1/proxy/: foo (200; 20.311458ms)
  I0419 16:46:59.100798 14 proxy.go:558] (12) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname2/proxy/: bar (200; 21.418626ms)
  I0419 16:46:59.101824 14 proxy.go:558] (12) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/tlsrewritem... (200; 21.879349ms)
  I0419 16:46:59.102897 14 proxy.go:558] (12) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname2/proxy/: bar (200; 22.694857ms)
  I0419 16:46:59.103565 14 proxy.go:558] (12) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname1/proxy/: tls baz (200; 23.193082ms)
  I0419 16:46:59.104613 14 proxy.go:558] (12) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:462/proxy/: tls qux (200; 23.914471ms)
  I0419 16:46:59.105049 14 proxy.go:558] (12) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname1/proxy/: foo (200; 23.74444ms)
  I0419 16:46:59.115784 14 proxy.go:558] (13) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/rewriteme">test</a> (200; 10.019901ms)
  I0419 16:46:59.125064 14 proxy.go:558] (13) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname2/proxy/: bar (200; 18.814245ms)
  I0419 16:46:59.125075 14 proxy.go:558] (13) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:460/proxy/: tls baz (200; 19.08613ms)
  I0419 16:46:59.125107 14 proxy.go:558] (13) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:162/proxy/: bar (200; 18.403684ms)
  I0419 16:46:59.125132 14 proxy.go:558] (13) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/rewriteme">test<... (200; 18.040471ms)
  I0419 16:46:59.127114 14 proxy.go:558] (13) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:462/proxy/: tls qux (200; 20.60916ms)
  I0419 16:46:59.127448 14 proxy.go:558] (13) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:160/proxy/: foo (200; 20.201092ms)
  I0419 16:46:59.127177 14 proxy.go:558] (13) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:160/proxy/: foo (200; 19.968756ms)
  I0419 16:46:59.127310 14 proxy.go:558] (13) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/rewriteme">... (200; 20.889498ms)
  I0419 16:46:59.127420 14 proxy.go:558] (13) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname2/proxy/: tls qux (200; 21.784518ms)
  I0419 16:46:59.127553 14 proxy.go:558] (13) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:162/proxy/: bar (200; 21.695813ms)
  I0419 16:46:59.127764 14 proxy.go:558] (13) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/tlsrewritem... (200; 22.160045ms)
  I0419 16:46:59.129400 14 proxy.go:558] (13) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname1/proxy/: tls baz (200; 23.102119ms)
  I0419 16:46:59.130185 14 proxy.go:558] (13) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname1/proxy/: foo (200; 24.011685ms)
  I0419 16:46:59.130751 14 proxy.go:558] (13) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname2/proxy/: bar (200; 23.890762ms)
  I0419 16:46:59.131236 14 proxy.go:558] (13) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname1/proxy/: foo (200; 24.646403ms)
  I0419 16:46:59.152725 14 proxy.go:558] (14) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:160/proxy/: foo (200; 20.441575ms)
  I0419 16:46:59.153002 14 proxy.go:558] (14) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:162/proxy/: bar (200; 19.798786ms)
  I0419 16:46:59.153374 14 proxy.go:558] (14) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:462/proxy/: tls qux (200; 21.360975ms)
  I0419 16:46:59.153583 14 proxy.go:558] (14) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:160/proxy/: foo (200; 21.023318ms)
  I0419 16:46:59.153764 14 proxy.go:558] (14) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:162/proxy/: bar (200; 20.513532ms)
  I0419 16:46:59.157542 14 proxy.go:558] (14) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:460/proxy/: tls baz (200; 24.253457ms)
  I0419 16:46:59.157649 14 proxy.go:558] (14) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/tlsrewritem... (200; 24.781801ms)
  I0419 16:46:59.157695 14 proxy.go:558] (14) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname1/proxy/: foo (200; 24.667565ms)
  I0419 16:46:59.157991 14 proxy.go:558] (14) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/rewriteme">... (200; 24.351875ms)
  I0419 16:46:59.157475 14 proxy.go:558] (14) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname2/proxy/: tls qux (200; 24.126467ms)
  I0419 16:46:59.159429 14 proxy.go:558] (14) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname1/proxy/: foo (200; 26.269725ms)
  I0419 16:46:59.159492 14 proxy.go:558] (14) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/rewriteme">test</a> (200; 27.535764ms)
  I0419 16:46:59.160489 14 proxy.go:558] (14) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname1/proxy/: tls baz (200; 26.783384ms)
  I0419 16:46:59.160961 14 proxy.go:558] (14) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/rewriteme">test<... (200; 27.529884ms)
  I0419 16:46:59.161289 14 proxy.go:558] (14) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname2/proxy/: bar (200; 27.776462ms)
  I0419 16:46:59.161894 14 proxy.go:558] (14) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname2/proxy/: bar (200; 28.798675ms)
  I0419 16:46:59.171606 14 proxy.go:558] (15) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:460/proxy/: tls baz (200; 9.314897ms)
  I0419 16:46:59.179738 14 proxy.go:558] (15) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:462/proxy/: tls qux (200; 17.141696ms)
  I0419 16:46:59.180204 14 proxy.go:558] (15) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:162/proxy/: bar (200; 17.39158ms)
  I0419 16:46:59.180732 14 proxy.go:558] (15) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/rewriteme">test<... (200; 17.502291ms)
  I0419 16:46:59.181304 14 proxy.go:558] (15) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:160/proxy/: foo (200; 17.990602ms)
  I0419 16:46:59.181614 14 proxy.go:558] (15) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname1/proxy/: tls baz (200; 19.285854ms)
  I0419 16:46:59.181833 14 proxy.go:558] (15) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/rewriteme">test</a> (200; 18.875108ms)
  I0419 16:46:59.181841 14 proxy.go:558] (15) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:162/proxy/: bar (200; 18.839508ms)
  I0419 16:46:59.182399 14 proxy.go:558] (15) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/rewriteme">... (200; 19.914169ms)
  I0419 16:46:59.182419 14 proxy.go:558] (15) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/tlsrewritem... (200; 18.952262ms)
  I0419 16:46:59.182919 14 proxy.go:558] (15) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:160/proxy/: foo (200; 19.862463ms)
  I0419 16:46:59.183375 14 proxy.go:558] (15) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname2/proxy/: bar (200; 19.818404ms)
  I0419 16:46:59.184821 14 proxy.go:558] (15) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname1/proxy/: foo (200; 22.127703ms)
  I0419 16:46:59.186402 14 proxy.go:558] (15) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname1/proxy/: foo (200; 23.025437ms)
  I0419 16:46:59.188799 14 proxy.go:558] (15) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname2/proxy/: bar (200; 25.66628ms)
  I0419 16:46:59.190961 14 proxy.go:558] (15) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname2/proxy/: tls qux (200; 28.082152ms)
  I0419 16:46:59.205102 14 proxy.go:558] (16) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/rewriteme">test<... (200; 13.691953ms)
  I0419 16:46:59.205256 14 proxy.go:558] (16) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/rewriteme">... (200; 13.579495ms)
  I0419 16:46:59.209205 14 proxy.go:558] (16) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:160/proxy/: foo (200; 17.307229ms)
  I0419 16:46:59.210174 14 proxy.go:558] (16) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:460/proxy/: tls baz (200; 18.75151ms)
  I0419 16:46:59.211124 14 proxy.go:558] (16) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/tlsrewritem... (200; 19.094518ms)
  I0419 16:46:59.211420 14 proxy.go:558] (16) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:462/proxy/: tls qux (200; 19.265078ms)
  I0419 16:46:59.211540 14 proxy.go:558] (16) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:160/proxy/: foo (200; 19.758079ms)
  I0419 16:46:59.213980 14 proxy.go:558] (16) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:162/proxy/: bar (200; 21.664577ms)
  I0419 16:46:59.215575 14 proxy.go:558] (16) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname2/proxy/: bar (200; 24.04516ms)
  I0419 16:46:59.215571 14 proxy.go:558] (16) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:162/proxy/: bar (200; 22.984948ms)
  I0419 16:46:59.215948 14 proxy.go:558] (16) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname1/proxy/: foo (200; 23.215427ms)
  I0419 16:46:59.216125 14 proxy.go:558] (16) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname1/proxy/: foo (200; 23.893203ms)
  I0419 16:46:59.216308 14 proxy.go:558] (16) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname2/proxy/: bar (200; 23.67078ms)
  I0419 16:46:59.217595 14 proxy.go:558] (16) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/rewriteme">test</a> (200; 25.094429ms)
  I0419 16:46:59.220508 14 proxy.go:558] (16) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname1/proxy/: tls baz (200; 27.697191ms)
  I0419 16:46:59.220519 14 proxy.go:558] (16) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname2/proxy/: tls qux (200; 28.125448ms)
  I0419 16:46:59.231195 14 proxy.go:558] (17) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:162/proxy/: bar (200; 9.096298ms)
  I0419 16:46:59.235514 14 proxy.go:558] (17) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:162/proxy/: bar (200; 13.262688ms)
  I0419 16:46:59.238966 14 proxy.go:558] (17) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/rewriteme">test<... (200; 17.113581ms)
  I0419 16:46:59.239145 14 proxy.go:558] (17) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/rewriteme">... (200; 17.564368ms)
  I0419 16:46:59.241412 14 proxy.go:558] (17) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/rewriteme">test</a> (200; 19.209757ms)
  I0419 16:46:59.241428 14 proxy.go:558] (17) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/tlsrewritem... (200; 19.058155ms)
  I0419 16:46:59.241499 14 proxy.go:558] (17) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:160/proxy/: foo (200; 19.660274ms)
  I0419 16:46:59.242834 14 proxy.go:558] (17) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:462/proxy/: tls qux (200; 20.303436ms)
  I0419 16:46:59.242942 14 proxy.go:558] (17) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname2/proxy/: bar (200; 21.350513ms)
  I0419 16:46:59.243269 14 proxy.go:558] (17) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:160/proxy/: foo (200; 20.752541ms)
  I0419 16:46:59.244944 14 proxy.go:558] (17) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname1/proxy/: foo (200; 22.95869ms)
  I0419 16:46:59.245168 14 proxy.go:558] (17) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname2/proxy/: tls qux (200; 23.011195ms)
  I0419 16:46:59.245643 14 proxy.go:558] (17) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname1/proxy/: tls baz (200; 22.927366ms)
  I0419 16:46:59.246030 14 proxy.go:558] (17) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:460/proxy/: tls baz (200; 23.728054ms)
  I0419 16:46:59.247128 14 proxy.go:558] (17) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname2/proxy/: bar (200; 24.56272ms)
  I0419 16:46:59.247319 14 proxy.go:558] (17) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname1/proxy/: foo (200; 24.893469ms)
  I0419 16:46:59.254514 14 proxy.go:558] (18) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:160/proxy/: foo (200; 6.151833ms)
  I0419 16:46:59.254596 14 proxy.go:558] (18) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:160/proxy/: foo (200; 5.908895ms)
  I0419 16:46:59.255172 14 proxy.go:558] (18) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:460/proxy/: tls baz (200; 7.656186ms)
  I0419 16:46:59.261341 14 proxy.go:558] (18) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/tlsrewritem... (200; 12.243637ms)
  I0419 16:46:59.261494 14 proxy.go:558] (18) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname2/proxy/: bar (200; 13.627721ms)
  I0419 16:46:59.261649 14 proxy.go:558] (18) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:162/proxy/: bar (200; 11.482374ms)
  I0419 16:46:59.261964 14 proxy.go:558] (18) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/rewriteme">test<... (200; 13.876019ms)
  I0419 16:46:59.262080 14 proxy.go:558] (18) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:462/proxy/: tls qux (200; 12.901717ms)
  I0419 16:46:59.263060 14 proxy.go:558] (18) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:162/proxy/: bar (200; 13.044892ms)
  I0419 16:46:59.263103 14 proxy.go:558] (18) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname2/proxy/: bar (200; 13.360294ms)
  I0419 16:46:59.264012 14 proxy.go:558] (18) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/rewriteme">test</a> (200; 13.923329ms)
  I0419 16:46:59.264101 14 proxy.go:558] (18) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/rewriteme">... (200; 14.228807ms)
  I0419 16:46:59.265541 14 proxy.go:558] (18) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname2/proxy/: tls qux (200; 15.610412ms)
  I0419 16:46:59.265579 14 proxy.go:558] (18) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname1/proxy/: foo (200; 16.026863ms)
  I0419 16:46:59.266858 14 proxy.go:558] (18) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname1/proxy/: foo (200; 17.210127ms)
  I0419 16:46:59.267390 14 proxy.go:558] (18) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname1/proxy/: tls baz (200; 17.58227ms)
  I0419 16:46:59.275967 14 proxy.go:558] (19) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:460/proxy/: tls baz (200; 8.4899ms)
  I0419 16:46:59.275980 14 proxy.go:558] (19) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:443/proxy/tlsrewritem... (200; 8.398932ms)
  I0419 16:46:59.279777 14 proxy.go:558] (19) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:160/proxy/: foo (200; 11.73835ms)
  I0419 16:46:59.279915 14 proxy.go:558] (19) /api/v1/namespaces/proxy-3547/pods/https:proxy-service-476cl-2nlpf:462/proxy/: tls qux (200; 11.777883ms)
  I0419 16:46:59.280440 14 proxy.go:558] (19) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:1080/proxy/rewriteme">test<... (200; 12.508605ms)
  I0419 16:46:59.280646 14 proxy.go:558] (19) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:160/proxy/: foo (200; 12.550046ms)
  I0419 16:46:59.283767 14 proxy.go:558] (19) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname1/proxy/: tls baz (200; 16.008222ms)
  I0419 16:46:59.284392 14 proxy.go:558] (19) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:1080/proxy/rewriteme">... (200; 16.05344ms)
  I0419 16:46:59.284840 14 proxy.go:558] (19) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname1/proxy/: foo (200; 16.657845ms)
  I0419 16:46:59.284934 14 proxy.go:558] (19) /api/v1/namespaces/proxy-3547/pods/http:proxy-service-476cl-2nlpf:162/proxy/: bar (200; 15.854372ms)
  I0419 16:46:59.284968 14 proxy.go:558] (19) /api/v1/namespaces/proxy-3547/services/http:proxy-service-476cl:portname2/proxy/: bar (200; 17.129446ms)
  I0419 16:46:59.285033 14 proxy.go:558] (19) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/: <a href="/api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf/proxy/rewriteme">test</a> (200; 16.094937ms)
  I0419 16:46:59.285733 14 proxy.go:558] (19) /api/v1/namespaces/proxy-3547/pods/proxy-service-476cl-2nlpf:162/proxy/: bar (200; 16.070436ms)
  I0419 16:46:59.286068 14 proxy.go:558] (19) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname2/proxy/: bar (200; 18.468191ms)
  I0419 16:46:59.288233 14 proxy.go:558] (19) /api/v1/namespaces/proxy-3547/services/proxy-service-476cl:portname1/proxy/: foo (200; 19.167552ms)
  I0419 16:46:59.290409 14 proxy.go:558] (19) /api/v1/namespaces/proxy-3547/services/https:proxy-service-476cl:tlsportname2/proxy/: tls qux (200; 22.180381ms)
  STEP: deleting ReplicationController proxy-service-476cl in namespace proxy-3547, will wait for the garbage collector to delete the pods @ 04/19/24 16:46:59.29
  I0419 16:46:59.356299 14 resources.go:139] Deleting ReplicationController proxy-service-476cl took: 11.102788ms
  E0419 16:46:59.364730      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:46:59.457925 14 resources.go:163] Terminating ReplicationController proxy-service-476cl pods took: 101.624567ms
  E0419 16:47:00.364814      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:01.366546      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:47:01.760952 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-3547" for this suite. @ 04/19/24 16:47:01.778
• [5.297 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:257
  STEP: Creating a kubernetes client @ 04/19/24 16:47:01.798
  I0419 16:47:01.798812 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename watch @ 04/19/24 16:47:01.804
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:47:01.838
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:47:01.845
  STEP: creating a watch on configmaps with a certain label @ 04/19/24 16:47:01.854
  STEP: creating a new configmap @ 04/19/24 16:47:01.858
  STEP: modifying the configmap once @ 04/19/24 16:47:01.878
  STEP: changing the label value of the configmap @ 04/19/24 16:47:01.896
  STEP: Expecting to observe a delete notification for the watched object @ 04/19/24 16:47:01.912
  I0419 16:47:01.913144 14 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7505  9cf567f8-7428-47d3-8786-4e22810dce7b 22791 0 2024-04-19 16:47:01 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-19 16:47:01 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0419 16:47:01.914024 14 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7505  9cf567f8-7428-47d3-8786-4e22810dce7b 22792 0 2024-04-19 16:47:01 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-19 16:47:01 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0419 16:47:01.914750 14 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7505  9cf567f8-7428-47d3-8786-4e22810dce7b 22793 0 2024-04-19 16:47:01 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-19 16:47:01 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time @ 04/19/24 16:47:01.915
  STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements @ 04/19/24 16:47:01.927
  E0419 16:47:02.367107      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:03.367981      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:04.368744      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:05.369095      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:06.369392      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:07.370330      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:08.370661      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:09.371024      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:10.371117      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:11.371709      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: changing the label value of the configmap back @ 04/19/24 16:47:11.927
  STEP: modifying the configmap a third time @ 04/19/24 16:47:11.952
  STEP: deleting the configmap @ 04/19/24 16:47:11.975
  STEP: Expecting to observe an add notification for the watched object when the label value was restored @ 04/19/24 16:47:11.994
  I0419 16:47:11.995218 14 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7505  9cf567f8-7428-47d3-8786-4e22810dce7b 22829 0 2024-04-19 16:47:01 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-19 16:47:11 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0419 16:47:11.996310 14 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7505  9cf567f8-7428-47d3-8786-4e22810dce7b 22830 0 2024-04-19 16:47:01 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-19 16:47:11 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0419 16:47:11.997381 14 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7505  9cf567f8-7428-47d3-8786-4e22810dce7b 22831 0 2024-04-19 16:47:01 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-19 16:47:11 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0419 16:47:11.998295 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-7505" for this suite. @ 04/19/24 16:47:12.02
• [10.249 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:105
  STEP: Creating a kubernetes client @ 04/19/24 16:47:12.05
  I0419 16:47:12.050429 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename subpath @ 04/19/24 16:47:12.054
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:47:12.09
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:47:12.097
  STEP: Setting up data @ 04/19/24 16:47:12.104
  STEP: Creating pod pod-subpath-test-projected-gdwp @ 04/19/24 16:47:12.131
  STEP: Creating a pod to test atomic-volume-subpath @ 04/19/24 16:47:12.131
  E0419 16:47:12.372451      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:13.373089      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:14.373766      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:15.374862      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:16.375027      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:17.375755      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:18.375714      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:19.376701      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:20.377290      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:21.378410      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:22.379012      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:23.379614      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:24.379843      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:25.380211      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:26.380579      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:27.381124      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:28.381854      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:29.382911      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:30.383783      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:31.384195      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:32.384552      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:33.384577      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:34.385618      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:35.385939      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:47:36.308
  I0419 16:47:36.323103 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-subpath-test-projected-gdwp container test-container-subpath-projected-gdwp: <nil>
  STEP: delete the pod @ 04/19/24 16:47:36.349
  E0419 16:47:36.387071      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting pod pod-subpath-test-projected-gdwp @ 04/19/24 16:47:36.394
  I0419 16:47:36.394188 14 delete.go:62] Deleting pod "pod-subpath-test-projected-gdwp" in namespace "subpath-9866"
  I0419 16:47:36.400214 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-9866" for this suite. @ 04/19/24 16:47:36.414
• [24.378 seconds]
------------------------------
SSS
------------------------------
[sig-node] Secrets should patch a secret [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:156
  STEP: Creating a kubernetes client @ 04/19/24 16:47:36.429
  I0419 16:47:36.430164 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename secrets @ 04/19/24 16:47:36.433
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:47:36.474
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:47:36.482
  STEP: creating a secret @ 04/19/24 16:47:36.49
  STEP: listing secrets in all namespaces to ensure that there are more than zero @ 04/19/24 16:47:36.502
  STEP: patching the secret @ 04/19/24 16:47:36.511
  STEP: deleting the secret using a LabelSelector @ 04/19/24 16:47:36.53
  STEP: listing secrets in all namespaces, searching for label name and value in patch @ 04/19/24 16:47:36.551
  I0419 16:47:36.558676 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3685" for this suite. @ 04/19/24 16:47:36.566
• [0.149 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:100
  STEP: Creating a kubernetes client @ 04/19/24 16:47:36.58
  I0419 16:47:36.580233 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename configmap @ 04/19/24 16:47:36.585
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:47:36.614
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:47:36.619
  STEP: Creating configMap with name configmap-test-volume-map-229b96cf-fd86-484b-9125-0f2b7a5d8794 @ 04/19/24 16:47:36.625
  STEP: Creating a pod to test consume configMaps @ 04/19/24 16:47:36.634
  E0419 16:47:37.387648      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:38.390640      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:39.389051      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:40.389511      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:47:40.685
  I0419 16:47:40.695248 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-configmaps-24ab4503-a531-450a-b662-dc9c8c0cf3b6 container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/24 16:47:40.719
  I0419 16:47:40.752867 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-979" for this suite. @ 04/19/24 16:47:40.763
• [4.196 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:224
  STEP: Creating a kubernetes client @ 04/19/24 16:47:40.778
  I0419 16:47:40.778854 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename sched-preemption @ 04/19/24 16:47:40.782
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:47:40.806
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:47:40.811
  I0419 16:47:40.841340 14 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0419 16:47:41.390188      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:42.390665      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:43.391405      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:44.391761      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:45.392040      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:46.392325      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:47.393126      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:48.393620      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:49.393901      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:50.394484      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:51.394708      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:52.395537      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:53.396550      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:54.397396      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:55.397521      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:56.397948      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:57.401232      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:58.401603      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:59.402349      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:00.403255      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:01.404377      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:02.404091      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:03.404246      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:04.404570      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:05.404782      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:06.405074      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:07.405723      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:08.405811      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:09.406456      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:10.406945      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:11.407176      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:12.408017      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:13.408869      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:14.409352      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:15.410232      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:16.411072      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:17.411717      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:18.412845      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:19.412984      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:20.414251      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:21.414430      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:22.414705      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:23.415814      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:24.416156      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:25.416301      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:26.416617      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:27.417649      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:28.418806      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:29.419283      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:30.420483      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:31.420590      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:32.420832      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:33.421230      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:34.421397      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:35.422200      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:36.422886      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:37.424364      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:38.425155      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:39.425253      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:40.425573      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:48:40.865959 14 util.go:400] Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 04/19/24 16:48:40.882
  I0419 16:48:40.976082 14 preemption.go:269] Created pod: pod0-0-sched-preemption-low-priority
  I0419 16:48:40.993462 14 preemption.go:269] Created pod: pod0-1-sched-preemption-medium-priority
  I0419 16:48:41.040125 14 preemption.go:269] Created pod: pod1-0-sched-preemption-medium-priority
  I0419 16:48:41.060609 14 preemption.go:269] Created pod: pod1-1-sched-preemption-medium-priority
  I0419 16:48:41.128201 14 preemption.go:269] Created pod: pod2-0-sched-preemption-medium-priority
  I0419 16:48:41.141215 14 preemption.go:269] Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 04/19/24 16:48:41.141
  E0419 16:48:41.426515      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:42.427044      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Run a critical pod that use same resources as that of a lower priority pod @ 04/19/24 16:48:43.212
  E0419 16:48:43.427806      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:44.428403      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:45.429017      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:46.430159      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:47.430404      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:48:47.504014 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-6735" for this suite. @ 04/19/24 16:48:47.515
• [66.750 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] Job should manage the lifecycle of a job [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:927
  STEP: Creating a kubernetes client @ 04/19/24 16:48:47.532
  I0419 16:48:47.532400 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename job @ 04/19/24 16:48:47.537
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:48:47.575
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:48:47.581
  STEP: Creating a suspended job @ 04/19/24 16:48:47.593
  STEP: Patching the Job @ 04/19/24 16:48:47.603
  STEP: Watching for Job to be patched @ 04/19/24 16:48:47.641
  I0419 16:48:47.649731 14 job.go:1109] Event ADDED observed for Job e2e-bs6dz in namespace job-1196 with labels: map[e2e-job-label:e2e-bs6dz] and annotations: map[]
  I0419 16:48:47.651073 14 job.go:1109] Event MODIFIED observed for Job e2e-bs6dz in namespace job-1196 with labels: map[e2e-job-label:e2e-bs6dz] and annotations: map[]
  I0419 16:48:47.652076 14 job.go:1112] Event MODIFIED found for Job e2e-bs6dz in namespace job-1196 with labels: map[e2e-bs6dz:patched e2e-job-label:e2e-bs6dz] and annotations: map[]
  STEP: Updating the job @ 04/19/24 16:48:47.652
  STEP: Watching for Job to be updated @ 04/19/24 16:48:47.675
  I0419 16:48:47.690873 14 job.go:1112] Event MODIFIED found for Job e2e-bs6dz in namespace job-1196 with labels: map[e2e-bs6dz:patched e2e-job-label:e2e-bs6dz] and annotations: map[updated:true]
  I0419 16:48:47.693294 14 job.go:1005] Found Job annotations: map[string]string{"updated":"true"}
  STEP: Listing all Jobs with LabelSelector @ 04/19/24 16:48:47.694
  I0419 16:48:47.714082 14 job.go:1012] Job: e2e-bs6dz as labels: map[e2e-bs6dz:patched e2e-job-label:e2e-bs6dz]
  STEP: Waiting for job to complete @ 04/19/24 16:48:47.714
  E0419 16:48:48.431265      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:49.431949      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:50.433319      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:51.434482      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:52.434582      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:53.435307      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:54.436057      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:55.436737      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Delete a job collection with a labelselector @ 04/19/24 16:48:55.725
  STEP: Watching for Job to be deleted @ 04/19/24 16:48:55.748
  I0419 16:48:55.754299 14 job.go:1109] Event MODIFIED observed for Job e2e-bs6dz in namespace job-1196 with labels: map[e2e-bs6dz:patched e2e-job-label:e2e-bs6dz] and annotations: map[updated:true]
  I0419 16:48:55.755125 14 job.go:1109] Event MODIFIED observed for Job e2e-bs6dz in namespace job-1196 with labels: map[e2e-bs6dz:patched e2e-job-label:e2e-bs6dz] and annotations: map[updated:true]
  I0419 16:48:55.755967 14 job.go:1109] Event MODIFIED observed for Job e2e-bs6dz in namespace job-1196 with labels: map[e2e-bs6dz:patched e2e-job-label:e2e-bs6dz] and annotations: map[updated:true]
  I0419 16:48:55.756594 14 job.go:1109] Event MODIFIED observed for Job e2e-bs6dz in namespace job-1196 with labels: map[e2e-bs6dz:patched e2e-job-label:e2e-bs6dz] and annotations: map[updated:true]
  I0419 16:48:55.757263 14 job.go:1109] Event MODIFIED observed for Job e2e-bs6dz in namespace job-1196 with labels: map[e2e-bs6dz:patched e2e-job-label:e2e-bs6dz] and annotations: map[updated:true]
  I0419 16:48:55.757838 14 job.go:1109] Event MODIFIED observed for Job e2e-bs6dz in namespace job-1196 with labels: map[e2e-bs6dz:patched e2e-job-label:e2e-bs6dz] and annotations: map[updated:true]
  I0419 16:48:55.758463 14 job.go:1109] Event MODIFIED observed for Job e2e-bs6dz in namespace job-1196 with labels: map[e2e-bs6dz:patched e2e-job-label:e2e-bs6dz] and annotations: map[updated:true]
  I0419 16:48:55.758803 14 job.go:1112] Event DELETED found for Job e2e-bs6dz in namespace job-1196 with labels: map[e2e-bs6dz:patched e2e-job-label:e2e-bs6dz] and annotations: map[updated:true]
  STEP: Relist jobs to confirm deletion @ 04/19/24 16:48:55.759
  I0419 16:48:55.769344 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-1196" for this suite. @ 04/19/24 16:48:55.784
• [8.288 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:56
  STEP: Creating a kubernetes client @ 04/19/24 16:48:55.827
  I0419 16:48:55.828086 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename projected @ 04/19/24 16:48:55.832
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:48:55.888
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:48:55.895
  STEP: Creating projection with secret that has name projected-secret-test-81038c4b-6eb1-40b4-a8ae-770af03e4d58 @ 04/19/24 16:48:55.901
  STEP: Creating a pod to test consume secrets @ 04/19/24 16:48:55.908
  E0419 16:48:56.437087      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:57.437597      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:58.437975      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:59.440473      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:48:59.969
  I0419 16:48:59.976708 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-projected-secrets-7c99cf16-cd1e-40a2-982f-703005d6efb6 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/24 16:48:59.995
  I0419 16:49:00.038103 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5540" for this suite. @ 04/19/24 16:49:00.047
• [4.232 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:251
  STEP: Creating a kubernetes client @ 04/19/24 16:49:00.061
  I0419 16:49:00.061260 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename projected @ 04/19/24 16:49:00.063
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:49:00.094
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:49:00.1
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 16:49:00.107
  E0419 16:49:00.441002      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:01.441384      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:02.442815      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:03.443265      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:49:04.161
  I0419 16:49:04.170590 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod downwardapi-volume-708a66c2-8f84-4324-ad3e-8725e0b0d2d8 container client-container: <nil>
  STEP: delete the pod @ 04/19/24 16:49:04.188
  I0419 16:49:04.224706 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2217" for this suite. @ 04/19/24 16:49:04.235
• [4.188 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:89
  STEP: Creating a kubernetes client @ 04/19/24 16:49:04.252
  I0419 16:49:04.252716 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename containers @ 04/19/24 16:49:04.257
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:49:04.286
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:49:04.294
  STEP: Creating a pod to test override all @ 04/19/24 16:49:04.301
  E0419 16:49:04.444417      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:05.444191      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:06.444864      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:07.446256      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:49:08.349
  I0419 16:49:08.359261 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod client-containers-a3bde5bc-89eb-4173-a37a-7381d5fba12f container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/24 16:49:08.379
  I0419 16:49:08.418270 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-1705" for this suite. @ 04/19/24 16:49:08.431
• [4.195 seconds]
------------------------------
  E0419 16:49:08.447171      14 retrywatcher.go:129] "Watch failed" err="context canceled"
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:140
  STEP: Creating a kubernetes client @ 04/19/24 16:49:08.452
  I0419 16:49:08.452690 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename emptydir @ 04/19/24 16:49:08.457
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:49:08.493
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:49:08.5
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 04/19/24 16:49:08.51
  E0419 16:49:09.447704      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:10.448234      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:11.448503      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:12.449173      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:49:12.559
  I0419 16:49:12.568712 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-5e155a33-5bc1-4211-8309-d2ec621734bd container test-container: <nil>
  STEP: delete the pod @ 04/19/24 16:49:12.588
  I0419 16:49:12.639092 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5509" for this suite. @ 04/19/24 16:49:12.655
• [4.220 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:443
  STEP: Creating a kubernetes client @ 04/19/24 16:49:12.673
  I0419 16:49:12.673900 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename daemonsets @ 04/19/24 16:49:12.682
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:49:12.713
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:49:12.721
  I0419 16:49:12.785825 14 daemon_set.go:447] Create a RollingUpdate DaemonSet
  I0419 16:49:12.796827 14 daemon_set.go:454] Check that daemon pods launch on every node of the cluster
  I0419 16:49:12.820576 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0419 16:49:12.821381 14 fixtures.go:130] Node eipo9quoh3ef-1 is running 0 daemon pod, expected 1
  E0419 16:49:13.450179      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:49:13.822181 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0419 16:49:13.822252 14 fixtures.go:130] Node eipo9quoh3ef-1 is running 0 daemon pod, expected 1
  E0419 16:49:14.450896      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:49:14.826820 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0419 16:49:14.826895 14 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  I0419 16:49:14.826934 14 daemon_set.go:458] Update the DaemonSet to trigger a rollout
  I0419 16:49:14.856802 14 daemon_set.go:102] Updating DaemonSet daemon-set
  E0419 16:49:15.450972      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:49:15.913163 14 daemon_set.go:493] Roll back the DaemonSet before rollout is complete
  I0419 16:49:15.936383 14 daemon_set.go:102] Updating DaemonSet daemon-set
  I0419 16:49:15.936496 14 daemon_set.go:499] Make sure DaemonSet rollback is complete
  I0419 16:49:15.947216 14 daemon_set.go:1178] Wrong image for pod: daemon-set-xqd47. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-4, got: foo:non-existent.
  I0419 16:49:15.947664 14 daemon_set.go:1183] Pod daemon-set-xqd47 is not available
  E0419 16:49:16.452118      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:17.453154      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:18.454049      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:19.454402      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:20.457348      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:49:20.954576 14 daemon_set.go:1183] Pod daemon-set-ptwbw is not available
  STEP: Deleting DaemonSet "daemon-set" @ 04/19/24 16:49:20.983
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3825, will wait for the garbage collector to delete the pods @ 04/19/24 16:49:20.983
  I0419 16:49:21.052090 14 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 11.072532ms
  I0419 16:49:21.153064 14 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.999008ms
  E0419 16:49:21.458334      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:22.459251      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:49:22.963033 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0419 16:49:22.963137 14 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0419 16:49:22.970779 14 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"23555"},"items":null}

  I0419 16:49:22.979099 14 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"23555"},"items":null}

  I0419 16:49:23.017182 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-3825" for this suite. @ 04/19/24 16:49:23.028
• [10.367 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] Job should delete a job [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:668
  STEP: Creating a kubernetes client @ 04/19/24 16:49:23.043
  I0419 16:49:23.043420 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename job @ 04/19/24 16:49:23.046
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:49:23.078
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:49:23.085
  STEP: Creating a job @ 04/19/24 16:49:23.093
  STEP: Ensuring active pods == parallelism @ 04/19/24 16:49:23.103
  E0419 16:49:23.459511      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:24.459706      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete a job @ 04/19/24 16:49:25.115
  STEP: deleting Job.batch foo in namespace job-9198, will wait for the garbage collector to delete the pods @ 04/19/24 16:49:25.115
  I0419 16:49:25.190835 14 resources.go:139] Deleting Job.batch foo took: 17.629716ms
  I0419 16:49:25.292272 14 resources.go:163] Terminating Job.batch foo pods took: 101.435623ms
  E0419 16:49:25.460226      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:26.461273      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring job was deleted @ 04/19/24 16:49:26.693
  I0419 16:49:26.699839 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-9198" for this suite. @ 04/19/24 16:49:26.709
• [3.681 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:836
  STEP: Creating a kubernetes client @ 04/19/24 16:49:26.734
  I0419 16:49:26.734975 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename daemonsets @ 04/19/24 16:49:26.737
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:49:26.762
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:49:26.768
  STEP: Creating simple DaemonSet "daemon-set" @ 04/19/24 16:49:26.814
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/19/24 16:49:26.824
  I0419 16:49:26.846874 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0419 16:49:26.847523 14 fixtures.go:130] Node eipo9quoh3ef-1 is running 0 daemon pod, expected 1
  E0419 16:49:27.461451      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:49:27.868309 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0419 16:49:27.869022 14 fixtures.go:130] Node eipo9quoh3ef-1 is running 0 daemon pod, expected 1
  E0419 16:49:28.461381      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:49:28.845880 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0419 16:49:28.845984 14 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: listing all DaemonSets @ 04/19/24 16:49:28.859
  STEP: DeleteCollection of the DaemonSets @ 04/19/24 16:49:28.868
  STEP: Verify that ReplicaSets have been deleted @ 04/19/24 16:49:28.884
  I0419 16:49:28.930131 14 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"23682"},"items":null}

  I0419 16:49:28.954749 14 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"23682"},"items":[{"metadata":{"name":"daemon-set-69c9s","generateName":"daemon-set-","namespace":"daemonsets-1893","uid":"3a766a76-89b1-47a4-b7b5-399156fe2462","resourceVersion":"23680","creationTimestamp":"2024-04-19T16:49:26Z","deletionTimestamp":"2024-04-19T16:49:58Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7d79bd845c","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"d82924d9-2f14-4448-9901-eef77558771c","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-04-19T16:49:26Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d82924d9-2f14-4448-9901-eef77558771c\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-04-19T16:49:28Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.93\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-vhtxn","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-vhtxn","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"eipo9quoh3ef-1","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["eipo9quoh3ef-1"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-19T16:49:28Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-19T16:49:26Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-19T16:49:28Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-19T16:49:28Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-19T16:49:26Z"}],"hostIP":"192.168.121.38","hostIPs":[{"ip":"192.168.121.38"}],"podIP":"10.233.64.93","podIPs":[{"ip":"10.233.64.93"}],"startTime":"2024-04-19T16:49:26Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-04-19T16:49:27Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"cri-o://96ee248b879fb04171b3af25fea1282f722491485c7c3a02f7e3c50f30a1dfe5","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-98kt5","generateName":"daemon-set-","namespace":"daemonsets-1893","uid":"c71c8962-095d-47c2-a105-7d6b8c37b937","resourceVersion":"23681","creationTimestamp":"2024-04-19T16:49:26Z","deletionTimestamp":"2024-04-19T16:49:58Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7d79bd845c","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"d82924d9-2f14-4448-9901-eef77558771c","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-04-19T16:49:26Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d82924d9-2f14-4448-9901-eef77558771c\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-04-19T16:49:27Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.15\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-l7vk4","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-l7vk4","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"eipo9quoh3ef-3","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["eipo9quoh3ef-3"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-19T16:49:27Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-19T16:49:26Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-19T16:49:27Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-19T16:49:27Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-19T16:49:26Z"}],"hostIP":"192.168.121.127","hostIPs":[{"ip":"192.168.121.127"}],"podIP":"10.233.66.15","podIPs":[{"ip":"10.233.66.15"}],"startTime":"2024-04-19T16:49:26Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-04-19T16:49:27Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"cri-o://7ebb5bc1e4f91e0f806a53a93ff6daff67f546b39644d460c73b98379947f8bc","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-p6npb","generateName":"daemon-set-","namespace":"daemonsets-1893","uid":"bdeab875-973a-4eb3-b874-9343d1753b06","resourceVersion":"23679","creationTimestamp":"2024-04-19T16:49:26Z","deletionTimestamp":"2024-04-19T16:49:58Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7d79bd845c","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"d82924d9-2f14-4448-9901-eef77558771c","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-04-19T16:49:26Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d82924d9-2f14-4448-9901-eef77558771c\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-04-19T16:49:27Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.70\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-qlm92","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-qlm92","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"eipo9quoh3ef-2","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["eipo9quoh3ef-2"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-19T16:49:27Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-19T16:49:26Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-19T16:49:27Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-19T16:49:27Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-19T16:49:26Z"}],"hostIP":"192.168.121.197","hostIPs":[{"ip":"192.168.121.197"}],"podIP":"10.233.65.70","podIPs":[{"ip":"10.233.65.70"}],"startTime":"2024-04-19T16:49:26Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-04-19T16:49:27Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"cri-o://43b14711c3e1b1feaf554bc8ffc2d8bb550c314e5f53e832f49e08507b83cf11","started":true}],"qosClass":"BestEffort"}}]}

  I0419 16:49:28.988399 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-1893" for this suite. @ 04/19/24 16:49:28.994
• [2.270 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:334
  STEP: Creating a kubernetes client @ 04/19/24 16:49:29.004
  I0419 16:49:29.005008 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename watch @ 04/19/24 16:49:29.007
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:49:29.024
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:49:29.028
  STEP: getting a starting resourceVersion @ 04/19/24 16:49:29.033
  STEP: starting a background goroutine to produce watch events @ 04/19/24 16:49:29.044
  STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order @ 04/19/24 16:49:29.044
  E0419 16:49:29.461770      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:30.462158      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:31.463149      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:49:31.829641 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-3706" for this suite. @ 04/19/24 16:49:31.865
• [2.913 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/controller_revision.go:126
  STEP: Creating a kubernetes client @ 04/19/24 16:49:31.923
  I0419 16:49:31.923429 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename controllerrevisions @ 04/19/24 16:49:31.927
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:49:31.949
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:49:31.955
  STEP: Creating DaemonSet "e2e-bbxrd-daemon-set" @ 04/19/24 16:49:32.004
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/19/24 16:49:32.021
  I0419 16:49:32.080350 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset e2e-bbxrd-daemon-set: 0
  I0419 16:49:32.080829 14 fixtures.go:130] Node eipo9quoh3ef-1 is running 0 daemon pod, expected 1
  E0419 16:49:32.463399      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:49:33.040779 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset e2e-bbxrd-daemon-set: 1
  I0419 16:49:33.041651 14 fixtures.go:130] Node eipo9quoh3ef-1 is running 0 daemon pod, expected 1
  E0419 16:49:33.465619      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:49:34.050646 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset e2e-bbxrd-daemon-set: 3
  I0419 16:49:34.051306 14 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset e2e-bbxrd-daemon-set
  STEP: Confirm DaemonSet "e2e-bbxrd-daemon-set" successfully created with "daemonset-name=e2e-bbxrd-daemon-set" label @ 04/19/24 16:49:34.064
  STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-bbxrd-daemon-set" @ 04/19/24 16:49:34.083
  I0419 16:49:34.092168 14 controller_revision.go:162] Located ControllerRevision: "e2e-bbxrd-daemon-set-6c48f49dd9"
  STEP: Patching ControllerRevision "e2e-bbxrd-daemon-set-6c48f49dd9" @ 04/19/24 16:49:34.102
  I0419 16:49:34.133259 14 controller_revision.go:173] e2e-bbxrd-daemon-set-6c48f49dd9 has been patched
  STEP: Create a new ControllerRevision @ 04/19/24 16:49:34.133
  I0419 16:49:34.143589 14 controller_revision.go:191] Created ControllerRevision: e2e-bbxrd-daemon-set-848fc5f7f5
  STEP: Confirm that there are two ControllerRevisions @ 04/19/24 16:49:34.144
  I0419 16:49:34.145230 14 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0419 16:49:34.156624 14 controller_revision.go:265] Found 2 ControllerRevisions
  STEP: Deleting ControllerRevision "e2e-bbxrd-daemon-set-6c48f49dd9" @ 04/19/24 16:49:34.157
  STEP: Confirm that there is only one ControllerRevision @ 04/19/24 16:49:34.171
  I0419 16:49:34.171925 14 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0419 16:49:34.182028 14 controller_revision.go:265] Found 1 ControllerRevisions
  STEP: Updating ControllerRevision "e2e-bbxrd-daemon-set-848fc5f7f5" @ 04/19/24 16:49:34.189
  I0419 16:49:34.212350 14 controller_revision.go:220] e2e-bbxrd-daemon-set-848fc5f7f5 has been updated
  STEP: Generate another ControllerRevision by patching the Daemonset @ 04/19/24 16:49:34.213
  W0419 16:49:34.237046      14 warnings.go:70] unknown field "updateStrategy"
  STEP: Confirm that there are two ControllerRevisions @ 04/19/24 16:49:34.237
  I0419 16:49:34.238213 14 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  E0419 16:49:34.464988      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:49:35.238555 14 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0419 16:49:35.248322 14 controller_revision.go:265] Found 2 ControllerRevisions
  STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-bbxrd-daemon-set-848fc5f7f5=updated" @ 04/19/24 16:49:35.249
  STEP: Confirm that there is only one ControllerRevision @ 04/19/24 16:49:35.273
  I0419 16:49:35.274662 14 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0419 16:49:35.282959 14 controller_revision.go:265] Found 1 ControllerRevisions
  I0419 16:49:35.289719 14 controller_revision.go:246] ControllerRevision "e2e-bbxrd-daemon-set-664c47f44b" has revision 3
  STEP: Deleting DaemonSet "e2e-bbxrd-daemon-set" @ 04/19/24 16:49:35.295
  STEP: deleting DaemonSet.extensions e2e-bbxrd-daemon-set in namespace controllerrevisions-8432, will wait for the garbage collector to delete the pods @ 04/19/24 16:49:35.295
  I0419 16:49:35.365470 14 resources.go:139] Deleting DaemonSet.extensions e2e-bbxrd-daemon-set took: 11.549854ms
  E0419 16:49:35.465188      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:49:35.466590 14 resources.go:163] Terminating DaemonSet.extensions e2e-bbxrd-daemon-set pods took: 101.114981ms
  E0419 16:49:36.466663      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:37.466979      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:49:37.673247 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset e2e-bbxrd-daemon-set: 0
  I0419 16:49:37.673621 14 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset e2e-bbxrd-daemon-set
  I0419 16:49:37.680522 14 controller_revision.go:73] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"23954"},"items":null}

  I0419 16:49:37.688538 14 controller_revision.go:78] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"23954"},"items":null}

  I0419 16:49:37.718120 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "controllerrevisions-8432" for this suite. @ 04/19/24 16:49:37.725
• [5.812 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:70
  STEP: Creating a kubernetes client @ 04/19/24 16:49:37.735
  I0419 16:49:37.735562 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename projected @ 04/19/24 16:49:37.738
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:49:37.76
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:49:37.765
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 16:49:37.77
  E0419 16:49:38.467819      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:39.468648      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:40.469109      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:41.469883      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:49:41.807
  I0419 16:49:41.813979 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod downwardapi-volume-d5dca6dc-d24b-4b10-93e1-2a2c66c09df7 container client-container: <nil>
  STEP: delete the pod @ 04/19/24 16:49:41.834
  I0419 16:49:41.864500 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4645" for this suite. @ 04/19/24 16:49:41.875
• [4.152 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:695
  STEP: Creating a kubernetes client @ 04/19/24 16:49:41.887
  I0419 16:49:41.887797 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename resourcequota @ 04/19/24 16:49:41.891
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:49:41.919
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:49:41.924
  STEP: Creating a ResourceQuota with terminating scope @ 04/19/24 16:49:41.932
  STEP: Ensuring ResourceQuota status is calculated @ 04/19/24 16:49:41.941
  E0419 16:49:42.470658      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:43.470582      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not terminating scope @ 04/19/24 16:49:43.951
  STEP: Ensuring ResourceQuota status is calculated @ 04/19/24 16:49:43.962
  E0419 16:49:44.470983      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:45.471285      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a long running pod @ 04/19/24 16:49:45.974
  STEP: Ensuring resource quota with not terminating scope captures the pod usage @ 04/19/24 16:49:46.01
  E0419 16:49:46.471654      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:47.472183      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with terminating scope ignored the pod usage @ 04/19/24 16:49:48.023
  E0419 16:49:48.473147      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:49.473382      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 04/19/24 16:49:50.035
  STEP: Ensuring resource quota status released the pod usage @ 04/19/24 16:49:50.089
  E0419 16:49:50.473735      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:51.473943      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a terminating pod @ 04/19/24 16:49:52.102
  STEP: Ensuring resource quota with terminating scope captures the pod usage @ 04/19/24 16:49:52.137
  E0419 16:49:52.475105      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:53.475240      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not terminating scope ignored the pod usage @ 04/19/24 16:49:54.156
  E0419 16:49:54.475997      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:55.476659      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 04/19/24 16:49:56.171
  STEP: Ensuring resource quota status released the pod usage @ 04/19/24 16:49:56.208
  E0419 16:49:56.476489      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:57.476823      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:49:58.218814 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5326" for this suite. @ 04/19/24 16:49:58.229
• [16.360 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:238
  STEP: Creating a kubernetes client @ 04/19/24 16:49:58.256
  I0419 16:49:58.256865 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename webhook @ 04/19/24 16:49:58.264
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:49:58.3
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:49:58.309
  STEP: Setting up server cert @ 04/19/24 16:49:58.364
  E0419 16:49:58.477260      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:59.477571      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 16:49:59.696
  STEP: Deploying the webhook pod @ 04/19/24 16:49:59.714
  STEP: Wait for the deployment to be ready @ 04/19/24 16:49:59.739
  I0419 16:49:59.765454 14 deployment.go:222] new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0419 16:50:00.478391      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:01.478917      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 16:50:01.795
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 16:50:01.831
  E0419 16:50:02.479305      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:50:02.832011 14 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API @ 04/19/24 16:50:02.857
  STEP: create a namespace for the webhook @ 04/19/24 16:50:02.921
  STEP: create a configmap should be unconditionally rejected by the webhook @ 04/19/24 16:50:02.946
  I0419 16:50:03.066755 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5888" for this suite. @ 04/19/24 16:50:03.075
  STEP: Destroying namespace "webhook-markers-7139" for this suite. @ 04/19/24 16:50:03.085
  STEP: Destroying namespace "fail-closed-namespace-4109" for this suite. @ 04/19/24 16:50:03.098
• [4.854 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface for CRDs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:303
  STEP: Creating a kubernetes client @ 04/19/24 16:50:03.122
  I0419 16:50:03.123104 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename aggregateddiscovery @ 04/19/24 16:50:03.125
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:50:03.155
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:50:03.16
  I0419 16:50:03.165958 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  E0419 16:50:03.479345      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:04.479448      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:05.479644      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:50:06.267069 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-4641" for this suite. @ 04/19/24 16:50:06.281
• [3.178 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Hostname [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:244
  STEP: Creating a kubernetes client @ 04/19/24 16:50:06.302
  I0419 16:50:06.302631 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename dns @ 04/19/24 16:50:06.306
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:50:06.349
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:50:06.357
  STEP: Creating a test headless service @ 04/19/24 16:50:06.367
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-8636.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-8636.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
   @ 04/19/24 16:50:06.39
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-8636.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-8636.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
   @ 04/19/24 16:50:06.392
  STEP: creating a pod to probe DNS @ 04/19/24 16:50:06.394
  STEP: submitting the pod to kubernetes @ 04/19/24 16:50:06.395
  E0419 16:50:06.480145      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:07.481621      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/19/24 16:50:08.436
  STEP: looking for the results for each expected name from probers @ 04/19/24 16:50:08.444
  E0419 16:50:08.481014      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:50:08.515290 14 dns_common.go:478] Unable to read jessie_hosts@dns-querier-2 from pod dns-8636/dns-test-a13ef13a-329c-4065-9ce5-4b191ca64545: the server could not find the requested resource (get pods dns-test-a13ef13a-329c-4065-9ce5-4b191ca64545)
  I0419 16:50:08.515717 14 dns_common.go:489] Lookups using dns-8636/dns-test-a13ef13a-329c-4065-9ce5-4b191ca64545 failed for: [jessie_hosts@dns-querier-2]

  I0419 16:50:08.530879 14 dns_common.go:495] Pod client logs for webserver: 
  I0419 16:50:08.544296 14 dns_common.go:495] Pod client logs for querier: 
  I0419 16:50:08.562920 14 dns_common.go:495] Pod client logs for jessie-querier: 
  E0419 16:50:09.482551      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:10.481914      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:11.481796      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:12.484368      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:13.482463      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:50:13.514418 14 dns_common.go:527] DNS probes using dns-8636/dns-test-a13ef13a-329c-4065-9ce5-4b191ca64545 succeeded

  STEP: deleting the pod @ 04/19/24 16:50:13.515
  STEP: deleting the test headless service @ 04/19/24 16:50:13.571
  I0419 16:50:13.614479 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-8636" for this suite. @ 04/19/24 16:50:13.628
• [7.342 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:446
  STEP: Creating a kubernetes client @ 04/19/24 16:50:13.645
  I0419 16:50:13.645708 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename sched-pred @ 04/19/24 16:50:13.651
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:50:13.677
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:50:13.682
  I0419 16:50:13.694893 14 helper.go:121] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0419 16:50:13.721214 14 util.go:400] Waiting for terminating namespaces to be deleted...
  I0419 16:50:13.727182 14 predicates.go:121] 
  Logging pods the apiserver thinks is on node eipo9quoh3ef-1 before test
  I0419 16:50:13.742610 14 predicates.go:887] kube-addon-manager-eipo9quoh3ef-1 from kube-system started at 2024-04-19 15:40:13 +0000 UTC (1 container statuses recorded)
  I0419 16:50:13.742973 14 predicates.go:889] 	Container kube-addon-manager ready: true, restart count 1
  I0419 16:50:13.743333 14 predicates.go:887] kube-apiserver-eipo9quoh3ef-1 from kube-system started at 2024-04-19 15:40:13 +0000 UTC (1 container statuses recorded)
  I0419 16:50:13.743635 14 predicates.go:889] 	Container kube-apiserver ready: true, restart count 1
  I0419 16:50:13.743959 14 predicates.go:887] kube-controller-manager-eipo9quoh3ef-1 from kube-system started at 2024-04-19 15:40:13 +0000 UTC (1 container statuses recorded)
  I0419 16:50:13.744265 14 predicates.go:889] 	Container kube-controller-manager ready: true, restart count 1
  I0419 16:50:13.744563 14 predicates.go:887] kube-flannel-ds-nk72d from kube-system started at 2024-04-19 15:44:46 +0000 UTC (1 container statuses recorded)
  I0419 16:50:13.744820 14 predicates.go:889] 	Container kube-flannel ready: true, restart count 0
  I0419 16:50:13.745141 14 predicates.go:887] kube-proxy-fpxst from kube-system started at 2024-04-19 15:44:45 +0000 UTC (1 container statuses recorded)
  I0419 16:50:13.745385 14 predicates.go:889] 	Container kube-proxy ready: true, restart count 0
  I0419 16:50:13.745687 14 predicates.go:887] kube-scheduler-eipo9quoh3ef-1 from kube-system started at 2024-04-19 15:40:13 +0000 UTC (1 container statuses recorded)
  I0419 16:50:13.745909 14 predicates.go:889] 	Container kube-scheduler ready: true, restart count 1
  I0419 16:50:13.746217 14 predicates.go:887] sonobuoy-systemd-logs-daemon-set-946d96f11a954c8b-87528 from sonobuoy started at 2024-04-19 15:45:05 +0000 UTC (2 container statuses recorded)
  I0419 16:50:13.746519 14 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0419 16:50:13.746779 14 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  I0419 16:50:13.747044 14 predicates.go:121] 
  Logging pods the apiserver thinks is on node eipo9quoh3ef-2 before test
  I0419 16:50:13.761840 14 predicates.go:887] coredns-7db6d8ff4d-2k6mj from kube-system started at 2024-04-19 15:44:44 +0000 UTC (1 container statuses recorded)
  I0419 16:50:13.762321 14 predicates.go:889] 	Container coredns ready: true, restart count 0
  I0419 16:50:13.762716 14 predicates.go:887] kube-addon-manager-eipo9quoh3ef-2 from kube-system started at 2024-04-19 15:34:39 +0000 UTC (1 container statuses recorded)
  I0419 16:50:13.763037 14 predicates.go:889] 	Container kube-addon-manager ready: true, restart count 1
  I0419 16:50:13.763369 14 predicates.go:887] kube-apiserver-eipo9quoh3ef-2 from kube-system started at 2024-04-19 15:34:39 +0000 UTC (1 container statuses recorded)
  I0419 16:50:13.763693 14 predicates.go:889] 	Container kube-apiserver ready: true, restart count 1
  I0419 16:50:13.764018 14 predicates.go:887] kube-controller-manager-eipo9quoh3ef-2 from kube-system started at 2024-04-19 15:34:39 +0000 UTC (1 container statuses recorded)
  I0419 16:50:13.764340 14 predicates.go:889] 	Container kube-controller-manager ready: true, restart count 1
  I0419 16:50:13.764636 14 predicates.go:887] kube-flannel-ds-nw295 from kube-system started at 2024-04-19 15:44:46 +0000 UTC (1 container statuses recorded)
  I0419 16:50:13.764938 14 predicates.go:889] 	Container kube-flannel ready: true, restart count 0
  I0419 16:50:13.765235 14 predicates.go:887] kube-proxy-thxpg from kube-system started at 2024-04-19 15:44:45 +0000 UTC (1 container statuses recorded)
  I0419 16:50:13.765496 14 predicates.go:889] 	Container kube-proxy ready: true, restart count 0
  I0419 16:50:13.765767 14 predicates.go:887] kube-scheduler-eipo9quoh3ef-2 from kube-system started at 2024-04-19 15:34:39 +0000 UTC (1 container statuses recorded)
  I0419 16:50:13.766043 14 predicates.go:889] 	Container kube-scheduler ready: true, restart count 1
  I0419 16:50:13.766354 14 predicates.go:887] sonobuoy-systemd-logs-daemon-set-946d96f11a954c8b-bhgtx from sonobuoy started at 2024-04-19 15:45:05 +0000 UTC (2 container statuses recorded)
  I0419 16:50:13.766764 14 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0419 16:50:13.767958 14 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  I0419 16:50:13.768986 14 predicates.go:121] 
  Logging pods the apiserver thinks is on node eipo9quoh3ef-3 before test
  I0419 16:50:13.784696 14 predicates.go:887] coredns-7db6d8ff4d-bcl67 from kube-system started at 2024-04-19 15:44:44 +0000 UTC (1 container statuses recorded)
  I0419 16:50:13.785123 14 predicates.go:889] 	Container coredns ready: true, restart count 0
  I0419 16:50:13.785517 14 predicates.go:887] kube-flannel-ds-p5c44 from kube-system started at 2024-04-19 15:44:46 +0000 UTC (1 container statuses recorded)
  I0419 16:50:13.785830 14 predicates.go:889] 	Container kube-flannel ready: true, restart count 0
  I0419 16:50:13.786161 14 predicates.go:887] kube-proxy-nh75b from kube-system started at 2024-04-19 15:44:45 +0000 UTC (1 container statuses recorded)
  I0419 16:50:13.786499 14 predicates.go:889] 	Container kube-proxy ready: true, restart count 0
  I0419 16:50:13.786839 14 predicates.go:887] sonobuoy from sonobuoy started at 2024-04-19 15:45:04 +0000 UTC (1 container statuses recorded)
  I0419 16:50:13.787164 14 predicates.go:889] 	Container kube-sonobuoy ready: true, restart count 0
  I0419 16:50:13.787491 14 predicates.go:887] sonobuoy-e2e-job-154f7ff9c64444f9 from sonobuoy started at 2024-04-19 15:45:05 +0000 UTC (2 container statuses recorded)
  I0419 16:50:13.787820 14 predicates.go:889] 	Container e2e ready: true, restart count 0
  I0419 16:50:13.788090 14 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0419 16:50:13.788398 14 predicates.go:887] sonobuoy-systemd-logs-daemon-set-946d96f11a954c8b-hhhbm from sonobuoy started at 2024-04-19 15:45:05 +0000 UTC (2 container statuses recorded)
  I0419 16:50:13.788680 14 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0419 16:50:13.788937 14 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to schedule Pod with nonempty NodeSelector. @ 04/19/24 16:50:13.789
  STEP: Considering event: 
  Type = [Warning], Name = [restricted-pod.17c7bc79a1e0b32d], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.] @ 04/19/24 16:50:13.839
  E0419 16:50:14.483866      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:50:14.844614 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-1958" for this suite. @ 04/19/24 16:50:14.86
• [1.242 seconds]
------------------------------
SS
------------------------------
[sig-network] Services should find a service from listing all namespaces [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3136
  STEP: Creating a kubernetes client @ 04/19/24 16:50:14.888
  I0419 16:50:14.888180 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename services @ 04/19/24 16:50:14.894
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:50:14.929
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:50:14.935
  STEP: fetching services @ 04/19/24 16:50:14.943
  I0419 16:50:14.952361 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1332" for this suite. @ 04/19/24 16:50:14.966
• [0.092 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:120
  STEP: Creating a kubernetes client @ 04/19/24 16:50:14.982
  I0419 16:50:14.982149 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename emptydir @ 04/19/24 16:50:14.984
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:50:15.007
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:50:15.012
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 04/19/24 16:50:15.018
  E0419 16:50:15.483670      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:16.483901      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:17.484013      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:18.485217      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:50:19.065
  I0419 16:50:19.073105 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-fbb1c001-c833-47f4-8a2d-47c8881e4890 container test-container: <nil>
  STEP: delete the pod @ 04/19/24 16:50:19.087
  I0419 16:50:19.112709 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2988" for this suite. @ 04/19/24 16:50:19.119
• [4.150 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1693
  STEP: Creating a kubernetes client @ 04/19/24 16:50:19.136
  I0419 16:50:19.136810 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename kubectl @ 04/19/24 16:50:19.139
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:50:19.172
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:50:19.18
  STEP: creating Agnhost RC @ 04/19/24 16:50:19.187
  I0419 16:50:19.188115 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-6159 create -f -'
  E0419 16:50:19.485944      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:50:19.560590 14 builder.go:146] stderr: ""
  I0419 16:50:19.560659 14 builder.go:147] stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 04/19/24 16:50:19.56
  E0419 16:50:20.486356      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:50:20.568859 14 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0419 16:50:20.569036 14 framework.go:733] Found 0 / 1
  E0419 16:50:21.486776      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:50:21.571029 14 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0419 16:50:21.571164 14 framework.go:733] Found 1 / 1
  I0419 16:50:21.571242 14 framework.go:742] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  STEP: patching all pods @ 04/19/24 16:50:21.571
  I0419 16:50:21.578269 14 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0419 16:50:21.578406 14 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0419 16:50:21.579241 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-6159 patch pod agnhost-primary-tbb94 -p {"metadata":{"annotations":{"x":"y"}}}'
  I0419 16:50:21.794222 14 builder.go:146] stderr: ""
  I0419 16:50:21.794330 14 builder.go:147] stdout: "pod/agnhost-primary-tbb94 patched\n"
  STEP: checking annotations @ 04/19/24 16:50:21.794
  I0419 16:50:21.802393 14 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0419 16:50:21.802466 14 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0419 16:50:21.802650 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6159" for this suite. @ 04/19/24 16:50:21.812
• [2.689 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:170
  STEP: Creating a kubernetes client @ 04/19/24 16:50:21.826
  I0419 16:50:21.826806 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 04/19/24 16:50:21.829
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:50:21.856
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:50:21.86
  STEP: create the container to handle the HTTPGet hook request. @ 04/19/24 16:50:21.872
  E0419 16:50:22.487976      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:23.489122      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 04/19/24 16:50:23.914
  E0419 16:50:24.489156      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:25.490108      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 04/19/24 16:50:25.955
  STEP: delete the pod with lifecycle hook @ 04/19/24 16:50:25.999
  E0419 16:50:26.489776      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:27.490583      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:50:28.037917 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-5088" for this suite. @ 04/19/24 16:50:28.051
• [6.242 seconds]
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:334
  STEP: Creating a kubernetes client @ 04/19/24 16:50:28.069
  I0419 16:50:28.069788 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename sched-pred @ 04/19/24 16:50:28.072
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:50:28.107
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:50:28.114
  I0419 16:50:28.123106 14 helper.go:121] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0419 16:50:28.153093 14 util.go:400] Waiting for terminating namespaces to be deleted...
  I0419 16:50:28.163118 14 predicates.go:121] 
  Logging pods the apiserver thinks is on node eipo9quoh3ef-1 before test
  I0419 16:50:28.177883 14 predicates.go:887] pod-handle-http-request from container-lifecycle-hook-5088 started at 2024-04-19 16:50:21 +0000 UTC (2 container statuses recorded)
  I0419 16:50:28.177935 14 predicates.go:889] 	Container container-handle-http-request ready: true, restart count 0
  I0419 16:50:28.177959 14 predicates.go:889] 	Container container-handle-https-request ready: true, restart count 0
  I0419 16:50:28.178040 14 predicates.go:887] kube-addon-manager-eipo9quoh3ef-1 from kube-system started at 2024-04-19 15:40:13 +0000 UTC (1 container statuses recorded)
  I0419 16:50:28.178063 14 predicates.go:889] 	Container kube-addon-manager ready: true, restart count 1
  I0419 16:50:28.178154 14 predicates.go:887] kube-apiserver-eipo9quoh3ef-1 from kube-system started at 2024-04-19 15:40:13 +0000 UTC (1 container statuses recorded)
  I0419 16:50:28.178172 14 predicates.go:889] 	Container kube-apiserver ready: true, restart count 1
  I0419 16:50:28.178244 14 predicates.go:887] kube-controller-manager-eipo9quoh3ef-1 from kube-system started at 2024-04-19 15:40:13 +0000 UTC (1 container statuses recorded)
  I0419 16:50:28.178261 14 predicates.go:889] 	Container kube-controller-manager ready: true, restart count 1
  I0419 16:50:28.178328 14 predicates.go:887] kube-flannel-ds-nk72d from kube-system started at 2024-04-19 15:44:46 +0000 UTC (1 container statuses recorded)
  I0419 16:50:28.178349 14 predicates.go:889] 	Container kube-flannel ready: true, restart count 0
  I0419 16:50:28.178435 14 predicates.go:887] kube-proxy-fpxst from kube-system started at 2024-04-19 15:44:45 +0000 UTC (1 container statuses recorded)
  I0419 16:50:28.178469 14 predicates.go:889] 	Container kube-proxy ready: true, restart count 0
  I0419 16:50:28.178538 14 predicates.go:887] kube-scheduler-eipo9quoh3ef-1 from kube-system started at 2024-04-19 15:40:13 +0000 UTC (1 container statuses recorded)
  I0419 16:50:28.178557 14 predicates.go:889] 	Container kube-scheduler ready: true, restart count 1
  I0419 16:50:28.178627 14 predicates.go:887] sonobuoy-systemd-logs-daemon-set-946d96f11a954c8b-87528 from sonobuoy started at 2024-04-19 15:45:05 +0000 UTC (2 container statuses recorded)
  I0419 16:50:28.178647 14 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0419 16:50:28.178723 14 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  I0419 16:50:28.178742 14 predicates.go:121] 
  Logging pods the apiserver thinks is on node eipo9quoh3ef-2 before test
  I0419 16:50:28.200011 14 predicates.go:887] coredns-7db6d8ff4d-2k6mj from kube-system started at 2024-04-19 15:44:44 +0000 UTC (1 container statuses recorded)
  I0419 16:50:28.200804 14 predicates.go:889] 	Container coredns ready: true, restart count 0
  I0419 16:50:28.201570 14 predicates.go:887] kube-addon-manager-eipo9quoh3ef-2 from kube-system started at 2024-04-19 15:34:39 +0000 UTC (1 container statuses recorded)
  I0419 16:50:28.202226 14 predicates.go:889] 	Container kube-addon-manager ready: true, restart count 1
  I0419 16:50:28.202932 14 predicates.go:887] kube-apiserver-eipo9quoh3ef-2 from kube-system started at 2024-04-19 15:34:39 +0000 UTC (1 container statuses recorded)
  I0419 16:50:28.203654 14 predicates.go:889] 	Container kube-apiserver ready: true, restart count 1
  I0419 16:50:28.204359 14 predicates.go:887] kube-controller-manager-eipo9quoh3ef-2 from kube-system started at 2024-04-19 15:34:39 +0000 UTC (1 container statuses recorded)
  I0419 16:50:28.204999 14 predicates.go:889] 	Container kube-controller-manager ready: true, restart count 1
  I0419 16:50:28.205777 14 predicates.go:887] kube-flannel-ds-nw295 from kube-system started at 2024-04-19 15:44:46 +0000 UTC (1 container statuses recorded)
  I0419 16:50:28.206503 14 predicates.go:889] 	Container kube-flannel ready: true, restart count 0
  I0419 16:50:28.207140 14 predicates.go:887] kube-proxy-thxpg from kube-system started at 2024-04-19 15:44:45 +0000 UTC (1 container statuses recorded)
  I0419 16:50:28.207740 14 predicates.go:889] 	Container kube-proxy ready: true, restart count 0
  I0419 16:50:28.208357 14 predicates.go:887] kube-scheduler-eipo9quoh3ef-2 from kube-system started at 2024-04-19 15:34:39 +0000 UTC (1 container statuses recorded)
  I0419 16:50:28.209301 14 predicates.go:889] 	Container kube-scheduler ready: true, restart count 1
  I0419 16:50:28.209900 14 predicates.go:887] sonobuoy-systemd-logs-daemon-set-946d96f11a954c8b-bhgtx from sonobuoy started at 2024-04-19 15:45:05 +0000 UTC (2 container statuses recorded)
  I0419 16:50:28.210553 14 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0419 16:50:28.211166 14 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  I0419 16:50:28.211700 14 predicates.go:121] 
  Logging pods the apiserver thinks is on node eipo9quoh3ef-3 before test
  I0419 16:50:28.231209 14 predicates.go:887] coredns-7db6d8ff4d-bcl67 from kube-system started at 2024-04-19 15:44:44 +0000 UTC (1 container statuses recorded)
  I0419 16:50:28.231272 14 predicates.go:889] 	Container coredns ready: true, restart count 0
  I0419 16:50:28.231368 14 predicates.go:887] kube-flannel-ds-p5c44 from kube-system started at 2024-04-19 15:44:46 +0000 UTC (1 container statuses recorded)
  I0419 16:50:28.231390 14 predicates.go:889] 	Container kube-flannel ready: true, restart count 0
  I0419 16:50:28.231458 14 predicates.go:887] kube-proxy-nh75b from kube-system started at 2024-04-19 15:44:45 +0000 UTC (1 container statuses recorded)
  I0419 16:50:28.231479 14 predicates.go:889] 	Container kube-proxy ready: true, restart count 0
  I0419 16:50:28.231497 14 predicates.go:887] sonobuoy from sonobuoy started at 2024-04-19 15:45:04 +0000 UTC (1 container statuses recorded)
  I0419 16:50:28.231561 14 predicates.go:889] 	Container kube-sonobuoy ready: true, restart count 0
  I0419 16:50:28.231581 14 predicates.go:887] sonobuoy-e2e-job-154f7ff9c64444f9 from sonobuoy started at 2024-04-19 15:45:05 +0000 UTC (2 container statuses recorded)
  I0419 16:50:28.231639 14 predicates.go:889] 	Container e2e ready: true, restart count 0
  I0419 16:50:28.231659 14 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0419 16:50:28.231738 14 predicates.go:887] sonobuoy-systemd-logs-daemon-set-946d96f11a954c8b-hhhbm from sonobuoy started at 2024-04-19 15:45:05 +0000 UTC (2 container statuses recorded)
  I0419 16:50:28.231778 14 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0419 16:50:28.231855 14 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  STEP: verifying the node has the label node eipo9quoh3ef-1 @ 04/19/24 16:50:28.277
  STEP: verifying the node has the label node eipo9quoh3ef-2 @ 04/19/24 16:50:28.306
  STEP: verifying the node has the label node eipo9quoh3ef-3 @ 04/19/24 16:50:28.339
  I0419 16:50:28.374444 14 predicates.go:374] Pod pod-handle-http-request requesting resource cpu=0m on Node eipo9quoh3ef-1
  I0419 16:50:28.374529 14 predicates.go:374] Pod coredns-7db6d8ff4d-2k6mj requesting resource cpu=100m on Node eipo9quoh3ef-2
  I0419 16:50:28.374549 14 predicates.go:374] Pod coredns-7db6d8ff4d-bcl67 requesting resource cpu=100m on Node eipo9quoh3ef-3
  I0419 16:50:28.374567 14 predicates.go:374] Pod kube-addon-manager-eipo9quoh3ef-1 requesting resource cpu=5m on Node eipo9quoh3ef-1
  I0419 16:50:28.374585 14 predicates.go:374] Pod kube-addon-manager-eipo9quoh3ef-2 requesting resource cpu=5m on Node eipo9quoh3ef-2
  I0419 16:50:28.374602 14 predicates.go:374] Pod kube-apiserver-eipo9quoh3ef-1 requesting resource cpu=250m on Node eipo9quoh3ef-1
  I0419 16:50:28.374619 14 predicates.go:374] Pod kube-apiserver-eipo9quoh3ef-2 requesting resource cpu=250m on Node eipo9quoh3ef-2
  I0419 16:50:28.374635 14 predicates.go:374] Pod kube-controller-manager-eipo9quoh3ef-1 requesting resource cpu=200m on Node eipo9quoh3ef-1
  I0419 16:50:28.374661 14 predicates.go:374] Pod kube-controller-manager-eipo9quoh3ef-2 requesting resource cpu=200m on Node eipo9quoh3ef-2
  I0419 16:50:28.374677 14 predicates.go:374] Pod kube-flannel-ds-nk72d requesting resource cpu=100m on Node eipo9quoh3ef-1
  I0419 16:50:28.374699 14 predicates.go:374] Pod kube-flannel-ds-nw295 requesting resource cpu=100m on Node eipo9quoh3ef-2
  I0419 16:50:28.374718 14 predicates.go:374] Pod kube-flannel-ds-p5c44 requesting resource cpu=100m on Node eipo9quoh3ef-3
  I0419 16:50:28.374735 14 predicates.go:374] Pod kube-proxy-fpxst requesting resource cpu=0m on Node eipo9quoh3ef-1
  I0419 16:50:28.374750 14 predicates.go:374] Pod kube-proxy-nh75b requesting resource cpu=0m on Node eipo9quoh3ef-3
  I0419 16:50:28.374766 14 predicates.go:374] Pod kube-proxy-thxpg requesting resource cpu=0m on Node eipo9quoh3ef-2
  I0419 16:50:28.374782 14 predicates.go:374] Pod kube-scheduler-eipo9quoh3ef-1 requesting resource cpu=100m on Node eipo9quoh3ef-1
  I0419 16:50:28.378447 14 predicates.go:374] Pod kube-scheduler-eipo9quoh3ef-2 requesting resource cpu=100m on Node eipo9quoh3ef-2
  I0419 16:50:28.378477 14 predicates.go:374] Pod sonobuoy requesting resource cpu=0m on Node eipo9quoh3ef-3
  I0419 16:50:28.378496 14 predicates.go:374] Pod sonobuoy-e2e-job-154f7ff9c64444f9 requesting resource cpu=0m on Node eipo9quoh3ef-3
  I0419 16:50:28.378512 14 predicates.go:374] Pod sonobuoy-systemd-logs-daemon-set-946d96f11a954c8b-87528 requesting resource cpu=0m on Node eipo9quoh3ef-1
  I0419 16:50:28.378529 14 predicates.go:374] Pod sonobuoy-systemd-logs-daemon-set-946d96f11a954c8b-bhgtx requesting resource cpu=0m on Node eipo9quoh3ef-2
  I0419 16:50:28.378563 14 predicates.go:374] Pod sonobuoy-systemd-logs-daemon-set-946d96f11a954c8b-hhhbm requesting resource cpu=0m on Node eipo9quoh3ef-3
  STEP: Starting Pods to consume most of the cluster CPU. @ 04/19/24 16:50:28.378
  I0419 16:50:28.378648 14 predicates.go:384] Creating a pod which consumes cpu=661m on Node eipo9quoh3ef-1
  I0419 16:50:28.398532 14 predicates.go:384] Creating a pod which consumes cpu=591m on Node eipo9quoh3ef-2
  I0419 16:50:28.409967 14 predicates.go:384] Creating a pod which consumes cpu=980m on Node eipo9quoh3ef-3
  E0419 16:50:28.492139      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:29.491095      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating another pod that requires unavailable amount of CPU. @ 04/19/24 16:50:30.465
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-066d5190-f243-4b65-a3fc-670300334066.17c7bc7d08c76659], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3785/filler-pod-066d5190-f243-4b65-a3fc-670300334066 to eipo9quoh3ef-3] @ 04/19/24 16:50:30.484
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-066d5190-f243-4b65-a3fc-670300334066.17c7bc7d24f167dd], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 04/19/24 16:50:30.484
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-066d5190-f243-4b65-a3fc-670300334066.17c7bc7d2d2b7ba0], Reason = [Created], Message = [Created container filler-pod-066d5190-f243-4b65-a3fc-670300334066] @ 04/19/24 16:50:30.485
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-066d5190-f243-4b65-a3fc-670300334066.17c7bc7d2fc74c5f], Reason = [Started], Message = [Started container filler-pod-066d5190-f243-4b65-a3fc-670300334066] @ 04/19/24 16:50:30.485
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-9bc638d6-8f35-4acd-aab9-9b2999a7bd2d.17c7bc7d08c27553], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3785/filler-pod-9bc638d6-8f35-4acd-aab9-9b2999a7bd2d to eipo9quoh3ef-2] @ 04/19/24 16:50:30.486
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-9bc638d6-8f35-4acd-aab9-9b2999a7bd2d.17c7bc7d27f6075a], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 04/19/24 16:50:30.486
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-9bc638d6-8f35-4acd-aab9-9b2999a7bd2d.17c7bc7d30421549], Reason = [Created], Message = [Created container filler-pod-9bc638d6-8f35-4acd-aab9-9b2999a7bd2d] @ 04/19/24 16:50:30.486
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-9bc638d6-8f35-4acd-aab9-9b2999a7bd2d.17c7bc7d33ad2ba3], Reason = [Started], Message = [Started container filler-pod-9bc638d6-8f35-4acd-aab9-9b2999a7bd2d] @ 04/19/24 16:50:30.487
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-c253338c-fd18-4bc7-9e38-efd5bf01f03b.17c7bc7d06e2dc6f], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3785/filler-pod-c253338c-fd18-4bc7-9e38-efd5bf01f03b to eipo9quoh3ef-1] @ 04/19/24 16:50:30.488
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-c253338c-fd18-4bc7-9e38-efd5bf01f03b.17c7bc7d28682879], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 04/19/24 16:50:30.488
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-c253338c-fd18-4bc7-9e38-efd5bf01f03b.17c7bc7d3075383e], Reason = [Created], Message = [Created container filler-pod-c253338c-fd18-4bc7-9e38-efd5bf01f03b] @ 04/19/24 16:50:30.488
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-c253338c-fd18-4bc7-9e38-efd5bf01f03b.17c7bc7d320a4e11], Reason = [Started], Message = [Started container filler-pod-c253338c-fd18-4bc7-9e38-efd5bf01f03b] @ 04/19/24 16:50:30.488
  E0419 16:50:30.491492      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Considering event: 
  Type = [Warning], Name = [additional-pod.17c7bc7d8406ebca], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod.] @ 04/19/24 16:50:30.519
  E0419 16:50:31.491979      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label node off the node eipo9quoh3ef-3 @ 04/19/24 16:50:31.523
  STEP: verifying the node doesn't have the label node @ 04/19/24 16:50:31.558
  STEP: removing the label node off the node eipo9quoh3ef-1 @ 04/19/24 16:50:31.574
  STEP: verifying the node doesn't have the label node @ 04/19/24 16:50:31.607
  STEP: removing the label node off the node eipo9quoh3ef-2 @ 04/19/24 16:50:31.616
  STEP: verifying the node doesn't have the label node @ 04/19/24 16:50:31.641
  I0419 16:50:31.647344 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-3785" for this suite. @ 04/19/24 16:50:31.665
• [3.620 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should allow expressions to refer variables. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:221
  STEP: Creating a kubernetes client @ 04/19/24 16:50:31.69
  I0419 16:50:31.690605 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename validating-admission-policy @ 04/19/24 16:50:31.694
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:50:31.716
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:50:31.723
  STEP: creating a policy with variables @ 04/19/24 16:50:31.744
  STEP: waiting until the marker is denied @ 04/19/24 16:50:31.813
  E0419 16:50:32.492852      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: testing a replicated Deployment to be allowed @ 04/19/24 16:50:32.809
  STEP: testing a non-replicated ReplicaSet not to be denied @ 04/19/24 16:50:32.875
  I0419 16:50:33.101340 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-7305" for this suite. @ 04/19/24 16:50:33.114
• [1.456 seconds]
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:69
  STEP: Creating a kubernetes client @ 04/19/24 16:50:33.148
  I0419 16:50:33.149216 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename subpath @ 04/19/24 16:50:33.163
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:50:33.23
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:50:33.249
  STEP: Setting up data @ 04/19/24 16:50:33.26
  STEP: Creating pod pod-subpath-test-configmap-rdss @ 04/19/24 16:50:33.292
  STEP: Creating a pod to test atomic-volume-subpath @ 04/19/24 16:50:33.292
  E0419 16:50:33.493721      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:34.494299      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:35.494977      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:36.496474      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:37.496471      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:38.496719      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:39.497717      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:40.498601      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:41.500648      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:42.501031      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:43.501094      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:44.502151      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:45.503042      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:46.503504      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:47.504561      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:48.505185      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:49.506139      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:50.506329      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:51.506711      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:52.507120      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:53.507651      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:54.508531      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:55.509427      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:56.511593      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:50:57.473
  I0419 16:50:57.484635 14 output.go:196] Trying to get logs from node eipo9quoh3ef-1 pod pod-subpath-test-configmap-rdss container test-container-subpath-configmap-rdss: <nil>
  STEP: delete the pod @ 04/19/24 16:50:57.504
  E0419 16:50:57.510447      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting pod pod-subpath-test-configmap-rdss @ 04/19/24 16:50:57.547
  I0419 16:50:57.547165 14 delete.go:62] Deleting pod "pod-subpath-test-configmap-rdss" in namespace "subpath-2465"
  I0419 16:50:57.553911 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-2465" for this suite. @ 04/19/24 16:50:57.564
• [24.445 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:103
  STEP: Creating a kubernetes client @ 04/19/24 16:50:57.595
  I0419 16:50:57.595248 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename resourcequota @ 04/19/24 16:50:57.599
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:50:57.627
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:50:57.631
  STEP: Counting existing ResourceQuota @ 04/19/24 16:50:57.639
  E0419 16:50:58.511032      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:59.511233      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:00.511543      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:01.523133      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:02.513949      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 04/19/24 16:51:02.651
  STEP: Ensuring resource quota status is calculated @ 04/19/24 16:51:02.667
  E0419 16:51:03.514022      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:04.514889      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Service @ 04/19/24 16:51:04.682
  STEP: Creating a NodePort Service @ 04/19/24 16:51:04.741
  STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota @ 04/19/24 16:51:04.813
  STEP: Ensuring resource quota status captures service creation @ 04/19/24 16:51:04.86
  E0419 16:51:05.524456      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:06.524453      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting Services @ 04/19/24 16:51:06.872
  STEP: Ensuring resource quota status released usage @ 04/19/24 16:51:06.952
  E0419 16:51:07.525352      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:08.526333      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:51:08.967233 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-424" for this suite. @ 04/19/24 16:51:08.981
• [11.403 seconds]
------------------------------
SSS
------------------------------
[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslicemirroring.go:55
  STEP: Creating a kubernetes client @ 04/19/24 16:51:09.02
  I0419 16:51:09.021049 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename endpointslicemirroring @ 04/19/24 16:51:09.028
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:51:09.072
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:51:09.08
  STEP: mirroring a new custom Endpoint @ 04/19/24 16:51:09.114
  I0419 16:51:09.133233 14 endpointslicemirroring.go:96] Waiting for at least 1 EndpointSlice to exist, got 0
  E0419 16:51:09.526561      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:10.527222      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mirroring an update to a custom Endpoint @ 04/19/24 16:51:11.158
  I0419 16:51:11.180510 14 endpointslicemirroring.go:171] Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
  E0419 16:51:11.527134      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:12.527439      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mirroring deletion of a custom Endpoint @ 04/19/24 16:51:13.196
  I0419 16:51:13.226240 14 endpointslicemirroring.go:194] Waiting for 0 EndpointSlices to exist, got 1
  E0419 16:51:13.528121      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:14.528203      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:51:15.235991 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslicemirroring-6487" for this suite. @ 04/19/24 16:51:15.258
• [6.264 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:227
  STEP: Creating a kubernetes client @ 04/19/24 16:51:15.293
  I0419 16:51:15.294295 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename pods @ 04/19/24 16:51:15.301
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:51:15.335
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:51:15.343
  STEP: creating the pod @ 04/19/24 16:51:15.349
  STEP: setting up watch @ 04/19/24 16:51:15.35
  STEP: submitting the pod to kubernetes @ 04/19/24 16:51:15.458
  STEP: verifying the pod is in kubernetes @ 04/19/24 16:51:15.477
  STEP: verifying pod creation was observed @ 04/19/24 16:51:15.489
  E0419 16:51:15.528215      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:16.529195      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 04/19/24 16:51:17.515
  E0419 16:51:17.530009      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying pod deletion was observed @ 04/19/24 16:51:17.534
  I0419 16:51:18.358437 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5917" for this suite. @ 04/19/24 16:51:18.369
• [3.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:177
  STEP: Creating a kubernetes client @ 04/19/24 16:51:18.384
  I0419 16:51:18.384258 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename daemonsets @ 04/19/24 16:51:18.387
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:51:18.413
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:51:18.421
  STEP: Creating simple DaemonSet "daemon-set" @ 04/19/24 16:51:18.465
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/19/24 16:51:18.476
  I0419 16:51:18.492556 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0419 16:51:18.492766 14 fixtures.go:130] Node eipo9quoh3ef-1 is running 0 daemon pod, expected 1
  E0419 16:51:18.531048      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:51:19.499518 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0419 16:51:19.499603 14 fixtures.go:130] Node eipo9quoh3ef-1 is running 0 daemon pod, expected 1
  E0419 16:51:19.533721      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:51:20.498854 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0419 16:51:20.499380 14 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Stop a daemon pod, check that the daemon pod is revived. @ 04/19/24 16:51:20.506
  E0419 16:51:20.534341      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:51:20.590651 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0419 16:51:20.591122 14 fixtures.go:130] Node eipo9quoh3ef-2 is running 0 daemon pod, expected 1
  E0419 16:51:21.535071      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:51:21.613210 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0419 16:51:21.613288 14 fixtures.go:130] Node eipo9quoh3ef-2 is running 0 daemon pod, expected 1
  E0419 16:51:22.535578      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:51:22.577088 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0419 16:51:22.577849 14 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 04/19/24 16:51:22.586
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2701, will wait for the garbage collector to delete the pods @ 04/19/24 16:51:22.586
  I0419 16:51:22.659327 14 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 13.957242ms
  I0419 16:51:22.760519 14 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 101.147434ms
  E0419 16:51:23.537043      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:24.537643      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:51:24.568743 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0419 16:51:24.569792 14 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0419 16:51:24.582650 14 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"24940"},"items":null}

  I0419 16:51:24.590595 14 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"24940"},"items":null}

  I0419 16:51:24.629457 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-2701" for this suite. @ 04/19/24 16:51:24.641
• [6.271 seconds]
------------------------------
[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/empty_dir_wrapper.go:67
  STEP: Creating a kubernetes client @ 04/19/24 16:51:24.657
  I0419 16:51:24.657220 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename emptydir-wrapper @ 04/19/24 16:51:24.663
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:51:24.691
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:51:24.698
  E0419 16:51:25.538515      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:26.539551      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Cleaning up the secret @ 04/19/24 16:51:26.782
  STEP: Cleaning up the configmap @ 04/19/24 16:51:26.806
  STEP: Cleaning up the pod @ 04/19/24 16:51:26.828
  I0419 16:51:26.863455 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-7727" for this suite. @ 04/19/24 16:51:26.875
• [2.233 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should allow opting out of API token automount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:163
  STEP: Creating a kubernetes client @ 04/19/24 16:51:26.9
  I0419 16:51:26.900201 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename svcaccounts @ 04/19/24 16:51:26.904
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:51:26.946
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:51:26.955
  I0419 16:51:27.002483 14 service_accounts.go:253] created pod pod-service-account-defaultsa
  I0419 16:51:27.002968 14 service_accounts.go:267] pod pod-service-account-defaultsa service account token volume mount: true
  I0419 16:51:27.012851 14 service_accounts.go:253] created pod pod-service-account-mountsa
  I0419 16:51:27.013400 14 service_accounts.go:267] pod pod-service-account-mountsa service account token volume mount: true
  I0419 16:51:27.027524 14 service_accounts.go:253] created pod pod-service-account-nomountsa
  I0419 16:51:27.027607 14 service_accounts.go:267] pod pod-service-account-nomountsa service account token volume mount: false
  I0419 16:51:27.050320 14 service_accounts.go:253] created pod pod-service-account-defaultsa-mountspec
  I0419 16:51:27.050825 14 service_accounts.go:267] pod pod-service-account-defaultsa-mountspec service account token volume mount: true
  I0419 16:51:27.061901 14 service_accounts.go:253] created pod pod-service-account-mountsa-mountspec
  I0419 16:51:27.061958 14 service_accounts.go:267] pod pod-service-account-mountsa-mountspec service account token volume mount: true
  I0419 16:51:27.082257 14 service_accounts.go:253] created pod pod-service-account-nomountsa-mountspec
  I0419 16:51:27.082339 14 service_accounts.go:267] pod pod-service-account-nomountsa-mountspec service account token volume mount: true
  I0419 16:51:27.097927 14 service_accounts.go:253] created pod pod-service-account-defaultsa-nomountspec
  I0419 16:51:27.097996 14 service_accounts.go:267] pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
  I0419 16:51:27.162489 14 service_accounts.go:253] created pod pod-service-account-mountsa-nomountspec
  I0419 16:51:27.162950 14 service_accounts.go:267] pod pod-service-account-mountsa-nomountspec service account token volume mount: false
  I0419 16:51:27.214277 14 service_accounts.go:253] created pod pod-service-account-nomountsa-nomountspec
  I0419 16:51:27.214704 14 service_accounts.go:267] pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
  I0419 16:51:27.215220 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-8875" for this suite. @ 04/19/24 16:51:27.268
• [0.406 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:270
  STEP: Creating a kubernetes client @ 04/19/24 16:51:27.306
  I0419 16:51:27.306415 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/19/24 16:51:27.309
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:51:27.368
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:51:27.373
  I0419 16:51:27.380185 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  E0419 16:51:27.540435      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:28.541496      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:29.541831      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:30.542506      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:51:30.869728 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-6414" for this suite. @ 04/19/24 16:51:30.886
• [3.598 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
k8s.io/kubernetes/test/e2e/node/taints.go:290
  STEP: Creating a kubernetes client @ 04/19/24 16:51:30.912
  I0419 16:51:30.913652 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename taint-single-pod @ 04/19/24 16:51:30.918
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:51:30.971
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:51:30.977
  I0419 16:51:30.986284 14 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0419 16:51:31.543822      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:32.557898      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:33.559020      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:34.559138      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:35.559448      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:36.560000      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:37.561219      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:38.562287      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:39.563179      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:40.563363      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:41.563478      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:42.563948      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:43.565568      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:44.565307      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:45.566037      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:46.567229      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:47.568311      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:48.569171      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:49.569542      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:50.570481      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:51.572110      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:52.571776      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:53.572102      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:54.573350      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:55.573507      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:56.579185      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:57.577612      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:58.578477      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:59.578911      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:00.579039      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:01.579494      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:02.580066      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:03.581580      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:04.581957      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:05.581985      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:06.582236      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:07.582453      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:08.583103      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:09.584172      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:10.586599      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:11.585258      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:12.586254      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:13.588386      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:14.589390      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:15.590158      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:16.591210      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:17.592393      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:18.592792      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:19.593239      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:20.594177      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:21.594548      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:22.595263      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:23.595499      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:24.595849      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:25.596181      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:26.596359      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:27.596716      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:28.597091      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:29.598121      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:30.598845      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:52:30.988603 14 util.go:400] Waiting for terminating namespaces to be deleted...
  I0419 16:52:31.000143 14 taints.go:150] Starting informer...
  STEP: Starting pod... @ 04/19/24 16:52:31.001
  I0419 16:52:31.238993 14 taints.go:300] Pod is running on eipo9quoh3ef-3. Tainting Node
  STEP: Trying to apply a taint on the Node @ 04/19/24 16:52:31.239
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 04/19/24 16:52:31.284
  STEP: Waiting short time to make sure Pod is queued for deletion @ 04/19/24 16:52:31.306
  I0419 16:52:31.308156 14 taints.go:319] Pod wasn't evicted. Proceeding
  I0419 16:52:31.311261 14 taints.go:326] Removing taint from Node
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 04/19/24 16:52:31.373
  STEP: Waiting some time to make sure that toleration time passed. @ 04/19/24 16:52:31.384
  E0419 16:52:31.599210      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:32.599709      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:33.599781      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:34.600470      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:35.600616      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:36.600633      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:37.600850      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:38.601975      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:39.602173      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:40.602558      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:41.602657      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:42.602975      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:43.604097      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:44.604794      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:45.605251      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:46.609514      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:47.606961      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:48.608089      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:49.609068      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:50.609419      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:51.609648      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:52.610072      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:53.611028      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:54.612150      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:55.612693      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:56.613835      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:57.614244      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:58.615304      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:59.615672      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:00.616050      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:01.616524      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:02.616595      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:03.617685      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:04.618061      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:05.618293      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:06.619764      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:07.620412      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:08.620603      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:09.621614      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:10.621921      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:11.622438      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:12.622793      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:13.623789      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:14.624712      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:15.625039      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:16.625278      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:17.625470      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:18.625692      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:19.626742      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:20.627746      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:21.627762      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:22.628159      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:23.629266      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:24.630516      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:25.630618      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:26.630774      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:27.631145      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:28.631906      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:29.632861      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:30.633274      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:31.633358      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:32.635525      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:33.636362      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:34.637050      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:35.637236      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:36.637878      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:37.638308      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:38.638884      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:39.639388      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:40.639907      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:41.640801      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:42.641433      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:43.642576      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:44.641948      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:45.642144      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:53:46.386349 14 taints.go:335] Pod wasn't evicted. Test successful
  I0419 16:53:46.387345 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-single-pod-6744" for this suite. @ 04/19/24 16:53:46.406
• [135.516 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:445
  STEP: Creating a kubernetes client @ 04/19/24 16:53:46.43
  I0419 16:53:46.430784 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename pods @ 04/19/24 16:53:46.436
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:53:46.478
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:53:46.489
  E0419 16:53:46.643405      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:47.644776      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:48.643910      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:49.644380      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:50.644525      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:51.645684      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:52.645809      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:53:52.652
  I0419 16:53:52.667668 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod client-envvars-196ddd38-381e-4ebd-9484-5042d5427f17 container env3cont: <nil>
  STEP: delete the pod @ 04/19/24 16:53:52.715
  I0419 16:53:52.751004 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-3528" for this suite. @ 04/19/24 16:53:52.763
• [6.348 seconds]
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:215
  STEP: Creating a kubernetes client @ 04/19/24 16:53:52.779
  I0419 16:53:52.779534 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 04/19/24 16:53:52.785
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:53:52.813
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:53:52.82
  STEP: create the container to handle the HTTPGet hook request. @ 04/19/24 16:53:52.842
  E0419 16:53:53.646843      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:54.647583      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 04/19/24 16:53:54.91
  E0419 16:53:55.647636      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:56.648047      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 04/19/24 16:53:56.971
  E0419 16:53:57.648259      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:58.653168      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 04/19/24 16:53:59.003
  I0419 16:53:59.045051 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-9611" for this suite. @ 04/19/24 16:53:59.056
• [6.294 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:90
  STEP: Creating a kubernetes client @ 04/19/24 16:53:59.078
  I0419 16:53:59.078826 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename emptydir @ 04/19/24 16:53:59.082
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:53:59.116
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:53:59.127
  STEP: Creating a pod to test emptydir volume type on tmpfs @ 04/19/24 16:53:59.137
  E0419 16:53:59.652409      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:00.653540      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:01.654333      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:02.654694      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:54:03.19
  I0419 16:54:03.197661 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-88e5dcc0-e8ae-496c-a98a-99f5a3b19168 container test-container: <nil>
  STEP: delete the pod @ 04/19/24 16:54:03.213
  I0419 16:54:03.244371 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7788" for this suite. @ 04/19/24 16:54:03.252
• [4.188 seconds]
------------------------------
[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance] [sig-scheduling, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/limit_range.go:62
  STEP: Creating a kubernetes client @ 04/19/24 16:54:03.266
  I0419 16:54:03.266998 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename limitrange @ 04/19/24 16:54:03.27
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:54:03.302
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:54:03.308
  STEP: Creating a LimitRange @ 04/19/24 16:54:03.32
  STEP: Setting up watch @ 04/19/24 16:54:03.32
  STEP: Submitting a LimitRange @ 04/19/24 16:54:03.429
  STEP: Verifying LimitRange creation was observed @ 04/19/24 16:54:03.451
  STEP: Fetching the LimitRange to ensure it has proper values @ 04/19/24 16:54:03.451
  I0419 16:54:03.459305 14 limit_range.go:355] Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  I0419 16:54:03.460174 14 limit_range.go:360] Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with no resource requirements @ 04/19/24 16:54:03.463
  STEP: Ensuring Pod has resource requirements applied from LimitRange @ 04/19/24 16:54:03.485
  I0419 16:54:03.497336 14 limit_range.go:355] Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  I0419 16:54:03.497440 14 limit_range.go:360] Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with partial resource requirements @ 04/19/24 16:54:03.497
  STEP: Ensuring Pod has merged resource requirements applied from LimitRange @ 04/19/24 16:54:03.509
  I0419 16:54:03.516554 14 limit_range.go:355] Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
  I0419 16:54:03.516634 14 limit_range.go:360] Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Failing to create a Pod with less than min resources @ 04/19/24 16:54:03.516
  STEP: Failing to create a Pod with more than max resources @ 04/19/24 16:54:03.52
  STEP: Updating a LimitRange @ 04/19/24 16:54:03.526
  STEP: Verifying LimitRange updating is effective @ 04/19/24 16:54:03.538
  E0419 16:54:03.655138      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:04.655087      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Pod with less than former min resources @ 04/19/24 16:54:05.55
  STEP: Failing to create a Pod with more than max resources @ 04/19/24 16:54:05.589
  STEP: Deleting a LimitRange @ 04/19/24 16:54:05.595
  STEP: Verifying the LimitRange was deleted @ 04/19/24 16:54:05.624
  E0419 16:54:05.656197      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:06.656784      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:07.656989      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:08.657174      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:09.657407      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:54:10.637872 14 limit_range.go:211] limitRange is already deleted
  STEP: Creating a Pod with more than former max resources @ 04/19/24 16:54:10.638
  E0419 16:54:10.658261      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:54:10.670021 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-6098" for this suite. @ 04/19/24 16:54:10.694
• [7.443 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
  STEP: Creating a kubernetes client @ 04/19/24 16:54:10.712
  I0419 16:54:10.712334 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename kubectl @ 04/19/24 16:54:10.717
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:54:10.745
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:54:10.751
  STEP: create deployment with httpd image @ 04/19/24 16:54:10.759
  I0419 16:54:10.762962 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-4912 create -f -'
  I0419 16:54:11.054012 14 builder.go:146] stderr: ""
  I0419 16:54:11.054174 14 builder.go:147] stdout: "deployment.apps/httpd-deployment created\n"
  STEP: verify diff finds difference between live and declared image @ 04/19/24 16:54:11.054
  I0419 16:54:11.056100 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-4912 diff -f -'
  I0419 16:54:11.392023 14 builder.go:135] rc: 1
  I0419 16:54:11.392589 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-4912 delete -f -'
  I0419 16:54:11.571198 14 builder.go:146] stderr: ""
  I0419 16:54:11.571270 14 builder.go:147] stdout: "deployment.apps \"httpd-deployment\" deleted\n"
  I0419 16:54:11.571462 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4912" for this suite. @ 04/19/24 16:54:11.582
• [0.883 seconds]
------------------------------
[sig-network] Services should test the lifecycle of an Endpoint [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3161
  STEP: Creating a kubernetes client @ 04/19/24 16:54:11.596
  I0419 16:54:11.596202 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename services @ 04/19/24 16:54:11.599
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:54:11.625
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:54:11.63
  STEP: creating an Endpoint @ 04/19/24 16:54:11.641
  STEP: waiting for available Endpoint @ 04/19/24 16:54:11.652
  STEP: listing all Endpoints @ 04/19/24 16:54:11.658
  E0419 16:54:11.658554      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: updating the Endpoint @ 04/19/24 16:54:11.665
  STEP: fetching the Endpoint @ 04/19/24 16:54:11.676
  STEP: patching the Endpoint @ 04/19/24 16:54:11.681
  STEP: fetching the Endpoint @ 04/19/24 16:54:11.698
  STEP: deleting the Endpoint by Collection @ 04/19/24 16:54:11.703
  STEP: waiting for Endpoint deletion @ 04/19/24 16:54:11.717
  STEP: fetching the Endpoint @ 04/19/24 16:54:11.721
  I0419 16:54:11.724841 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9702" for this suite. @ 04/19/24 16:54:11.731
• [0.147 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:109
  STEP: Creating a kubernetes client @ 04/19/24 16:54:11.745
  I0419 16:54:11.745544 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename kubelet-test @ 04/19/24 16:54:11.751
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:54:11.774
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:54:11.779
  E0419 16:54:12.659654      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:13.660794      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:14.661320      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:15.662131      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:54:15.820191 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-5379" for this suite. @ 04/19/24 16:54:15.84
• [4.113 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:453
  STEP: Creating a kubernetes client @ 04/19/24 16:54:15.864
  I0419 16:54:15.865278 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename resourcequota @ 04/19/24 16:54:15.869
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:54:15.921
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:54:15.927
  STEP: Counting existing ResourceQuota @ 04/19/24 16:54:15.933
  E0419 16:54:16.662492      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:17.662648      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:18.662838      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:19.663742      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:20.664142      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 04/19/24 16:54:20.965
  STEP: Ensuring resource quota status is calculated @ 04/19/24 16:54:20.977
  E0419 16:54:21.665028      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:22.665228      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ReplicaSet @ 04/19/24 16:54:22.989
  STEP: Ensuring resource quota status captures replicaset creation @ 04/19/24 16:54:23.024
  E0419 16:54:23.665694      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:24.666457      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicaSet @ 04/19/24 16:54:25.038
  STEP: Ensuring resource quota status released usage @ 04/19/24 16:54:25.065
  E0419 16:54:25.666216      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:26.667120      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:54:27.075233 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-7817" for this suite. @ 04/19/24 16:54:27.089
• [11.241 seconds]
------------------------------
S
------------------------------
[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:269
  STEP: Creating a kubernetes client @ 04/19/24 16:54:27.106
  I0419 16:54:27.106662 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename downward-api @ 04/19/24 16:54:27.109
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:54:27.159
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:54:27.168
  STEP: Creating a pod to test downward api env vars @ 04/19/24 16:54:27.176
  E0419 16:54:27.667777      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:28.668068      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:29.668454      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:30.669293      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:54:31.232
  I0419 16:54:31.240186 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod downward-api-3f7b19af-6351-4da9-9aaf-a9bdf1b23d75 container dapi-container: <nil>
  STEP: delete the pod @ 04/19/24 16:54:31.257
  I0419 16:54:31.297416 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-244" for this suite. @ 04/19/24 16:54:31.316
• [4.225 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:962
  STEP: Creating a kubernetes client @ 04/19/24 16:54:31.338
  I0419 16:54:31.338576 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename statefulset @ 04/19/24 16:54:31.344
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:54:31.375
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:54:31.382
  STEP: Creating service test in namespace statefulset-1369 @ 04/19/24 16:54:31.391
  I0419 16:54:31.419842 14 wait.go:40] Found 0 stateful pods, waiting for 1
  E0419 16:54:31.669613      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:32.670255      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:33.670972      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:34.671279      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:35.671488      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:36.671654      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:37.672042      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:38.673148      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:39.674065      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:40.674850      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:54:41.427854 14 wait.go:50] Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: patching the StatefulSet @ 04/19/24 16:54:41.447
  W0419 16:54:41.480123      14 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
  I0419 16:54:41.503843 14 wait.go:40] Found 1 stateful pods, waiting for 2
  E0419 16:54:41.675917      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:42.677063      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:43.677945      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:44.677981      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:45.678609      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:46.679166      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:47.679584      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:48.680217      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:49.680502      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:50.681406      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:54:51.499518 14 wait.go:50] Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I0419 16:54:51.499971 14 wait.go:50] Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Listing all StatefulSets @ 04/19/24 16:54:51.525
  STEP: Delete all of the StatefulSets @ 04/19/24 16:54:51.537
  STEP: Verify that StatefulSets have been deleted @ 04/19/24 16:54:51.585
  I0419 16:54:51.606806 14 statefulset.go:135] Deleting all statefulset in ns statefulset-1369
  I0419 16:54:51.671101 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0419 16:54:51.681312      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "statefulset-1369" for this suite. @ 04/19/24 16:54:51.701
• [20.386 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:250
  STEP: Creating a kubernetes client @ 04/19/24 16:54:51.725
  I0419 16:54:51.725114 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename webhook @ 04/19/24 16:54:51.727
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:54:51.749
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:54:51.754
  STEP: Setting up server cert @ 04/19/24 16:54:51.828
  E0419 16:54:52.683496      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 16:54:53.434
  STEP: Deploying the webhook pod @ 04/19/24 16:54:53.454
  STEP: Wait for the deployment to be ready @ 04/19/24 16:54:53.486
  I0419 16:54:53.516486 14 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0419 16:54:53.683930      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:54.684219      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 16:54:55.548
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 16:54:55.572
  E0419 16:54:55.685296      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:54:56.572581 14 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating configmap webhook via the AdmissionRegistration API @ 04/19/24 16:54:56.588
  STEP: create a configmap that should be updated by the webhook @ 04/19/24 16:54:56.629
  E0419 16:54:56.685167      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:54:56.747767 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8953" for this suite. @ 04/19/24 16:54:56.765
  STEP: Destroying namespace "webhook-markers-2003" for this suite. @ 04/19/24 16:54:56.783
• [5.069 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:622
  STEP: Creating a kubernetes client @ 04/19/24 16:54:56.795
  I0419 16:54:56.795430 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename field-validation @ 04/19/24 16:54:56.799
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:54:56.829
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:54:56.835
  I0419 16:54:56.850597 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  E0419 16:54:57.685798      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:58.687124      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0419 16:54:59.624197      14 warnings.go:70] unknown field "alpha"
  W0419 16:54:59.624245      14 warnings.go:70] unknown field "beta"
  W0419 16:54:59.624257      14 warnings.go:70] unknown field "delta"
  W0419 16:54:59.624268      14 warnings.go:70] unknown field "epsilon"
  W0419 16:54:59.624278      14 warnings.go:70] unknown field "gamma"
  E0419 16:54:59.687842      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:55:00.217272 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-2900" for this suite. @ 04/19/24 16:55:00.228
• [3.453 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2203
  STEP: Creating a kubernetes client @ 04/19/24 16:55:00.25
  I0419 16:55:00.250582 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename services @ 04/19/24 16:55:00.253
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:55:00.287
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:55:00.294
  STEP: creating service in namespace services-1394 @ 04/19/24 16:55:00.3
  STEP: creating service affinity-clusterip-transition in namespace services-1394 @ 04/19/24 16:55:00.301
  STEP: creating replication controller affinity-clusterip-transition in namespace services-1394 @ 04/19/24 16:55:00.324
  I0419 16:55:00.340532      14 runners.go:198] Created replication controller with name: affinity-clusterip-transition, namespace: services-1394, replica count: 3
  E0419 16:55:00.689147      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:01.690182      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:02.691083      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:55:03.391703      14 runners.go:198] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0419 16:55:03.409410 14 resource.go:361] Creating new exec pod
  E0419 16:55:03.692301      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:04.694117      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:05.694994      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:55:06.453697 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-1394 exec execpod-affinityjwrc9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
  E0419 16:55:06.695318      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:55:06.810366 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
  I0419 16:55:06.810557 14 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0419 16:55:06.810865 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-1394 exec execpod-affinityjwrc9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.52.89 80'
  I0419 16:55:07.107545 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.52.89 80\nConnection to 10.233.52.89 80 port [tcp/http] succeeded!\n"
  I0419 16:55:07.107627 14 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0419 16:55:07.133945 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-1394 exec execpod-affinityjwrc9 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.52.89:80/ ; done'
  I0419 16:55:07.562830 14 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.89:80/\n"
  I0419 16:55:07.562934 14 builder.go:147] stdout: "\naffinity-clusterip-transition-twjrh\naffinity-clusterip-transition-tzb9b\naffinity-clusterip-transition-l8sbm\naffinity-clusterip-transition-tzb9b\naffinity-clusterip-transition-twjrh\naffinity-clusterip-transition-tzb9b\naffinity-clusterip-transition-tzb9b\naffinity-clusterip-transition-twjrh\naffinity-clusterip-transition-tzb9b\naffinity-clusterip-transition-tzb9b\naffinity-clusterip-transition-tzb9b\naffinity-clusterip-transition-twjrh\naffinity-clusterip-transition-l8sbm\naffinity-clusterip-transition-tzb9b\naffinity-clusterip-transition-tzb9b\naffinity-clusterip-transition-tzb9b"
  I0419 16:55:07.562976 14 service.go:242] Received response from host: affinity-clusterip-transition-twjrh
  I0419 16:55:07.562998 14 service.go:242] Received response from host: affinity-clusterip-transition-tzb9b
  I0419 16:55:07.563021 14 service.go:242] Received response from host: affinity-clusterip-transition-l8sbm
  I0419 16:55:07.563038 14 service.go:242] Received response from host: affinity-clusterip-transition-tzb9b
  I0419 16:55:07.563055 14 service.go:242] Received response from host: affinity-clusterip-transition-twjrh
  I0419 16:55:07.563071 14 service.go:242] Received response from host: affinity-clusterip-transition-tzb9b
  I0419 16:55:07.563101 14 service.go:242] Received response from host: affinity-clusterip-transition-tzb9b
  I0419 16:55:07.563118 14 service.go:242] Received response from host: affinity-clusterip-transition-twjrh
  I0419 16:55:07.563136 14 service.go:242] Received response from host: affinity-clusterip-transition-tzb9b
  I0419 16:55:07.563152 14 service.go:242] Received response from host: affinity-clusterip-transition-tzb9b
  I0419 16:55:07.563168 14 service.go:242] Received response from host: affinity-clusterip-transition-tzb9b
  I0419 16:55:07.563219 14 service.go:242] Received response from host: affinity-clusterip-transition-twjrh
  I0419 16:55:07.563238 14 service.go:242] Received response from host: affinity-clusterip-transition-l8sbm
  I0419 16:55:07.563254 14 service.go:242] Received response from host: affinity-clusterip-transition-tzb9b
  I0419 16:55:07.563271 14 service.go:242] Received response from host: affinity-clusterip-transition-tzb9b
  I0419 16:55:07.563301 14 service.go:242] Received response from host: affinity-clusterip-transition-tzb9b
  I0419 16:55:07.585201 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-1394 exec execpod-affinityjwrc9 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.52.89:80/ ; done'
  E0419 16:55:07.696494      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:55:08.085714 14 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.89:80/\n"
  I0419 16:55:08.085807 14 builder.go:147] stdout: "\naffinity-clusterip-transition-tzb9b\naffinity-clusterip-transition-tzb9b\naffinity-clusterip-transition-tzb9b\naffinity-clusterip-transition-tzb9b\naffinity-clusterip-transition-tzb9b\naffinity-clusterip-transition-tzb9b\naffinity-clusterip-transition-tzb9b\naffinity-clusterip-transition-tzb9b\naffinity-clusterip-transition-tzb9b\naffinity-clusterip-transition-tzb9b\naffinity-clusterip-transition-tzb9b\naffinity-clusterip-transition-tzb9b\naffinity-clusterip-transition-tzb9b\naffinity-clusterip-transition-tzb9b\naffinity-clusterip-transition-tzb9b\naffinity-clusterip-transition-tzb9b"
  I0419 16:55:08.085895 14 service.go:242] Received response from host: affinity-clusterip-transition-tzb9b
  I0419 16:55:08.085929 14 service.go:242] Received response from host: affinity-clusterip-transition-tzb9b
  I0419 16:55:08.085966 14 service.go:242] Received response from host: affinity-clusterip-transition-tzb9b
  I0419 16:55:08.085985 14 service.go:242] Received response from host: affinity-clusterip-transition-tzb9b
  I0419 16:55:08.086003 14 service.go:242] Received response from host: affinity-clusterip-transition-tzb9b
  I0419 16:55:08.086020 14 service.go:242] Received response from host: affinity-clusterip-transition-tzb9b
  I0419 16:55:08.086036 14 service.go:242] Received response from host: affinity-clusterip-transition-tzb9b
  I0419 16:55:08.086052 14 service.go:242] Received response from host: affinity-clusterip-transition-tzb9b
  I0419 16:55:08.086068 14 service.go:242] Received response from host: affinity-clusterip-transition-tzb9b
  I0419 16:55:08.086084 14 service.go:242] Received response from host: affinity-clusterip-transition-tzb9b
  I0419 16:55:08.086100 14 service.go:242] Received response from host: affinity-clusterip-transition-tzb9b
  I0419 16:55:08.086116 14 service.go:242] Received response from host: affinity-clusterip-transition-tzb9b
  I0419 16:55:08.086132 14 service.go:242] Received response from host: affinity-clusterip-transition-tzb9b
  I0419 16:55:08.086172 14 service.go:242] Received response from host: affinity-clusterip-transition-tzb9b
  I0419 16:55:08.086188 14 service.go:242] Received response from host: affinity-clusterip-transition-tzb9b
  I0419 16:55:08.086203 14 service.go:242] Received response from host: affinity-clusterip-transition-tzb9b
  I0419 16:55:08.086361 14 service.go:4014] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-1394, will wait for the garbage collector to delete the pods @ 04/19/24 16:55:08.108
  I0419 16:55:08.186861 14 resources.go:139] Deleting ReplicationController affinity-clusterip-transition took: 21.68881ms
  I0419 16:55:08.289018 14 resources.go:163] Terminating ReplicationController affinity-clusterip-transition pods took: 102.156619ms
  E0419 16:55:08.697078      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:09.697714      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:10.698207      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:55:11.347711 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1394" for this suite. @ 04/19/24 16:55:11.356
• [11.120 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:195
  STEP: Creating a kubernetes client @ 04/19/24 16:55:11.371
  I0419 16:55:11.371961 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename container-runtime @ 04/19/24 16:55:11.374
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:55:11.402
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:55:11.406
  STEP: create the container @ 04/19/24 16:55:11.412
  W0419 16:55:11.427212      14 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 04/19/24 16:55:11.427
  E0419 16:55:11.699018      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:12.700064      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:13.700252      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 04/19/24 16:55:14.484
  STEP: the container should be terminated @ 04/19/24 16:55:14.491
  STEP: the termination message should be set @ 04/19/24 16:55:14.492
  I0419 16:55:14.492466 14 runtime.go:167] Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 04/19/24 16:55:14.492
  I0419 16:55:14.531130 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-5424" for this suite. @ 04/19/24 16:55:14.539
• [3.182 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Subdomain [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:286
  STEP: Creating a kubernetes client @ 04/19/24 16:55:14.554
  I0419 16:55:14.554584 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename dns @ 04/19/24 16:55:14.558
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:55:14.583
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:55:14.59
  STEP: Creating a test headless service @ 04/19/24 16:55:14.598
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-2882.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-2882.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-2882.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-2882.svc.cluster.local;sleep 1; done
   @ 04/19/24 16:55:14.61
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-2882.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-2882.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-2882.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-2882.svc.cluster.local;sleep 1; done
   @ 04/19/24 16:55:14.611
  STEP: creating a pod to probe DNS @ 04/19/24 16:55:14.611
  STEP: submitting the pod to kubernetes @ 04/19/24 16:55:14.611
  E0419 16:55:14.701391      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:15.703445      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/19/24 16:55:16.654
  STEP: looking for the results for each expected name from probers @ 04/19/24 16:55:16.662
  I0419 16:55:16.670202 14 dns_common.go:478] Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local from pod dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98: the server could not find the requested resource (get pods dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98)
  I0419 16:55:16.680223 14 dns_common.go:478] Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local from pod dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98: the server could not find the requested resource (get pods dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98)
  I0419 16:55:16.684554 14 dns_common.go:478] Unable to read wheezy_udp@dns-test-service-2.dns-2882.svc.cluster.local from pod dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98: the server could not find the requested resource (get pods dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98)
  I0419 16:55:16.693498 14 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service-2.dns-2882.svc.cluster.local from pod dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98: the server could not find the requested resource (get pods dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98)
  I0419 16:55:16.702084 14 dns_common.go:478] Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local from pod dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98: the server could not find the requested resource (get pods dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98)
  E0419 16:55:16.704226      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:55:16.715503 14 dns_common.go:478] Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local from pod dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98: the server could not find the requested resource (get pods dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98)
  I0419 16:55:16.721277 14 dns_common.go:478] Unable to read jessie_udp@dns-test-service-2.dns-2882.svc.cluster.local from pod dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98: the server could not find the requested resource (get pods dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98)
  I0419 16:55:16.729740 14 dns_common.go:478] Unable to read jessie_tcp@dns-test-service-2.dns-2882.svc.cluster.local from pod dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98: the server could not find the requested resource (get pods dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98)
  I0419 16:55:16.730347 14 dns_common.go:489] Lookups using dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local wheezy_udp@dns-test-service-2.dns-2882.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-2882.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local jessie_udp@dns-test-service-2.dns-2882.svc.cluster.local jessie_tcp@dns-test-service-2.dns-2882.svc.cluster.local]

  I0419 16:55:16.756975 14 dns_common.go:495] Pod client logs for webserver: 
  I0419 16:55:16.770530 14 dns_common.go:495] Pod client logs for querier: 
  I0419 16:55:16.789564 14 dns_common.go:495] Pod client logs for jessie-querier: 
  E0419 16:55:17.704778      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:18.705272      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:19.705124      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:20.706956      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:55:21.704940 14 dns_common.go:478] Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local from pod dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98: the server could not find the requested resource (get pods dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98)
  E0419 16:55:21.707866      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:55:21.717427 14 dns_common.go:478] Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local from pod dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98: the server could not find the requested resource (get pods dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98)
  I0419 16:55:21.744326 14 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service-2.dns-2882.svc.cluster.local from pod dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98: the server could not find the requested resource (get pods dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98)
  I0419 16:55:21.752657 14 dns_common.go:478] Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local from pod dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98: the server could not find the requested resource (get pods dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98)
  I0419 16:55:21.764689 14 dns_common.go:478] Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local from pod dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98: the server could not find the requested resource (get pods dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98)
  I0419 16:55:21.783774 14 dns_common.go:489] Lookups using dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-2882.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local]

  I0419 16:55:21.810708 14 dns_common.go:495] Pod client logs for webserver: 
  I0419 16:55:21.828207 14 dns_common.go:495] Pod client logs for querier: 
  I0419 16:55:21.846044 14 dns_common.go:495] Pod client logs for jessie-querier: 
  E0419 16:55:22.707487      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:23.709456      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:24.709432      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:25.709831      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:55:26.677375 14 dns_common.go:478] Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local from pod dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98: the server could not find the requested resource (get pods dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98)
  I0419 16:55:26.687599 14 dns_common.go:478] Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local from pod dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98: the server could not find the requested resource (get pods dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98)
  E0419 16:55:26.712003      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:55:26.719507 14 dns_common.go:478] Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local from pod dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98: the server could not find the requested resource (get pods dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98)
  I0419 16:55:26.730142 14 dns_common.go:478] Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local from pod dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98: the server could not find the requested resource (get pods dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98)
  I0419 16:55:26.750770 14 dns_common.go:489] Lookups using dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local]

  I0419 16:55:26.772166 14 dns_common.go:495] Pod client logs for webserver: 
  I0419 16:55:26.795217 14 dns_common.go:495] Pod client logs for querier: 
  I0419 16:55:26.816278 14 dns_common.go:495] Pod client logs for jessie-querier: 
  E0419 16:55:27.711735      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:28.712172      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:29.713319      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:30.713407      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:55:31.674730 14 dns_common.go:478] Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local from pod dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98: the server could not find the requested resource (get pods dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98)
  I0419 16:55:31.688457 14 dns_common.go:478] Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local from pod dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98: the server could not find the requested resource (get pods dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98)
  E0419 16:55:31.714796      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:55:31.723436 14 dns_common.go:478] Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local from pod dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98: the server could not find the requested resource (get pods dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98)
  I0419 16:55:31.733821 14 dns_common.go:478] Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local from pod dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98: the server could not find the requested resource (get pods dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98)
  I0419 16:55:31.754772 14 dns_common.go:489] Lookups using dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local]

  I0419 16:55:31.779602 14 dns_common.go:495] Pod client logs for webserver: 
  I0419 16:55:31.795500 14 dns_common.go:495] Pod client logs for querier: 
  I0419 16:55:31.845177 14 dns_common.go:495] Pod client logs for jessie-querier: 
  E0419 16:55:32.715047      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:33.718593      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:34.719289      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:35.717166      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:55:36.683956 14 dns_common.go:478] Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local from pod dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98: the server could not find the requested resource (get pods dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98)
  I0419 16:55:36.704522 14 dns_common.go:478] Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local from pod dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98: the server could not find the requested resource (get pods dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98)
  E0419 16:55:36.718496      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:55:36.742304 14 dns_common.go:478] Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local from pod dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98: the server could not find the requested resource (get pods dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98)
  I0419 16:55:36.761973 14 dns_common.go:478] Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local from pod dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98: the server could not find the requested resource (get pods dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98)
  I0419 16:55:36.782456 14 dns_common.go:489] Lookups using dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local]

  I0419 16:55:36.798834 14 dns_common.go:495] Pod client logs for webserver: 
  I0419 16:55:36.813506 14 dns_common.go:495] Pod client logs for querier: 
  I0419 16:55:36.829734 14 dns_common.go:495] Pod client logs for jessie-querier: 
  E0419 16:55:37.720620      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:38.718662      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:39.719340      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:40.719718      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:55:41.706419 14 dns_common.go:478] Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local from pod dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98: the server could not find the requested resource (get pods dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98)
  I0419 16:55:41.721600 14 dns_common.go:478] Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local from pod dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98: the server could not find the requested resource (get pods dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98)
  E0419 16:55:41.723214      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:55:41.751461 14 dns_common.go:478] Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local from pod dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98: the server could not find the requested resource (get pods dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98)
  I0419 16:55:41.758022 14 dns_common.go:478] Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local from pod dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98: the server could not find the requested resource (get pods dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98)
  I0419 16:55:41.776144 14 dns_common.go:489] Lookups using dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-2882.svc.cluster.local]

  I0419 16:55:41.789725 14 dns_common.go:495] Pod client logs for webserver: 
  I0419 16:55:41.802477 14 dns_common.go:495] Pod client logs for querier: 
  I0419 16:55:41.817516 14 dns_common.go:495] Pod client logs for jessie-querier: 
  E0419 16:55:42.723712      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:43.728688      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:44.729665      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:45.730344      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:46.731670      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:55:46.765524 14 dns_common.go:527] DNS probes using dns-2882/dns-test-35a3196f-4036-45fd-b47b-8b5f7f71bd98 succeeded

  STEP: deleting the pod @ 04/19/24 16:55:46.768
  STEP: deleting the test headless service @ 04/19/24 16:55:46.829
  I0419 16:55:46.876274 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-2882" for this suite. @ 04/19/24 16:55:46.887
• [32.352 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:358
  STEP: Creating a kubernetes client @ 04/19/24 16:55:46.907
  I0419 16:55:46.907928 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/19/24 16:55:46.912
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:55:46.938
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:55:46.943
  STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation @ 04/19/24 16:55:46.947
  I0419 16:55:46.949071 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  E0419 16:55:47.731923      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:48.733057      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:55:48.917993 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  E0419 16:55:49.733278      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:50.734086      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:51.734945      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:52.735823      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:53.736854      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:54.737099      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:55.739510      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:55:56.379740 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-4520" for this suite. @ 04/19/24 16:55:56.406
• [9.514 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject mutating webhook configurations with invalid match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:841
  STEP: Creating a kubernetes client @ 04/19/24 16:55:56.424
  I0419 16:55:56.424733 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename webhook @ 04/19/24 16:55:56.428
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:55:56.467
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:55:56.474
  STEP: Setting up server cert @ 04/19/24 16:55:56.528
  E0419 16:55:56.739104      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 16:55:57.574
  STEP: Deploying the webhook pod @ 04/19/24 16:55:57.602
  STEP: Wait for the deployment to be ready @ 04/19/24 16:55:57.627
  I0419 16:55:57.651350 14 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0419 16:55:57.739675      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:58.740127      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:55:59.680332 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 16, 55, 57, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 55, 57, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 55, 57, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 55, 57, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-6b869959d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 16:55:59.740568      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:00.741117      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 16:56:01.693
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 16:56:01.721
  E0419 16:56:01.741206      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:56:02.722298 14 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  E0419 16:56:02.741479      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating a mutating webhook with match conditions @ 04/19/24 16:56:02.742
  I0419 16:56:02.863189 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4199" for this suite. @ 04/19/24 16:56:02.873
  STEP: Destroying namespace "webhook-markers-2998" for this suite. @ 04/19/24 16:56:02.9
• [6.490 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:372
  STEP: Creating a kubernetes client @ 04/19/24 16:56:02.916
  I0419 16:56:02.916612 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename namespaces @ 04/19/24 16:56:02.923
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:56:02.995
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:56:03.002
  STEP: Updating Namespace "namespaces-6427" @ 04/19/24 16:56:03.007
  I0419 16:56:03.021867 14 namespace.go:389] Namespace "namespaces-6427" now has labels, map[string]string{"e2e-framework":"namespaces", "e2e-run":"382b244f-26f0-439d-b230-5b385b51cde5", "kubernetes.io/metadata.name":"namespaces-6427", "namespaces-6427":"updated", "pod-security.kubernetes.io/audit":"baseline", "pod-security.kubernetes.io/enforce":"baseline", "pod-security.kubernetes.io/warn":"baseline"}
  I0419 16:56:03.022672 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-6427" for this suite. @ 04/19/24 16:56:03.034
• [0.135 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:742
  STEP: Creating a kubernetes client @ 04/19/24 16:56:03.053
  I0419 16:56:03.053999 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename svcaccounts @ 04/19/24 16:56:03.057
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:56:03.084
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:56:03.088
  I0419 16:56:03.100933 14 service_accounts.go:754] Got root ca configmap in namespace "svcaccounts-708"
  I0419 16:56:03.119436 14 service_accounts.go:757] Deleted root ca configmap in namespace "svcaccounts-708"
  STEP: waiting for a new root ca configmap created @ 04/19/24 16:56:03.621
  I0419 16:56:03.631013 14 service_accounts.go:771] Recreated root ca configmap in namespace "svcaccounts-708"
  I0419 16:56:03.642671 14 service_accounts.go:782] Updated root ca configmap in namespace "svcaccounts-708"
  E0419 16:56:03.742255      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting for the root ca configmap reconciled @ 04/19/24 16:56:04.144
  I0419 16:56:04.158877 14 service_accounts.go:800] Reconciled root ca configmap in namespace "svcaccounts-708"
  I0419 16:56:04.159363 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-708" for this suite. @ 04/19/24 16:56:04.174
• [1.135 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:443
  STEP: Creating a kubernetes client @ 04/19/24 16:56:04.189
  I0419 16:56:04.189790 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/19/24 16:56:04.192
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:56:04.224
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:56:04.229
  STEP: set up a multi version CRD @ 04/19/24 16:56:04.234
  I0419 16:56:04.234821 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  E0419 16:56:04.742549      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:05.743315      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:06.744105      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:07.749345      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:08.751191      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mark a version not serverd @ 04/19/24 16:56:08.807
  STEP: check the unserved version gets removed @ 04/19/24 16:56:08.839
  E0419 16:56:09.752566      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the other version is not changed @ 04/19/24 16:56:10.131
  E0419 16:56:10.753018      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:11.753686      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:12.754103      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:13.755069      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:56:13.873638 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-3752" for this suite. @ 04/19/24 16:56:13.897
• [9.726 seconds]
------------------------------
SSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:812
  STEP: Creating a kubernetes client @ 04/19/24 16:56:13.917
  I0419 16:56:13.918159 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename sched-preemption @ 04/19/24 16:56:13.921
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:56:13.957
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:56:13.963
  I0419 16:56:13.997332 14 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0419 16:56:14.755866      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:15.755696      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:16.756311      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:17.756039      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:18.756719      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:19.756985      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:20.757786      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:21.758251      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:22.758860      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:23.760222      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:24.760731      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:25.761071      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:26.762052      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:27.762136      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:28.763899      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:29.763220      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:30.765464      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:31.764380      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:32.765210      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:33.765220      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:34.765485      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:35.766065      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:36.766309      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:37.766609      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:38.766886      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:39.768144      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:40.768513      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:41.768956      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:42.769580      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:43.770629      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:44.771701      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:45.773174      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:46.772554      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:47.773285      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:48.773493      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:49.773758      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:50.774297      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:51.774882      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:52.777206      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:53.778196      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:54.778787      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:55.779670      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:56.780780      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:57.780595      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:58.780957      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:59.781246      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:00.782010      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:01.782331      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:02.782527      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:03.783550      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:04.783773      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:05.784424      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:06.784624      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:07.785070      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:08.785177      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:09.785335      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:10.786186      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:11.787232      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:12.787431      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:13.787745      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:57:14.014534 14 util.go:400] Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 04/19/24 16:57:14.026
  I0419 16:57:14.027551 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename sched-preemption-path @ 04/19/24 16:57:14.034
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:57:14.079
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:57:14.087
  I0419 16:57:14.135489 14 preemption.go:818] PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
  I0419 16:57:14.148710 14 preemption.go:824] PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
  I0419 16:57:14.366184 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-2675" for this suite. @ 04/19/24 16:57:14.38
  I0419 16:57:14.397850 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-4848" for this suite. @ 04/19/24 16:57:14.41
• [60.509 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/events.go:207
  STEP: Creating a kubernetes client @ 04/19/24 16:57:14.427
  I0419 16:57:14.427583 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename events @ 04/19/24 16:57:14.433
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:57:14.465
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:57:14.475
  STEP: Create set of events @ 04/19/24 16:57:14.484
  STEP: get a list of Events with a label in the current namespace @ 04/19/24 16:57:14.519
  STEP: delete a list of events @ 04/19/24 16:57:14.527
  I0419 16:57:14.528410 14 events.go:224] requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 04/19/24 16:57:14.581
  I0419 16:57:14.588757 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-9523" for this suite. @ 04/19/24 16:57:14.604
• [0.192 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:220
  STEP: Creating a kubernetes client @ 04/19/24 16:57:14.62
  I0419 16:57:14.620203 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename emptydir @ 04/19/24 16:57:14.623
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:57:14.661
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:57:14.672
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 04/19/24 16:57:14.686
  E0419 16:57:14.788772      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:15.789701      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:16.790731      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:17.791724      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:57:18.737
  I0419 16:57:18.745193 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-ee6e93bf-6c61-4db0-b0f6-8776bbab1a24 container test-container: <nil>
  STEP: delete the pod @ 04/19/24 16:57:18.79
  E0419 16:57:18.791622      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:57:18.823253 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4593" for this suite. @ 04/19/24 16:57:18.832
• [4.224 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:315
  STEP: Creating a kubernetes client @ 04/19/24 16:57:18.844
  I0419 16:57:18.844676 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename webhook @ 04/19/24 16:57:18.846
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:57:18.871
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:57:18.876
  STEP: Setting up server cert @ 04/19/24 16:57:18.914
  E0419 16:57:19.792272      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 16:57:20.291
  STEP: Deploying the webhook pod @ 04/19/24 16:57:20.311
  STEP: Wait for the deployment to be ready @ 04/19/24 16:57:20.335
  I0419 16:57:20.351274 14 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0419 16:57:20.792707      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:21.794091      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 16:57:22.396
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 16:57:22.434
  E0419 16:57:22.795018      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:57:23.436950 14 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0419 16:57:23.457860 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  E0419 16:57:23.795938      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3743-crds.webhook.example.com via the AdmissionRegistration API @ 04/19/24 16:57:24.007
  STEP: Creating a custom resource while v1 is storage version @ 04/19/24 16:57:24.051
  E0419 16:57:24.796342      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:25.796519      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Patching Custom Resource Definition to set v2 as storage @ 04/19/24 16:57:26.295
  STEP: Patching the custom resource while v2 is storage version @ 04/19/24 16:57:26.339
  E0419 16:57:26.797157      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:57:27.158440 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6627" for this suite. @ 04/19/24 16:57:27.173
  STEP: Destroying namespace "webhook-markers-1629" for this suite. @ 04/19/24 16:57:27.197
• [8.369 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:714
  STEP: Creating a kubernetes client @ 04/19/24 16:57:27.232
  I0419 16:57:27.232805 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename gc @ 04/19/24 16:57:27.236
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:57:27.272
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:57:27.278
  STEP: create the rc1 @ 04/19/24 16:57:27.298
  STEP: create the rc2 @ 04/19/24 16:57:27.315
  E0419 16:57:27.797967      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:28.798216      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:29.798370      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:30.798515      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:31.798646      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:32.798776      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well @ 04/19/24 16:57:33.351
  E0419 16:57:33.799293      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:34.800272      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc simpletest-rc-to-be-deleted @ 04/19/24 16:57:34.836
  STEP: wait for the rc to be deleted @ 04/19/24 16:57:34.943
  E0419 16:57:35.801035      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:36.801458      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:37.802194      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:38.802560      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:39.802611      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:57:40.080426 14 garbage_collector.go:762] 71 pods remaining
  I0419 16:57:40.080496 14 garbage_collector.go:769] 71 pods has nil DeletionTimestamp
  I0419 16:57:40.080513 14 garbage_collector.go:770] 
  E0419 16:57:40.803152      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:41.803230      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:42.803483      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:43.804428      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:44.805357      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 04/19/24 16:57:44.971
  I0419 16:57:45.170046 14 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0419 16:57:45.176555 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-227pj" in namespace "gc-2572"
  I0419 16:57:45.211057 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-28ws5" in namespace "gc-2572"
  I0419 16:57:45.248867 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-298pp" in namespace "gc-2572"
  I0419 16:57:45.268382 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-29t4s" in namespace "gc-2572"
  I0419 16:57:45.290570 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-2zxjx" in namespace "gc-2572"
  I0419 16:57:45.375214 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-4nc6k" in namespace "gc-2572"
  I0419 16:57:45.427814 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-5j8gr" in namespace "gc-2572"
  I0419 16:57:45.474047 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-62cmm" in namespace "gc-2572"
  I0419 16:57:45.583379 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-6pqnn" in namespace "gc-2572"
  I0419 16:57:45.679217 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-6zfc7" in namespace "gc-2572"
  I0419 16:57:45.731312 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-7jdbl" in namespace "gc-2572"
  E0419 16:57:45.806095      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:57:45.809176 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-7vj4g" in namespace "gc-2572"
  I0419 16:57:45.850897 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-89lh2" in namespace "gc-2572"
  I0419 16:57:45.911287 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-8b4s9" in namespace "gc-2572"
  I0419 16:57:45.954544 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-8k42d" in namespace "gc-2572"
  I0419 16:57:45.986667 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-8qf2w" in namespace "gc-2572"
  I0419 16:57:46.045748 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-94ll7" in namespace "gc-2572"
  I0419 16:57:46.089385 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-9kfhq" in namespace "gc-2572"
  I0419 16:57:46.169587 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-9l86c" in namespace "gc-2572"
  I0419 16:57:46.214762 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-9sbn7" in namespace "gc-2572"
  I0419 16:57:46.304185 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-9sct4" in namespace "gc-2572"
  I0419 16:57:46.366365 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-9wfld" in namespace "gc-2572"
  I0419 16:57:46.453550 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-b5wf6" in namespace "gc-2572"
  I0419 16:57:46.487739 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-bhhht" in namespace "gc-2572"
  I0419 16:57:46.545487 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-bhscw" in namespace "gc-2572"
  I0419 16:57:46.605445 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-bnlxc" in namespace "gc-2572"
  I0419 16:57:46.649621 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-bpvrw" in namespace "gc-2572"
  I0419 16:57:46.684199 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-bq5fz" in namespace "gc-2572"
  I0419 16:57:46.755045 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-bv6sw" in namespace "gc-2572"
  I0419 16:57:46.782612 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-bvfck" in namespace "gc-2572"
  E0419 16:57:46.807989      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:57:46.851933 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-bxn8n" in namespace "gc-2572"
  I0419 16:57:46.913044 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-bxtwg" in namespace "gc-2572"
  I0419 16:57:46.955962 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-cj6rs" in namespace "gc-2572"
  I0419 16:57:47.073491 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-cjvmw" in namespace "gc-2572"
  I0419 16:57:47.151470 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-cql4r" in namespace "gc-2572"
  I0419 16:57:47.242759 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-cww58" in namespace "gc-2572"
  I0419 16:57:47.278945 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-fhmq7" in namespace "gc-2572"
  I0419 16:57:47.369050 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-fzgsv" in namespace "gc-2572"
  I0419 16:57:47.426718 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-g2j5d" in namespace "gc-2572"
  I0419 16:57:47.449821 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-g6krv" in namespace "gc-2572"
  I0419 16:57:47.497425 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-g7z7d" in namespace "gc-2572"
  I0419 16:57:47.540963 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-gfw9d" in namespace "gc-2572"
  I0419 16:57:47.586062 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-gjk8k" in namespace "gc-2572"
  I0419 16:57:47.635214 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-gpjzg" in namespace "gc-2572"
  I0419 16:57:47.687399 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-gx4ht" in namespace "gc-2572"
  I0419 16:57:47.786649 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-hhqdt" in namespace "gc-2572"
  E0419 16:57:47.808074      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:57:48.005497 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-hhx94" in namespace "gc-2572"
  I0419 16:57:48.071011 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-hphzx" in namespace "gc-2572"
  I0419 16:57:48.124244 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-htfdl" in namespace "gc-2572"
  I0419 16:57:48.181414 14 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-j5wzq" in namespace "gc-2572"
  I0419 16:57:48.244320 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-2572" for this suite. @ 04/19/24 16:57:48.272
• [21.056 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:110
  STEP: Creating a kubernetes client @ 04/19/24 16:57:48.29
  I0419 16:57:48.290299 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename configmap @ 04/19/24 16:57:48.296
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:57:48.353
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:57:48.358
  STEP: Creating configMap with name configmap-test-volume-map-067ae1c9-9813-417b-acbe-58707f10ab37 @ 04/19/24 16:57:48.363
  STEP: Creating a pod to test consume configMaps @ 04/19/24 16:57:48.384
  E0419 16:57:48.809176      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:49.809663      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:50.810008      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:51.810445      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:57:52.449
  I0419 16:57:52.458329 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-configmaps-9cfafdad-8bba-41ef-a763-1c3907c3e8a9 container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/24 16:57:52.476
  I0419 16:57:52.516437 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-146" for this suite. @ 04/19/24 16:57:52.531
• [4.260 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:380
  STEP: Creating a kubernetes client @ 04/19/24 16:57:52.557
  I0419 16:57:52.557667 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename gc @ 04/19/24 16:57:52.563
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:57:52.596
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:57:52.603
  STEP: create the rc @ 04/19/24 16:57:52.633
  W0419 16:57:52.644717      14 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0419 16:57:52.811636      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:53.811240      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:54.812158      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:55.812263      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:56.813885      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:57.814011      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 04/19/24 16:57:58.653
  STEP: wait for the rc to be deleted @ 04/19/24 16:57:58.713
  E0419 16:57:58.814667      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:59.815066      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:00.815544      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:01.816230      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:02.816602      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods @ 04/19/24 16:58:03.729
  E0419 16:58:03.817695      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:04.817756      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:05.818392      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:06.819187      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:07.819305      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:08.819694      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:09.820029      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:10.820321      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:11.820552      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:12.820655      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:13.821794      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:14.822317      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:15.822682      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:16.823560      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:17.824267      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:18.825331      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:19.825608      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:20.825762      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:21.825953      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:22.826604      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:23.826868      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:24.827016      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:25.827364      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:26.827689      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:27.828083      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:28.829059      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:29.829807      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:30.830970      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:31.831483      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:32.832174      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 04/19/24 16:58:33.78
  E0419 16:58:33.833071      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:58:34.010653 14 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0419 16:58:34.011478 14 delete.go:95] Deleting pod "simpletest.rc-248k9" in namespace "gc-7397"
  I0419 16:58:34.061943 14 delete.go:95] Deleting pod "simpletest.rc-29rdk" in namespace "gc-7397"
  I0419 16:58:34.103058 14 delete.go:95] Deleting pod "simpletest.rc-2pskr" in namespace "gc-7397"
  I0419 16:58:34.165970 14 delete.go:95] Deleting pod "simpletest.rc-2twdj" in namespace "gc-7397"
  I0419 16:58:34.187145 14 delete.go:95] Deleting pod "simpletest.rc-2vbk6" in namespace "gc-7397"
  I0419 16:58:34.278652 14 delete.go:95] Deleting pod "simpletest.rc-4frt4" in namespace "gc-7397"
  I0419 16:58:34.320610 14 delete.go:95] Deleting pod "simpletest.rc-4nst7" in namespace "gc-7397"
  I0419 16:58:34.403662 14 delete.go:95] Deleting pod "simpletest.rc-4qt9c" in namespace "gc-7397"
  I0419 16:58:34.439182 14 delete.go:95] Deleting pod "simpletest.rc-58qpv" in namespace "gc-7397"
  I0419 16:58:34.476574 14 delete.go:95] Deleting pod "simpletest.rc-5jbdf" in namespace "gc-7397"
  I0419 16:58:34.546656 14 delete.go:95] Deleting pod "simpletest.rc-5lq5g" in namespace "gc-7397"
  I0419 16:58:34.611815 14 delete.go:95] Deleting pod "simpletest.rc-5sflp" in namespace "gc-7397"
  I0419 16:58:34.645624 14 delete.go:95] Deleting pod "simpletest.rc-5tgtk" in namespace "gc-7397"
  I0419 16:58:34.704285 14 delete.go:95] Deleting pod "simpletest.rc-5tm46" in namespace "gc-7397"
  I0419 16:58:34.798084 14 delete.go:95] Deleting pod "simpletest.rc-64ltq" in namespace "gc-7397"
  E0419 16:58:34.834327      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:58:34.834555 14 delete.go:95] Deleting pod "simpletest.rc-64x9t" in namespace "gc-7397"
  I0419 16:58:34.891147 14 delete.go:95] Deleting pod "simpletest.rc-65t8m" in namespace "gc-7397"
  I0419 16:58:34.976102 14 delete.go:95] Deleting pod "simpletest.rc-65zph" in namespace "gc-7397"
  I0419 16:58:35.024707 14 delete.go:95] Deleting pod "simpletest.rc-67zl9" in namespace "gc-7397"
  I0419 16:58:35.108109 14 delete.go:95] Deleting pod "simpletest.rc-6r52s" in namespace "gc-7397"
  I0419 16:58:35.195241 14 delete.go:95] Deleting pod "simpletest.rc-6svtj" in namespace "gc-7397"
  I0419 16:58:35.260191 14 delete.go:95] Deleting pod "simpletest.rc-6sxfc" in namespace "gc-7397"
  I0419 16:58:35.295110 14 delete.go:95] Deleting pod "simpletest.rc-7bnr6" in namespace "gc-7397"
  I0419 16:58:35.330040 14 delete.go:95] Deleting pod "simpletest.rc-7mhjl" in namespace "gc-7397"
  I0419 16:58:35.361053 14 delete.go:95] Deleting pod "simpletest.rc-8bnr9" in namespace "gc-7397"
  I0419 16:58:35.381921 14 delete.go:95] Deleting pod "simpletest.rc-8grbj" in namespace "gc-7397"
  I0419 16:58:35.445752 14 delete.go:95] Deleting pod "simpletest.rc-8ndt6" in namespace "gc-7397"
  I0419 16:58:35.495232 14 delete.go:95] Deleting pod "simpletest.rc-96g22" in namespace "gc-7397"
  I0419 16:58:35.551141 14 delete.go:95] Deleting pod "simpletest.rc-9q5lx" in namespace "gc-7397"
  I0419 16:58:35.583562 14 delete.go:95] Deleting pod "simpletest.rc-9r4t6" in namespace "gc-7397"
  I0419 16:58:35.647439 14 delete.go:95] Deleting pod "simpletest.rc-9vz4m" in namespace "gc-7397"
  I0419 16:58:35.706275 14 delete.go:95] Deleting pod "simpletest.rc-9zj7g" in namespace "gc-7397"
  I0419 16:58:35.752365 14 delete.go:95] Deleting pod "simpletest.rc-9znp8" in namespace "gc-7397"
  I0419 16:58:35.822159 14 delete.go:95] Deleting pod "simpletest.rc-b5h8n" in namespace "gc-7397"
  E0419 16:58:35.834563      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:58:35.948630 14 delete.go:95] Deleting pod "simpletest.rc-bhxhn" in namespace "gc-7397"
  I0419 16:58:36.008292 14 delete.go:95] Deleting pod "simpletest.rc-bkljv" in namespace "gc-7397"
  I0419 16:58:36.086948 14 delete.go:95] Deleting pod "simpletest.rc-bvjj9" in namespace "gc-7397"
  I0419 16:58:36.178044 14 delete.go:95] Deleting pod "simpletest.rc-cdqjh" in namespace "gc-7397"
  I0419 16:58:36.237784 14 delete.go:95] Deleting pod "simpletest.rc-cp85f" in namespace "gc-7397"
  I0419 16:58:36.283298 14 delete.go:95] Deleting pod "simpletest.rc-cq4f7" in namespace "gc-7397"
  I0419 16:58:36.340838 14 delete.go:95] Deleting pod "simpletest.rc-cqkmh" in namespace "gc-7397"
  I0419 16:58:36.385810 14 delete.go:95] Deleting pod "simpletest.rc-czqrf" in namespace "gc-7397"
  I0419 16:58:36.420312 14 delete.go:95] Deleting pod "simpletest.rc-dp4nt" in namespace "gc-7397"
  I0419 16:58:36.463272 14 delete.go:95] Deleting pod "simpletest.rc-dxdcs" in namespace "gc-7397"
  I0419 16:58:36.503473 14 delete.go:95] Deleting pod "simpletest.rc-dxnjp" in namespace "gc-7397"
  I0419 16:58:36.537682 14 delete.go:95] Deleting pod "simpletest.rc-ffrh6" in namespace "gc-7397"
  I0419 16:58:36.572469 14 delete.go:95] Deleting pod "simpletest.rc-fj4mm" in namespace "gc-7397"
  I0419 16:58:36.612332 14 delete.go:95] Deleting pod "simpletest.rc-fl6s4" in namespace "gc-7397"
  I0419 16:58:36.662228 14 delete.go:95] Deleting pod "simpletest.rc-fpvvl" in namespace "gc-7397"
  I0419 16:58:36.742178 14 delete.go:95] Deleting pod "simpletest.rc-g44z7" in namespace "gc-7397"
  I0419 16:58:36.789434 14 delete.go:95] Deleting pod "simpletest.rc-g9488" in namespace "gc-7397"
  I0419 16:58:36.825428 14 delete.go:95] Deleting pod "simpletest.rc-gljr4" in namespace "gc-7397"
  E0419 16:58:36.834652      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:58:36.912322 14 delete.go:95] Deleting pod "simpletest.rc-gp4vg" in namespace "gc-7397"
  I0419 16:58:37.007597 14 delete.go:95] Deleting pod "simpletest.rc-hlv4r" in namespace "gc-7397"
  I0419 16:58:37.066016 14 delete.go:95] Deleting pod "simpletest.rc-j7xfw" in namespace "gc-7397"
  I0419 16:58:37.124177 14 delete.go:95] Deleting pod "simpletest.rc-jgzph" in namespace "gc-7397"
  I0419 16:58:37.242567 14 delete.go:95] Deleting pod "simpletest.rc-jlfks" in namespace "gc-7397"
  I0419 16:58:37.271328 14 delete.go:95] Deleting pod "simpletest.rc-k785t" in namespace "gc-7397"
  I0419 16:58:37.322905 14 delete.go:95] Deleting pod "simpletest.rc-kd6t7" in namespace "gc-7397"
  I0419 16:58:37.545137 14 delete.go:95] Deleting pod "simpletest.rc-kl96x" in namespace "gc-7397"
  I0419 16:58:37.673163 14 delete.go:95] Deleting pod "simpletest.rc-kmwvs" in namespace "gc-7397"
  I0419 16:58:37.736486 14 delete.go:95] Deleting pod "simpletest.rc-kp7xm" in namespace "gc-7397"
  E0419 16:58:37.835458      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:58:37.845117 14 delete.go:95] Deleting pod "simpletest.rc-krsj8" in namespace "gc-7397"
  I0419 16:58:37.887309 14 delete.go:95] Deleting pod "simpletest.rc-ktgdw" in namespace "gc-7397"
  I0419 16:58:37.943078 14 delete.go:95] Deleting pod "simpletest.rc-lmbls" in namespace "gc-7397"
  I0419 16:58:38.007058 14 delete.go:95] Deleting pod "simpletest.rc-lxhxs" in namespace "gc-7397"
  I0419 16:58:38.053600 14 delete.go:95] Deleting pod "simpletest.rc-mmjjw" in namespace "gc-7397"
  I0419 16:58:38.164366 14 delete.go:95] Deleting pod "simpletest.rc-n8xsv" in namespace "gc-7397"
  I0419 16:58:38.216687 14 delete.go:95] Deleting pod "simpletest.rc-ndld4" in namespace "gc-7397"
  I0419 16:58:38.266574 14 delete.go:95] Deleting pod "simpletest.rc-p4xjg" in namespace "gc-7397"
  I0419 16:58:38.297336 14 delete.go:95] Deleting pod "simpletest.rc-pd2gm" in namespace "gc-7397"
  I0419 16:58:38.365092 14 delete.go:95] Deleting pod "simpletest.rc-pgr54" in namespace "gc-7397"
  I0419 16:58:38.395711 14 delete.go:95] Deleting pod "simpletest.rc-pl756" in namespace "gc-7397"
  I0419 16:58:38.437200 14 delete.go:95] Deleting pod "simpletest.rc-prxwb" in namespace "gc-7397"
  I0419 16:58:38.457718 14 delete.go:95] Deleting pod "simpletest.rc-q6mvp" in namespace "gc-7397"
  I0419 16:58:38.480071 14 delete.go:95] Deleting pod "simpletest.rc-q8jtq" in namespace "gc-7397"
  I0419 16:58:38.517184 14 delete.go:95] Deleting pod "simpletest.rc-qb9jd" in namespace "gc-7397"
  I0419 16:58:38.553589 14 delete.go:95] Deleting pod "simpletest.rc-qlrbw" in namespace "gc-7397"
  I0419 16:58:38.583943 14 delete.go:95] Deleting pod "simpletest.rc-qmd5s" in namespace "gc-7397"
  I0419 16:58:38.658253 14 delete.go:95] Deleting pod "simpletest.rc-qvc9t" in namespace "gc-7397"
  I0419 16:58:38.704822 14 delete.go:95] Deleting pod "simpletest.rc-rldfr" in namespace "gc-7397"
  I0419 16:58:38.733560 14 delete.go:95] Deleting pod "simpletest.rc-rq2m7" in namespace "gc-7397"
  I0419 16:58:38.761507 14 delete.go:95] Deleting pod "simpletest.rc-rxr6t" in namespace "gc-7397"
  I0419 16:58:38.811277 14 delete.go:95] Deleting pod "simpletest.rc-s2l5n" in namespace "gc-7397"
  E0419 16:58:38.835650      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:58:38.865071 14 delete.go:95] Deleting pod "simpletest.rc-sjf9z" in namespace "gc-7397"
  I0419 16:58:38.890636 14 delete.go:95] Deleting pod "simpletest.rc-sntnv" in namespace "gc-7397"
  I0419 16:58:39.008330 14 delete.go:95] Deleting pod "simpletest.rc-t74fc" in namespace "gc-7397"
  I0419 16:58:39.057778 14 delete.go:95] Deleting pod "simpletest.rc-tqmp5" in namespace "gc-7397"
  I0419 16:58:39.112951 14 delete.go:95] Deleting pod "simpletest.rc-v5x2l" in namespace "gc-7397"
  I0419 16:58:39.164479 14 delete.go:95] Deleting pod "simpletest.rc-v9lhh" in namespace "gc-7397"
  I0419 16:58:39.209406 14 delete.go:95] Deleting pod "simpletest.rc-vrx79" in namespace "gc-7397"
  I0419 16:58:39.260518 14 delete.go:95] Deleting pod "simpletest.rc-vttvp" in namespace "gc-7397"
  I0419 16:58:39.350858 14 delete.go:95] Deleting pod "simpletest.rc-w7qf9" in namespace "gc-7397"
  I0419 16:58:39.415285 14 delete.go:95] Deleting pod "simpletest.rc-w7x4b" in namespace "gc-7397"
  I0419 16:58:39.489107 14 delete.go:95] Deleting pod "simpletest.rc-wn486" in namespace "gc-7397"
  I0419 16:58:39.553240 14 delete.go:95] Deleting pod "simpletest.rc-wr9kd" in namespace "gc-7397"
  I0419 16:58:39.591696 14 delete.go:95] Deleting pod "simpletest.rc-wwfgt" in namespace "gc-7397"
  I0419 16:58:39.670554 14 delete.go:95] Deleting pod "simpletest.rc-xgrqs" in namespace "gc-7397"
  I0419 16:58:39.726129 14 delete.go:95] Deleting pod "simpletest.rc-xr74d" in namespace "gc-7397"
  I0419 16:58:39.767208 14 delete.go:95] Deleting pod "simpletest.rc-zwvzk" in namespace "gc-7397"
  E0419 16:58:39.836727      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:58:39.870214 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-7397" for this suite. @ 04/19/24 16:58:39.913
• [47.411 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:163
  STEP: Creating a kubernetes client @ 04/19/24 16:58:39.97
  I0419 16:58:39.970532 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename resourcequota @ 04/19/24 16:58:39.976
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:58:40.002
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:58:40.006
  STEP: Discovering how many secrets are in namespace by default @ 04/19/24 16:58:40.016
  E0419 16:58:40.837471      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:41.839084      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:42.839262      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:43.840671      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:44.840657      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 04/19/24 16:58:45.027
  E0419 16:58:45.842046      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:46.842721      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:47.843021      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:48.843331      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:49.843274      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 04/19/24 16:58:50.033
  STEP: Ensuring resource quota status is calculated @ 04/19/24 16:58:50.044
  E0419 16:58:50.843459      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:51.844068      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Secret @ 04/19/24 16:58:52.057
  STEP: Ensuring resource quota status captures secret creation @ 04/19/24 16:58:52.081
  E0419 16:58:52.844345      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:53.846009      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a secret @ 04/19/24 16:58:54.09
  STEP: Ensuring resource quota status released usage @ 04/19/24 16:58:54.107
  E0419 16:58:54.846468      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:55.846584      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:58:56.118704 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1664" for this suite. @ 04/19/24 16:58:56.13
• [16.185 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance] [sig-scheduling, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/limit_range.go:253
  STEP: Creating a kubernetes client @ 04/19/24 16:58:56.16
  I0419 16:58:56.160787 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename limitrange @ 04/19/24 16:58:56.164
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:58:56.201
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:58:56.208
  STEP: Creating LimitRange "e2e-limitrange-5zpjs" in namespace "limitrange-3781" @ 04/19/24 16:58:56.219
  STEP: Creating another limitRange in another namespace @ 04/19/24 16:58:56.229
  I0419 16:58:56.258490 14 limit_range.go:299] Namespace "e2e-limitrange-5zpjs-7674" created
  I0419 16:58:56.258586 14 limit_range.go:300] Creating LimitRange "e2e-limitrange-5zpjs" in namespace "e2e-limitrange-5zpjs-7674"
  STEP: Listing all LimitRanges with label "e2e-test=e2e-limitrange-5zpjs" @ 04/19/24 16:58:56.274
  I0419 16:58:56.281084 14 limit_range.go:309] Found 2 limitRanges
  STEP: Patching LimitRange "e2e-limitrange-5zpjs" in "limitrange-3781" namespace @ 04/19/24 16:58:56.281
  I0419 16:58:56.294915 14 limit_range.go:335] LimitRange "e2e-limitrange-5zpjs" has been patched
  STEP: Delete LimitRange "e2e-limitrange-5zpjs" by Collection with labelSelector: "e2e-limitrange-5zpjs=patched" @ 04/19/24 16:58:56.294
  STEP: Confirm that the limitRange "e2e-limitrange-5zpjs" has been deleted @ 04/19/24 16:58:56.31
  I0419 16:58:56.310221 14 limit_range.go:443] Requesting list of LimitRange to confirm quantity
  I0419 16:58:56.317273 14 limit_range.go:453] Found 0 LimitRange with label "e2e-limitrange-5zpjs=patched"
  I0419 16:58:56.317928 14 limit_range.go:344] LimitRange "e2e-limitrange-5zpjs" has been deleted.
  STEP: Confirm that a single LimitRange still exists with label "e2e-test=e2e-limitrange-5zpjs" @ 04/19/24 16:58:56.318
  I0419 16:58:56.325635 14 limit_range.go:350] Found 1 limitRange
  I0419 16:58:56.325860 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-3781" for this suite. @ 04/19/24 16:58:56.336
  STEP: Destroying namespace "e2e-limitrange-5zpjs-7674" for this suite. @ 04/19/24 16:58:56.347
• [0.202 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:154
  STEP: Creating a kubernetes client @ 04/19/24 16:58:56.363
  I0419 16:58:56.363134 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename tables @ 04/19/24 16:58:56.365
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:58:56.387
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:58:56.392
  I0419 16:58:56.401072 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "tables-4562" for this suite. @ 04/19/24 16:58:56.412
• [0.064 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:376
  STEP: Creating a kubernetes client @ 04/19/24 16:58:56.428
  I0419 16:58:56.428259 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename projected @ 04/19/24 16:58:56.433
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:58:56.454
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:58:56.459
  STEP: Creating configMap with name projected-configmap-test-volume-3331cbc9-1096-42ad-885f-56e54a9d466c @ 04/19/24 16:58:56.465
  STEP: Creating a pod to test consume configMaps @ 04/19/24 16:58:56.474
  E0419 16:58:56.847569      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:57.848462      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:58.849484      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:59.849702      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:59:00.521
  I0419 16:59:00.530592 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-projected-configmaps-c17569d8-43da-47ba-9669-ef54e1131279 container projected-configmap-volume-test: <nil>
  STEP: delete the pod @ 04/19/24 16:59:00.552
  I0419 16:59:00.593086 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6329" for this suite. @ 04/19/24 16:59:00.604
• [4.193 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:142
  STEP: Creating a kubernetes client @ 04/19/24 16:59:00.632
  I0419 16:59:00.632319 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename watch @ 04/19/24 16:59:00.635
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:59:00.665
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:59:00.671
  STEP: creating a new configmap @ 04/19/24 16:59:00.677
  STEP: modifying the configmap once @ 04/19/24 16:59:00.689
  STEP: modifying the configmap a second time @ 04/19/24 16:59:00.712
  STEP: deleting the configmap @ 04/19/24 16:59:00.733
  STEP: creating a watch on configmaps from the resource version returned by the first update @ 04/19/24 16:59:00.748
  STEP: Expecting to observe notifications for all changes to the configmap after the first update @ 04/19/24 16:59:00.751
  I0419 16:59:00.752478 14 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-699  b42b8db0-5d1f-4169-a3c1-739ee2e3191c 30680 0 2024-04-19 16:59:00 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-04-19 16:59:00 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0419 16:59:00.753177 14 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-699  b42b8db0-5d1f-4169-a3c1-739ee2e3191c 30681 0 2024-04-19 16:59:00 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-04-19 16:59:00 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0419 16:59:00.753721 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-699" for this suite. @ 04/19/24 16:59:00.764
• [0.146 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:332
  STEP: Creating a kubernetes client @ 04/19/24 16:59:00.78
  I0419 16:59:00.780362 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename webhook @ 04/19/24 16:59:00.782
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:59:00.807
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:59:00.812
  E0419 16:59:00.850836      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Setting up server cert @ 04/19/24 16:59:00.859
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 16:59:01.68
  STEP: Deploying the webhook pod @ 04/19/24 16:59:01.704
  STEP: Wait for the deployment to be ready @ 04/19/24 16:59:01.729
  I0419 16:59:01.738804 14 deployment.go:222] new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0419 16:59:01.850988      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:02.852004      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:59:03.770500 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 16, 59, 1, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 59, 1, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 59, 1, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 59, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-6b869959d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 16:59:03.852569      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:04.853560      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:59:05.794806 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 16, 59, 1, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 59, 1, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 59, 1, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 59, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-6b869959d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 16:59:05.854535      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:06.854641      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:59:07.779823 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 16, 59, 1, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 59, 1, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 59, 1, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 59, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-6b869959d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 16:59:07.854976      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:08.855230      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:59:09.779528 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 16, 59, 1, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 59, 1, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 59, 1, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 59, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-6b869959d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 16:59:09.855537      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:10.857267      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 16:59:11.779
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 16:59:11.817
  E0419 16:59:11.856781      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:59:12.818440 14 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0419 16:59:12.835689 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  E0419 16:59:12.857684      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8393-crds.webhook.example.com via the AdmissionRegistration API @ 04/19/24 16:59:13.378
  STEP: Creating a custom resource that should be mutated by the webhook @ 04/19/24 16:59:13.423
  E0419 16:59:13.858512      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:14.859752      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:15.860029      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:59:16.519036 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4186" for this suite. @ 04/19/24 16:59:16.533
  STEP: Destroying namespace "webhook-markers-3946" for this suite. @ 04/19/24 16:59:16.545
• [15.774 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:117
  STEP: Creating a kubernetes client @ 04/19/24 16:59:16.556
  I0419 16:59:16.556462 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename dns @ 04/19/24 16:59:16.562
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:59:16.583
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:59:16.588
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8503.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-8503.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
   @ 04/19/24 16:59:16.596
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8503.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-8503.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
   @ 04/19/24 16:59:16.597
  STEP: creating a pod to probe /etc/hosts @ 04/19/24 16:59:16.597
  STEP: submitting the pod to kubernetes @ 04/19/24 16:59:16.598
  E0419 16:59:16.860092      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:17.860797      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/19/24 16:59:18.633
  STEP: looking for the results for each expected name from probers @ 04/19/24 16:59:18.643
  I0419 16:59:18.702357 14 dns_common.go:478] Unable to read jessie_hosts@dns-querier-1 from pod dns-8503/dns-test-12051c34-1488-465c-863f-e50684e482c9: the server could not find the requested resource (get pods dns-test-12051c34-1488-465c-863f-e50684e482c9)
  I0419 16:59:18.703016 14 dns_common.go:489] Lookups using dns-8503/dns-test-12051c34-1488-465c-863f-e50684e482c9 failed for: [jessie_hosts@dns-querier-1]

  I0419 16:59:18.719459 14 dns_common.go:495] Pod client logs for webserver: 
  I0419 16:59:18.735510 14 dns_common.go:495] Pod client logs for querier: 
  I0419 16:59:18.752727 14 dns_common.go:495] Pod client logs for jessie-querier: 
  E0419 16:59:18.861499      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:19.861827      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:20.862079      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:21.863330      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:22.864167      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:59:23.694855 14 dns_common.go:478] Unable to read jessie_hosts@dns-querier-1 from pod dns-8503/dns-test-12051c34-1488-465c-863f-e50684e482c9: the server could not find the requested resource (get pods dns-test-12051c34-1488-465c-863f-e50684e482c9)
  I0419 16:59:23.695556 14 dns_common.go:489] Lookups using dns-8503/dns-test-12051c34-1488-465c-863f-e50684e482c9 failed for: [jessie_hosts@dns-querier-1]

  I0419 16:59:23.717202 14 dns_common.go:495] Pod client logs for webserver: 
  I0419 16:59:23.735882 14 dns_common.go:495] Pod client logs for querier: 
  I0419 16:59:23.756218 14 dns_common.go:495] Pod client logs for jessie-querier: 
  E0419 16:59:23.866323      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:24.865665      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:25.866031      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:26.869381      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:27.867912      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:59:28.692382 14 dns_common.go:527] DNS probes using dns-8503/dns-test-12051c34-1488-465c-863f-e50684e482c9 succeeded

  STEP: deleting the pod @ 04/19/24 16:59:28.693
  I0419 16:59:28.743975 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-8503" for this suite. @ 04/19/24 16:59:28.755
• [12.227 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/flowcontrol.go:514
  STEP: Creating a kubernetes client @ 04/19/24 16:59:28.793
  I0419 16:59:28.793961 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename apf @ 04/19/24 16:59:28.803
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:59:28.826
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:59:28.833
  STEP: getting /apis @ 04/19/24 16:59:28.845
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 04/19/24 16:59:28.857
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 04/19/24 16:59:28.859
  STEP: creating @ 04/19/24 16:59:28.862
  E0419 16:59:28.868346      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: getting @ 04/19/24 16:59:28.895
  STEP: listing @ 04/19/24 16:59:28.945
  STEP: watching @ 04/19/24 16:59:28.953
  I0419 16:59:28.954050 14 flowcontrol.go:620] starting watch
  STEP: patching @ 04/19/24 16:59:28.956
  STEP: updating @ 04/19/24 16:59:28.968
  I0419 16:59:28.984136 14 flowcontrol.go:648] waiting for watch events with expected annotations
  STEP: getting /status @ 04/19/24 16:59:28.984
  STEP: patching /status @ 04/19/24 16:59:28.99
  STEP: updating /status @ 04/19/24 16:59:29
  STEP: deleting @ 04/19/24 16:59:29.015
  STEP: deleting a collection @ 04/19/24 16:59:29.039
  I0419 16:59:29.082747 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-8042" for this suite. @ 04/19/24 16:59:29.094
• [0.316 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:248
  STEP: Creating a kubernetes client @ 04/19/24 16:59:29.113
  I0419 16:59:29.113708 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename container-runtime @ 04/19/24 16:59:29.116
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:59:29.149
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:59:29.157
  STEP: create the container @ 04/19/24 16:59:29.164
  W0419 16:59:29.177039      14 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 04/19/24 16:59:29.177
  E0419 16:59:29.868494      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:30.868852      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:31.869324      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 04/19/24 16:59:32.228
  STEP: the container should be terminated @ 04/19/24 16:59:32.237
  STEP: the termination message should be set @ 04/19/24 16:59:32.237
  I0419 16:59:32.237668 14 runtime.go:167] Expected: &{OK} to match Container's Termination Message: OK --
  STEP: delete the container @ 04/19/24 16:59:32.237
  I0419 16:59:32.273928 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-8392" for this suite. @ 04/19/24 16:59:32.287
• [3.194 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:86
  STEP: Creating a kubernetes client @ 04/19/24 16:59:32.308
  I0419 16:59:32.308537 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/19/24 16:59:32.312
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:59:32.346
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:59:32.354
  I0419 16:59:32.362036 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  E0419 16:59:32.870192      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:33.871007      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:34.871024      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:35.872269      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:36.873031      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:37.873991      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:38.874112      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:59:38.912012 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-2796" for this suite. @ 04/19/24 16:59:38.923
• [6.631 seconds]
------------------------------
[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:639
  STEP: Creating a kubernetes client @ 04/19/24 16:59:38.94
  I0419 16:59:38.941403 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename gc @ 04/19/24 16:59:38.949
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:59:38.987
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:59:38.995
  STEP: create the rc @ 04/19/24 16:59:39.022
  W0419 16:59:39.043894      14 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0419 16:59:39.874463      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:40.874881      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:41.876682      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:42.888696      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:43.881549      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:44.881754      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 04/19/24 16:59:45.053
  STEP: wait for the rc to be deleted @ 04/19/24 16:59:45.084
  E0419 16:59:45.881791      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:59:46.117209 14 garbage_collector.go:670] 80 pods remaining
  I0419 16:59:46.117341 14 garbage_collector.go:677] 80 pods has nil DeletionTimestamp
  I0419 16:59:46.117360 14 garbage_collector.go:678] 
  E0419 16:59:46.882451      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:59:47.149898 14 garbage_collector.go:670] 72 pods remaining
  I0419 16:59:47.150020 14 garbage_collector.go:677] 71 pods has nil DeletionTimestamp
  I0419 16:59:47.150040 14 garbage_collector.go:678] 
  E0419 16:59:47.882840      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:59:48.135725 14 garbage_collector.go:670] 59 pods remaining
  I0419 16:59:48.136229 14 garbage_collector.go:677] 59 pods has nil DeletionTimestamp
  I0419 16:59:48.136433 14 garbage_collector.go:678] 
  E0419 16:59:48.882854      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:59:49.191554 14 garbage_collector.go:670] 40 pods remaining
  I0419 16:59:49.191662 14 garbage_collector.go:677] 40 pods has nil DeletionTimestamp
  I0419 16:59:49.191683 14 garbage_collector.go:678] 
  E0419 16:59:49.883766      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:59:50.134123 14 garbage_collector.go:670] 32 pods remaining
  I0419 16:59:50.134565 14 garbage_collector.go:677] 32 pods has nil DeletionTimestamp
  I0419 16:59:50.134757 14 garbage_collector.go:678] 
  E0419 16:59:50.884425      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:59:51.177186 14 garbage_collector.go:670] 18 pods remaining
  I0419 16:59:51.177491 14 garbage_collector.go:677] 18 pods has nil DeletionTimestamp
  I0419 16:59:51.177677 14 garbage_collector.go:678] 
  E0419 16:59:51.885178      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:59:52.133480 14 garbage_collector.go:670] 0 pods remaining
  I0419 16:59:52.133792 14 garbage_collector.go:677] 0 pods has nil DeletionTimestamp
  I0419 16:59:52.134091 14 garbage_collector.go:678] 
  E0419 16:59:52.885432      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 04/19/24 16:59:53.112
  I0419 16:59:53.601679 14 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0419 16:59:53.612220 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-3845" for this suite. @ 04/19/24 16:59:53.623
• [14.704 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1394
  STEP: Creating a kubernetes client @ 04/19/24 16:59:53.645
  I0419 16:59:53.645472 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename kubectl @ 04/19/24 16:59:53.648
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:59:53.774
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:59:53.778
  I0419 16:59:53.783423 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-3378 create -f -'
  E0419 16:59:53.885739      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:59:54.256545 14 builder.go:146] stderr: ""
  I0419 16:59:54.256684 14 builder.go:147] stdout: "replicationcontroller/agnhost-primary created\n"
  I0419 16:59:54.257443 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-3378 create -f -'
  I0419 16:59:54.728548 14 builder.go:146] stderr: ""
  I0419 16:59:54.728629 14 builder.go:147] stdout: "service/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 04/19/24 16:59:54.728
  E0419 16:59:54.886809      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:59:55.770768 14 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0419 16:59:55.770920 14 framework.go:733] Found 0 / 1
  E0419 16:59:55.887780      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:59:56.737366 14 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0419 16:59:56.737445 14 framework.go:733] Found 0 / 1
  E0419 16:59:56.887822      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:59:57.735534 14 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0419 16:59:57.735615 14 framework.go:733] Found 1 / 1
  I0419 16:59:57.735670 14 framework.go:742] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  I0419 16:59:57.742428 14 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0419 16:59:57.743063 14 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0419 16:59:57.744750 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-3378 describe pod agnhost-primary-lrmpw'
  E0419 16:59:57.888615      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:59:57.947356 14 builder.go:146] stderr: ""
  I0419 16:59:57.947517 14 builder.go:147] stdout: "Name:             agnhost-primary-lrmpw\nNamespace:        kubectl-3378\nPriority:         0\nService Account:  default\nNode:             eipo9quoh3ef-3/192.168.121.127\nStart Time:       Fri, 19 Apr 2024 16:59:54 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               10.233.66.164\nIPs:\n  IP:           10.233.66.164\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   cri-o://66477fa8bab90fa38bc51bf54f2fd6ed49d1e879a79dd09964b701aacb590e6f\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.47\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:c9997bf8d2e223d7d2a0078dcfb11a653e9b16cf09418829ec03e1d57ca9628a\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 19 Apr 2024 16:59:56 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-xvs7l (ro)\nConditions:\n  Type                        Status\n  PodReadyToStartContainers   True \n  Initialized                 True \n  Ready                       True \n  ContainersReady             True \n  PodScheduled                True \nVolumes:\n  kube-api-access-xvs7l:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  3s    default-scheduler  Successfully assigned kubectl-3378/agnhost-primary-lrmpw to eipo9quoh3ef-3\n  Normal  Pulled     2s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.47\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
  I0419 16:59:57.947841 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-3378 describe rc agnhost-primary'
  I0419 16:59:58.104721 14 builder.go:146] stderr: ""
  I0419 16:59:58.104851 14 builder.go:147] stdout: "Name:         agnhost-primary\nNamespace:    kubectl-3378\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:         registry.k8s.io/e2e-test-images/agnhost:2.47\n    Port:          6379/TCP\n    Host Port:     0/TCP\n    Environment:   <none>\n    Mounts:        <none>\n  Volumes:         <none>\n  Node-Selectors:  <none>\n  Tolerations:     <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  4s    replication-controller  Created pod: agnhost-primary-lrmpw\n"
  I0419 16:59:58.105263 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-3378 describe service agnhost-primary'
  I0419 16:59:58.246072 14 builder.go:146] stderr: ""
  I0419 16:59:58.246181 14 builder.go:147] stdout: "Name:              agnhost-primary\nNamespace:         kubectl-3378\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.233.55.217\nIPs:               10.233.55.217\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.233.66.164:6379\nSession Affinity:  None\nEvents:            <none>\n"
  I0419 16:59:58.256576 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-3378 describe node eipo9quoh3ef-1'
  I0419 16:59:58.540990 14 builder.go:146] stderr: ""
  I0419 16:59:58.541443 14 builder.go:147] stdout: "Name:               eipo9quoh3ef-1\nRoles:              control-plane\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=eipo9quoh3ef-1\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/control-plane=\n                    node.kubernetes.io/exclude-from-external-load-balancers=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VNI\":1,\"VtepMAC\":\"d2:62:50:bb:2e:8d\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 192.168.121.38\n                    kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/crio/crio.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 19 Apr 2024 15:24:18 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  eipo9quoh3ef-1\n  AcquireTime:     <unset>\n  RenewTime:       Fri, 19 Apr 2024 16:59:58 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Fri, 19 Apr 2024 15:44:50 +0000   Fri, 19 Apr 2024 15:44:50 +0000   FlannelIsUp                  Flannel is running on this node\n  MemoryPressure       False   Fri, 19 Apr 2024 16:56:38 +0000   Fri, 19 Apr 2024 15:40:34 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Fri, 19 Apr 2024 16:56:38 +0000   Fri, 19 Apr 2024 15:40:34 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Fri, 19 Apr 2024 16:56:38 +0000   Fri, 19 Apr 2024 15:40:34 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Fri, 19 Apr 2024 16:56:38 +0000   Fri, 19 Apr 2024 15:40:34 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  192.168.121.38\n  Hostname:    eipo9quoh3ef-1\nCapacity:\n  cpu:                2\n  ephemeral-storage:  115008636Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             8123552Ki\n  pods:               110\nAllocatable:\n  cpu:                1600m\n  ephemeral-storage:  111880401014\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             3273888Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 03f30dbc3de14582af241899829ba962\n  System UUID:                03f30dbc-3de1-4582-af24-1899829ba962\n  Boot ID:                    ea0f7c09-3086-4581-9141-21fcf6ef5153\n  Kernel Version:             6.5.0-28-generic\n  OS Image:                   Ubuntu 22.04.4 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  cri-o://1.30.0\n  Kubelet Version:            v1.30.0\n  Kube-Proxy Version:         v1.30.0\nPodCIDR:                      10.233.64.0/24\nPodCIDRs:                     10.233.64.0/24\nNon-terminated Pods:          (8 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 coredns-7db6d8ff4d-5xj2j                                   100m (6%)     0 (0%)      70Mi (2%)        170Mi (5%)     7m27s\n  kube-system                 kube-addon-manager-eipo9quoh3ef-1                          5m (0%)       0 (0%)      50Mi (1%)        0 (0%)         75m\n  kube-system                 kube-apiserver-eipo9quoh3ef-1                              250m (15%)    0 (0%)      0 (0%)           0 (0%)         75m\n  kube-system                 kube-controller-manager-eipo9quoh3ef-1                     200m (12%)    0 (0%)      0 (0%)           0 (0%)         75m\n  kube-system                 kube-flannel-ds-nk72d                                      100m (6%)     0 (0%)      50Mi (1%)        0 (0%)         75m\n  kube-system                 kube-proxy-fpxst                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         75m\n  kube-system                 kube-scheduler-eipo9quoh3ef-1                              100m (6%)     0 (0%)      0 (0%)           0 (0%)         75m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-946d96f11a954c8b-87528    0 (0%)        0 (0%)      0 (0%)           0 (0%)         74m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                755m (47%)  0 (0%)\n  memory             170Mi (5%)  170Mi (5%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:              <none>\n"
  I0419 16:59:58.542348 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-3378 describe namespace kubectl-3378'
  I0419 16:59:58.746184 14 builder.go:146] stderr: ""
  I0419 16:59:58.746332 14 builder.go:147] stdout: "Name:         kubectl-3378\nLabels:       e2e-framework=kubectl\n              e2e-run=382b244f-26f0-439d-b230-5b385b51cde5\n              kubernetes.io/metadata.name=kubectl-3378\n              pod-security.kubernetes.io/audit=baseline\n              pod-security.kubernetes.io/enforce=baseline\n              pod-security.kubernetes.io/warn=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
  I0419 16:59:58.746857 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3378" for this suite. @ 04/19/24 16:59:58.755
• [5.126 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:169
  STEP: Creating a kubernetes client @ 04/19/24 16:59:58.772
  I0419 16:59:58.772566 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename container-probe @ 04/19/24 16:59:58.781
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:59:58.812
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:59:58.819
  STEP: Creating pod liveness-7743025c-3005-44fe-b9bb-7c7abcdf8c6a in namespace container-probe-3686 @ 04/19/24 16:59:58.831
  E0419 16:59:58.888793      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:59.891797      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/19/24 17:00:00.869
  I0419 17:00:00.876507 14 container_probe.go:1749] Initial restart count of pod liveness-7743025c-3005-44fe-b9bb-7c7abcdf8c6a is 0
  E0419 17:00:00.890488      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:00:00.890981 14 container_probe.go:1759] Get pod liveness-7743025c-3005-44fe-b9bb-7c7abcdf8c6a in namespace container-probe-3686
  E0419 17:00:01.895895      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:02.895311      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:00:02.897595 14 container_probe.go:1759] Get pod liveness-7743025c-3005-44fe-b9bb-7c7abcdf8c6a in namespace container-probe-3686
  E0419 17:00:03.895375      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:04.896646      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:00:04.909202 14 container_probe.go:1759] Get pod liveness-7743025c-3005-44fe-b9bb-7c7abcdf8c6a in namespace container-probe-3686
  E0419 17:00:05.897303      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:06.897114      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:00:06.922933 14 container_probe.go:1759] Get pod liveness-7743025c-3005-44fe-b9bb-7c7abcdf8c6a in namespace container-probe-3686
  E0419 17:00:07.897429      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:08.898434      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:00:08.940114 14 container_probe.go:1759] Get pod liveness-7743025c-3005-44fe-b9bb-7c7abcdf8c6a in namespace container-probe-3686
  E0419 17:00:09.898783      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:10.899120      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:00:10.949616 14 container_probe.go:1759] Get pod liveness-7743025c-3005-44fe-b9bb-7c7abcdf8c6a in namespace container-probe-3686
  E0419 17:00:11.900040      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:12.900799      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:00:12.958560 14 container_probe.go:1759] Get pod liveness-7743025c-3005-44fe-b9bb-7c7abcdf8c6a in namespace container-probe-3686
  E0419 17:00:13.901079      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:14.901573      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:00:14.971145 14 container_probe.go:1759] Get pod liveness-7743025c-3005-44fe-b9bb-7c7abcdf8c6a in namespace container-probe-3686
  E0419 17:00:15.902590      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:16.903580      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:00:16.976292 14 container_probe.go:1759] Get pod liveness-7743025c-3005-44fe-b9bb-7c7abcdf8c6a in namespace container-probe-3686
  E0419 17:00:17.903938      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:18.905100      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:00:18.988016 14 container_probe.go:1759] Get pod liveness-7743025c-3005-44fe-b9bb-7c7abcdf8c6a in namespace container-probe-3686
  E0419 17:00:19.905393      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:20.905611      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:00:20.997848 14 container_probe.go:1759] Get pod liveness-7743025c-3005-44fe-b9bb-7c7abcdf8c6a in namespace container-probe-3686
  E0419 17:00:21.906720      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:22.906905      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:00:23.011281 14 container_probe.go:1759] Get pod liveness-7743025c-3005-44fe-b9bb-7c7abcdf8c6a in namespace container-probe-3686
  I0419 17:00:23.012058 14 container_probe.go:1763] Restart count of pod container-probe-3686/liveness-7743025c-3005-44fe-b9bb-7c7abcdf8c6a is now 1 (22.135123727s elapsed)
  STEP: deleting the pod @ 04/19/24 17:00:23.013
  I0419 17:00:23.055240 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-3686" for this suite. @ 04/19/24 17:00:23.072
• [24.321 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:808
  STEP: Creating a kubernetes client @ 04/19/24 17:00:23.095
  I0419 17:00:23.095498 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename resourcequota @ 04/19/24 17:00:23.1
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:00:23.133
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:00:23.142
  STEP: Creating a ResourceQuota with best effort scope @ 04/19/24 17:00:23.149
  STEP: Ensuring ResourceQuota status is calculated @ 04/19/24 17:00:23.159
  E0419 17:00:23.907189      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:24.907683      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not best effort scope @ 04/19/24 17:00:25.17
  STEP: Ensuring ResourceQuota status is calculated @ 04/19/24 17:00:25.187
  E0419 17:00:25.908356      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:26.909204      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a best-effort pod @ 04/19/24 17:00:27.196
  STEP: Ensuring resource quota with best effort scope captures the pod usage @ 04/19/24 17:00:27.231
  E0419 17:00:27.909688      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:28.910022      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not best effort ignored the pod usage @ 04/19/24 17:00:29.242
  E0419 17:00:29.910807      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:30.910990      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 04/19/24 17:00:31.253
  STEP: Ensuring resource quota status released the pod usage @ 04/19/24 17:00:31.288
  E0419 17:00:31.911226      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:32.911561      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a not best-effort pod @ 04/19/24 17:00:33.299
  STEP: Ensuring resource quota with not best effort scope captures the pod usage @ 04/19/24 17:00:33.327
  E0419 17:00:33.911900      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:34.912760      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with best effort scope ignored the pod usage @ 04/19/24 17:00:35.335
  E0419 17:00:35.913110      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:36.913544      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 04/19/24 17:00:37.346
  STEP: Ensuring resource quota status released the pod usage @ 04/19/24 17:00:37.373
  E0419 17:00:37.913923      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:38.914223      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:00:39.381929 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1962" for this suite. @ 04/19/24 17:00:39.396
• [16.316 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:125
  STEP: Creating a kubernetes client @ 04/19/24 17:00:39.414
  I0419 17:00:39.414786 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename pod-network-test @ 04/19/24 17:00:39.419
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:00:39.458
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:00:39.466
  STEP: Performing setup for networking test in namespace pod-network-test-8771 @ 04/19/24 17:00:39.473
  STEP: creating a selector @ 04/19/24 17:00:39.473
  STEP: Creating the service pods in kubernetes @ 04/19/24 17:00:39.473
  I0419 17:00:39.473756 14 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0419 17:00:39.914448      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:40.916529      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:41.918284      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:42.917728      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:43.918070      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:44.918473      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:45.918875      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:46.920432      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:47.930709      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:48.925604      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:49.927097      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:50.926825      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:51.926926      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:52.928057      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:53.929050      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:54.930087      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:55.930915      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:56.931714      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:57.931920      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:58.932510      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:59.933620      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:00.933858      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 04/19/24 17:01:01.775
  E0419 17:01:01.934805      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:02.935094      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:01:03.880030 14 utils.go:779] Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  I0419 17:01:03.880149 14 utils.go:472] Going to poll 10.233.64.203 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  I0419 17:01:03.885580 14 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.64.203 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8771 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0419 17:01:03.885820 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 17:01:03.888101 14 exec_util.go:62] ExecWithOptions: Clientset creation
  I0419 17:01:03.888438 14 exec_util.go:79] ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-8771/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.64.203+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0419 17:01:03.935628      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:04.936158      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:01:05.036836 14 utils.go:489] Found all 1 expected endpoints: [netserver-0]
  I0419 17:01:05.037582 14 utils.go:472] Going to poll 10.233.65.175 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  I0419 17:01:05.049488 14 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.65.175 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8771 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0419 17:01:05.050058 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 17:01:05.053839 14 exec_util.go:62] ExecWithOptions: Clientset creation
  I0419 17:01:05.054615 14 exec_util.go:79] ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-8771/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.65.175+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0419 17:01:05.936473      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:01:06.169612 14 utils.go:489] Found all 1 expected endpoints: [netserver-1]
  I0419 17:01:06.169883 14 utils.go:472] Going to poll 10.233.66.166 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  I0419 17:01:06.180868 14 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.66.166 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8771 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0419 17:01:06.181058 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 17:01:06.183608 14 exec_util.go:62] ExecWithOptions: Clientset creation
  I0419 17:01:06.184027 14 exec_util.go:79] ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-8771/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.66.166+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0419 17:01:06.937448      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:01:07.347009 14 utils.go:489] Found all 1 expected endpoints: [netserver-2]
  I0419 17:01:07.348755 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-8771" for this suite. @ 04/19/24 17:01:07.364
• [27.970 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version should check is all data is printed [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1726
  STEP: Creating a kubernetes client @ 04/19/24 17:01:07.386
  I0419 17:01:07.386507 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename kubectl @ 04/19/24 17:01:07.39
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:01:07.423
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:01:07.433
  I0419 17:01:07.447178 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-1359 version'
  I0419 17:01:07.615855 14 builder.go:146] stderr: ""
  I0419 17:01:07.615967 14 builder.go:147] stdout: "Client Version: v1.30.0\nKustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3\nServer Version: v1.30.0\n"
  I0419 17:01:07.616521 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1359" for this suite. @ 04/19/24 17:01:07.624
• [0.250 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:215
  STEP: Creating a kubernetes client @ 04/19/24 17:01:07.636
  I0419 17:01:07.637100 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename container-probe @ 04/19/24 17:01:07.639
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:01:07.664
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:01:07.669
  STEP: Creating pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961 @ 04/19/24 17:01:07.676
  E0419 17:01:07.938141      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:08.938227      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/19/24 17:01:09.717
  I0419 17:01:09.727162 14 container_probe.go:1749] Initial restart count of pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 is 0
  I0419 17:01:09.737918 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:01:09.939492      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:10.939572      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:01:11.753320 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:01:11.939661      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:12.940004      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:01:13.775856 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:01:13.940638      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:14.941414      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:01:15.784601 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:01:15.941731      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:16.942800      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:01:17.795878 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:01:17.942990      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:18.943372      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:01:19.807956 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:01:19.944020      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:20.944238      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:01:21.819865 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:01:21.944969      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:22.945635      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:01:23.828629 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:01:23.946483      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:24.946534      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:01:25.848556 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:01:25.947147      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:26.947520      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:01:27.857542 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:01:27.947638      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:28.947911      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:01:29.869584 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:01:29.949196      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:30.949395      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:01:31.879986 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:01:31.949774      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:32.949984      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:01:33.891017 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:01:33.950614      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:34.951839      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:01:35.907399 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:01:35.952511      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:36.953838      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:01:37.919809 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:01:37.953715      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:38.954150      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:01:39.932427 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:01:39.954460      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:40.954713      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:01:41.946485 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:01:41.955577      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:42.956116      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:01:43.957094 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:01:43.957151      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:44.957392      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:45.961739      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:01:45.974767 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:01:46.963078      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:47.962958      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:01:47.990705 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:01:48.963164      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:49.963529      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:01:50.003368 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:01:50.964399      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:51.964628      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:01:52.013983 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:01:52.973039      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:53.966957      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:01:54.030502 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:01:54.967251      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:55.967923      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:01:56.040772 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:01:56.968276      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:57.968788      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:01:58.053176 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:01:58.970915      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:59.970999      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:02:00.063979 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:02:00.971232      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:01.971736      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:02:02.076833 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:02:02.972003      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:03.973084      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:02:04.087036 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:02:04.973340      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:05.973729      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:02:06.097671 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:02:06.974854      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:07.974917      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:02:08.108310 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:02:08.975484      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:09.977686      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:02:10.122258 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:02:10.977696      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:11.978020      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:02:12.133626 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:02:12.978673      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:13.979280      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:02:14.148586 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:02:14.980000      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:15.980241      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:02:16.157336 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:02:16.981400      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:17.981981      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:02:18.170528 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:02:18.982721      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:19.982910      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:02:20.179472 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:02:20.983432      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:21.983959      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:02:22.190601 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:02:22.984046      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:23.984042      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:02:24.201360 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:02:24.984818      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:25.985211      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:02:26.213820 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:02:26.985711      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:27.986456      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:02:28.225516 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:02:28.987005      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:29.988011      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:02:30.235211 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:02:30.988303      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:31.989036      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:02:32.254473 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:02:32.993300      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:33.994429      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:02:34.266478 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:02:34.994806      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:35.995889      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:02:36.276822 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:02:36.996801      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:37.997493      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:02:38.290012 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:02:38.998430      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:39.998588      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:02:40.304073 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:02:40.999011      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:42.000232      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:02:42.317513 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:02:43.004272      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:44.001232      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:02:44.329383 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:02:45.001450      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:46.001908      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:02:46.343036 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:02:47.002526      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:48.002644      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:02:48.352381 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:02:49.003042      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:50.004157      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:02:50.368064 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:02:51.004483      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:52.004503      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:02:52.382287 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:02:53.004938      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:54.005310      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:02:54.391225 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:02:55.005377      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:56.005442      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:02:56.404483 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:02:57.006595      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:58.006815      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:02:58.416032 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:02:59.007017      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:00.007180      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:03:00.429088 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:03:01.007534      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:02.008095      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:03:02.442181 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:03:03.008685      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:04.009045      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:03:04.454459 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:03:05.009780      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:06.010902      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:03:06.464987 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:03:07.012018      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:08.012137      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:03:08.476472 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:03:09.013119      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:10.013418      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:03:10.491362 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:03:11.013839      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:12.013883      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:03:12.507756 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:03:13.014255      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:14.015550      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:03:14.521211 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:03:15.015734      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:16.016634      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:03:16.528755 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:03:17.017716      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:18.017944      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:03:18.538411 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:03:19.019148      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:20.019150      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:03:20.549339 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:03:21.020041      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:22.021316      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:03:22.559008 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:03:23.022360      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:24.022575      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:03:24.569104 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:03:25.023367      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:26.024275      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:03:26.577957 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:03:27.025282      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:28.025373      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:03:28.587903 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:03:29.026231      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:30.027133      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:03:30.598349 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:03:31.028262      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:32.028313      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:03:32.610509 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:03:33.029009      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:34.029126      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:03:34.621838 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:03:35.029350      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:36.030398      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:03:36.632010 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:03:37.031031      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:38.031303      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:03:38.641870 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:03:39.031489      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:40.031759      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:03:40.654145 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:03:41.032735      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:42.033166      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:03:42.664796 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:03:43.033321      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:44.033376      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:03:44.678079 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:03:45.034321      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:46.035072      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:03:46.690928 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:03:47.035727      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:48.036259      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:03:48.699582 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:03:49.037722      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:50.037370      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:03:50.709189 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:03:51.037761      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:52.038040      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:03:52.721815 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:03:53.038460      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:54.039124      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:03:54.729119 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:03:55.039561      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:56.039860      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:03:56.743012 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:03:57.041278      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:58.041794      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:03:58.751836 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:03:59.043080      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:00.042864      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:04:00.764854 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:04:01.043424      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:02.043762      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:04:02.775113 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:04:03.045234      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:04.045102      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:04:04.788434 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:04:05.046124      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:06.047136      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:04:06.797701 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:04:07.047493      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:08.047870      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:04:08.816022 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:04:09.048406      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:10.049373      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:04:10.829812 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:04:11.049926      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:12.050433      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:04:12.842412 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:04:13.051132      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:14.051521      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:04:14.853310 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:04:15.051727      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:16.051829      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:04:16.877004 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:04:17.052430      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:18.052528      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:04:18.885874 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:04:19.053846      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:20.053984      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:04:20.905966 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:04:21.054785      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:22.055699      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:04:22.917657 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:04:23.055907      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:24.056071      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:04:24.954671 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:04:25.057076      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:26.057849      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:04:26.965530 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:04:27.058434      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:28.058747      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:04:28.976989 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:04:29.059665      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:30.059889      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:04:30.992803 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:04:31.060595      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:32.061194      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:04:33.004026 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:04:33.062171      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:34.062085      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:04:35.014214 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:04:35.062361      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:36.062541      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:04:37.022537 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:04:37.062630      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:38.062927      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:04:39.034460 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:04:39.063460      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:40.065099      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:04:41.046137 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:04:41.064765      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:42.065250      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:04:43.061977 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:04:43.066172      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:44.066510      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:45.067445      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:04:45.073040 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:04:46.067668      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:47.068644      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:04:47.084608 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:04:48.069193      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:49.069462      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:04:49.096860 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:04:50.069783      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:51.069995      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:04:51.106554 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:04:52.070105      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:53.070471      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:04:53.119384 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:04:54.070650      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:55.070894      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:04:55.129655 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:04:56.071071      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:57.072004      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:04:57.141923 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:04:58.072751      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:59.072782      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:04:59.153754 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:05:00.073269      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:01.074068      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:05:01.165307 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:05:02.073995      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:03.074742      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:05:03.174922 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:05:04.074949      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:05.075580      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:05:05.184541 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:05:06.076793      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:07.077592      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:05:07.199088 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:05:08.077886      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:09.078125      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:05:09.208869 14 container_probe.go:1759] Get pod test-webserver-a070ba0d-6350-4649-9867-0355e9598376 in namespace container-probe-6961
  E0419 17:05:10.078745      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:11.079867      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 04/19/24 17:05:11.21
  I0419 17:05:11.242543 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-6961" for this suite. @ 04/19/24 17:05:11.27
• [243.648 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:70
  STEP: Creating a kubernetes client @ 04/19/24 17:05:11.286
  I0419 17:05:11.286729 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/19/24 17:05:11.291
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:05:11.326
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:05:11.333
  I0419 17:05:11.340221 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  E0419 17:05:12.080704      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:13.081229      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with known and required properties @ 04/19/24 17:05:13.318
  I0419 17:05:13.319654 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=crd-publish-openapi-8398 --namespace=crd-publish-openapi-8398 create -f -'
  I0419 17:05:13.742909 14 builder.go:146] stderr: ""
  I0419 17:05:13.743046 14 builder.go:147] stdout: "e2e-test-crd-publish-openapi-6374-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  I0419 17:05:13.743652 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=crd-publish-openapi-8398 --namespace=crd-publish-openapi-8398 delete e2e-test-crd-publish-openapi-6374-crds test-foo'
  I0419 17:05:13.936318 14 builder.go:146] stderr: ""
  I0419 17:05:13.936399 14 builder.go:147] stdout: "e2e-test-crd-publish-openapi-6374-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  I0419 17:05:13.937308 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=crd-publish-openapi-8398 --namespace=crd-publish-openapi-8398 apply -f -'
  E0419 17:05:14.082185      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:05:14.094945 14 builder.go:146] stderr: ""
  I0419 17:05:14.095015 14 builder.go:147] stdout: "e2e-test-crd-publish-openapi-6374-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  I0419 17:05:14.095367 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=crd-publish-openapi-8398 --namespace=crd-publish-openapi-8398 delete e2e-test-crd-publish-openapi-6374-crds test-foo'
  I0419 17:05:14.358209 14 builder.go:146] stderr: ""
  I0419 17:05:14.358324 14 builder.go:147] stdout: "e2e-test-crd-publish-openapi-6374-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values @ 04/19/24 17:05:14.358
  I0419 17:05:14.358738 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=crd-publish-openapi-8398 --namespace=crd-publish-openapi-8398 create -f -'
  I0419 17:05:14.517806 14 builder.go:135] rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema @ 04/19/24 17:05:14.517
  I0419 17:05:14.518487 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=crd-publish-openapi-8398 --namespace=crd-publish-openapi-8398 create -f -'
  I0419 17:05:14.678113 14 builder.go:135] rc: 1
  I0419 17:05:14.678602 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=crd-publish-openapi-8398 --namespace=crd-publish-openapi-8398 apply -f -'
  I0419 17:05:14.843691 14 builder.go:135] rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request without required properties @ 04/19/24 17:05:14.843
  I0419 17:05:14.844155 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=crd-publish-openapi-8398 --namespace=crd-publish-openapi-8398 create -f -'
  I0419 17:05:15.020224 14 builder.go:135] rc: 1
  I0419 17:05:15.020732 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=crd-publish-openapi-8398 --namespace=crd-publish-openapi-8398 apply -f -'
  E0419 17:05:15.082303      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:05:15.216751 14 builder.go:135] rc: 1
  STEP: kubectl explain works to explain CR properties @ 04/19/24 17:05:15.216
  I0419 17:05:15.217290 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=crd-publish-openapi-8398 explain e2e-test-crd-publish-openapi-6374-crds'
  I0419 17:05:15.384404 14 builder.go:146] stderr: ""
  I0419 17:05:15.384507 14 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-6374-crd\nVERSION:    v1\n\nDESCRIPTION:\n    Foo CRD for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Foo\n\n  status\t<Object>\n    Status of Foo\n\n\n"
  STEP: kubectl explain works to explain CR properties recursively @ 04/19/24 17:05:15.385
  I0419 17:05:15.385250 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=crd-publish-openapi-8398 explain e2e-test-crd-publish-openapi-6374-crds.metadata'
  I0419 17:05:15.541780 14 builder.go:146] stderr: ""
  I0419 17:05:15.542043 14 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-6374-crd\nVERSION:    v1\n\nFIELD: metadata <ObjectMeta>\n\n\nDESCRIPTION:\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n    ObjectMeta is metadata that all persisted resources must have, which\n    includes all objects users must create.\n    \nFIELDS:\n  annotations\t<map[string]string>\n    Annotations is an unstructured key value map stored with a resource that may\n    be set by external tools to store and retrieve arbitrary metadata. They are\n    not queryable and should be preserved when modifying objects. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations\n\n  creationTimestamp\t<string>\n    CreationTimestamp is a timestamp representing the server time when this\n    object was created. It is not guaranteed to be set in happens-before order\n    across separate operations. Clients may not set this value. It is\n    represented in RFC3339 form and is in UTC.\n    \n    Populated by the system. Read-only. Null for lists. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  deletionGracePeriodSeconds\t<integer>\n    Number of seconds allowed for this object to gracefully terminate before it\n    will be removed from the system. Only set when deletionTimestamp is also\n    set. May only be shortened. Read-only.\n\n  deletionTimestamp\t<string>\n    DeletionTimestamp is RFC 3339 date and time at which this resource will be\n    deleted. This field is set by the server when a graceful deletion is\n    requested by the user, and is not directly settable by a client. The\n    resource is expected to be deleted (no longer visible from resource lists,\n    and not reachable by name) after the time in this field, once the finalizers\n    list is empty. As long as the finalizers list contains items, deletion is\n    blocked. Once the deletionTimestamp is set, this value may not be unset or\n    be set further into the future, although it may be shortened or the resource\n    may be deleted prior to this time. For example, a user may request that a\n    pod is deleted in 30 seconds. The Kubelet will react by sending a graceful\n    termination signal to the containers in the pod. After that 30 seconds, the\n    Kubelet will send a hard termination signal (SIGKILL) to the container and\n    after cleanup, remove the pod from the API. In the presence of network\n    partitions, this object may still exist after this timestamp, until an\n    administrator or automated process can determine the resource is fully\n    terminated. If not set, graceful deletion of the object has not been\n    requested.\n    \n    Populated by the system when a graceful deletion is requested. Read-only.\n    More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  finalizers\t<[]string>\n    Must be empty before the object is deleted from the registry. Each entry is\n    an identifier for the responsible component that will remove the entry from\n    the list. If the deletionTimestamp of the object is non-nil, entries in this\n    list can only be removed. Finalizers may be processed and removed in any\n    order.  Order is NOT enforced because it introduces significant risk of\n    stuck finalizers. finalizers is a shared field, any actor with permission\n    can reorder it. If the finalizer list is processed in order, then this can\n    lead to a situation in which the component responsible for the first\n    finalizer in the list is waiting for a signal (field value, external system,\n    or other) produced by a component responsible for a finalizer later in the\n    list, resulting in a deadlock. Without enforced ordering finalizers are free\n    to order amongst themselves and are not vulnerable to ordering changes in\n    the list.\n\n  generateName\t<string>\n    GenerateName is an optional prefix, used by the server, to generate a unique\n    name ONLY IF the Name field has not been provided. If this field is used,\n    the name returned to the client will be different than the name passed. This\n    value will also be combined with a unique suffix. The provided value has the\n    same validation rules as the Name field, and may be truncated by the length\n    of the suffix required to make the value unique on the server.\n    \n    If this field is specified and the generated name exists, the server will\n    return a 409.\n    \n    Applied only if Name is not specified. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n  generation\t<integer>\n    A sequence number representing a specific generation of the desired state.\n    Populated by the system. Read-only.\n\n  labels\t<map[string]string>\n    Map of string keys and values that can be used to organize and categorize\n    (scope and select) objects. May match selectors of replication controllers\n    and services. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\n\n  managedFields\t<[]ManagedFieldsEntry>\n    ManagedFields maps workflow-id and version to the set of fields that are\n    managed by that workflow. This is mostly for internal housekeeping, and\n    users typically shouldn't need to set or understand this field. A workflow\n    can be the user's name, a controller's name, or the name of a specific apply\n    path like \"ci-cd\". The set of fields is always in the version that the\n    workflow used when modifying the object.\n\n  name\t<string>\n    Name must be unique within a namespace. Is required when creating resources,\n    although some resources may allow a client to request the generation of an\n    appropriate name automatically. Name is primarily intended for creation\n    idempotence and configuration definition. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#names\n\n  namespace\t<string>\n    Namespace defines the space within which each name must be unique. An empty\n    namespace is equivalent to the \"default\" namespace, but \"default\" is the\n    canonical representation. Not all objects are required to be scoped to a\n    namespace - the value of this field for those objects will be empty.\n    \n    Must be a DNS_LABEL. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces\n\n  ownerReferences\t<[]OwnerReference>\n    List of objects depended by this object. If ALL objects in the list have\n    been deleted, this object will be garbage collected. If this object is\n    managed by a controller, then an entry in this list will point to this\n    controller, with the controller field set to true. There cannot be more than\n    one managing controller.\n\n  resourceVersion\t<string>\n    An opaque value that represents the internal version of this object that can\n    be used by clients to determine when objects have changed. May be used for\n    optimistic concurrency, change detection, and the watch operation on a\n    resource or set of resources. Clients must treat these values as opaque and\n    passed unmodified back to the server. They may only be valid for a\n    particular resource or set of resources.\n    \n    Populated by the system. Read-only. Value must be treated as opaque by\n    clients and . More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n  selfLink\t<string>\n    Deprecated: selfLink is a legacy read-only field that is no longer populated\n    by the system.\n\n  uid\t<string>\n    UID is the unique in time and space value for this object. It is typically\n    generated by the server on successful creation of a resource and is not\n    allowed to change on PUT operations.\n    \n    Populated by the system. Read-only. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#uids\n\n\n"
  I0419 17:05:15.542595 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=crd-publish-openapi-8398 explain e2e-test-crd-publish-openapi-6374-crds.spec'
  I0419 17:05:15.686575 14 builder.go:146] stderr: ""
  I0419 17:05:15.686659 14 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-6374-crd\nVERSION:    v1\n\nFIELD: spec <Object>\n\n\nDESCRIPTION:\n    Specification of Foo\n    \nFIELDS:\n  bars\t<[]Object>\n    List of Bars and their specs.\n\n\n"
  I0419 17:05:15.687101 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=crd-publish-openapi-8398 explain e2e-test-crd-publish-openapi-6374-crds.spec.bars'
  I0419 17:05:15.821812 14 builder.go:146] stderr: ""
  I0419 17:05:15.821919 14 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-6374-crd\nVERSION:    v1\n\nFIELD: bars <[]Object>\n\n\nDESCRIPTION:\n    List of Bars and their specs.\n    \nFIELDS:\n  age\t<string>\n    Age of Bar.\n\n  bazs\t<[]string>\n    List of Bazs.\n\n  feeling\t<string>\n  enum: Great, Down\n    Whether Bar is feeling great.\n\n  name\t<string> -required-\n    Name of Bar.\n\n\n"
  STEP: kubectl explain works to return error when explain is called on property that doesn't exist @ 04/19/24 17:05:15.822
  I0419 17:05:15.822646 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=crd-publish-openapi-8398 explain e2e-test-crd-publish-openapi-6374-crds.spec.bars2'
  I0419 17:05:15.964861 14 builder.go:135] rc: 1
  E0419 17:05:16.083633      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:17.083967      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:05:17.490017 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-8398" for this suite. @ 04/19/24 17:05:17.515
• [6.242 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1420
  STEP: Creating a kubernetes client @ 04/19/24 17:05:17.533
  I0419 17:05:17.533396 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename services @ 04/19/24 17:05:17.537
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:05:17.582
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:05:17.589
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-9002 @ 04/19/24 17:05:17.596
  STEP: changing the ExternalName service to type=ClusterIP @ 04/19/24 17:05:17.605
  STEP: creating replication controller externalname-service in namespace services-9002 @ 04/19/24 17:05:17.633
  I0419 17:05:17.651090      14 runners.go:198] Created replication controller with name: externalname-service, namespace: services-9002, replica count: 2
  E0419 17:05:18.084516      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:19.085872      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:20.086675      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:05:20.703127      14 runners.go:198] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0419 17:05:20.703779 14 resource.go:361] Creating new exec pod
  E0419 17:05:21.087175      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:22.088372      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:23.088994      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:05:23.747078 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-9002 exec execpodrcp6r -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  I0419 17:05:24.074743 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  I0419 17:05:24.074829 14 builder.go:147] stdout: ""
  E0419 17:05:24.089083      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:05:24.747535 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-9002 exec execpodrcp6r -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  I0419 17:05:25.059750 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  I0419 17:05:25.060069 14 builder.go:147] stdout: ""
  E0419 17:05:25.089686      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:05:25.747321 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-9002 exec execpodrcp6r -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  I0419 17:05:26.075026 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  I0419 17:05:26.075127 14 builder.go:147] stdout: "externalname-service-6m8lx"
  I0419 17:05:26.075650 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-9002 exec execpodrcp6r -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.50.96 80'
  E0419 17:05:26.090321      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:05:26.372018 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.50.96 80\nConnection to 10.233.50.96 80 port [tcp/http] succeeded!\n"
  I0419 17:05:26.372101 14 builder.go:147] stdout: "externalname-service-cxvk2"
  I0419 17:05:26.372366 14 service.go:1429] Cleaning up the ExternalName to ClusterIP test service
  I0419 17:05:26.412101 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9002" for this suite. @ 04/19/24 17:05:26.419
• [8.901 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:48
  STEP: Creating a kubernetes client @ 04/19/24 17:05:26.435
  I0419 17:05:26.435466 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename configmap @ 04/19/24 17:05:26.439
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:05:26.472
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:05:26.478
  STEP: Creating configMap with name configmap-test-volume-2bfa92be-f1a2-47e4-bc46-28b252388297 @ 04/19/24 17:05:26.486
  STEP: Creating a pod to test consume configMaps @ 04/19/24 17:05:26.501
  E0419 17:05:27.090677      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:28.091526      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:29.091647      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:30.092454      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:05:30.544
  I0419 17:05:30.553378 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-configmaps-a4690a54-7682-4016-893d-5e32b1e28a9d container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/24 17:05:30.59
  I0419 17:05:30.618780 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9796" for this suite. @ 04/19/24 17:05:30.628
• [4.207 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/sysctl.go:125
  STEP: Creating a kubernetes client @ 04/19/24 17:05:30.642
  I0419 17:05:30.642887 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename sysctl @ 04/19/24 17:05:30.645
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:05:30.691
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:05:30.699
  STEP: Creating a pod with one valid and two invalid sysctls @ 04/19/24 17:05:30.707
  I0419 17:05:30.719738 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-1607" for this suite. @ 04/19/24 17:05:30.729
• [0.102 seconds]
------------------------------
[sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/chunking.go:83
  STEP: Creating a kubernetes client @ 04/19/24 17:05:30.746
  I0419 17:05:30.746950 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename chunking @ 04/19/24 17:05:30.751
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:05:30.783
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:05:30.791
  STEP: creating a large number of resources @ 04/19/24 17:05:30.797
  E0419 17:05:31.092783      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:32.093365      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:33.093658      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:34.093666      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:35.094645      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:36.094995      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:37.096360      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:38.097166      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:39.097495      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:40.098014      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:41.098753      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:42.099411      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:43.100305      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:44.101157      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:45.102220      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:46.102464      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:47.102527      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:48.102522      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving those results in paged fashion several times @ 04/19/24 17:05:48.465
  I0419 17:05:48.512742 14 chunking.go:98] Retrieved 17/17 results with rv 34035 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzUsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  I0419 17:05:48.564566 14 chunking.go:98] Retrieved 17/17 results with rv 34035 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzUsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  I0419 17:05:48.616168 14 chunking.go:98] Retrieved 17/17 results with rv 34035 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzUsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  I0419 17:05:48.665849 14 chunking.go:98] Retrieved 17/17 results with rv 34035 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzUsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  I0419 17:05:48.717002 14 chunking.go:98] Retrieved 17/17 results with rv 34035 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzUsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  I0419 17:05:48.769623 14 chunking.go:98] Retrieved 17/17 results with rv 34035 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzUsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  I0419 17:05:48.813636 14 chunking.go:98] Retrieved 17/17 results with rv 34035 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzUsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  I0419 17:05:48.863777 14 chunking.go:98] Retrieved 17/17 results with rv 34035 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzUsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  I0419 17:05:48.914289 14 chunking.go:98] Retrieved 17/17 results with rv 34035 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzUsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  I0419 17:05:48.961728 14 chunking.go:98] Retrieved 17/17 results with rv 34035 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzUsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  I0419 17:05:49.014961 14 chunking.go:98] Retrieved 17/17 results with rv 34035 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzUsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  I0419 17:05:49.062668 14 chunking.go:98] Retrieved 17/17 results with rv 34035 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzUsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  E0419 17:05:49.102671      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:05:49.112463 14 chunking.go:98] Retrieved 17/17 results with rv 34035 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzUsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  I0419 17:05:49.167265 14 chunking.go:98] Retrieved 17/17 results with rv 34035 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzUsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  I0419 17:05:49.213878 14 chunking.go:98] Retrieved 17/17 results with rv 34035 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzUsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  I0419 17:05:49.261416 14 chunking.go:98] Retrieved 17/17 results with rv 34035 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzUsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  I0419 17:05:49.320545 14 chunking.go:98] Retrieved 17/17 results with rv 34035 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzUsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  I0419 17:05:49.365152 14 chunking.go:98] Retrieved 17/17 results with rv 34035 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzUsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  I0419 17:05:49.412265 14 chunking.go:98] Retrieved 17/17 results with rv 34035 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzUsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  I0419 17:05:49.459494 14 chunking.go:98] Retrieved 17/17 results with rv 34035 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzUsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  I0419 17:05:49.508371 14 chunking.go:98] Retrieved 17/17 results with rv 34035 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzUsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  I0419 17:05:49.559059 14 chunking.go:98] Retrieved 17/17 results with rv 34035 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzUsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  I0419 17:05:49.610227 14 chunking.go:98] Retrieved 17/17 results with rv 34035 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzUsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  I0419 17:05:49.658906 14 chunking.go:98] Retrieved 9/17 results with rv 34035 and continue 
  I0419 17:05:49.711569 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  I0419 17:05:49.765066 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  I0419 17:05:49.815751 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  I0419 17:05:49.865515 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  I0419 17:05:49.914019 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  I0419 17:05:49.965594 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  I0419 17:05:50.013634 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  I0419 17:05:50.065893 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  E0419 17:05:50.102989      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:05:50.112349 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  I0419 17:05:50.163416 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  I0419 17:05:50.215329 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  I0419 17:05:50.265884 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  I0419 17:05:50.312240 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  I0419 17:05:50.363181 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  I0419 17:05:50.414257 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  I0419 17:05:50.464067 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  I0419 17:05:50.513939 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  I0419 17:05:50.567081 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  I0419 17:05:50.612251 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  I0419 17:05:50.664533 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  I0419 17:05:50.717026 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  I0419 17:05:50.760668 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  I0419 17:05:50.812241 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  I0419 17:05:50.859219 14 chunking.go:98] Retrieved 9/17 results with rv 34038 and continue 
  I0419 17:05:50.909797 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  I0419 17:05:50.964193 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  I0419 17:05:51.010643 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  I0419 17:05:51.062192 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  E0419 17:05:51.102946      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:05:51.113571 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  I0419 17:05:51.160677 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  I0419 17:05:51.211748 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  I0419 17:05:51.265948 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  I0419 17:05:51.315177 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  I0419 17:05:51.364076 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  I0419 17:05:51.413940 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  I0419 17:05:51.463884 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  I0419 17:05:51.510472 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  I0419 17:05:51.564561 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  I0419 17:05:51.613149 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  I0419 17:05:51.667318 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  I0419 17:05:51.717563 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  I0419 17:05:51.762596 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  I0419 17:05:51.813068 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  I0419 17:05:51.868738 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  I0419 17:05:51.912269 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  I0419 17:05:51.959001 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  I0419 17:05:52.013005 14 chunking.go:98] Retrieved 17/17 results with rv 34038 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQwMzgsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  I0419 17:05:52.063225 14 chunking.go:98] Retrieved 9/17 results with rv 34038 and continue 
  STEP: retrieving those results all at once @ 04/19/24 17:05:52.063
  E0419 17:05:52.103444      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:05:52.135416 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-1190" for this suite. @ 04/19/24 17:05:52.162
• [21.469 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject validating webhook configurations with invalid match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:817
  STEP: Creating a kubernetes client @ 04/19/24 17:05:52.219
  I0419 17:05:52.219927 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename webhook @ 04/19/24 17:05:52.223
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:05:52.253
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:05:52.258
  STEP: Setting up server cert @ 04/19/24 17:05:52.304
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 17:05:52.997
  STEP: Deploying the webhook pod @ 04/19/24 17:05:53.021
  STEP: Wait for the deployment to be ready @ 04/19/24 17:05:53.046
  I0419 17:05:53.067866 14 deployment.go:222] new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0419 17:05:53.104311      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:54.104353      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 17:05:55.094
  E0419 17:05:55.105278      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 17:05:55.115
  E0419 17:05:56.105161      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:05:56.116508 14 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a validating webhook with match conditions @ 04/19/24 17:05:56.131
  I0419 17:05:56.225465 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5861" for this suite. @ 04/19/24 17:05:56.237
  STEP: Destroying namespace "webhook-markers-1885" for this suite. @ 04/19/24 17:05:56.245
• [4.034 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:105
  STEP: Creating a kubernetes client @ 04/19/24 17:05:56.255
  I0419 17:05:56.256233 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename endpointslice @ 04/19/24 17:05:56.259
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:05:56.283
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:05:56.289
  I0419 17:05:56.374632 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-2976" for this suite. @ 04/19/24 17:05:56.381
• [0.138 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:229
  STEP: Creating a kubernetes client @ 04/19/24 17:05:56.399
  I0419 17:05:56.399513 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename var-expansion @ 04/19/24 17:05:56.402
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:05:56.43
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:05:56.433
  STEP: creating the pod with failed condition @ 04/19/24 17:05:56.438
  E0419 17:05:57.105549      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:58.105755      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:59.106260      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:00.106619      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:01.107219      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:02.107875      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:03.108190      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:04.108692      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:05.109675      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:06.110906      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:07.112158      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:08.113283      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:09.113398      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:10.113659      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:11.114764      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:12.115044      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:13.115966      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:14.116296      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:15.116548      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:16.117280      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:17.117434      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:18.117890      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:19.117971      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:20.118808      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:21.119666      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:22.120548      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:23.120586      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:24.121026      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:25.121876      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:26.122895      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:27.123551      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:28.124258      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:29.125216      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:30.125399      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:31.125472      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:32.126008      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:33.126021      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:34.126143      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:35.126219      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:36.127180      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:37.128022      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:38.128393      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:39.129011      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:40.129200      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:41.129280      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:42.130569      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:43.131460      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:44.131935      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:45.132043      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:46.132376      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:47.132629      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:48.133856      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:49.134711      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:50.135687      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:51.136046      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:52.136107      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:53.137059      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:54.137324      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:55.137518      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:56.137652      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:57.137998      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:58.138833      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:59.139551      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:00.139678      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:01.140553      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:02.141261      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:03.141498      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:04.141826      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:05.142051      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:06.142434      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:07.142697      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:08.143602      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:09.144291      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:10.144639      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:11.144742      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:12.145041      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:13.146125      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:14.146579      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:15.147059      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:16.147319      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:17.148432      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:18.148718      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:19.150033      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:20.149897      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:21.151715      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:22.151352      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:23.152011      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:24.152415      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:25.153219      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:26.153524      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:27.153644      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:28.153752      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:29.154922      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:30.154752      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:31.155467      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:32.156215      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:33.157570      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:34.157957      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:35.158072      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:36.158401      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:37.158469      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:38.158838      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:39.159720      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:40.159784      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:41.160036      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:42.160771      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:43.161383      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:44.161565      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:45.161555      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:46.162158      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:47.163419      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:48.164135      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:49.167316      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:50.166116      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:51.167512      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:52.167758      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:53.168971      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:54.169218      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:55.170449      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:56.170716      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: updating the pod @ 04/19/24 17:07:56.455
  I0419 17:07:56.994079 14 pod_client.go:141] Successfully updated pod "var-expansion-ff3f3364-c058-4a2c-9ac2-dde3f025787c"
  STEP: waiting for pod running @ 04/19/24 17:07:56.995
  E0419 17:07:57.171820      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:58.172358      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 04/19/24 17:07:59.037
  I0419 17:07:59.038123 14 delete.go:62] Deleting pod "var-expansion-ff3f3364-c058-4a2c-9ac2-dde3f025787c" in namespace "var-expansion-9298"
  I0419 17:07:59.057111 14 delete.go:70] Wait up to 5m0s for pod "var-expansion-ff3f3364-c058-4a2c-9ac2-dde3f025787c" to be fully deleted
  E0419 17:07:59.172946      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:00.173660      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:01.174571      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:02.175547      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:03.176745      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:04.177121      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:05.178337      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:06.178634      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:07.178770      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:08.179475      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:09.179497      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:10.180299      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:11.181158      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:12.182025      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:13.181313      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:14.181818      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:15.182566      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:16.183155      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:17.183632      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:18.184323      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:19.185331      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:20.185732      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:21.186013      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:22.186148      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:23.187284      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:24.187429      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:25.187659      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:26.187999      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:27.188280      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:28.188563      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:29.188680      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:30.189314      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:31.189577      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:08:31.254069 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-9298" for this suite. @ 04/19/24 17:08:31.271
• [154.893 seconds]
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:498
  STEP: Creating a kubernetes client @ 04/19/24 17:08:31.294
  I0419 17:08:31.294160 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename webhook @ 04/19/24 17:08:31.301
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:08:31.344
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:08:31.354
  STEP: Setting up server cert @ 04/19/24 17:08:31.418
  E0419 17:08:32.189665      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 17:08:32.299
  STEP: Deploying the webhook pod @ 04/19/24 17:08:32.324
  STEP: Wait for the deployment to be ready @ 04/19/24 17:08:32.352
  I0419 17:08:32.372718 14 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0419 17:08:33.190422      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:34.190806      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 17:08:34.406
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 17:08:34.439
  E0419 17:08:35.190635      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:08:35.440468 14 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a mutating webhook configuration @ 04/19/24 17:08:35.46
  STEP: Updating a mutating webhook configuration's rules to not include the create operation @ 04/19/24 17:08:35.514
  STEP: Creating a configMap that should not be mutated @ 04/19/24 17:08:35.536
  STEP: Patching a mutating webhook configuration's rules to include the create operation @ 04/19/24 17:08:35.569
  STEP: Creating a configMap that should be mutated @ 04/19/24 17:08:35.593
  I0419 17:08:35.755163 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8798" for this suite. @ 04/19/24 17:08:35.77
  STEP: Destroying namespace "webhook-markers-2895" for this suite. @ 04/19/24 17:08:35.785
• [4.507 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:889
  STEP: Creating a kubernetes client @ 04/19/24 17:08:35.8
  I0419 17:08:35.800722 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename resourcequota @ 04/19/24 17:08:35.804
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:08:35.836
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:08:35.843
  STEP: Creating a ResourceQuota @ 04/19/24 17:08:35.879
  STEP: Getting a ResourceQuota @ 04/19/24 17:08:35.889
  STEP: Updating a ResourceQuota @ 04/19/24 17:08:35.896
  STEP: Verifying a ResourceQuota was modified @ 04/19/24 17:08:35.909
  STEP: Deleting a ResourceQuota @ 04/19/24 17:08:35.918
  STEP: Verifying the deleted ResourceQuota @ 04/19/24 17:08:35.927
  I0419 17:08:35.932640 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-8436" for this suite. @ 04/19/24 17:08:35.941
• [0.156 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should validate against a Deployment [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:77
  STEP: Creating a kubernetes client @ 04/19/24 17:08:35.957
  I0419 17:08:35.957549 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename validating-admission-policy @ 04/19/24 17:08:35.959
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:08:35.985
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:08:35.99
  STEP: creating the policy @ 04/19/24 17:08:36.01
  STEP: waiting until the marker is denied @ 04/19/24 17:08:36.046
  E0419 17:08:36.192714      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: testing a replicated Deployment to be allowed @ 04/19/24 17:08:36.563
  STEP: testing a non-replicated ReplicaSet not to be denied @ 04/19/24 17:08:36.583
  I0419 17:08:36.641997 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-6487" for this suite. @ 04/19/24 17:08:36.651
• [0.719 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:399
  STEP: Creating a kubernetes client @ 04/19/24 17:08:36.677
  I0419 17:08:36.677926 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename pods @ 04/19/24 17:08:36.681
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:08:36.741
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:08:36.752
  STEP: creating the pod @ 04/19/24 17:08:36.759
  STEP: submitting the pod to kubernetes @ 04/19/24 17:08:36.759
  W0419 17:08:36.775783      14 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  E0419 17:08:37.192692      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:38.193369      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 04/19/24 17:08:38.798
  STEP: updating the pod @ 04/19/24 17:08:38.808
  E0419 17:08:39.194456      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:08:39.340379 14 pod_client.go:141] Successfully updated pod "pod-update-activedeadlineseconds-8eca5da8-298c-4842-8788-8918ec30d6f4"
  E0419 17:08:40.194207      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:41.195316      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:42.195526      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:43.195611      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:08:43.370909 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-3304" for this suite. @ 04/19/24 17:08:43.384
• [6.725 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:191
  STEP: Creating a kubernetes client @ 04/19/24 17:08:43.405
  I0419 17:08:43.406009 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename dns @ 04/19/24 17:08:43.41
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:08:43.449
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:08:43.461
  STEP: Creating a test headless service @ 04/19/24 17:08:43.472
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8207 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8207;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8207 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8207;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8207.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8207.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8207.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8207.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8207.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-8207.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8207.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-8207.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8207.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-8207.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8207.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-8207.svc;check="$$(dig +notcp +noall +answer +search 48.61.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.61.48_udp@PTR;check="$$(dig +tcp +noall +answer +search 48.61.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.61.48_tcp@PTR;sleep 1; done
   @ 04/19/24 17:08:43.526
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8207 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8207;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8207 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8207;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8207.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8207.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8207.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8207.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8207.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-8207.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8207.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-8207.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8207.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-8207.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8207.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-8207.svc;check="$$(dig +notcp +noall +answer +search 48.61.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.61.48_udp@PTR;check="$$(dig +tcp +noall +answer +search 48.61.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.61.48_tcp@PTR;sleep 1; done
   @ 04/19/24 17:08:43.527
  STEP: creating a pod to probe DNS @ 04/19/24 17:08:43.527
  STEP: submitting the pod to kubernetes @ 04/19/24 17:08:43.529
  E0419 17:08:44.196298      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:45.196679      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/19/24 17:08:45.575
  STEP: looking for the results for each expected name from probers @ 04/19/24 17:08:45.581
  I0419 17:08:45.593186 14 dns_common.go:478] Unable to read wheezy_udp@dns-test-service from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:45.599774 14 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:45.605589 14 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8207 from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:45.612772 14 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8207 from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:45.619176 14 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:45.625927 14 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:45.635454 14 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:45.644095 14 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:45.679943 14 dns_common.go:478] Unable to read jessie_udp@dns-test-service from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:45.685524 14 dns_common.go:478] Unable to read jessie_tcp@dns-test-service from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:45.697005 14 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8207 from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:45.705707 14 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8207 from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:45.717363 14 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:45.726298 14 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:45.737412 14 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:45.748685 14 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:45.788775 14 dns_common.go:489] Lookups using dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8207 wheezy_tcp@dns-test-service.dns-8207 wheezy_udp@dns-test-service.dns-8207.svc wheezy_tcp@dns-test-service.dns-8207.svc wheezy_udp@_http._tcp.dns-test-service.dns-8207.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8207.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8207 jessie_tcp@dns-test-service.dns-8207 jessie_udp@dns-test-service.dns-8207.svc jessie_tcp@dns-test-service.dns-8207.svc jessie_udp@_http._tcp.dns-test-service.dns-8207.svc jessie_tcp@_http._tcp.dns-test-service.dns-8207.svc]

  I0419 17:08:45.834296 14 dns_common.go:495] Pod client logs for webserver: 
  I0419 17:08:45.852420 14 dns_common.go:495] Pod client logs for querier: 
  I0419 17:08:45.866679 14 dns_common.go:495] Pod client logs for jessie-querier: 
  E0419 17:08:46.197203      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:47.198287      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:48.198048      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:49.198407      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:50.199135      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:08:50.593942 14 dns_common.go:478] Unable to read wheezy_udp@dns-test-service from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:50.609552 14 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:50.618882 14 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8207 from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:50.628206 14 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8207 from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:50.638290 14 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:50.651814 14 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:50.663961 14 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:50.677981 14 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:50.714511 14 dns_common.go:478] Unable to read jessie_udp@dns-test-service from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:50.722904 14 dns_common.go:478] Unable to read jessie_tcp@dns-test-service from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:50.731398 14 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8207 from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:50.740406 14 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8207 from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:50.747636 14 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:50.760603 14 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:50.768043 14 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:50.773918 14 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:50.805855 14 dns_common.go:489] Lookups using dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8207 wheezy_tcp@dns-test-service.dns-8207 wheezy_udp@dns-test-service.dns-8207.svc wheezy_tcp@dns-test-service.dns-8207.svc wheezy_udp@_http._tcp.dns-test-service.dns-8207.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8207.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8207 jessie_tcp@dns-test-service.dns-8207 jessie_udp@dns-test-service.dns-8207.svc jessie_tcp@dns-test-service.dns-8207.svc jessie_udp@_http._tcp.dns-test-service.dns-8207.svc jessie_tcp@_http._tcp.dns-test-service.dns-8207.svc]

  I0419 17:08:50.818511 14 dns_common.go:495] Pod client logs for webserver: 
  I0419 17:08:50.831909 14 dns_common.go:495] Pod client logs for querier: 
  I0419 17:08:50.843257 14 dns_common.go:495] Pod client logs for jessie-querier: 
  E0419 17:08:51.199390      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:52.199287      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:53.200408      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:54.200191      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:55.200368      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:08:55.594453 14 dns_common.go:478] Unable to read wheezy_udp@dns-test-service from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:55.605326 14 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:55.617174 14 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8207 from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:55.629099 14 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8207 from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:55.642617 14 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:55.657324 14 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:55.669207 14 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:55.682284 14 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:55.744009 14 dns_common.go:478] Unable to read jessie_udp@dns-test-service from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:55.757282 14 dns_common.go:478] Unable to read jessie_tcp@dns-test-service from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:55.773945 14 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8207 from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:55.786985 14 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8207 from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:55.819717 14 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:55.831537 14 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:55.842294 14 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:55.851007 14 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:08:55.910613 14 dns_common.go:489] Lookups using dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8207 wheezy_tcp@dns-test-service.dns-8207 wheezy_udp@dns-test-service.dns-8207.svc wheezy_tcp@dns-test-service.dns-8207.svc wheezy_udp@_http._tcp.dns-test-service.dns-8207.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8207.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8207 jessie_tcp@dns-test-service.dns-8207 jessie_udp@dns-test-service.dns-8207.svc jessie_tcp@dns-test-service.dns-8207.svc jessie_udp@_http._tcp.dns-test-service.dns-8207.svc jessie_tcp@_http._tcp.dns-test-service.dns-8207.svc]

  I0419 17:08:55.925125 14 dns_common.go:495] Pod client logs for webserver: 
  I0419 17:08:55.940543 14 dns_common.go:495] Pod client logs for querier: 
  I0419 17:08:55.955009 14 dns_common.go:495] Pod client logs for jessie-querier: 
  E0419 17:08:56.200715      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:57.202133      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:58.201843      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:59.202140      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:00.205759      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:09:00.592994 14 dns_common.go:478] Unable to read wheezy_udp@dns-test-service from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:00.607356 14 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:00.618555 14 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8207 from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:00.629635 14 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8207 from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:00.639585 14 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:00.648081 14 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:00.658726 14 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:00.669135 14 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:00.722931 14 dns_common.go:478] Unable to read jessie_udp@dns-test-service from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:00.733053 14 dns_common.go:478] Unable to read jessie_tcp@dns-test-service from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:00.741236 14 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8207 from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:00.751867 14 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8207 from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:00.763661 14 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:00.782912 14 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:00.798078 14 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:00.810057 14 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:00.868254 14 dns_common.go:489] Lookups using dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8207 wheezy_tcp@dns-test-service.dns-8207 wheezy_udp@dns-test-service.dns-8207.svc wheezy_tcp@dns-test-service.dns-8207.svc wheezy_udp@_http._tcp.dns-test-service.dns-8207.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8207.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8207 jessie_tcp@dns-test-service.dns-8207 jessie_udp@dns-test-service.dns-8207.svc jessie_tcp@dns-test-service.dns-8207.svc jessie_udp@_http._tcp.dns-test-service.dns-8207.svc jessie_tcp@_http._tcp.dns-test-service.dns-8207.svc]

  I0419 17:09:00.882873 14 dns_common.go:495] Pod client logs for webserver: 
  I0419 17:09:00.896392 14 dns_common.go:495] Pod client logs for querier: 
  I0419 17:09:00.907335 14 dns_common.go:495] Pod client logs for jessie-querier: 
  E0419 17:09:01.204360      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:02.204760      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:03.205130      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:04.205531      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:05.206089      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:09:05.606481 14 dns_common.go:478] Unable to read wheezy_udp@dns-test-service from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:05.615493 14 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:05.632514 14 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8207 from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:05.643374 14 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8207 from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:05.649378 14 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:05.658051 14 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:05.666011 14 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:05.671468 14 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:05.717249 14 dns_common.go:478] Unable to read jessie_udp@dns-test-service from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:05.727145 14 dns_common.go:478] Unable to read jessie_tcp@dns-test-service from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:05.733734 14 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8207 from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:05.739515 14 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8207 from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:05.748290 14 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:05.758527 14 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:05.764967 14 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:05.772121 14 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:05.798948 14 dns_common.go:489] Lookups using dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8207 wheezy_tcp@dns-test-service.dns-8207 wheezy_udp@dns-test-service.dns-8207.svc wheezy_tcp@dns-test-service.dns-8207.svc wheezy_udp@_http._tcp.dns-test-service.dns-8207.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8207.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8207 jessie_tcp@dns-test-service.dns-8207 jessie_udp@dns-test-service.dns-8207.svc jessie_tcp@dns-test-service.dns-8207.svc jessie_udp@_http._tcp.dns-test-service.dns-8207.svc jessie_tcp@_http._tcp.dns-test-service.dns-8207.svc]

  I0419 17:09:05.815749 14 dns_common.go:495] Pod client logs for webserver: 
  I0419 17:09:05.830202 14 dns_common.go:495] Pod client logs for querier: 
  I0419 17:09:05.844510 14 dns_common.go:495] Pod client logs for jessie-querier: 
  E0419 17:09:06.206624      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:07.206878      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:08.207454      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:09.207228      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:10.207460      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:09:10.594649 14 dns_common.go:478] Unable to read wheezy_udp@dns-test-service from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:10.609924 14 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:10.624651 14 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8207 from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:10.635088 14 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8207 from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:10.648676 14 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:10.660834 14 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:10.673443 14 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:10.688064 14 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:10.756108 14 dns_common.go:478] Unable to read jessie_udp@dns-test-service from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:10.768381 14 dns_common.go:478] Unable to read jessie_tcp@dns-test-service from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:10.783392 14 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8207 from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:10.794938 14 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8207 from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:10.808648 14 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:10.820681 14 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:10.831666 14 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:10.844200 14 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:10.880077 14 dns_common.go:489] Lookups using dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8207 wheezy_tcp@dns-test-service.dns-8207 wheezy_udp@dns-test-service.dns-8207.svc wheezy_tcp@dns-test-service.dns-8207.svc wheezy_udp@_http._tcp.dns-test-service.dns-8207.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8207.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8207 jessie_tcp@dns-test-service.dns-8207 jessie_udp@dns-test-service.dns-8207.svc jessie_tcp@dns-test-service.dns-8207.svc jessie_udp@_http._tcp.dns-test-service.dns-8207.svc jessie_tcp@_http._tcp.dns-test-service.dns-8207.svc]

  I0419 17:09:10.892589 14 dns_common.go:495] Pod client logs for webserver: 
  I0419 17:09:10.908750 14 dns_common.go:495] Pod client logs for querier: 
  I0419 17:09:10.922833 14 dns_common.go:495] Pod client logs for jessie-querier: 
  E0419 17:09:11.207748      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:12.208483      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:13.208815      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:14.208772      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:15.209230      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:09:15.603167 14 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:15.613268 14 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8207 from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:15.623407 14 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8207 from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:15.631669 14 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:15.637709 14 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:15.644745 14 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:15.659620 14 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8207.svc from pod dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce: the server could not find the requested resource (get pods dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce)
  I0419 17:09:15.818650 14 dns_common.go:489] Lookups using dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce failed for: [wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8207 wheezy_tcp@dns-test-service.dns-8207 wheezy_udp@dns-test-service.dns-8207.svc wheezy_tcp@dns-test-service.dns-8207.svc wheezy_udp@_http._tcp.dns-test-service.dns-8207.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8207.svc]

  I0419 17:09:15.840599 14 dns_common.go:495] Pod client logs for webserver: 
  I0419 17:09:15.879155 14 dns_common.go:495] Pod client logs for querier: 
  I0419 17:09:15.890894 14 dns_common.go:495] Pod client logs for jessie-querier: 
  E0419 17:09:16.210430      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:17.210990      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:18.211453      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:19.212141      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:20.212228      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:09:20.781065 14 dns_common.go:527] DNS probes using dns-8207/dns-test-726034d3-eeb1-43aa-819b-5b8ef721cfce succeeded

  STEP: deleting the pod @ 04/19/24 17:09:20.782
  STEP: deleting the test service @ 04/19/24 17:09:20.814
  STEP: deleting the test headless service @ 04/19/24 17:09:20.9
  I0419 17:09:21.004452 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-8207" for this suite. @ 04/19/24 17:09:21.044
• [37.652 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should apply changes to a job status [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:833
  STEP: Creating a kubernetes client @ 04/19/24 17:09:21.062
  I0419 17:09:21.062747 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename job @ 04/19/24 17:09:21.068
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:09:21.102
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:09:21.109
  STEP: Creating a job @ 04/19/24 17:09:21.115
  STEP: Ensure pods equal to parallelism count is attached to the job @ 04/19/24 17:09:21.132
  E0419 17:09:21.215282      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:22.215454      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching /status @ 04/19/24 17:09:23.141
  STEP: updating /status @ 04/19/24 17:09:23.16
  STEP: get /status @ 04/19/24 17:09:23.185
  I0419 17:09:23.194681 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-5041" for this suite. @ 04/19/24 17:09:23.212
  E0419 17:09:23.216196      14 retrywatcher.go:129] "Watch failed" err="context canceled"
• [2.167 seconds]
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:79
  STEP: Creating a kubernetes client @ 04/19/24 17:09:23.231
  I0419 17:09:23.231267 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename secrets @ 04/19/24 17:09:23.235
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:09:23.262
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:09:23.268
  STEP: Creating secret with name secret-test-map-111177ef-f8c6-40c4-a0c1-0a493659c839 @ 04/19/24 17:09:23.275
  STEP: Creating a pod to test consume secrets @ 04/19/24 17:09:23.289
  E0419 17:09:24.217480      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:25.217430      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:26.217515      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:27.218698      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:09:27.344
  I0419 17:09:27.355483 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-secrets-08df22df-bc1d-4d45-80a8-ad3194b3e982 container secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/24 17:09:27.374
  I0419 17:09:27.418767 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-399" for this suite. @ 04/19/24 17:09:27.433
• [4.225 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:75
  STEP: Creating a kubernetes client @ 04/19/24 17:09:27.461
  I0419 17:09:27.461335 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename containers @ 04/19/24 17:09:27.465
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:09:27.507
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:09:27.521
  STEP: Creating a pod to test override command @ 04/19/24 17:09:27.53
  E0419 17:09:28.219975      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:29.220026      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:30.220668      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:31.220789      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:09:31.603
  I0419 17:09:31.612158 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod client-containers-fd571472-7bd1-4460-ad4b-24afbbff36e3 container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/24 17:09:31.634
  I0419 17:09:31.681492 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-7893" for this suite. @ 04/19/24 17:09:31.698
• [4.255 seconds]
------------------------------
[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:305
  STEP: Creating a kubernetes client @ 04/19/24 17:09:31.716
  I0419 17:09:31.716064 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename daemonsets @ 04/19/24 17:09:31.718
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:09:31.756
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:09:31.761
  STEP: Creating a simple DaemonSet "daemon-set" @ 04/19/24 17:09:31.821
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/19/24 17:09:31.883
  I0419 17:09:31.901368 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0419 17:09:31.901435 14 fixtures.go:130] Node eipo9quoh3ef-1 is running 0 daemon pod, expected 1
  E0419 17:09:32.220777      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:09:32.909645 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0419 17:09:32.909752 14 fixtures.go:130] Node eipo9quoh3ef-1 is running 0 daemon pod, expected 1
  E0419 17:09:33.221763      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:09:33.910459 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0419 17:09:33.911256 14 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. @ 04/19/24 17:09:33.92
  I0419 17:09:33.986350 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0419 17:09:33.986926 14 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Wait for the failed daemon pod to be completely deleted. @ 04/19/24 17:09:33.987
  STEP: Deleting DaemonSet "daemon-set" @ 04/19/24 17:09:34.044
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1337, will wait for the garbage collector to delete the pods @ 04/19/24 17:09:34.044
  I0419 17:09:34.151873 14 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 16.614455ms
  E0419 17:09:34.222468      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:09:34.253268 14 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 101.007754ms
  E0419 17:09:35.222510      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:09:36.062066 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0419 17:09:36.062177 14 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0419 17:09:36.066873 14 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"35414"},"items":null}

  I0419 17:09:36.073488 14 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"35414"},"items":null}

  I0419 17:09:36.104483 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-1337" for this suite. @ 04/19/24 17:09:36.114
• [4.412 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:237
  STEP: Creating a kubernetes client @ 04/19/24 17:09:36.134
  I0419 17:09:36.134385 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/19/24 17:09:36.136
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:09:36.166
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:09:36.171
  I0419 17:09:36.178500 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  E0419 17:09:36.223652      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:37.224122      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 04/19/24 17:09:38.111
  I0419 17:09:38.112425 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=crd-publish-openapi-9308 --namespace=crd-publish-openapi-9308 create -f -'
  E0419 17:09:38.224577      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:09:38.514904 14 builder.go:146] stderr: ""
  I0419 17:09:38.515239 14 builder.go:147] stdout: "e2e-test-crd-publish-openapi-6512-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  I0419 17:09:38.515919 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=crd-publish-openapi-9308 --namespace=crd-publish-openapi-9308 delete e2e-test-crd-publish-openapi-6512-crds test-cr'
  I0419 17:09:38.700268 14 builder.go:146] stderr: ""
  I0419 17:09:38.700384 14 builder.go:147] stdout: "e2e-test-crd-publish-openapi-6512-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  I0419 17:09:38.700847 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=crd-publish-openapi-9308 --namespace=crd-publish-openapi-9308 apply -f -'
  I0419 17:09:38.878498 14 builder.go:146] stderr: ""
  I0419 17:09:38.878579 14 builder.go:147] stdout: "e2e-test-crd-publish-openapi-6512-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  I0419 17:09:38.879079 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=crd-publish-openapi-9308 --namespace=crd-publish-openapi-9308 delete e2e-test-crd-publish-openapi-6512-crds test-cr'
  I0419 17:09:39.051870 14 builder.go:146] stderr: ""
  I0419 17:09:39.051958 14 builder.go:147] stdout: "e2e-test-crd-publish-openapi-6512-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 04/19/24 17:09:39.051
  I0419 17:09:39.052411 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=crd-publish-openapi-9308 explain e2e-test-crd-publish-openapi-6512-crds'
  E0419 17:09:39.225125      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:09:39.227554 14 builder.go:146] stderr: ""
  I0419 17:09:39.227649 14 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-unknown-in-nested.example.com\nKIND:       e2e-test-crd-publish-openapi-6512-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties in nested field for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E0419 17:09:40.225495      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:09:41.075543 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-9308" for this suite. @ 04/19/24 17:09:41.099
• [4.979 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2181
  STEP: Creating a kubernetes client @ 04/19/24 17:09:41.113
  I0419 17:09:41.113490 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename services @ 04/19/24 17:09:41.118
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:09:41.167
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:09:41.173
  STEP: creating service in namespace services-3152 @ 04/19/24 17:09:41.18
  STEP: creating service affinity-clusterip in namespace services-3152 @ 04/19/24 17:09:41.18
  STEP: creating replication controller affinity-clusterip in namespace services-3152 @ 04/19/24 17:09:41.201
  I0419 17:09:41.215776      14 runners.go:198] Created replication controller with name: affinity-clusterip, namespace: services-3152, replica count: 3
  E0419 17:09:41.226046      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:42.226647      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:43.226850      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:44.226920      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:09:44.268096      14 runners.go:198] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0419 17:09:44.284500 14 resource.go:361] Creating new exec pod
  E0419 17:09:45.227230      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:46.227322      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:47.228164      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:09:47.321099 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-3152 exec execpod-affinitynb6g4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
  I0419 17:09:47.702355 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
  I0419 17:09:47.702464 14 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0419 17:09:47.703228 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-3152 exec execpod-affinitynb6g4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.9.16 80'
  I0419 17:09:47.982084 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.9.16 80\nConnection to 10.233.9.16 80 port [tcp/http] succeeded!\n"
  I0419 17:09:47.982245 14 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0419 17:09:47.982823 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-3152 exec execpod-affinitynb6g4 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.9.16:80/ ; done'
  E0419 17:09:48.228338      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:09:48.408075 14 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.16:80/\n"
  I0419 17:09:48.408195 14 builder.go:147] stdout: "\naffinity-clusterip-2zf66\naffinity-clusterip-2zf66\naffinity-clusterip-2zf66\naffinity-clusterip-2zf66\naffinity-clusterip-2zf66\naffinity-clusterip-2zf66\naffinity-clusterip-2zf66\naffinity-clusterip-2zf66\naffinity-clusterip-2zf66\naffinity-clusterip-2zf66\naffinity-clusterip-2zf66\naffinity-clusterip-2zf66\naffinity-clusterip-2zf66\naffinity-clusterip-2zf66\naffinity-clusterip-2zf66\naffinity-clusterip-2zf66"
  I0419 17:09:48.408251 14 service.go:242] Received response from host: affinity-clusterip-2zf66
  I0419 17:09:48.408410 14 service.go:242] Received response from host: affinity-clusterip-2zf66
  I0419 17:09:48.408459 14 service.go:242] Received response from host: affinity-clusterip-2zf66
  I0419 17:09:48.408478 14 service.go:242] Received response from host: affinity-clusterip-2zf66
  I0419 17:09:48.408495 14 service.go:242] Received response from host: affinity-clusterip-2zf66
  I0419 17:09:48.408512 14 service.go:242] Received response from host: affinity-clusterip-2zf66
  I0419 17:09:48.408563 14 service.go:242] Received response from host: affinity-clusterip-2zf66
  I0419 17:09:48.408595 14 service.go:242] Received response from host: affinity-clusterip-2zf66
  I0419 17:09:48.408748 14 service.go:242] Received response from host: affinity-clusterip-2zf66
  I0419 17:09:48.408768 14 service.go:242] Received response from host: affinity-clusterip-2zf66
  I0419 17:09:48.408790 14 service.go:242] Received response from host: affinity-clusterip-2zf66
  I0419 17:09:48.408937 14 service.go:242] Received response from host: affinity-clusterip-2zf66
  I0419 17:09:48.408962 14 service.go:242] Received response from host: affinity-clusterip-2zf66
  I0419 17:09:48.409075 14 service.go:242] Received response from host: affinity-clusterip-2zf66
  I0419 17:09:48.409094 14 service.go:242] Received response from host: affinity-clusterip-2zf66
  I0419 17:09:48.409110 14 service.go:242] Received response from host: affinity-clusterip-2zf66
  I0419 17:09:48.409382 14 service.go:4014] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip in namespace services-3152, will wait for the garbage collector to delete the pods @ 04/19/24 17:09:48.432
  I0419 17:09:48.505478 14 resources.go:139] Deleting ReplicationController affinity-clusterip took: 15.150941ms
  I0419 17:09:48.607379 14 resources.go:163] Terminating ReplicationController affinity-clusterip pods took: 102.149311ms
  E0419 17:09:49.229180      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:50.229953      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:51.230315      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:09:51.859746 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3152" for this suite. @ 04/19/24 17:09:51.874
• [10.810 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:230
  STEP: Creating a kubernetes client @ 04/19/24 17:09:51.925
  I0419 17:09:51.925087 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename emptydir @ 04/19/24 17:09:51.928
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:09:51.956
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:09:51.964
  STEP: Creating Pod @ 04/19/24 17:09:51.971
  E0419 17:09:52.231931      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:53.232016      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Reading file content from the nginx-container @ 04/19/24 17:09:54.008
  I0419 17:09:54.008701 14 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-7788 PodName:pod-sharedvolume-a642d858-1816-45e6-9824-f8bfeff3d2b6 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0419 17:09:54.009428 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 17:09:54.012246 14 exec_util.go:62] ExecWithOptions: Clientset creation
  I0419 17:09:54.012819 14 exec_util.go:79] ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/emptydir-7788/pods/pod-sharedvolume-a642d858-1816-45e6-9824-f8bfeff3d2b6/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
  I0419 17:09:54.147697 14 exec_util.go:106] Exec stderr: ""
  I0419 17:09:54.148824 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7788" for this suite. @ 04/19/24 17:09:54.162
• [2.254 seconds]
------------------------------
SSS
------------------------------
[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:171
  STEP: Creating a kubernetes client @ 04/19/24 17:09:54.179
  I0419 17:09:54.179727 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename configmap @ 04/19/24 17:09:54.182
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:09:54.228
  E0419 17:09:54.232080      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:09:54.238
  STEP: creating a ConfigMap @ 04/19/24 17:09:54.245
  STEP: fetching the ConfigMap @ 04/19/24 17:09:54.261
  STEP: patching the ConfigMap @ 04/19/24 17:09:54.269
  STEP: listing all ConfigMaps in all namespaces with a label selector @ 04/19/24 17:09:54.284
  STEP: deleting the ConfigMap by collection with a label selector @ 04/19/24 17:09:54.294
  STEP: listing all ConfigMaps in test namespace @ 04/19/24 17:09:54.315
  I0419 17:09:54.324274 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6391" for this suite. @ 04/19/24 17:09:54.34
• [0.181 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should support configurable pod DNS nameservers [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:407
  STEP: Creating a kubernetes client @ 04/19/24 17:09:54.378
  I0419 17:09:54.378582 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename dns @ 04/19/24 17:09:54.383
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:09:54.427
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:09:54.434
  STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... @ 04/19/24 17:09:54.44
  I0419 17:09:54.461451 14 dns.go:419] Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-6725  8c390423-5de9-4b77-b0e6-8e07d7b153fa 35613 0 2024-04-19 17:09:54 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2024-04-19 17:09:54 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xrfx7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,ClusterTrustBundle:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.47,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xrfx7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,RecursiveReadOnly:nil,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,AppArmorProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,AppArmorProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,ResourceClaimStatuses:[]PodResourceClaimStatus{},HostIPs:[]HostIP{},},}
  E0419 17:09:55.233142      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:56.233012      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying customized DNS suffix list is configured on pod... @ 04/19/24 17:09:56.482
  I0419 17:09:56.482509 14 exec_util.go:55] ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-6725 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0419 17:09:56.482561 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 17:09:56.484661 14 exec_util.go:62] ExecWithOptions: Clientset creation
  I0419 17:09:56.484844 14 exec_util.go:79] ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/dns-6725/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  STEP: Verifying customized DNS server is configured on pod... @ 04/19/24 17:09:56.644
  I0419 17:09:56.644948 14 exec_util.go:55] ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-6725 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0419 17:09:56.645035 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 17:09:56.647547 14 exec_util.go:62] ExecWithOptions: Clientset creation
  I0419 17:09:56.648246 14 exec_util.go:79] ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/dns-6725/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  I0419 17:09:56.792600 14 dns.go:421] Deleting pod test-dns-nameservers...
  I0419 17:09:56.817606 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-6725" for this suite. @ 04/19/24 17:09:56.83
• [2.466 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:96
  STEP: Creating a kubernetes client @ 04/19/24 17:09:56.846
  I0419 17:09:56.846868 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename var-expansion @ 04/19/24 17:09:56.85
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:09:56.883
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:09:56.888
  STEP: Creating a pod to test substitution in container's args @ 04/19/24 17:09:56.895
  E0419 17:09:57.233046      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:58.233627      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:09:58.927
  I0419 17:09:58.933966 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod var-expansion-bb34b5ce-7ceb-4485-8ceb-6d83a5647079 container dapi-container: <nil>
  STEP: delete the pod @ 04/19/24 17:09:58.947
  I0419 17:09:58.975997 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-6780" for this suite. @ 04/19/24 17:09:58.985
• [2.155 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-instrumentation] Events should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/core_events.go:176
  STEP: Creating a kubernetes client @ 04/19/24 17:09:59.005
  I0419 17:09:59.005727 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename events @ 04/19/24 17:09:59.008
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:09:59.048
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:09:59.055
  STEP: Create set of events @ 04/19/24 17:09:59.061
  I0419 17:09:59.071921 14 core_events.go:198] created test-event-1
  I0419 17:09:59.080396 14 core_events.go:198] created test-event-2
  I0419 17:09:59.091989 14 core_events.go:198] created test-event-3
  STEP: get a list of Events with a label in the current namespace @ 04/19/24 17:09:59.092
  STEP: delete collection of events @ 04/19/24 17:09:59.099
  I0419 17:09:59.099911 14 core_events.go:213] requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 04/19/24 17:09:59.155
  I0419 17:09:59.156101 14 core_events.go:230] requesting list of events to confirm quantity
  I0419 17:09:59.164514 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-353" for this suite. @ 04/19/24 17:09:59.175
• [0.198 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:57
  STEP: Creating a kubernetes client @ 04/19/24 17:09:59.204
  I0419 17:09:59.204046 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename runtimeclass @ 04/19/24 17:09:59.207
  E0419 17:09:59.233655      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:09:59.248
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:09:59.254
  I0419 17:09:59.284503 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-8874" for this suite. @ 04/19/24 17:09:59.293
• [0.100 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:51
  STEP: Creating a kubernetes client @ 04/19/24 17:09:59.306
  I0419 17:09:59.306419 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename kubelet-test @ 04/19/24 17:09:59.31
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:09:59.343
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:09:59.349
  E0419 17:10:00.234489      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:01.235238      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:10:01.441950 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-4600" for this suite. @ 04/19/24 17:10:01.456
• [2.169 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:221
  STEP: Creating a kubernetes client @ 04/19/24 17:10:01.477
  I0419 17:10:01.477844 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename webhook @ 04/19/24 17:10:01.48
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:10:01.518
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:10:01.523
  STEP: Setting up server cert @ 04/19/24 17:10:01.592
  E0419 17:10:02.235260      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 17:10:02.935
  STEP: Deploying the webhook pod @ 04/19/24 17:10:02.95
  STEP: Wait for the deployment to be ready @ 04/19/24 17:10:02.974
  I0419 17:10:02.996464 14 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0419 17:10:03.236196      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:04.236523      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 17:10:05.026
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 17:10:05.056
  E0419 17:10:05.237469      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:10:06.057698 14 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0419 17:10:06.077986 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  E0419 17:10:06.238586      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the custom resource webhook via the AdmissionRegistration API @ 04/19/24 17:10:06.607
  STEP: Creating a custom resource that should be denied by the webhook @ 04/19/24 17:10:06.658
  E0419 17:10:07.238760      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:08.239318      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a custom resource whose deletion would be denied by the webhook @ 04/19/24 17:10:08.812
  STEP: Updating the custom resource with disallowed data should be denied @ 04/19/24 17:10:08.832
  STEP: Deleting the custom resource should be denied @ 04/19/24 17:10:08.864
  STEP: Remove the offending key and value from the custom resource data @ 04/19/24 17:10:08.886
  STEP: Deleting the updated custom resource should be successful @ 04/19/24 17:10:08.938
  E0419 17:10:09.239544      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:10:09.584528 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8186" for this suite. @ 04/19/24 17:10:09.593
  STEP: Destroying namespace "webhook-markers-6520" for this suite. @ 04/19/24 17:10:09.605
• [8.138 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:200
  STEP: Creating a kubernetes client @ 04/19/24 17:10:09.615
  I0419 17:10:09.615687 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename emptydir @ 04/19/24 17:10:09.617
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:10:09.651
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:10:09.658
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 04/19/24 17:10:09.664
  E0419 17:10:10.242611      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:11.243779      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:12.243975      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:13.244443      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:10:13.721
  I0419 17:10:13.728486 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-a8b9b1de-dc40-436d-90a3-8f63bc9f4268 container test-container: <nil>
  STEP: delete the pod @ 04/19/24 17:10:13.74
  I0419 17:10:13.772644 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5444" for this suite. @ 04/19/24 17:10:13.781
• [4.188 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:72
  STEP: Creating a kubernetes client @ 04/19/24 17:10:13.805
  I0419 17:10:13.805301 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename container-probe @ 04/19/24 17:10:13.808
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:10:13.847
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:10:13.852
  E0419 17:10:14.245538      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:15.245739      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:16.246780      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:17.247064      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:18.247988      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:19.248516      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:20.248985      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:21.249065      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:22.249652      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:23.249650      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:24.250796      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:25.251201      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:26.251722      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:27.252665      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:28.253974      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:29.253917      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:30.254244      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:31.254666      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:32.254694      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:33.254978      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:34.255545      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:35.256216      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:10:35.994459 14 container_probe.go:92] Container started at 2024-04-19 17:10:14 +0000 UTC, pod became ready at 2024-04-19 17:10:34 +0000 UTC
  I0419 17:10:35.995503 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-6093" for this suite. @ 04/19/24 17:10:36.006
• [22.215 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:154
  STEP: Creating a kubernetes client @ 04/19/24 17:10:36.022
  I0419 17:10:36.022778 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/19/24 17:10:36.025
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:10:36.063
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:10:36.068
  I0419 17:10:36.075624 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  E0419 17:10:36.256549      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:37.256504      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 04/19/24 17:10:37.903
  I0419 17:10:37.906503 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=crd-publish-openapi-987 --namespace=crd-publish-openapi-987 create -f -'
  E0419 17:10:38.256629      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:10:38.292524 14 builder.go:146] stderr: ""
  I0419 17:10:38.292601 14 builder.go:147] stdout: "e2e-test-crd-publish-openapi-7012-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  I0419 17:10:38.293134 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=crd-publish-openapi-987 --namespace=crd-publish-openapi-987 delete e2e-test-crd-publish-openapi-7012-crds test-cr'
  I0419 17:10:38.472047 14 builder.go:146] stderr: ""
  I0419 17:10:38.472122 14 builder.go:147] stdout: "e2e-test-crd-publish-openapi-7012-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  I0419 17:10:38.472406 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=crd-publish-openapi-987 --namespace=crd-publish-openapi-987 apply -f -'
  I0419 17:10:38.758971 14 builder.go:146] stderr: ""
  I0419 17:10:38.759100 14 builder.go:147] stdout: "e2e-test-crd-publish-openapi-7012-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  I0419 17:10:38.759380 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=crd-publish-openapi-987 --namespace=crd-publish-openapi-987 delete e2e-test-crd-publish-openapi-7012-crds test-cr'
  I0419 17:10:38.955032 14 builder.go:146] stderr: ""
  I0419 17:10:38.955527 14 builder.go:147] stdout: "e2e-test-crd-publish-openapi-7012-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR without validation schema @ 04/19/24 17:10:38.955
  I0419 17:10:38.955878 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=crd-publish-openapi-987 explain e2e-test-crd-publish-openapi-7012-crds'
  I0419 17:10:39.110563 14 builder.go:146] stderr: ""
  I0419 17:10:39.110666 14 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-empty.example.com\nKIND:       e2e-test-crd-publish-openapi-7012-crd\nVERSION:    v1\n\nDESCRIPTION:\n    <empty>\nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n\n"
  E0419 17:10:39.257336      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:40.258776      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:10:40.972433 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-987" for this suite. @ 04/19/24 17:10:40.999
• [4.994 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:289
  STEP: Creating a kubernetes client @ 04/19/24 17:10:41.034
  I0419 17:10:41.034646 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename field-validation @ 04/19/24 17:10:41.037
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:10:41.073
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:10:41.079
  I0419 17:10:41.085994 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  E0419 17:10:41.259177      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:42.259489      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:43.259898      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:44.260808      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:10:44.408678 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-4499" for this suite. @ 04/19/24 17:10:44.422
• [3.409 seconds]
------------------------------
SS
------------------------------
[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:140
  STEP: Creating a kubernetes client @ 04/19/24 17:10:44.445
  I0419 17:10:44.445519 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename configmap @ 04/19/24 17:10:44.449
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:10:44.486
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:10:44.493
  STEP: Creating configMap that has name configmap-test-emptyKey-e4dcd3ad-4a37-42b5-b844-89c72bf56f5b @ 04/19/24 17:10:44.5
  I0419 17:10:44.504502 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6521" for this suite. @ 04/19/24 17:10:44.515
• [0.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:356
  STEP: Creating a kubernetes client @ 04/19/24 17:10:44.536
  I0419 17:10:44.536063 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename endpointslice @ 04/19/24 17:10:44.539
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:10:44.565
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:10:44.571
  STEP: getting /apis @ 04/19/24 17:10:44.577
  STEP: getting /apis/discovery.k8s.io @ 04/19/24 17:10:44.586
  STEP: getting /apis/discovery.k8s.iov1 @ 04/19/24 17:10:44.588
  STEP: creating @ 04/19/24 17:10:44.591
  STEP: getting @ 04/19/24 17:10:44.625
  STEP: listing @ 04/19/24 17:10:44.633
  STEP: watching @ 04/19/24 17:10:44.643
  I0419 17:10:44.643083 14 endpointslice.go:447] starting watch
  STEP: cluster-wide listing @ 04/19/24 17:10:44.645
  STEP: cluster-wide watching @ 04/19/24 17:10:44.651
  I0419 17:10:44.651160 14 endpointslice.go:459] starting watch
  STEP: patching @ 04/19/24 17:10:44.653
  STEP: updating @ 04/19/24 17:10:44.665
  I0419 17:10:44.684144 14 endpointslice.go:482] waiting for watch events with expected annotations
  I0419 17:10:44.684513 14 endpointslice.go:495] saw patched and updated annotations
  STEP: deleting @ 04/19/24 17:10:44.685
  STEP: deleting a collection @ 04/19/24 17:10:44.703
  I0419 17:10:44.725628 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-9081" for this suite. @ 04/19/24 17:10:44.733
• [0.208 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:119
  STEP: Creating a kubernetes client @ 04/19/24 17:10:44.744
  I0419 17:10:44.744716 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename webhook @ 04/19/24 17:10:44.747
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:10:44.768
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:10:44.774
  STEP: Setting up server cert @ 04/19/24 17:10:44.818
  E0419 17:10:45.261795      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 17:10:45.78
  STEP: Deploying the webhook pod @ 04/19/24 17:10:45.798
  STEP: Wait for the deployment to be ready @ 04/19/24 17:10:45.825
  I0419 17:10:45.848949 14 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0419 17:10:46.262164      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:47.263046      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 17:10:47.876
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 17:10:47.914
  E0419 17:10:48.263866      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:10:48.915468 14 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: fetching the /apis discovery document @ 04/19/24 17:10:48.937
  STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document @ 04/19/24 17:10:48.939
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document @ 04/19/24 17:10:48.939
  STEP: fetching the /apis/admissionregistration.k8s.io discovery document @ 04/19/24 17:10:48.94
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document @ 04/19/24 17:10:48.942
  STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document @ 04/19/24 17:10:48.942
  STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document @ 04/19/24 17:10:48.945
  I0419 17:10:49.041851 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-645" for this suite. @ 04/19/24 17:10:49.052
  STEP: Destroying namespace "webhook-markers-3299" for this suite. @ 04/19/24 17:10:49.068
• [4.338 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:75
  STEP: Creating a kubernetes client @ 04/19/24 17:10:49.084
  I0419 17:10:49.084780 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename projected @ 04/19/24 17:10:49.088
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:10:49.146
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:10:49.153
  STEP: Creating configMap with name projected-configmap-test-volume-38ce606f-eb79-4bae-a9d1-9d3cb4eed53f @ 04/19/24 17:10:49.161
  STEP: Creating a pod to test consume configMaps @ 04/19/24 17:10:49.17
  E0419 17:10:49.263759      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:50.263790      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:51.265258      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:52.265494      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:10:53.227
  I0419 17:10:53.235296 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-projected-configmaps-bebd8a96-1ab1-480c-a9e1-065f32b2ee4f container agnhost-container: <nil>
  E0419 17:10:53.266342      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod @ 04/19/24 17:10:53.285
  I0419 17:10:53.329166 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-351" for this suite. @ 04/19/24 17:10:53.34
• [4.272 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:89
  STEP: Creating a kubernetes client @ 04/19/24 17:10:53.357
  I0419 17:10:53.357880 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename secrets @ 04/19/24 17:10:53.361
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:10:53.438
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:10:53.443
  STEP: Creating secret with name secret-test-map-14e7a0e3-a7c9-46b2-8a50-c083f7e5fa09 @ 04/19/24 17:10:53.45
  STEP: Creating a pod to test consume secrets @ 04/19/24 17:10:53.465
  E0419 17:10:54.266595      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:55.267370      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:56.267728      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:57.268828      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:10:57.532
  I0419 17:10:57.542344 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-secrets-98d63c55-c7b8-49ef-9305-d792a51e8bee container secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/24 17:10:57.572
  I0419 17:10:57.611533 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3787" for this suite. @ 04/19/24 17:10:57.62
• [4.277 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:175
  STEP: Creating a kubernetes client @ 04/19/24 17:10:57.645
  I0419 17:10:57.645104 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename projected @ 04/19/24 17:10:57.648
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:10:57.674
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:10:57.681
  STEP: Creating configMap with name cm-test-opt-del-1bd5e104-17be-4801-a009-48f4b2f32abf @ 04/19/24 17:10:57.702
  STEP: Creating configMap with name cm-test-opt-upd-0a23fb85-0bfb-45bf-bd36-5d76e7332fce @ 04/19/24 17:10:57.711
  STEP: Creating the pod @ 04/19/24 17:10:57.721
  E0419 17:10:58.269396      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:59.270105      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-1bd5e104-17be-4801-a009-48f4b2f32abf @ 04/19/24 17:10:59.8
  STEP: Updating configmap cm-test-opt-upd-0a23fb85-0bfb-45bf-bd36-5d76e7332fce @ 04/19/24 17:10:59.812
  STEP: Creating configMap with name cm-test-opt-create-2602ecb3-65e1-499f-bbf2-2f65e993d2a8 @ 04/19/24 17:10:59.823
  STEP: waiting to observe update in volume @ 04/19/24 17:10:59.834
  E0419 17:11:00.271417      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:01.272349      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:02.272609      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:03.273179      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:04.273416      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:05.273665      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:06.274234      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:07.274487      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:08.275374      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:09.275947      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:10.276734      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:11.277529      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:12.278347      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:13.278680      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:14.279308      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:15.279583      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:16.280340      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:17.280568      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:18.281347      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:19.281841      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:20.282346      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:21.282541      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:22.283333      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:23.285279      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:24.284181      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:25.285446      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:26.286004      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:27.286345      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:28.286862      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:29.287243      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:30.287886      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:31.288226      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:32.289042      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:33.289258      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:34.289876      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:35.291142      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:36.291813      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:37.293141      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:38.293136      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:39.293325      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:40.293770      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:41.294402      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:42.294646      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:43.295720      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:44.295771      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:45.297104      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:46.297392      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:47.297661      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:48.298309      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:49.298344      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:50.299354      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:51.299673      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:52.300470      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:53.300605      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:54.301725      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:55.301876      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:56.302266      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:57.302501      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:58.302979      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:59.303270      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:00.303453      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:01.304275      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:02.304594      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:03.305400      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:04.305843      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:05.306829      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:06.307046      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:07.307279      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:08.307863      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:09.308258      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:10.309365      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:12:10.686921 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3690" for this suite. @ 04/19/24 17:12:10.696
• [73.071 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:170
  STEP: Creating a kubernetes client @ 04/19/24 17:12:10.717
  I0419 17:12:10.717086 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename emptydir @ 04/19/24 17:12:10.723
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:12:10.758
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:12:10.765
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 04/19/24 17:12:10.773
  E0419 17:12:11.310427      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:12.313553      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:13.312294      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:14.313093      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:12:14.839
  I0419 17:12:14.854640 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-a35a8fdb-440b-4840-8aba-511e885e3ed7 container test-container: <nil>
  STEP: delete the pod @ 04/19/24 17:12:14.879
  I0419 17:12:14.930974 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8735" for this suite. @ 04/19/24 17:12:14.947
• [4.254 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:505
  STEP: Creating a kubernetes client @ 04/19/24 17:12:14.974
  I0419 17:12:14.974253 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename configmap @ 04/19/24 17:12:14.982
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:12:15.023
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:12:15.031
  I0419 17:12:15.132048 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8791" for this suite. @ 04/19/24 17:12:15.146
• [0.190 seconds]
------------------------------
S
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:52
  STEP: Creating a kubernetes client @ 04/19/24 17:12:15.165
  I0419 17:12:15.165360 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename container-runtime @ 04/19/24 17:12:15.168
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:12:15.19
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:12:15.195
  STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' @ 04/19/24 17:12:15.22
  E0419 17:12:15.315525      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:16.316544      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:17.317731      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:18.319107      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:19.319960      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:20.320455      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:21.324390      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:22.324485      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:23.325728      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:24.326334      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:25.326840      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:26.326967      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:27.326997      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:28.327749      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:29.328491      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:30.328292      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:31.328867      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' @ 04/19/24 17:12:31.424
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition @ 04/19/24 17:12:31.432
  STEP: Container 'terminate-cmd-rpa': should get the expected 'State' @ 04/19/24 17:12:31.446
  STEP: Container 'terminate-cmd-rpa': should be possible to delete @ 04/19/24 17:12:31.446
  STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' @ 04/19/24 17:12:31.498
  E0419 17:12:32.328734      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:33.330241      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:34.330704      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' @ 04/19/24 17:12:34.537
  E0419 17:12:35.330469      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition @ 04/19/24 17:12:35.558
  STEP: Container 'terminate-cmd-rpof': should get the expected 'State' @ 04/19/24 17:12:35.575
  STEP: Container 'terminate-cmd-rpof': should be possible to delete @ 04/19/24 17:12:35.575
  STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' @ 04/19/24 17:12:35.626
  E0419 17:12:36.330811      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' @ 04/19/24 17:12:36.646
  E0419 17:12:37.331014      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:38.331527      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition @ 04/19/24 17:12:38.684
  STEP: Container 'terminate-cmd-rpn': should get the expected 'State' @ 04/19/24 17:12:38.709
  STEP: Container 'terminate-cmd-rpn': should be possible to delete @ 04/19/24 17:12:38.71
  I0419 17:12:38.773819 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-9491" for this suite. @ 04/19/24 17:12:38.786
• [23.640 seconds]
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:310
  STEP: Creating a kubernetes client @ 04/19/24 17:12:38.806
  I0419 17:12:38.807254 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/19/24 17:12:38.814
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:12:38.843
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:12:38.85
  STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation @ 04/19/24 17:12:38.859
  I0419 17:12:38.863262 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  E0419 17:12:39.332333      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:40.332321      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:41.333306      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:42.333284      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:43.334305      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:44.335010      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:45.334902      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:46.335759      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation @ 04/19/24 17:12:46.351
  I0419 17:12:46.354088 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  E0419 17:12:47.335928      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:12:48.303674 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  E0419 17:12:48.336620      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:49.337890      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:50.338275      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:51.339605      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:52.339766      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:53.340513      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:54.340698      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:55.341729      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:12:55.758176 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-5960" for this suite. @ 04/19/24 17:12:55.778
• [16.990 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:177
  STEP: Creating a kubernetes client @ 04/19/24 17:12:55.797
  I0419 17:12:55.797811 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename replicaset @ 04/19/24 17:12:55.801
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:12:55.834
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:12:55.84
  STEP: Create a Replicaset @ 04/19/24 17:12:55.874
  STEP: Verify that the required pods have come up. @ 04/19/24 17:12:55.884
  I0419 17:12:55.890476 14 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  E0419 17:12:56.342062      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:57.342733      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:58.342726      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:59.343095      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:00.343375      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:13:00.897526 14 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/19/24 17:13:00.897
  STEP: Getting /status @ 04/19/24 17:13:00.897
  I0419 17:13:00.932125 14 replica_set.go:643] Replicaset test-rs has Conditions: []
  STEP: updating the Replicaset Status @ 04/19/24 17:13:00.932
  I0419 17:13:00.948946 14 replica_set.go:663] updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the ReplicaSet status to be updated @ 04/19/24 17:13:00.949
  I0419 17:13:00.952967 14 replica_set.go:689] Observed &ReplicaSet event: ADDED
  I0419 17:13:00.953892 14 replica_set.go:689] Observed &ReplicaSet event: MODIFIED
  I0419 17:13:00.955279 14 replica_set.go:689] Observed &ReplicaSet event: MODIFIED
  I0419 17:13:00.956104 14 replica_set.go:689] Observed &ReplicaSet event: MODIFIED
  I0419 17:13:00.956735 14 replica_set.go:682] Found replicaset test-rs in namespace replicaset-9208 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0419 17:13:00.957373 14 replica_set.go:693] Replicaset test-rs has an updated status
  STEP: patching the Replicaset Status @ 04/19/24 17:13:00.957
  I0419 17:13:00.958315 14 replica_set.go:697] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I0419 17:13:00.970468 14 replica_set.go:701] Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Replicaset status to be patched @ 04/19/24 17:13:00.971
  I0419 17:13:00.976163 14 replica_set.go:725] Observed &ReplicaSet event: ADDED
  I0419 17:13:00.976350 14 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I0419 17:13:00.976501 14 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I0419 17:13:00.977248 14 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I0419 17:13:00.977333 14 replica_set.go:721] Observed replicaset test-rs in namespace replicaset-9208 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0419 17:13:00.977494 14 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I0419 17:13:00.977543 14 replica_set.go:718] Found replicaset test-rs in namespace replicaset-9208 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
  I0419 17:13:00.977567 14 replica_set.go:729] Replicaset test-rs has a patched status
  I0419 17:13:00.977686 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-9208" for this suite. @ 04/19/24 17:13:00.988
• [5.203 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-auth] SubjectReview should support SubjectReview API operations [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/subjectreviews.go:50
  STEP: Creating a kubernetes client @ 04/19/24 17:13:01.005
  I0419 17:13:01.006039 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename subjectreview @ 04/19/24 17:13:01.008
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:13:01.031
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:13:01.037
  STEP: Creating a Serviceaccount "e2e" in namespace "subjectreview-9958" @ 04/19/24 17:13:01.043
  I0419 17:13:01.055736 14 subjectreviews.go:66] saUsername: "system:serviceaccount:subjectreview-9958:e2e"
  I0419 17:13:01.056205 14 subjectreviews.go:69] saGroups: []string{"system:authenticated", "system:serviceaccounts", "system:serviceaccounts:subjectreview-9958"}
  I0419 17:13:01.056560 14 subjectreviews.go:71] saUID: "87788047-7303-4f95-8bae-d23cd1906cc3"
  STEP: Creating clientset to impersonate "system:serviceaccount:subjectreview-9958:e2e" @ 04/19/24 17:13:01.056
  STEP: Creating SubjectAccessReview for "system:serviceaccount:subjectreview-9958:e2e" @ 04/19/24 17:13:01.057
  I0419 17:13:01.061184 14 subjectreviews.go:102] sarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  STEP: Verifying as "system:serviceaccount:subjectreview-9958:e2e" api 'list' configmaps in "subjectreview-9958" namespace @ 04/19/24 17:13:01.061
  I0419 17:13:01.064127 14 subjectreviews.go:121] SubjectAccessReview has been verified
  STEP: Creating a LocalSubjectAccessReview for "system:serviceaccount:subjectreview-9958:e2e" @ 04/19/24 17:13:01.064
  I0419 17:13:01.068185 14 subjectreviews.go:144] lsarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  I0419 17:13:01.068684 14 subjectreviews.go:150] LocalSubjectAccessReview has been verified
  I0419 17:13:01.069365 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subjectreview-9958" for this suite. @ 04/19/24 17:13:01.082
• [0.092 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:86
  STEP: Creating a kubernetes client @ 04/19/24 17:13:01.098
  I0419 17:13:01.098342 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename replication-controller @ 04/19/24 17:13:01.103
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:13:01.127
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:13:01.138
  I0419 17:13:01.145488 14 rc.go:544] Creating quota "condition-test" that allows only two pods to run in the current namespace
  E0419 17:13:01.345237      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating rc "condition-test" that asks for more than the allowed pod quota @ 04/19/24 17:13:02.175
  STEP: Checking rc "condition-test" has the desired failure condition set @ 04/19/24 17:13:02.194
  E0419 17:13:02.344552      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down rc "condition-test" to satisfy pod quota @ 04/19/24 17:13:03.213
  I0419 17:13:03.242709 14 rc.go:730] Updating replication controller "condition-test"
  STEP: Checking rc "condition-test" has no failure condition set @ 04/19/24 17:13:03.243
  E0419 17:13:03.344845      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:13:04.261981 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-9843" for this suite. @ 04/19/24 17:13:04.273
• [3.197 seconds]
------------------------------
[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:191
  STEP: Creating a kubernetes client @ 04/19/24 17:13:04.295
  I0419 17:13:04.295846 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename watch @ 04/19/24 17:13:04.299
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:13:04.335
  E0419 17:13:04.345234      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:13:04.346
  STEP: creating a watch on configmaps @ 04/19/24 17:13:04.355
  STEP: creating a new configmap @ 04/19/24 17:13:04.359
  STEP: modifying the configmap once @ 04/19/24 17:13:04.376
  STEP: closing the watch once it receives two notifications @ 04/19/24 17:13:04.396
  I0419 17:13:04.397410 14 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5460  cfc9de62-1722-4ed7-8c09-22445cbd50ad 36634 0 2024-04-19 17:13:04 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-04-19 17:13:04 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0419 17:13:04.398121 14 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5460  cfc9de62-1722-4ed7-8c09-22445cbd50ad 36635 0 2024-04-19 17:13:04 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-04-19 17:13:04 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time, while the watch is closed @ 04/19/24 17:13:04.398
  STEP: creating a new watch on configmaps from the last resource version observed by the first watch @ 04/19/24 17:13:04.427
  STEP: deleting the configmap @ 04/19/24 17:13:04.432
  STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed @ 04/19/24 17:13:04.45
  I0419 17:13:04.450782 14 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5460  cfc9de62-1722-4ed7-8c09-22445cbd50ad 36636 0 2024-04-19 17:13:04 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-04-19 17:13:04 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0419 17:13:04.451970 14 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5460  cfc9de62-1722-4ed7-8c09-22445cbd50ad 36637 0 2024-04-19 17:13:04 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-04-19 17:13:04 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0419 17:13:04.452725 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-5460" for this suite. @ 04/19/24 17:13:04.466
• [0.192 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:322
  STEP: Creating a kubernetes client @ 04/19/24 17:13:04.489
  I0419 17:13:04.489978 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename gc @ 04/19/24 17:13:04.495
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:13:04.525
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:13:04.535
  STEP: create the rc @ 04/19/24 17:13:04.548
  W0419 17:13:04.570481      14 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0419 17:13:05.345501      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:06.345649      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:07.346713      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:08.347571      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:09.347989      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 04/19/24 17:13:09.582
  STEP: wait for all pods to be garbage collected @ 04/19/24 17:13:09.598
  E0419 17:13:10.349149      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:11.350351      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:12.351633      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:13.351655      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:14.351929      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 04/19/24 17:13:14.621
  I0419 17:13:14.872805 14 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0419 17:13:14.873487 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-8713" for this suite. @ 04/19/24 17:13:14.891
• [10.424 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:59
  STEP: Creating a kubernetes client @ 04/19/24 17:13:14.916
  I0419 17:13:14.916655 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/19/24 17:13:14.92
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:13:14.964
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:13:14.969
  I0419 17:13:14.975442 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  E0419 17:13:15.352855      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:13:16.046739 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-7894" for this suite. @ 04/19/24 17:13:16.06
• [1.166 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:126
  STEP: Creating a kubernetes client @ 04/19/24 17:13:16.088
  I0419 17:13:16.089030 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename discovery @ 04/19/24 17:13:16.093
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:13:16.126
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:13:16.132
  STEP: Setting up server cert @ 04/19/24 17:13:16.143
  E0419 17:13:16.353638      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:13:16.652396 14 discovery.go:139] Checking APIGroup: apiregistration.k8s.io
  I0419 17:13:16.656010 14 discovery.go:147] PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
  I0419 17:13:16.656402 14 discovery.go:148] Versions found [{apiregistration.k8s.io/v1 v1}]
  I0419 17:13:16.656730 14 discovery.go:154] apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
  I0419 17:13:16.657029 14 discovery.go:139] Checking APIGroup: apps
  I0419 17:13:16.660131 14 discovery.go:147] PreferredVersion.GroupVersion: apps/v1
  I0419 17:13:16.660182 14 discovery.go:148] Versions found [{apps/v1 v1}]
  I0419 17:13:16.660200 14 discovery.go:154] apps/v1 matches apps/v1
  I0419 17:13:16.660217 14 discovery.go:139] Checking APIGroup: events.k8s.io
  I0419 17:13:16.663599 14 discovery.go:147] PreferredVersion.GroupVersion: events.k8s.io/v1
  I0419 17:13:16.663644 14 discovery.go:148] Versions found [{events.k8s.io/v1 v1}]
  I0419 17:13:16.663661 14 discovery.go:154] events.k8s.io/v1 matches events.k8s.io/v1
  I0419 17:13:16.663675 14 discovery.go:139] Checking APIGroup: authentication.k8s.io
  I0419 17:13:16.665514 14 discovery.go:147] PreferredVersion.GroupVersion: authentication.k8s.io/v1
  I0419 17:13:16.665621 14 discovery.go:148] Versions found [{authentication.k8s.io/v1 v1}]
  I0419 17:13:16.666180 14 discovery.go:154] authentication.k8s.io/v1 matches authentication.k8s.io/v1
  I0419 17:13:16.666573 14 discovery.go:139] Checking APIGroup: authorization.k8s.io
  I0419 17:13:16.668929 14 discovery.go:147] PreferredVersion.GroupVersion: authorization.k8s.io/v1
  I0419 17:13:16.668996 14 discovery.go:148] Versions found [{authorization.k8s.io/v1 v1}]
  I0419 17:13:16.669100 14 discovery.go:154] authorization.k8s.io/v1 matches authorization.k8s.io/v1
  I0419 17:13:16.669122 14 discovery.go:139] Checking APIGroup: autoscaling
  I0419 17:13:16.671364 14 discovery.go:147] PreferredVersion.GroupVersion: autoscaling/v2
  I0419 17:13:16.673097 14 discovery.go:148] Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1}]
  I0419 17:13:16.674867 14 discovery.go:154] autoscaling/v2 matches autoscaling/v2
  I0419 17:13:16.676372 14 discovery.go:139] Checking APIGroup: batch
  I0419 17:13:16.685339 14 discovery.go:147] PreferredVersion.GroupVersion: batch/v1
  I0419 17:13:16.686261 14 discovery.go:148] Versions found [{batch/v1 v1}]
  I0419 17:13:16.687489 14 discovery.go:154] batch/v1 matches batch/v1
  I0419 17:13:16.687826 14 discovery.go:139] Checking APIGroup: certificates.k8s.io
  I0419 17:13:16.690933 14 discovery.go:147] PreferredVersion.GroupVersion: certificates.k8s.io/v1
  I0419 17:13:16.693025 14 discovery.go:148] Versions found [{certificates.k8s.io/v1 v1}]
  I0419 17:13:16.693126 14 discovery.go:154] certificates.k8s.io/v1 matches certificates.k8s.io/v1
  I0419 17:13:16.693149 14 discovery.go:139] Checking APIGroup: networking.k8s.io
  I0419 17:13:16.695578 14 discovery.go:147] PreferredVersion.GroupVersion: networking.k8s.io/v1
  I0419 17:13:16.695658 14 discovery.go:148] Versions found [{networking.k8s.io/v1 v1}]
  I0419 17:13:16.695677 14 discovery.go:154] networking.k8s.io/v1 matches networking.k8s.io/v1
  I0419 17:13:16.695786 14 discovery.go:139] Checking APIGroup: policy
  I0419 17:13:16.697969 14 discovery.go:147] PreferredVersion.GroupVersion: policy/v1
  I0419 17:13:16.698088 14 discovery.go:148] Versions found [{policy/v1 v1}]
  I0419 17:13:16.698109 14 discovery.go:154] policy/v1 matches policy/v1
  I0419 17:13:16.698178 14 discovery.go:139] Checking APIGroup: rbac.authorization.k8s.io
  I0419 17:13:16.700226 14 discovery.go:147] PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
  I0419 17:13:16.700406 14 discovery.go:148] Versions found [{rbac.authorization.k8s.io/v1 v1}]
  I0419 17:13:16.700481 14 discovery.go:154] rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
  I0419 17:13:16.700501 14 discovery.go:139] Checking APIGroup: storage.k8s.io
  I0419 17:13:16.705059 14 discovery.go:147] PreferredVersion.GroupVersion: storage.k8s.io/v1
  I0419 17:13:16.705129 14 discovery.go:148] Versions found [{storage.k8s.io/v1 v1}]
  I0419 17:13:16.705149 14 discovery.go:154] storage.k8s.io/v1 matches storage.k8s.io/v1
  I0419 17:13:16.705166 14 discovery.go:139] Checking APIGroup: admissionregistration.k8s.io
  I0419 17:13:16.708969 14 discovery.go:147] PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
  I0419 17:13:16.709586 14 discovery.go:148] Versions found [{admissionregistration.k8s.io/v1 v1}]
  I0419 17:13:16.710792 14 discovery.go:154] admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
  I0419 17:13:16.710914 14 discovery.go:139] Checking APIGroup: apiextensions.k8s.io
  I0419 17:13:16.714624 14 discovery.go:147] PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
  I0419 17:13:16.715852 14 discovery.go:148] Versions found [{apiextensions.k8s.io/v1 v1}]
  I0419 17:13:16.716858 14 discovery.go:154] apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
  I0419 17:13:16.717448 14 discovery.go:139] Checking APIGroup: scheduling.k8s.io
  I0419 17:13:16.722534 14 discovery.go:147] PreferredVersion.GroupVersion: scheduling.k8s.io/v1
  I0419 17:13:16.725537 14 discovery.go:148] Versions found [{scheduling.k8s.io/v1 v1}]
  I0419 17:13:16.726844 14 discovery.go:154] scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
  I0419 17:13:16.727409 14 discovery.go:139] Checking APIGroup: coordination.k8s.io
  I0419 17:13:16.731353 14 discovery.go:147] PreferredVersion.GroupVersion: coordination.k8s.io/v1
  I0419 17:13:16.731956 14 discovery.go:148] Versions found [{coordination.k8s.io/v1 v1}]
  I0419 17:13:16.732510 14 discovery.go:154] coordination.k8s.io/v1 matches coordination.k8s.io/v1
  I0419 17:13:16.733243 14 discovery.go:139] Checking APIGroup: node.k8s.io
  I0419 17:13:16.737691 14 discovery.go:147] PreferredVersion.GroupVersion: node.k8s.io/v1
  I0419 17:13:16.738330 14 discovery.go:148] Versions found [{node.k8s.io/v1 v1}]
  I0419 17:13:16.738829 14 discovery.go:154] node.k8s.io/v1 matches node.k8s.io/v1
  I0419 17:13:16.739464 14 discovery.go:139] Checking APIGroup: discovery.k8s.io
  I0419 17:13:16.743031 14 discovery.go:147] PreferredVersion.GroupVersion: discovery.k8s.io/v1
  I0419 17:13:16.743872 14 discovery.go:148] Versions found [{discovery.k8s.io/v1 v1}]
  I0419 17:13:16.744528 14 discovery.go:154] discovery.k8s.io/v1 matches discovery.k8s.io/v1
  I0419 17:13:16.745272 14 discovery.go:139] Checking APIGroup: flowcontrol.apiserver.k8s.io
  I0419 17:13:16.748429 14 discovery.go:147] PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1
  I0419 17:13:16.749317 14 discovery.go:148] Versions found [{flowcontrol.apiserver.k8s.io/v1 v1} {flowcontrol.apiserver.k8s.io/v1beta3 v1beta3}]
  I0419 17:13:16.750104 14 discovery.go:154] flowcontrol.apiserver.k8s.io/v1 matches flowcontrol.apiserver.k8s.io/v1
  I0419 17:13:16.751122 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-6193" for this suite. @ 04/19/24 17:13:16.762
• [0.686 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:209
  STEP: Creating a kubernetes client @ 04/19/24 17:13:16.782
  I0419 17:13:16.783198 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename projected @ 04/19/24 17:13:16.785
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:13:16.813
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:13:16.82
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 17:13:16.826
  E0419 17:13:17.353949      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:18.355161      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:19.355189      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:20.355379      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:13:20.876
  I0419 17:13:20.892602 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod downwardapi-volume-94ad904e-d637-4ae6-92d1-2b7d4e63f411 container client-container: <nil>
  STEP: delete the pod @ 04/19/24 17:13:20.914
  I0419 17:13:20.985464 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9405" for this suite. @ 04/19/24 17:13:20.997
• [4.230 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicyBinding API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:673
  STEP: Creating a kubernetes client @ 04/19/24 17:13:21.014
  I0419 17:13:21.015225 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename validating-admission-policy @ 04/19/24 17:13:21.018
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:13:21.051
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:13:21.058
  STEP: getting /apis @ 04/19/24 17:13:21.077
  STEP: getting /apis/admissionregistration.k8s.io @ 04/19/24 17:13:21.087
  STEP: getting /apis/admissionregistration.k8s.io/v1 @ 04/19/24 17:13:21.088
  STEP: creating @ 04/19/24 17:13:21.09
  STEP: getting @ 04/19/24 17:13:21.112
  STEP: listing @ 04/19/24 17:13:21.119
  STEP: watching @ 04/19/24 17:13:21.126
  I0419 17:13:21.126101 14 validatingadmissionpolicy.go:768] starting watch
  STEP: patching @ 04/19/24 17:13:21.129
  STEP: updating @ 04/19/24 17:13:21.143
  I0419 17:13:21.157961 14 validatingadmissionpolicy.go:796] waiting for watch events with expected annotations
  STEP: deleting @ 04/19/24 17:13:21.158
  STEP: deleting a collection @ 04/19/24 17:13:21.182
  I0419 17:13:21.212965 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-463" for this suite. @ 04/19/24 17:13:21.221
• [0.220 seconds]
------------------------------
S
------------------------------
[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:48
  STEP: Creating a kubernetes client @ 04/19/24 17:13:21.236
  I0419 17:13:21.236830 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename var-expansion @ 04/19/24 17:13:21.24
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:13:21.267
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:13:21.272
  STEP: Creating a pod to test env composition @ 04/19/24 17:13:21.276
  E0419 17:13:21.356328      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:22.357378      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:23.358427      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:24.358748      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:13:25.322
  I0419 17:13:25.330387 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod var-expansion-d5839bf2-970f-4426-be4b-c5d8715471b4 container dapi-container: <nil>
  STEP: delete the pod @ 04/19/24 17:13:25.346
  E0419 17:13:25.359950      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:13:25.380979 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-3108" for this suite. @ 04/19/24 17:13:25.39
• [4.186 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] PreStop should call prestop when killing a pod [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pre_stop.go:169
  STEP: Creating a kubernetes client @ 04/19/24 17:13:25.423
  I0419 17:13:25.423101 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename prestop @ 04/19/24 17:13:25.426
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:13:25.49
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:13:25.498
  STEP: Creating server pod server in namespace prestop-8129 @ 04/19/24 17:13:25.502
  STEP: Waiting for pods to come up. @ 04/19/24 17:13:25.52
  E0419 17:13:26.359856      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:27.360254      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating tester pod tester in namespace prestop-8129 @ 04/19/24 17:13:27.549
  E0419 17:13:28.361016      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:29.361317      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting pre-stop pod @ 04/19/24 17:13:29.578
  E0419 17:13:30.362402      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:31.363200      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:32.363409      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:33.363797      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:34.364149      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:13:34.624460 14 pre_stop.go:140] Saw: {
  	"Hostname": "server",
  	"Sent": null,
  	"Received": {
  		"prestop": 1
  	},
  	"Errors": null,
  	"Log": [
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
  	],
  	"StillContactingPeers": true
  }
  STEP: Deleting the server pod @ 04/19/24 17:13:34.625
  I0419 17:13:34.681698 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "prestop-8129" for this suite. @ 04/19/24 17:13:34.693
• [9.299 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:125
  STEP: Creating a kubernetes client @ 04/19/24 17:13:34.722
  I0419 17:13:34.722148 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename configmap @ 04/19/24 17:13:34.726
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:13:34.753
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:13:34.758
  STEP: Creating configMap with name configmap-test-upd-e2f0c21e-e44b-4fea-9ee1-8323b4a626c2 @ 04/19/24 17:13:34.778
  STEP: Creating the pod @ 04/19/24 17:13:34.788
  E0419 17:13:35.365161      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:36.365409      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating configmap configmap-test-upd-e2f0c21e-e44b-4fea-9ee1-8323b4a626c2 @ 04/19/24 17:13:36.85
  STEP: waiting to observe update in volume @ 04/19/24 17:13:36.863
  E0419 17:13:37.366042      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:38.366873      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:39.367020      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:40.368115      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:41.369090      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:42.369961      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:43.371188      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:44.371568      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:45.371441      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:46.372181      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:47.373944      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:48.373192      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:49.373368      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:50.374555      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:51.374753      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:52.375034      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:53.375827      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:54.376070      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:55.377134      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:56.377299      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:57.378444      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:58.378524      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:59.379642      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:00.379908      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:01.380675      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:02.380989      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:03.381051      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:04.381527      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:05.382617      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:06.382892      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:07.383131      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:08.384318      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:09.385254      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:10.385677      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:11.386549      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:12.387131      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:13.387302      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:14.387583      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:15.388244      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:16.389236      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:17.389582      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:18.390696      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:19.391742      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:20.392858      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:21.393660      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:22.394098      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:23.397685      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:24.398106      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:25.398254      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:26.398737      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:27.398929      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:28.399918      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:29.400004      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:30.400798      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:31.401429      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:32.401735      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:33.405877      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:34.403183      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:35.404187      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:36.404551      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:37.404721      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:38.415966      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:39.409245      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:14:39.601218 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1075" for this suite. @ 04/19/24 17:14:39.616
• [64.915 seconds]
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/ephemeral_containers.go:51
  STEP: Creating a kubernetes client @ 04/19/24 17:14:39.638
  I0419 17:14:39.638728 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 04/19/24 17:14:39.646
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:14:39.681
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:14:39.69
  STEP: creating a target pod @ 04/19/24 17:14:39.699
  E0419 17:14:40.409357      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:41.409669      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 04/19/24 17:14:41.746
  E0419 17:14:42.410100      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:43.410908      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:44.411712      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:45.412834      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 04/19/24 17:14:45.835
  I0419 17:14:45.835344 14 exec_util.go:55] ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-5274 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0419 17:14:45.835462 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 17:14:45.837632 14 exec_util.go:62] ExecWithOptions: Clientset creation
  I0419 17:14:45.837860 14 exec_util.go:79] ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/ephemeral-containers-test-5274/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  I0419 17:14:45.970813 14 exec_util.go:106] Exec stderr: ""
  I0419 17:14:45.990370 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-5274" for this suite. @ 04/19/24 17:14:46.005
• [6.386 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1497
  STEP: Creating a kubernetes client @ 04/19/24 17:14:46.028
  I0419 17:14:46.028857 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename services @ 04/19/24 17:14:46.031
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:14:46.067
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:14:46.077
  STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-6264 @ 04/19/24 17:14:46.087
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 04/19/24 17:14:46.115
  STEP: creating service externalsvc in namespace services-6264 @ 04/19/24 17:14:46.115
  STEP: creating replication controller externalsvc in namespace services-6264 @ 04/19/24 17:14:46.154
  I0419 17:14:46.169356      14 runners.go:198] Created replication controller with name: externalsvc, namespace: services-6264, replica count: 2
  E0419 17:14:46.412795      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:47.414087      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:48.414418      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:14:49.221537      14 runners.go:198] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the ClusterIP service to type=ExternalName @ 04/19/24 17:14:49.234
  I0419 17:14:49.279527 14 resource.go:361] Creating new exec pod
  E0419 17:14:49.414299      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:50.414607      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:14:51.321395 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-6264 exec execpodqsjvv -- /bin/sh -x -c nslookup clusterip-service.services-6264.svc.cluster.local'
  E0419 17:14:51.414554      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:14:51.737734 14 builder.go:146] stderr: "+ nslookup clusterip-service.services-6264.svc.cluster.local\n"
  I0419 17:14:51.737905 14 builder.go:147] stdout: "Server:\t\t10.233.0.10\nAddress:\t10.233.0.10#53\n\nclusterip-service.services-6264.svc.cluster.local\tcanonical name = externalsvc.services-6264.svc.cluster.local.\nName:\texternalsvc.services-6264.svc.cluster.local\nAddress: 10.233.58.28\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-6264, will wait for the garbage collector to delete the pods @ 04/19/24 17:14:51.738
  I0419 17:14:51.810025 14 resources.go:139] Deleting ReplicationController externalsvc took: 12.268891ms
  I0419 17:14:51.911332 14 resources.go:163] Terminating ReplicationController externalsvc pods took: 101.30333ms
  E0419 17:14:52.415294      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:53.415650      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:54.416587      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:14:54.753047 14 service.go:1506] Cleaning up the ClusterIP to ExternalName test service
  I0419 17:14:54.777189 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6264" for this suite. @ 04/19/24 17:14:54.787
• [8.770 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:78
  STEP: Creating a kubernetes client @ 04/19/24 17:14:54.799
  I0419 17:14:54.799672 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename resourcequota @ 04/19/24 17:14:54.803
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:14:54.832
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:14:54.838
  STEP: Counting existing ResourceQuota @ 04/19/24 17:14:54.844
  E0419 17:14:55.417205      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:56.418921      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:57.418828      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:58.420145      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:59.420315      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 04/19/24 17:14:59.857
  STEP: Ensuring resource quota status is calculated @ 04/19/24 17:14:59.872
  E0419 17:15:00.421458      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:01.420716      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:15:01.890457 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6432" for this suite. @ 04/19/24 17:15:01.905
• [7.130 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:254
  STEP: Creating a kubernetes client @ 04/19/24 17:15:01.939
  I0419 17:15:01.940336 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename namespaces @ 04/19/24 17:15:01.947
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:15:01.988
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:15:01.995
  STEP: Creating a test namespace @ 04/19/24 17:15:02.003
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:15:02.037
  STEP: Creating a service in the namespace @ 04/19/24 17:15:02.044
  STEP: Deleting the namespace @ 04/19/24 17:15:02.071
  STEP: Waiting for the namespace to be removed. @ 04/19/24 17:15:02.089
  E0419 17:15:02.420640      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:03.421291      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:04.422979      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:05.423676      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:06.424185      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:07.424316      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 04/19/24 17:15:08.099
  STEP: Verifying there is no service in the namespace @ 04/19/24 17:15:08.131
  I0419 17:15:08.141295 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-2155" for this suite. @ 04/19/24 17:15:08.154
  STEP: Destroying namespace "nsdeletetest-4859" for this suite. @ 04/19/24 17:15:08.169
  I0419 17:15:08.174653 14 framework.go:370] Namespace nsdeletetest-4859 was already deleted
  STEP: Destroying namespace "nsdeletetest-3700" for this suite. @ 04/19/24 17:15:08.174
• [6.248 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:237
  STEP: Creating a kubernetes client @ 04/19/24 17:15:08.19
  I0419 17:15:08.190781 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename downward-api @ 04/19/24 17:15:08.194
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:15:08.219
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:15:08.228
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 17:15:08.241
  E0419 17:15:08.425373      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:09.425803      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:10.426774      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:11.427988      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:15:12.293
  I0419 17:15:12.304277 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod downwardapi-volume-76167c13-bbbb-4d57-86d2-5e3de39818ff container client-container: <nil>
  STEP: delete the pod @ 04/19/24 17:15:12.325
  I0419 17:15:12.362260 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8626" for this suite. @ 04/19/24 17:15:12.378
• [4.208 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] StorageClasses CSI Conformance should run through the lifecycle of a StorageClass [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/storageclass.go:53
  STEP: Creating a kubernetes client @ 04/19/24 17:15:12.407
  I0419 17:15:12.407984 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename csi-storageclass @ 04/19/24 17:15:12.412
  E0419 17:15:12.429183      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:15:12.448
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:15:12.455
  STEP: Creating a StorageClass @ 04/19/24 17:15:12.469
  STEP: Get StorageClass "e2e-4wv2d" @ 04/19/24 17:15:12.481
  STEP: Patching the StorageClass "e2e-4wv2d" @ 04/19/24 17:15:12.49
  STEP: Delete StorageClass "e2e-4wv2d" @ 04/19/24 17:15:12.509
  STEP: Confirm deletion of StorageClass "e2e-4wv2d" @ 04/19/24 17:15:12.528
  STEP: Create a replacement StorageClass @ 04/19/24 17:15:12.536
  STEP: Updating StorageClass "e2e-v2-t78nr" @ 04/19/24 17:15:12.548
  STEP: Listing all StorageClass with the labelSelector: "e2e-v2-t78nr=updated" @ 04/19/24 17:15:12.568
  STEP: Deleting StorageClass "e2e-v2-t78nr" via DeleteCollection @ 04/19/24 17:15:12.578
  STEP: Confirm deletion of StorageClass "e2e-v2-t78nr" @ 04/19/24 17:15:12.603
  I0419 17:15:12.611371 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csi-storageclass-6174" for this suite. @ 04/19/24 17:15:12.621
• [0.226 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should get a host IP [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:205
  STEP: Creating a kubernetes client @ 04/19/24 17:15:12.634
  I0419 17:15:12.635030 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename pods @ 04/19/24 17:15:12.638
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:15:12.671
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:15:12.683
  STEP: creating pod @ 04/19/24 17:15:12.691
  E0419 17:15:13.429626      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:14.430250      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:15:14.773068 14 pods.go:83] Pod pod-hostip-2d8e92b0-2abd-4902-a25e-651eaff694a5 has hostIP: 192.168.121.127
  I0419 17:15:14.773670 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-1390" for this suite. @ 04/19/24 17:15:14.786
• [2.167 seconds]
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose should create services for rc [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1533
  STEP: Creating a kubernetes client @ 04/19/24 17:15:14.81
  I0419 17:15:14.810374 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename kubectl @ 04/19/24 17:15:14.814
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:15:14.842
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:15:14.848
  STEP: creating Agnhost RC @ 04/19/24 17:15:14.856
  I0419 17:15:14.856081 14 kubectl.go:1540] namespace kubectl-8894
  I0419 17:15:14.856801 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-8894 create -f -'
  I0419 17:15:15.223863 14 builder.go:146] stderr: ""
  I0419 17:15:15.223962 14 builder.go:147] stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 04/19/24 17:15:15.223
  E0419 17:15:15.431381      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:15:16.232237 14 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0419 17:15:16.232322 14 framework.go:733] Found 0 / 1
  E0419 17:15:16.431532      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:15:17.233095 14 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0419 17:15:17.233181 14 framework.go:733] Found 1 / 1
  I0419 17:15:17.233225 14 framework.go:742] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  I0419 17:15:17.238917 14 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0419 17:15:17.239304 14 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0419 17:15:17.239603 14 kubectl.go:1547] wait on agnhost-primary startup in kubectl-8894 
  I0419 17:15:17.240126 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-8894 logs agnhost-primary-7t9mr agnhost-primary'
  I0419 17:15:17.420643 14 builder.go:146] stderr: ""
  I0419 17:15:17.420916 14 builder.go:147] stdout: "Paused\n"
  STEP: exposing RC @ 04/19/24 17:15:17.42
  I0419 17:15:17.421209 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-8894 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
  E0419 17:15:17.431728      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:15:17.638393 14 builder.go:146] stderr: ""
  I0419 17:15:17.638502 14 builder.go:147] stdout: "service/rm2 exposed\n"
  I0419 17:15:17.646744 14 utils.go:1179] Service rm2 in namespace kubectl-8894 found.
  E0419 17:15:18.432352      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:19.433366      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: exposing service @ 04/19/24 17:15:19.667
  I0419 17:15:19.668168 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-8894 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
  I0419 17:15:19.933818 14 builder.go:146] stderr: ""
  I0419 17:15:19.935377 14 builder.go:147] stdout: "service/rm3 exposed\n"
  I0419 17:15:19.946404 14 utils.go:1179] Service rm3 in namespace kubectl-8894 found.
  E0419 17:15:20.434101      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:21.434611      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:15:21.965450 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8894" for this suite. @ 04/19/24 17:15:21.979
• [7.196 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:301
  STEP: Creating a kubernetes client @ 04/19/24 17:15:22.008
  I0419 17:15:22.008371 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename webhook @ 04/19/24 17:15:22.012
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:15:22.044
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:15:22.05
  STEP: Setting up server cert @ 04/19/24 17:15:22.086
  E0419 17:15:22.435394      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 17:15:23.349
  STEP: Deploying the webhook pod @ 04/19/24 17:15:23.368
  STEP: Wait for the deployment to be ready @ 04/19/24 17:15:23.393
  I0419 17:15:23.426709 14 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0419 17:15:23.435846      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:24.436543      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:25.437502      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:15:25.455302 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 17, 15, 23, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 15, 23, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 15, 23, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 15, 23, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-6b869959d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 17:15:26.437889      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:27.437934      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:15:27.464681 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 17, 15, 23, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 15, 23, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 15, 23, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 15, 23, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-6b869959d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 17:15:28.439582      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:29.439453      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:15:29.463719 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 17, 15, 23, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 15, 23, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 15, 23, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 15, 23, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-6b869959d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 17:15:30.439618      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:31.440303      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:15:31.466811 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 17, 15, 23, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 15, 23, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 15, 23, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 15, 23, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-6b869959d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 17:15:32.440296      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:33.441123      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:15:33.463646 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 17, 15, 23, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 15, 23, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 15, 23, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 15, 23, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-6b869959d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 17:15:34.441882      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:35.442162      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 17:15:35.468
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 17:15:35.498
  E0419 17:15:36.442990      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:15:36.498791 14 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the crd webhook via the AdmissionRegistration API @ 04/19/24 17:15:36.518
  STEP: Creating a custom resource definition that should be denied by the webhook @ 04/19/24 17:15:36.581
  I0419 17:15:36.581297 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 17:15:36.739549 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1829" for this suite. @ 04/19/24 17:15:36.752
  STEP: Destroying namespace "webhook-markers-7338" for this suite. @ 04/19/24 17:15:36.787
• [14.790 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:385
  STEP: Creating a kubernetes client @ 04/19/24 17:15:36.799
  I0419 17:15:36.799341 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename daemonsets @ 04/19/24 17:15:36.802
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:15:36.823
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:15:36.828
  I0419 17:15:36.879535 14 daemon_set.go:388] Creating simple daemon set daemon-set
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/19/24 17:15:36.938
  I0419 17:15:36.967778 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0419 17:15:36.967939 14 fixtures.go:130] Node eipo9quoh3ef-1 is running 0 daemon pod, expected 1
  E0419 17:15:37.444140      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:15:37.965179 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0419 17:15:37.965381 14 fixtures.go:130] Node eipo9quoh3ef-2 is running 0 daemon pod, expected 1
  E0419 17:15:38.444030      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:15:38.958858 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0419 17:15:38.959460 14 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Update daemon pods image. @ 04/19/24 17:15:38.988
  STEP: Check that daemon pods images are updated. @ 04/19/24 17:15:39.017
  I0419 17:15:39.027305 14 daemon_set.go:1178] Wrong image for pod: daemon-set-jttmn. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I0419 17:15:39.027523 14 daemon_set.go:1178] Wrong image for pod: daemon-set-mjb5s. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I0419 17:15:39.027646 14 daemon_set.go:1178] Wrong image for pod: daemon-set-zd4tx. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  E0419 17:15:39.445257      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:15:40.029921 14 daemon_set.go:1178] Wrong image for pod: daemon-set-jttmn. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I0419 17:15:40.030664 14 daemon_set.go:1178] Wrong image for pod: daemon-set-zd4tx. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  E0419 17:15:40.445278      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:15:41.029340 14 daemon_set.go:1183] Pod daemon-set-5722l is not available
  I0419 17:15:41.029413 14 daemon_set.go:1178] Wrong image for pod: daemon-set-jttmn. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I0419 17:15:41.029435 14 daemon_set.go:1178] Wrong image for pod: daemon-set-zd4tx. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  E0419 17:15:41.446415      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:15:42.029181 14 daemon_set.go:1178] Wrong image for pod: daemon-set-zd4tx. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  E0419 17:15:42.446404      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:43.447288      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:15:44.027185 14 daemon_set.go:1183] Pod daemon-set-mvm29 is not available
  STEP: Check that daemon pods are still running on every node of the cluster. @ 04/19/24 17:15:44.038
  I0419 17:15:44.058088 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0419 17:15:44.058551 14 fixtures.go:130] Node eipo9quoh3ef-2 is running 0 daemon pod, expected 1
  E0419 17:15:44.448418      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:15:45.062532 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0419 17:15:45.062919 14 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 04/19/24 17:15:45.102
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3967, will wait for the garbage collector to delete the pods @ 04/19/24 17:15:45.102
  I0419 17:15:45.178583 14 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 17.134831ms
  I0419 17:15:45.279375 14 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.795926ms
  E0419 17:15:45.448989      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:46.448555      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:47.449420      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:15:47.906321 14 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0419 17:15:47.906390 14 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0419 17:15:47.911247 14 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"37664"},"items":null}

  I0419 17:15:47.915293 14 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"37664"},"items":null}

  I0419 17:15:47.950822 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-3967" for this suite. @ 04/19/24 17:15:47.964
• [11.183 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:531
  STEP: Creating a kubernetes client @ 04/19/24 17:15:47.982
  I0419 17:15:47.982580 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename svcaccounts @ 04/19/24 17:15:47.985
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:15:48.013
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:15:48.018
  I0419 17:15:48.045884 14 service_accounts.go:618] created pod
  E0419 17:15:48.449919      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:49.450263      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:50.450914      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:51.451958      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:15:52.077
  E0419 17:15:52.452680      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:53.452702      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:54.453110      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:55.454359      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:56.454972      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:57.455857      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:58.456221      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:59.457159      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:00.457779      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:01.458057      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:02.458895      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:03.459250      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:04.459721      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:05.459741      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:06.459977      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:07.461145      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:08.461801      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:09.462162      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:10.462301      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:11.462685      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:12.463800      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:13.464499      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:14.465410      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:15.465655      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:16.466495      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:17.467521      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:18.468844      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:19.469233      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:20.469639      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:21.470020      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:16:22.079002 14 service_accounts.go:624] polling logs
  I0419 17:16:22.122202 14 service_accounts.go:634] Pod logs: 
  I0419 17:15:48.707568       1 log.go:245] OK: Got token
  I0419 17:15:48.709052       1 log.go:245] validating with in-cluster discovery
  I0419 17:15:48.710706       1 log.go:245] OK: got issuer https://kubernetes.default.svc.cluster.local
  I0419 17:15:48.710757       1 log.go:245] Full, not-validated claims: 
  openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-1222:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc00047efa0), NotBefore:(*jwt.NumericDate)(0xc00047f090), IssuedAt:(*jwt.NumericDate)(0xc00047efb0), ID:"d99a8f8d-3f99-4b87-9b3f-63a87c43e95e"}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-1222", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"89331a5b-aa10-4a53-a075-72ee0ece1f5b"}}}
  I0419 17:15:48.741526       1 log.go:245] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
  I0419 17:15:48.755622       1 log.go:245] OK: Validated signature on JWT
  I0419 17:15:48.756068       1 log.go:245] OK: Got valid claims from token!
  I0419 17:15:48.756224       1 log.go:245] Full, validated claims: 
  &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-1222:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc00047fd08), NotBefore:(*jwt.NumericDate)(0xc00047fd30), IssuedAt:(*jwt.NumericDate)(0xc00047fd10), ID:"d99a8f8d-3f99-4b87-9b3f-63a87c43e95e"}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-1222", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"89331a5b-aa10-4a53-a075-72ee0ece1f5b"}}}

  I0419 17:16:22.122386 14 service_accounts.go:638] completed pod
  I0419 17:16:22.144511 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-1222" for this suite. @ 04/19/24 17:16:22.156
• [34.195 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:166
  STEP: Creating a kubernetes client @ 04/19/24 17:16:22.178
  I0419 17:16:22.178451 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename replicaset @ 04/19/24 17:16:22.185
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:16:22.211
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:16:22.217
  STEP: Create a ReplicaSet @ 04/19/24 17:16:22.226
  STEP: Verify that the required pods have come up @ 04/19/24 17:16:22.244
  I0419 17:16:22.253310 14 resource.go:87] Pod name sample-pod: Found 0 pods out of 3
  E0419 17:16:22.470930      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:23.470793      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:24.471926      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:25.471897      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:26.472462      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:16:27.265384 14 resource.go:87] Pod name sample-pod: Found 3 pods out of 3
  STEP: ensuring each pod is running @ 04/19/24 17:16:27.265
  I0419 17:16:27.274608 14 replica_set.go:583] Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
  STEP: Listing all ReplicaSets @ 04/19/24 17:16:27.275
  STEP: DeleteCollection of the ReplicaSets @ 04/19/24 17:16:27.285
  STEP: After DeleteCollection verify that ReplicaSets have been deleted @ 04/19/24 17:16:27.308
  I0419 17:16:27.319878 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-2258" for this suite. @ 04/19/24 17:16:27.331
• [5.171 seconds]
------------------------------
SSSS
------------------------------
[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:208
  STEP: Creating a kubernetes client @ 04/19/24 17:16:27.351
  I0419 17:16:27.351840 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename endpointslice @ 04/19/24 17:16:27.359
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:16:27.435
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:16:27.441
  E0419 17:16:27.473561      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:28.474855      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:29.475022      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: referencing a single matching pod @ 04/19/24 17:16:29.622
  STEP: referencing matching pods with named port @ 04/19/24 17:16:29.638
  STEP: creating empty Endpoints and EndpointSlices for no matching Pods @ 04/19/24 17:16:29.652
  STEP: recreating EndpointSlices after they've been deleted @ 04/19/24 17:16:29.668
  I0419 17:16:29.719138 14 endpointslice.go:938] EndpointSlice for Service endpointslice-9310/example-named-port not found
  E0419 17:16:30.475502      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:31.476755      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:16:31.729486 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-9310" for this suite. @ 04/19/24 17:16:31.743
• [4.406 seconds]
------------------------------
S
------------------------------
[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1459
  STEP: Creating a kubernetes client @ 04/19/24 17:16:31.759
  I0419 17:16:31.760040 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename services @ 04/19/24 17:16:31.764
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:16:31.8
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:16:31.808
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-3618 @ 04/19/24 17:16:31.82
  STEP: changing the ExternalName service to type=NodePort @ 04/19/24 17:16:31.832
  STEP: creating replication controller externalname-service in namespace services-3618 @ 04/19/24 17:16:31.885
  I0419 17:16:31.902638      14 runners.go:198] Created replication controller with name: externalname-service, namespace: services-3618, replica count: 2
  E0419 17:16:32.476950      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:33.477960      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:34.478441      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:16:34.955190      14 runners.go:198] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0419 17:16:34.956668 14 resource.go:361] Creating new exec pod
  E0419 17:16:35.478879      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:36.479654      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:37.479442      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:16:38.041497 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-3618 exec execpod9qjzp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  E0419 17:16:38.479703      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:16:38.481747 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  I0419 17:16:38.481822 14 builder.go:147] stdout: "externalname-service-6sp66"
  I0419 17:16:38.482569 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-3618 exec execpod9qjzp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.13.249 80'
  I0419 17:16:38.788464 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.13.249 80\nConnection to 10.233.13.249 80 port [tcp/http] succeeded!\n"
  I0419 17:16:38.788539 14 builder.go:147] stdout: "externalname-service-6sp66"
  I0419 17:16:38.789297 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-3618 exec execpod9qjzp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.127 31896'
  I0419 17:16:39.052345 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.127 31896\nConnection to 192.168.121.127 31896 port [tcp/*] succeeded!\n"
  I0419 17:16:39.052441 14 builder.go:147] stdout: ""
  E0419 17:16:39.480153      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:16:39.789241 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-3618 exec execpod9qjzp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.127 31896'
  I0419 17:16:40.098341 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.127 31896\nConnection to 192.168.121.127 31896 port [tcp/*] succeeded!\n"
  I0419 17:16:40.098427 14 builder.go:147] stdout: "externalname-service-hw89c"
  I0419 17:16:40.099375 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=services-3618 exec execpod9qjzp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.197 31896'
  I0419 17:16:40.395145 14 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.197 31896\nConnection to 192.168.121.197 31896 port [tcp/*] succeeded!\n"
  I0419 17:16:40.395225 14 builder.go:147] stdout: "externalname-service-6sp66"
  I0419 17:16:40.395389 14 service.go:1468] Cleaning up the ExternalName to NodePort test service
  I0419 17:16:40.461570 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3618" for this suite. @ 04/19/24 17:16:40.476
  E0419 17:16:40.480839      14 retrywatcher.go:129] "Watch failed" err="context canceled"
• [8.735 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:48
  STEP: Creating a kubernetes client @ 04/19/24 17:16:40.495
  I0419 17:16:40.495183 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename projected @ 04/19/24 17:16:40.498
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:16:40.528
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:16:40.533
  STEP: Creating configMap with name projected-configmap-test-volume-24ff3b3c-f98d-4072-8fa3-db415410f4c6 @ 04/19/24 17:16:40.537
  STEP: Creating a pod to test consume configMaps @ 04/19/24 17:16:40.546
  E0419 17:16:41.481321      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:42.482255      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:43.483695      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:44.484785      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:16:44.6
  I0419 17:16:44.612958 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-projected-configmaps-39bca5c4-ef97-440e-a55d-746e7f3a2724 container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/24 17:16:44.635
  I0419 17:16:44.684397 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-798" for this suite. @ 04/19/24 17:16:44.697
• [4.228 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:474
  STEP: Creating a kubernetes client @ 04/19/24 17:16:44.723
  I0419 17:16:44.723689 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename field-validation @ 04/19/24 17:16:44.729
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:16:44.767
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:16:44.772
  I0419 17:16:44.783463 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  E0419 17:16:45.483686      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:46.485033      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:47.484999      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0419 17:16:47.558154      14 warnings.go:70] unknown field "alpha"
  W0419 17:16:47.558249      14 warnings.go:70] unknown field "beta"
  W0419 17:16:47.558273      14 warnings.go:70] unknown field "delta"
  W0419 17:16:47.558291      14 warnings.go:70] unknown field "epsilon"
  W0419 17:16:47.558308      14 warnings.go:70] unknown field "gamma"
  I0419 17:16:48.174398 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-1050" for this suite. @ 04/19/24 17:16:48.183
• [3.476 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:70
  STEP: Creating a kubernetes client @ 04/19/24 17:16:48.201
  I0419 17:16:48.201593 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename downward-api @ 04/19/24 17:16:48.218
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:16:48.249
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:16:48.256
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 17:16:48.261
  E0419 17:16:48.485847      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:49.486844      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:16:50.306
  I0419 17:16:50.312538 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod downwardapi-volume-f0ba2bd4-5fa9-4115-8c83-390a630bb0a3 container client-container: <nil>
  STEP: delete the pod @ 04/19/24 17:16:50.327
  I0419 17:16:50.359242 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9825" for this suite. @ 04/19/24 17:16:50.373
• [2.182 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label should update the label on a resource [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1627
  STEP: Creating a kubernetes client @ 04/19/24 17:16:50.387
  I0419 17:16:50.387922 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename kubectl @ 04/19/24 17:16:50.391
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:16:50.418
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:16:50.423
  STEP: creating the pod @ 04/19/24 17:16:50.43
  I0419 17:16:50.431207 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-3253 create -f -'
  E0419 17:16:50.486907      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:16:50.803560 14 builder.go:146] stderr: ""
  I0419 17:16:50.803685 14 builder.go:147] stdout: "pod/pause created\n"
  E0419 17:16:51.487412      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:52.487884      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding the label testing-label with value testing-label-value to a pod @ 04/19/24 17:16:52.833
  I0419 17:16:52.834605 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-3253 label pods pause testing-label=testing-label-value'
  I0419 17:16:53.057850 14 builder.go:146] stderr: ""
  I0419 17:16:53.057936 14 builder.go:147] stdout: "pod/pause labeled\n"
  STEP: verifying the pod has the label testing-label with the value testing-label-value @ 04/19/24 17:16:53.058
  I0419 17:16:53.058630 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-3253 get pod pause -L testing-label'
  I0419 17:16:53.266580 14 builder.go:146] stderr: ""
  I0419 17:16:53.266714 14 builder.go:147] stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
  STEP: removing the label testing-label of a pod @ 04/19/24 17:16:53.266
  I0419 17:16:53.267203 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-3253 label pods pause testing-label-'
  I0419 17:16:53.478662 14 builder.go:146] stderr: ""
  I0419 17:16:53.478743 14 builder.go:147] stdout: "pod/pause unlabeled\n"
  STEP: verifying the pod doesn't have the label testing-label @ 04/19/24 17:16:53.478
  I0419 17:16:53.479501 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-3253 get pod pause -L testing-label'
  E0419 17:16:53.488076      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:16:53.639192 14 builder.go:146] stderr: ""
  I0419 17:16:53.639268 14 builder.go:147] stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
  STEP: using delete to clean up resources @ 04/19/24 17:16:53.639
  I0419 17:16:53.639793 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-3253 delete --grace-period=0 --force -f -'
  I0419 17:16:53.806604 14 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0419 17:16:53.806686 14 builder.go:147] stdout: "pod \"pause\" force deleted\n"
  I0419 17:16:53.807100 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-3253 get rc,svc -l name=pause --no-headers'
  I0419 17:16:54.002678 14 builder.go:146] stderr: "No resources found in kubectl-3253 namespace.\n"
  I0419 17:16:54.002786 14 builder.go:147] stdout: ""
  I0419 17:16:54.003230 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-3253 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  I0419 17:16:54.170220 14 builder.go:146] stderr: ""
  I0419 17:16:54.170318 14 builder.go:147] stdout: ""
  I0419 17:16:54.170676 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3253" for this suite. @ 04/19/24 17:16:54.186
• [3.817 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:98
  STEP: Creating a kubernetes client @ 04/19/24 17:16:54.205
  I0419 17:16:54.205885 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename aggregator @ 04/19/24 17:16:54.209
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:16:54.248
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:16:54.255
  I0419 17:16:54.263959 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Registering the sample API server. @ 04/19/24 17:16:54.267
  E0419 17:16:54.488337      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:55.488529      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:56.489098      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:16:56.588448 14 helpers.go:161] Found ClusterRoles; assuming RBAC is enabled.
  I0419 17:16:56.653423 14 deployment.go:222] new replicaset for deployment "sample-apiserver-deployment" is yet to be created
  E0419 17:16:57.490431      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:58.491061      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:16:58.759034 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 17:16:59.491336      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:00.491908      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:17:00.768377 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 17:17:01.492282      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:02.492698      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:17:02.768765 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 17:17:03.495880      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:04.496980      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:17:04.769780 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 17:17:05.497250      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:06.497782      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:17:06.770488 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 17:17:07.498414      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:08.498625      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:17:08.768578 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 17:17:09.498806      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:10.499661      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:17:10.770306 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 17:17:11.500468      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:12.501489      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:17:12.772387 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 17:17:13.501943      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:14.502687      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:17:14.773398 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 17:17:15.502857      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:16.503085      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:17:16.765875 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 17:17:17.503175      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:18.503910      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:17:18.772412 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 17:17:19.504635      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:20.505033      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:17:20.767512 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 17:17:21.505697      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:22.505835      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:17:22.773256 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 16, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 17:17:23.506740      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:24.507531      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:17:24.927187 14 aggregator.go:749] Waited 133.366462ms for the sample-apiserver to be ready to handle requests.
  STEP: Read Status for v1alpha1.wardle.example.com @ 04/19/24 17:17:25.047
  STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' @ 04/19/24 17:17:25.06
  STEP: List APIServices @ 04/19/24 17:17:25.073
  I0419 17:17:25.088266 14 aggregator.go:550] Found v1alpha1.wardle.example.com in APIServiceList
  STEP: Adding a label to the APIService @ 04/19/24 17:17:25.09
  I0419 17:17:25.129308 14 aggregator.go:575] APIService labels: map[e2e-apiservice:patched]
  STEP: Updating APIService Status @ 04/19/24 17:17:25.129
  I0419 17:17:25.143779 14 aggregator.go:601] updatedStatus.Conditions: []v1.APIServiceCondition{v1.APIServiceCondition{Type:"Available", Status:"True", LastTransitionTime:time.Date(2024, time.April, 19, 17, 17, 24, 0, time.Local), Reason:"Passed", Message:"all checks passed"}, v1.APIServiceCondition{Type:"StatusUpdated", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: Confirm that v1alpha1.wardle.example.com /status was updated @ 04/19/24 17:17:25.144
  I0419 17:17:25.156070 14 aggregator.go:619] Observed APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {Available True 2024-04-19 17:17:24 +0000 UTC Passed all checks passed}
  I0419 17:17:25.156392 14 aggregator.go:615] Found APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0419 17:17:25.156691 14 aggregator.go:625] Found updated status condition for v1alpha1.wardle.example.com
  STEP: Replace APIService v1alpha1.wardle.example.com @ 04/19/24 17:17:25.156
  I0419 17:17:25.175076 14 aggregator.go:641] Found updated apiService label for "v1alpha1.wardle.example.com"
  STEP: Delete flunders resource "dynamic-flunder-1368147433" @ 04/19/24 17:17:25.175
  STEP: Recreating test-flunder before removing endpoint via deleteCollection @ 04/19/24 17:17:25.198
  STEP: Read v1alpha1.wardle.example.com /status before patching it @ 04/19/24 17:17:25.211
  STEP: Patch APIService Status @ 04/19/24 17:17:25.22
  STEP: Confirm that v1alpha1.wardle.example.com /status was patched @ 04/19/24 17:17:25.232
  I0419 17:17:25.240552 14 aggregator.go:719] Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {Available True 2024-04-19 17:17:24 +0000 UTC Passed all checks passed}
  I0419 17:17:25.240723 14 aggregator.go:719] Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0419 17:17:25.240827 14 aggregator.go:715] Found APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC E2E Set by e2e test}
  I0419 17:17:25.240916 14 aggregator.go:725] Found patched status condition for v1alpha1.wardle.example.com
  STEP: APIService deleteCollection with labelSelector: "v1alpha1.wardle.example.com=updated" @ 04/19/24 17:17:25.241
  STEP: Confirm that the generated APIService has been deleted @ 04/19/24 17:17:25.257
  I0419 17:17:25.257173 14 aggregator.go:786] Requesting list of APIServices to confirm quantity
  I0419 17:17:25.266145 14 aggregator.go:796] Found 0 APIService with label "v1alpha1.wardle.example.com=updated"
  I0419 17:17:25.266248 14 aggregator.go:738] APIService v1alpha1.wardle.example.com has been deleted.
  I0419 17:17:25.482392 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregator-3877" for this suite. @ 04/19/24 17:17:25.495
  E0419 17:17:25.507265      14 retrywatcher.go:129] "Watch failed" err="context canceled"
• [31.318 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Environment:NotInUserNS] [Conformance] [sig-node, NodeConformance, Environment:NotInUserNS, Conformance]
k8s.io/kubernetes/test/e2e/common/node/sysctl.go:79
  STEP: Creating a kubernetes client @ 04/19/24 17:17:25.526
  I0419 17:17:25.527142 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename sysctl @ 04/19/24 17:17:25.53
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:17:25.558
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:17:25.563
  STEP: Creating a pod with the kernel.shm_rmid_forced sysctl @ 04/19/24 17:17:25.567
  STEP: Watching for error events or started pod @ 04/19/24 17:17:25.582
  E0419 17:17:26.507729      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:27.508119      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for pod completion @ 04/19/24 17:17:27.591
  E0419 17:17:28.508992      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:29.509679      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Checking that the pod succeeded @ 04/19/24 17:17:29.624
  STEP: Getting logs from the pod @ 04/19/24 17:17:29.625
  STEP: Checking that the sysctl is actually updated @ 04/19/24 17:17:29.643
  I0419 17:17:29.644099 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-7214" for this suite. @ 04/19/24 17:17:29.658
• [4.152 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:205
  STEP: Creating a kubernetes client @ 04/19/24 17:17:29.678
  I0419 17:17:29.678951 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename secrets @ 04/19/24 17:17:29.683
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:17:29.714
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:17:29.72
  STEP: Creating secret with name s-test-opt-del-833d8c60-2d09-45a6-88b3-7dabeadcfafd @ 04/19/24 17:17:29.743
  STEP: Creating secret with name s-test-opt-upd-8183b331-f7cd-4985-bcb5-a2f58c996cd7 @ 04/19/24 17:17:29.752
  STEP: Creating the pod @ 04/19/24 17:17:29.762
  E0419 17:17:30.510346      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:31.511117      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-833d8c60-2d09-45a6-88b3-7dabeadcfafd @ 04/19/24 17:17:31.882
  STEP: Updating secret s-test-opt-upd-8183b331-f7cd-4985-bcb5-a2f58c996cd7 @ 04/19/24 17:17:31.892
  STEP: Creating secret with name s-test-opt-create-628a728d-e19c-4022-8788-fa852e996145 @ 04/19/24 17:17:31.9
  STEP: waiting to observe update in volume @ 04/19/24 17:17:31.906
  E0419 17:17:32.512521      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:33.513265      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:34.513137      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:35.514066      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:17:35.992721 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6117" for this suite. @ 04/19/24 17:17:36.002
• [6.338 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:195
  STEP: Creating a kubernetes client @ 04/19/24 17:17:36.017
  I0419 17:17:36.017917 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename projected @ 04/19/24 17:17:36.02
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:17:36.047
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:17:36.052
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 17:17:36.057
  E0419 17:17:36.514024      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:37.514207      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:38.514831      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:39.515094      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:17:40.1
  I0419 17:17:40.107670 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod downwardapi-volume-5b0a5b5b-4339-4858-be88-1cf9e421d2d3 container client-container: <nil>
  STEP: delete the pod @ 04/19/24 17:17:40.126
  I0419 17:17:40.175964 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6546" for this suite. @ 04/19/24 17:17:40.187
• [4.185 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_inline.go:50
  STEP: Creating a kubernetes client @ 04/19/24 17:17:40.204
  I0419 17:17:40.204089 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename csiinlinevolumes @ 04/19/24 17:17:40.207
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:17:40.244
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:17:40.248
  STEP: creating @ 04/19/24 17:17:40.254
  STEP: getting @ 04/19/24 17:17:40.299
  STEP: listing in namespace @ 04/19/24 17:17:40.305
  STEP: patching @ 04/19/24 17:17:40.321
  STEP: deleting @ 04/19/24 17:17:40.346
  I0419 17:17:40.367720 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-664" for this suite. @ 04/19/24 17:17:40.376
• [0.187 seconds]
------------------------------
SSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/ephemeral_containers.go:98
  STEP: Creating a kubernetes client @ 04/19/24 17:17:40.394
  I0419 17:17:40.395582 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 04/19/24 17:17:40.4
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:17:40.425
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:17:40.432
  STEP: creating a target pod @ 04/19/24 17:17:40.44
  E0419 17:17:40.516247      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:41.516796      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 04/19/24 17:17:42.489
  E0419 17:17:42.519701      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:43.519654      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:44.519911      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 04/19/24 17:17:44.532
  I0419 17:17:44.533152 14 exec_util.go:55] ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-3199 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0419 17:17:44.533224 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 17:17:44.536032 14 exec_util.go:62] ExecWithOptions: Clientset creation
  I0419 17:17:44.536257 14 exec_util.go:79] ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/ephemeral-containers-test-3199/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  I0419 17:17:44.700940 14 exec_util.go:106] Exec stderr: ""
  STEP: checking pod "ephemeral-containers-target-pod" has only one ephemeralcontainer @ 04/19/24 17:17:44.717
  STEP: adding another ephemeralcontainer to pod "ephemeral-containers-target-pod" @ 04/19/24 17:17:44.726
  STEP: checking pod "ephemeral-containers-target-pod" has only two ephemeralcontainers @ 04/19/24 17:17:44.763
  I0419 17:17:44.775087 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-3199" for this suite. @ 04/19/24 17:17:44.787
• [4.419 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:125
  STEP: Creating a kubernetes client @ 04/19/24 17:17:44.814
  I0419 17:17:44.814764 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename cronjob @ 04/19/24 17:17:44.818
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:17:44.855
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:17:44.863
  STEP: Creating a ForbidConcurrent cronjob @ 04/19/24 17:17:44.867
  STEP: Ensuring a job is scheduled @ 04/19/24 17:17:44.879
  E0419 17:17:45.520113      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:46.521732      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:47.521779      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:48.521863      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:49.521944      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:50.522862      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:51.523181      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:52.523420      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:53.524051      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:54.524394      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:55.524556      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:56.524846      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:57.525100      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:58.526231      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:59.526199      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:00.526553      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 04/19/24 17:18:00.888
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 04/19/24 17:18:00.895
  STEP: Ensuring no more jobs are scheduled @ 04/19/24 17:18:00.901
  STEP: Removing cronjob @ 04/19/24 17:18:00.909
  I0419 17:18:00.933478 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-9423" for this suite. @ 04/19/24 17:18:00.947
• [16.148 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:537
  STEP: Creating a kubernetes client @ 04/19/24 17:18:00.964
  I0419 17:18:00.965266 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename pods @ 04/19/24 17:18:00.97
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:18:01.017
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:18:01.022
  I0419 17:18:01.028046 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: creating the pod @ 04/19/24 17:18:01.03
  STEP: submitting the pod to kubernetes @ 04/19/24 17:18:01.03
  E0419 17:18:01.527114      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:02.528423      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:18:03.184835 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8949" for this suite. @ 04/19/24 17:18:03.195
• [2.247 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:55
  STEP: Creating a kubernetes client @ 04/19/24 17:18:03.216
  I0419 17:18:03.216553 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename downward-api @ 04/19/24 17:18:03.221
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:18:03.247
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:18:03.256
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 17:18:03.263
  E0419 17:18:03.529141      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:04.529335      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:05.529603      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:06.530538      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:18:07.314
  I0419 17:18:07.325260 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod downwardapi-volume-3bd43286-8023-4245-99f5-913b9ab2c5af container client-container: <nil>
  STEP: delete the pod @ 04/19/24 17:18:07.341
  I0419 17:18:07.369042 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6480" for this suite. @ 04/19/24 17:18:07.377
• [4.172 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:350
  STEP: Creating a kubernetes client @ 04/19/24 17:18:07.392
  I0419 17:18:07.392112 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename security-context-test @ 04/19/24 17:18:07.4
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:18:07.425
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:18:07.431
  E0419 17:18:07.531010      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:08.531292      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:09.532132      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:10.532395      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:18:11.484087 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-6315" for this suite. @ 04/19/24 17:18:11.493
• [4.113 seconds]
------------------------------
SS
------------------------------
[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:99
  STEP: Creating a kubernetes client @ 04/19/24 17:18:11.504
  I0419 17:18:11.505149 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename secrets @ 04/19/24 17:18:11.511
  E0419 17:18:11.533674      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:18:11.541
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:18:11.548
  STEP: Creating secret with name secret-test-2eb7d7e7-828a-476c-99f9-ced510bb2303 @ 04/19/24 17:18:11.592
  STEP: Creating a pod to test consume secrets @ 04/19/24 17:18:11.601
  E0419 17:18:12.533344      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:13.533803      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:14.534795      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:15.534343      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:18:15.654
  I0419 17:18:15.660567 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-secrets-ac2e1804-4098-4ca3-ac3d-9be76bdcfce9 container secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/24 17:18:15.676
  I0419 17:18:15.714756 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8009" for this suite. @ 04/19/24 17:18:15.722
  STEP: Destroying namespace "secret-namespace-9700" for this suite. @ 04/19/24 17:18:15.734
• [4.242 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:277
  STEP: Creating a kubernetes client @ 04/19/24 17:18:15.747
  I0419 17:18:15.747582 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/19/24 17:18:15.751
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:18:15.785
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:18:15.799
  STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation @ 04/19/24 17:18:15.809
  I0419 17:18:15.813037 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  E0419 17:18:16.534961      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:18:17.514384 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  E0419 17:18:17.535379      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:18.536128      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:19.536648      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:20.537553      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:21.538848      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:22.539082      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:23.540257      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:24.540764      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:18:24.568660 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-7710" for this suite. @ 04/19/24 17:18:24.589
• [8.856 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:810
  STEP: Creating a kubernetes client @ 04/19/24 17:18:24.606
  I0419 17:18:24.606204 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename svcaccounts @ 04/19/24 17:18:24.609
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:18:24.639
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:18:24.643
  STEP: Creating ServiceAccount "e2e-sa-q4dgj"  @ 04/19/24 17:18:24.649
  I0419 17:18:24.656391 14 service_accounts.go:825] AutomountServiceAccountToken: false
  STEP: Updating ServiceAccount "e2e-sa-q4dgj"  @ 04/19/24 17:18:24.656
  I0419 17:18:24.669937 14 service_accounts.go:839] AutomountServiceAccountToken: true
  I0419 17:18:24.670606 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-5844" for this suite. @ 04/19/24 17:18:24.677
• [0.083 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:58
  STEP: Creating a kubernetes client @ 04/19/24 17:18:24.691
  I0419 17:18:24.692107 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename configmap @ 04/19/24 17:18:24.695
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:18:24.729
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:18:24.736
  STEP: Creating configMap with name configmap-test-volume-94bba5a5-2c19-4c4c-bd99-9c7cf756d47f @ 04/19/24 17:18:24.745
  STEP: Creating a pod to test consume configMaps @ 04/19/24 17:18:24.753
  E0419 17:18:25.541263      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:26.541734      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:27.541944      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:28.542948      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:18:28.795
  I0419 17:18:28.806806 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-configmaps-602d358b-8b43-4b00-9782-a599b362288e container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/24 17:18:28.82
  I0419 17:18:28.860364 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-610" for this suite. @ 04/19/24 17:18:28.87
• [4.192 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:180
  STEP: Creating a kubernetes client @ 04/19/24 17:18:28.888
  I0419 17:18:28.888300 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename emptydir @ 04/19/24 17:18:28.891
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:18:28.94
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:18:28.946
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 04/19/24 17:18:28.95
  E0419 17:18:29.543229      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:30.543266      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:31.543582      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:32.544122      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:18:32.994
  I0419 17:18:33.003382 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-55d84441-1c6b-49de-a143-30e35ef45f2c container test-container: <nil>
  STEP: delete the pod @ 04/19/24 17:18:33.016
  I0419 17:18:33.044199 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-3656" for this suite. @ 04/19/24 17:18:33.051
• [4.173 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:210
  STEP: Creating a kubernetes client @ 04/19/24 17:18:33.063
  I0419 17:18:33.063341 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename webhook @ 04/19/24 17:18:33.066
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:18:33.092
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:18:33.096
  STEP: Setting up server cert @ 04/19/24 17:18:33.132
  E0419 17:18:33.544651      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:34.545014      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 17:18:34.714
  STEP: Deploying the webhook pod @ 04/19/24 17:18:34.735
  STEP: Wait for the deployment to be ready @ 04/19/24 17:18:34.762
  I0419 17:18:34.785098 14 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0419 17:18:35.546122      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:36.546901      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:18:36.811994 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 17, 18, 34, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 18, 34, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 18, 34, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 18, 34, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-6b869959d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 17:18:37.546968      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:38.548024      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:18:38.823401 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 17, 18, 34, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 18, 34, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 18, 34, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 18, 34, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-6b869959d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 17:18:39.548245      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:40.549024      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:18:40.821186 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 17, 18, 34, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 18, 34, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 18, 34, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 18, 34, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-6b869959d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 17:18:41.550187      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:42.550370      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:18:42.823223 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 17, 18, 34, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 18, 34, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 18, 34, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 18, 34, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-6b869959d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 17:18:43.550587      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:44.551593      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:18:44.821363 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 17, 18, 34, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 18, 34, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 18, 34, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 18, 34, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-6b869959d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 17:18:45.552232      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:46.553073      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 17:18:46.823
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 17:18:46.85
  E0419 17:18:47.553771      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:18:47.852115 14 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 04/19/24 17:18:47.907
  STEP: create a pod @ 04/19/24 17:18:47.95
  E0419 17:18:48.554214      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:49.555130      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: 'kubectl attach' the pod, should be denied by the webhook @ 04/19/24 17:18:49.986
  I0419 17:18:49.988932 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=webhook-2105 attach --namespace=webhook-2105 to-be-attached-pod -i -c=container1'
  I0419 17:18:50.242635 14 builder.go:135] rc: 1
  I0419 17:18:50.347909 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2105" for this suite. @ 04/19/24 17:18:50.365
  STEP: Destroying namespace "webhook-markers-1965" for this suite. @ 04/19/24 17:18:50.383
• [17.333 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:48
  STEP: Creating a kubernetes client @ 04/19/24 17:18:50.395
  I0419 17:18:50.395949 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename secrets @ 04/19/24 17:18:50.403
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:18:50.422
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:18:50.43
  STEP: Creating secret with name secret-test-d0479346-795b-41d0-9776-cbd5f22ab291 @ 04/19/24 17:18:50.433
  STEP: Creating a pod to test consume secrets @ 04/19/24 17:18:50.452
  E0419 17:18:50.556428      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:51.557068      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:52.557886      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:53.558472      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:18:54.499
  I0419 17:18:54.507990 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-secrets-0beeee88-85d1-45d2-a1c1-78413c61565b container secret-env-test: <nil>
  STEP: delete the pod @ 04/19/24 17:18:54.527
  E0419 17:18:54.558644      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:18:54.577759 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4989" for this suite. @ 04/19/24 17:18:54.588
• [4.211 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:330
  STEP: Creating a kubernetes client @ 04/19/24 17:18:54.614
  I0419 17:18:54.614176 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename resourcequota @ 04/19/24 17:18:54.618
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:18:54.654
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:18:54.662
  E0419 17:18:55.559592      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:56.560028      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:57.560115      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:58.561088      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:59.561093      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:00.561472      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:01.561782      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:02.562861      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:03.563648      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:04.563800      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:05.564435      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:06.564690      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:07.564821      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:08.565695      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:09.566025      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:10.566382      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:11.566700      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 04/19/24 17:19:11.682
  E0419 17:19:12.567044      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:13.567782      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:14.568109      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:15.568376      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:16.568697      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 04/19/24 17:19:16.692
  STEP: Ensuring resource quota status is calculated @ 04/19/24 17:19:16.713
  E0419 17:19:17.569049      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:18.569875      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ConfigMap @ 04/19/24 17:19:18.73
  STEP: Ensuring resource quota status captures configMap creation @ 04/19/24 17:19:18.759
  E0419 17:19:19.570336      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:20.570836      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ConfigMap @ 04/19/24 17:19:20.769
  STEP: Ensuring resource quota status released usage @ 04/19/24 17:19:20.783
  E0419 17:19:21.571340      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:22.572226      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:19:22.795510 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4025" for this suite. @ 04/19/24 17:19:22.808
• [28.216 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:190
  STEP: Creating a kubernetes client @ 04/19/24 17:19:22.829
  I0419 17:19:22.829911 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename emptydir @ 04/19/24 17:19:22.833
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:19:22.87
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:19:22.877
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 04/19/24 17:19:22.884
  E0419 17:19:23.571704      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:24.572155      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:25.572933      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:26.573289      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:19:26.938
  I0419 17:19:26.948360 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-1913a48c-ccb3-402c-98da-b10fd4212419 container test-container: <nil>
  STEP: delete the pod @ 04/19/24 17:19:26.972
  I0419 17:19:27.020484 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-3842" for this suite. @ 04/19/24 17:19:27.034
• [4.224 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should delete old replica sets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:122
  STEP: Creating a kubernetes client @ 04/19/24 17:19:27.054
  I0419 17:19:27.054367 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename deployment @ 04/19/24 17:19:27.059
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:19:27.092
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:19:27.098
  I0419 17:19:27.129243 14 resource.go:87] Pod name cleanup-pod: Found 0 pods out of 1
  E0419 17:19:27.574319      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:28.574595      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:29.574754      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:30.575275      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:31.575441      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:19:32.140603 14 resource.go:87] Pod name cleanup-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/19/24 17:19:32.14
  I0419 17:19:32.140791 14 deployment.go:841] Creating deployment test-cleanup-deployment
  STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up @ 04/19/24 17:19:32.181
  I0419 17:19:32.206796 14 deployment.go:633] Deployment "test-cleanup-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7806",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0012cb1d-7ece-4030-970a-07ccad090164",
      ResourceVersion: (string) (len=5) "39073",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143972,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143972,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(0),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 0,
      Replicas: (int32) 0,
      UpdatedReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) <nil>,
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0419 17:19:32.223313 14 deployment.go:39] New ReplicaSet "test-cleanup-deployment-7c4d497584" of Deployment "test-cleanup-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-cleanup-deployment-7c4d497584",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7806",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "dcadc124-0d34-4269-b0cc-1e909f73d17c",
      ResourceVersion: (string) (len=5) "39075",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143972,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7c4d497584"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=23) "test-cleanup-deployment",
          UID: (types.UID) (len=36) "0012cb1d-7ece-4030-970a-07ccad090164",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143972,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 30 30 31 32 63 62  31 64 2d 37 65 63 65 2d  |\"0012cb1d-7ece-|
              00000120  34 30 33 30 2d 39 37 30  61 2d 30 37 63 63 61 64  |4030-970a-07ccad|
              00000130  30 39 30 31 36 34 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |090164\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "7c4d497584"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "7c4d497584"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 0,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0419 17:19:32.241641 14 deployment.go:44] All old ReplicaSets of Deployment "test-cleanup-deployment":
  I0419 17:19:32.242097 14 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7806",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f3f1d3fb-fe0b-43be-946d-a9dbd9640bf9",
      ResourceVersion: (string) (len=5) "39074",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143967,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=3) "pod": (string) (len=5) "httpd",
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=23) "test-cleanup-deployment",
          UID: (types.UID) (len=36) "0012cb1d-7ece-4030-970a-07ccad090164",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143967,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=483) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000050  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000060  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000070  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000080  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000090  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              000000a0  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000b0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000c0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000d0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000e0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000f0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000100  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000110  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000120  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000130  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000140  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000160  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000170  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000180  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000190  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000001a0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001b0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001c0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001d0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001e0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143968,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143972,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=103) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000020  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              00000030  22 75 69 64 5c 22 3a 5c  22 30 30 31 32 63 62 31  |"uid\":\"0012cb1|
              00000040  64 2d 37 65 63 65 2d 34  30 33 30 2d 39 37 30 61  |d-7ece-4030-970a|
              00000050  2d 30 37 63 63 61 64 30  39 30 31 36 34 5c 22 7d  |-07ccad090164\"}|
              00000060  22 3a 7b 7d 7d 7d 7d                              |":{}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0419 17:19:32.254640 14 deployment.go:67] Pod "test-cleanup-controller-56r6f" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=29) "test-cleanup-controller-56r6f",
      GenerateName: (string) (len=24) "test-cleanup-controller-",
      Namespace: (string) (len=15) "deployment-7806",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "dcff5d8e-7d67-4f5e-9bef-a3aa9e11cdb1",
      ResourceVersion: (string) (len=5) "39058",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143967,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=23) "test-cleanup-controller",
          UID: (types.UID) (len=36) "f3f1d3fb-fe0b-43be-946d-a9dbd9640bf9",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143967,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=500) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 2c 22 66  |},"f:pod":{}},"f|
              00000050  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000060  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000070  75 69 64 5c 22 3a 5c 22  66 33 66 31 64 33 66 62  |uid\":\"f3f1d3fb|
              00000080  2d 66 65 30 62 2d 34 33  62 65 2d 39 34 36 64 2d  |-fe0b-43be-946d-|
              00000090  61 39 64 62 64 39 36 34  30 62 66 39 5c 22 7d 22  |a9dbd9640bf9\"}"|
              000000a0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000b0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000c0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              000000d0  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              000000e0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              000000f0  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000100  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000110  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000120  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000130  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000140  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000150  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000160  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              00000170  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              00000180  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              00000190  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001a0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001b0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001c0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              000001d0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              000001e0  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              000001f0  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143968,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 36 2e  32 34 30 5c 22 7d 22 3a  |.233.66.240\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-r52nm",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-r52nm",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)(<nil>),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "eipo9quoh3ef-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143968,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143967,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143968,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143968,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143967,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.127",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.127"
        }
      },
      PodIP: (string) (len=13) "10.233.66.240",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.66.240"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143967,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63849143967,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://a1da76766f3716760e5fe66face2dc10e54063ba184495f789244d6182d1c6a8",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0419 17:19:32.267245 14 deployment.go:67] Pod "test-cleanup-deployment-7c4d497584-brg78" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-cleanup-deployment-7c4d497584-brg78",
      GenerateName: (string) (len=35) "test-cleanup-deployment-7c4d497584-",
      Namespace: (string) (len=15) "deployment-7806",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "65e3eebc-33c3-42f1-bfb8-880d58db88a0",
      ResourceVersion: (string) (len=5) "39077",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143972,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7c4d497584"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=34) "test-cleanup-deployment-7c4d497584",
          UID: (types.UID) (len=36) "dcadc124-0d34-4269-b0cc-1e909f73d17c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143972,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 63  61 64 63 31 32 34 2d 30  |d\":\"dcadc124-0|
              00000090  64 33 34 2d 34 32 36 39  2d 62 30 63 63 2d 31 65  |d34-4269-b0cc-1e|
              000000a0  39 30 39 66 37 33 64 31  37 63 5c 22 7d 22 3a 7b  |909f73d17c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-5998m",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-5998m",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0419 17:19:32.269416 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-7806" for this suite. @ 04/19/24 17:19:32.296
• [5.269 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:245
  STEP: Creating a kubernetes client @ 04/19/24 17:19:32.324
  I0419 17:19:32.324437 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename namespaces @ 04/19/24 17:19:32.327
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:19:32.353
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:19:32.358
  STEP: Creating a test namespace @ 04/19/24 17:19:32.363
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:19:32.387
  STEP: Creating a pod in the namespace @ 04/19/24 17:19:32.393
  STEP: Waiting for the pod to have running status @ 04/19/24 17:19:32.41
  E0419 17:19:32.576098      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:33.576349      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the namespace @ 04/19/24 17:19:34.428
  STEP: Waiting for the namespace to be removed. @ 04/19/24 17:19:34.45
  E0419 17:19:34.586675      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:35.584268      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:36.585219      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:37.586287      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:38.586624      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:39.587369      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:40.587629      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:41.588142      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:42.588762      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:43.589794      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:44.590002      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 04/19/24 17:19:45.459
  STEP: Verifying there are no pods in the namespace @ 04/19/24 17:19:45.484
  I0419 17:19:45.491325 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-6592" for this suite. @ 04/19/24 17:19:45.499
  STEP: Destroying namespace "nsdeletetest-5561" for this suite. @ 04/19/24 17:19:45.508
  I0419 17:19:45.518029 14 framework.go:370] Namespace nsdeletetest-5561 was already deleted
  STEP: Destroying namespace "nsdeletetest-8389" for this suite. @ 04/19/24 17:19:45.518
• [13.207 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:90
  STEP: Creating a kubernetes client @ 04/19/24 17:19:45.537
  I0419 17:19:45.538220 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename projected @ 04/19/24 17:19:45.541
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:19:45.575
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:19:45.582
  STEP: Creating configMap with name projected-configmap-test-volume-map-6ab1829c-3cd7-4106-a115-a0156df191ed @ 04/19/24 17:19:45.587
  E0419 17:19:45.592929      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a pod to test consume configMaps @ 04/19/24 17:19:45.597
  E0419 17:19:46.593236      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:47.593484      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:48.594467      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:49.595449      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:19:49.656
  I0419 17:19:49.666967 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-projected-configmaps-8971a4df-e773-4b61-92d4-5e6930172d2d container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/24 17:19:49.692
  I0419 17:19:49.735386 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5360" for this suite. @ 04/19/24 17:19:49.75
• [4.231 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:77
  STEP: Creating a kubernetes client @ 04/19/24 17:19:49.77
  I0419 17:19:49.770774 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename var-expansion @ 04/19/24 17:19:49.774
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:19:49.806
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:19:49.813
  STEP: Creating a pod to test substitution in container's command @ 04/19/24 17:19:49.822
  E0419 17:19:50.595818      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:51.596846      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:52.597376      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:53.598199      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:19:53.879
  I0419 17:19:53.890352 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod var-expansion-cfe8f667-f8ff-4708-8377-9db79a8bfb7b container dapi-container: <nil>
  STEP: delete the pod @ 04/19/24 17:19:53.91
  I0419 17:19:53.955883 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-5580" for this suite. @ 04/19/24 17:19:53.97
• [4.218 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:551
  STEP: Creating a kubernetes client @ 04/19/24 17:19:54
  I0419 17:19:54.001365 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename container-probe @ 04/19/24 17:19:54.005
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:19:54.041
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:19:54.051
  STEP: Creating pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738 @ 04/19/24 17:19:54.061
  E0419 17:19:54.599296      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:55.600164      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/19/24 17:19:56.108
  I0419 17:19:56.115758 14 container_probe.go:1749] Initial restart count of pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 is 0
  I0419 17:19:56.124162 14 container_probe.go:1759] Get pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738
  E0419 17:19:56.600647      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:57.601202      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:19:58.145802 14 container_probe.go:1759] Get pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738
  E0419 17:19:58.602435      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:59.602569      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:20:00.156297 14 container_probe.go:1759] Get pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738
  E0419 17:20:00.603358      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:01.604192      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:20:02.165747 14 container_probe.go:1759] Get pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738
  E0419 17:20:02.605074      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:03.605808      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:20:04.180077 14 container_probe.go:1759] Get pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738
  E0419 17:20:04.605609      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:05.606784      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:20:06.191253 14 container_probe.go:1759] Get pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738
  E0419 17:20:06.607382      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:07.607579      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:20:08.202346 14 container_probe.go:1759] Get pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738
  E0419 17:20:08.609343      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:09.609640      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:20:10.213125 14 container_probe.go:1759] Get pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738
  E0419 17:20:10.610698      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:11.611152      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:20:12.220705 14 container_probe.go:1759] Get pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738
  E0419 17:20:12.612032      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:13.612255      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:20:14.230367 14 container_probe.go:1759] Get pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738
  E0419 17:20:14.613838      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:15.613733      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:20:16.237800 14 container_probe.go:1759] Get pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738
  E0419 17:20:16.614862      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:17.615154      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:20:18.248747 14 container_probe.go:1759] Get pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738
  E0419 17:20:18.615366      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:19.616112      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:20:20.259065 14 container_probe.go:1759] Get pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738
  E0419 17:20:20.616610      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:21.616750      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:20:22.267270 14 container_probe.go:1759] Get pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738
  E0419 17:20:22.617899      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:23.618437      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:20:24.280755 14 container_probe.go:1759] Get pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738
  E0419 17:20:24.618665      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:25.618629      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:20:26.294709 14 container_probe.go:1759] Get pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738
  E0419 17:20:26.619616      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:27.619770      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:20:28.302639 14 container_probe.go:1759] Get pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738
  E0419 17:20:28.620042      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:29.620820      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:20:30.314381 14 container_probe.go:1759] Get pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738
  E0419 17:20:30.621761      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:31.622818      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:20:32.324319 14 container_probe.go:1759] Get pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738
  E0419 17:20:32.623943      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:33.624783      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:20:34.337658 14 container_probe.go:1759] Get pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738
  E0419 17:20:34.625049      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:35.625856      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:20:36.348549 14 container_probe.go:1759] Get pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738
  E0419 17:20:36.626508      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:37.627253      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:20:38.361785 14 container_probe.go:1759] Get pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738
  E0419 17:20:38.628354      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:39.629003      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:20:40.372971 14 container_probe.go:1759] Get pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738
  E0419 17:20:40.629019      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:41.629641      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:20:42.383996 14 container_probe.go:1759] Get pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738
  E0419 17:20:42.630218      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:43.631503      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:20:44.398052 14 container_probe.go:1759] Get pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738
  E0419 17:20:44.632131      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:45.633120      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:20:46.409831 14 container_probe.go:1759] Get pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738
  E0419 17:20:46.633697      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:47.633837      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:20:48.422679 14 container_probe.go:1759] Get pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738
  E0419 17:20:48.634772      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:49.635010      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:20:50.432930 14 container_probe.go:1759] Get pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738
  E0419 17:20:50.635562      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:51.635664      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:20:52.443317 14 container_probe.go:1759] Get pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738
  E0419 17:20:52.636154      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:53.636845      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:20:54.452861 14 container_probe.go:1759] Get pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738
  E0419 17:20:54.637844      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:55.638540      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:20:56.464513 14 container_probe.go:1759] Get pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738
  E0419 17:20:56.638504      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:57.639039      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:20:58.475500 14 container_probe.go:1759] Get pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738
  E0419 17:20:58.639023      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:59.639062      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:21:00.489719 14 container_probe.go:1759] Get pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738
  E0419 17:21:00.639678      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:01.639821      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:21:02.500937 14 container_probe.go:1759] Get pod test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 in namespace container-probe-9738
  I0419 17:21:02.501243 14 container_probe.go:1763] Restart count of pod container-probe-9738/test-grpc-4fdd5930-3514-42d6-934a-d4189a39e1c5 is now 1 (1m6.385381801s elapsed)
  STEP: deleting the pod @ 04/19/24 17:21:02.501
  I0419 17:21:02.528308 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-9738" for this suite. @ 04/19/24 17:21:02.544
• [68.565 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update validating webhook configurations with match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:715
  STEP: Creating a kubernetes client @ 04/19/24 17:21:02.566
  I0419 17:21:02.566767 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename webhook @ 04/19/24 17:21:02.569
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:21:02.61
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:21:02.617
  E0419 17:21:02.640514      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Setting up server cert @ 04/19/24 17:21:02.666
  E0419 17:21:03.640772      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 17:21:04.18
  STEP: Deploying the webhook pod @ 04/19/24 17:21:04.196
  STEP: Wait for the deployment to be ready @ 04/19/24 17:21:04.219
  I0419 17:21:04.231888 14 deployment.go:222] new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0419 17:21:04.642126      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:05.642395      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:21:06.275389 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 17, 21, 4, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 21, 4, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 21, 4, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 21, 4, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-6b869959d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 17:21:06.643556      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:07.644458      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:21:08.283772 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 17, 21, 4, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 21, 4, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 21, 4, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 21, 4, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-6b869959d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 17:21:08.645325      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:09.645519      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:21:10.290654 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 17, 21, 4, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 21, 4, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 21, 4, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 21, 4, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-6b869959d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 17:21:10.646542      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:11.647183      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:21:12.286620 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 17, 21, 4, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 21, 4, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 21, 4, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 21, 4, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-6b869959d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 17:21:12.646943      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:13.647905      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:21:14.288196 14 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 17, 21, 4, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 21, 4, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 21, 4, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 21, 4, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-6b869959d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 17:21:14.647724      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:15.648343      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 17:21:16.285
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 17:21:16.31
  E0419 17:21:16.649270      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:21:17.310676 14 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a validating webhook with match conditions @ 04/19/24 17:21:17.333
  STEP: verifying the validating webhook match conditions @ 04/19/24 17:21:17.347
  STEP: updating the validating webhook match conditions @ 04/19/24 17:21:17.354
  STEP: verifying the validating webhook match conditions @ 04/19/24 17:21:17.369
  I0419 17:21:17.490388 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6085" for this suite. @ 04/19/24 17:21:17.499
  STEP: Destroying namespace "webhook-markers-3966" for this suite. @ 04/19/24 17:21:17.527
• [14.971 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:152
  STEP: Creating a kubernetes client @ 04/19/24 17:21:17.54
  I0419 17:21:17.541031 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename container-probe @ 04/19/24 17:21:17.544
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:21:17.582
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:21:17.588
  STEP: Creating pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245 @ 04/19/24 17:21:17.593
  E0419 17:21:17.650307      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:18.651100      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/19/24 17:21:19.63
  I0419 17:21:19.639581 14 container_probe.go:1749] Initial restart count of pod busybox-37590268-c358-423f-be76-4ee6b944b224 is 0
  I0419 17:21:19.651492 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:21:19.653082      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:20.652506      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:21.653721      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:21:21.665583 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:21:22.652540      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:23.653727      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:21:23.675620 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:21:24.654458      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:25.654879      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:21:25.693169 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:21:26.655562      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:27.656486      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:21:27.703655 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:21:28.656800      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:29.657390      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:21:29.713617 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:21:30.657895      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:31.658040      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:21:31.725192 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:21:32.659026      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:33.659395      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:21:33.738678 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:21:34.659580      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:35.660046      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:21:35.751392 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:21:36.660085      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:37.660444      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:21:37.761592 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:21:38.661048      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:39.662941      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:21:39.772973 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:21:40.662951      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:41.662847      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:21:41.788842 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:21:42.663113      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:43.663409      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:21:43.807480 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:21:44.663908      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:45.664141      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:21:45.817609 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:21:46.664497      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:47.664734      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:21:47.829380 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:21:48.665295      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:49.666507      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:21:49.841752 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:21:50.666115      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:51.666589      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:21:51.851939 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:21:52.667174      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:53.668059      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:21:53.864856 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:21:54.669065      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:55.669729      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:21:55.872617 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:21:56.670146      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:57.669888      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:21:57.883411 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:21:58.670289      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:59.674944      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:21:59.892973 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:22:00.671425      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:01.671190      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:22:01.906523 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:22:02.672425      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:03.672534      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:22:03.914957 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:22:04.672825      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:05.674991      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:22:05.924004 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:22:06.674311      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:07.674586      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:22:07.934450 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:22:08.675621      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:09.675963      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:22:09.947199 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:22:10.676242      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:11.676571      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:22:11.957486 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:22:12.676959      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:13.677021      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:22:13.973448 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:22:14.677159      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:15.677523      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:22:15.982184 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:22:16.677868      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:17.678304      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:22:18.001211 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:22:18.679099      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:19.679462      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:22:20.009278 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:22:20.679695      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:21.681811      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:22:22.020503 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:22:22.682035      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:23.683205      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:22:24.028798 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:22:24.683508      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:25.683920      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:22:26.039801 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:22:26.683846      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:27.684265      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:22:28.047602 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:22:28.684518      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:29.685512      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:22:30.059834 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:22:30.686879      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:31.687145      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:22:32.069514 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:22:32.687606      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:33.687893      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:22:34.080613 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:22:34.688220      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:35.689240      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:22:36.089576 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:22:36.689765      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:37.690495      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:22:38.102418 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:22:38.690763      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:39.691130      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:22:40.111613 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:22:40.692469      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:41.693010      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:22:42.123899 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:22:42.693387      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:43.693703      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:22:44.145641 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:22:44.694880      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:45.696073      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:22:46.158659 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:22:46.696196      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:47.696477      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:22:48.167967 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:22:48.696797      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:49.697271      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:22:50.181831 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:22:50.697480      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:51.698250      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:22:52.195166 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:22:52.698976      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:53.699041      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:22:54.208684 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:22:54.699208      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:55.700276      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:22:56.219663 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:22:56.701222      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:57.701345      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:22:58.232130 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:22:58.702129      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:59.702787      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:23:00.242816 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:23:00.703829      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:01.704298      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:23:02.254161 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:23:02.705265      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:03.706075      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:23:04.263963 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:23:04.706560      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:05.707543      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:23:06.273857 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:23:06.708370      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:07.708599      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:23:08.285681 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:23:08.709303      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:09.710075      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:23:10.298281 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:23:10.710588      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:11.711369      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:23:12.306845 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:23:12.711536      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:13.712293      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:23:14.315667 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:23:14.713028      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:15.714258      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:23:16.325903 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:23:16.714931      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:17.715204      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:23:18.338021 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:23:18.716017      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:19.716411      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:23:20.350471 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:23:20.717168      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:21.718184      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:23:22.362596 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:23:22.718930      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:23.720069      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:23:24.370977 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:23:24.720378      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:25.721454      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:23:26.381209 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:23:26.721632      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:27.722556      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:23:28.394947 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:23:28.723334      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:29.723588      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:23:30.404328 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:23:30.724495      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:31.724970      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:23:32.417563 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:23:32.724983      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:33.725215      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:23:34.429753 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:23:34.725989      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:35.726839      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:23:36.440428 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:23:36.727042      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:37.727238      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:23:38.452869 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:23:38.728068      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:39.728276      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:23:40.469908 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:23:40.728932      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:41.729234      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:23:42.484292 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:23:42.729863      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:43.730213      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:23:44.497864 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:23:44.731152      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:45.732158      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:23:46.509157 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:23:46.732830      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:47.733862      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:23:48.521567 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:23:48.733972      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:49.734995      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:23:50.529064 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:23:50.735190      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:51.735561      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:23:52.539608 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:23:52.736494      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:53.736868      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:23:54.549554 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:23:54.737902      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:55.738589      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:23:56.558543 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:23:56.739736      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:57.739997      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:23:58.573062 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:23:58.740176      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:59.740475      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:24:00.584389 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:24:00.741197      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:01.742147      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:24:02.598339 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:24:02.742353      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:03.742601      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:24:04.606585 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:24:04.743359      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:05.744258      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:24:06.614237 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:24:06.745130      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:07.746317      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:24:08.625234 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:24:08.746290      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:09.746985      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:24:10.635389 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:24:10.747714      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:11.748466      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:24:12.647405 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:24:12.749114      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:13.750359      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:24:14.658522 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:24:14.751200      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:15.751499      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:24:16.669271 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:24:16.752295      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:17.752843      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:24:18.678561 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:24:18.753759      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:19.754479      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:24:20.687488 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:24:20.755140      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:21.755487      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:24:22.696792 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:24:22.755834      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:23.756979      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:24:24.707339 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:24:24.758016      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:25.759282      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:24:26.716778 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:24:26.759554      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:27.759918      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:24:28.728857 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:24:28.760848      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:29.761645      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:24:30.738882 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:24:30.762016      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:31.762636      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:24:32.754063 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:24:32.763261      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:33.763790      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:34.764553      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:24:34.765737 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:24:35.765226      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:36.766866      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:24:36.776691 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:24:37.767243      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:38.768469      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:24:38.791127 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:24:39.770072      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:40.769522      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:24:40.801653 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:24:41.770465      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:42.770500      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:24:42.812548 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:24:43.770854      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:44.771443      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:24:44.824783 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:24:45.772312      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:46.772964      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:24:46.835844 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:24:47.773500      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:48.774414      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:24:48.846176 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:24:49.775302      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:50.775886      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:24:50.857503 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:24:51.776503      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:52.776968      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:24:52.883528 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:24:53.777183      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:54.777459      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:24:54.896132 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:24:55.778113      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:56.778814      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:24:56.908655 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:24:57.779598      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:58.780400      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:24:58.926582 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:24:59.780752      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:00.781028      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:25:00.938202 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:25:01.781093      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:02.782098      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:25:02.950359 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:25:03.782630      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:04.782888      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:25:04.958991 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:25:05.783931      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:06.784227      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:25:06.967805 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:25:07.785525      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:08.785810      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:25:08.982392 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:25:09.786974      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:10.788051      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:25:10.994893 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:25:11.788390      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:12.789101      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:25:13.005637 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:25:13.790137      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:14.791067      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:25:15.015048 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:25:15.791382      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:16.792361      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:25:17.022047 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:25:17.793257      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:18.794045      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:25:19.034546 14 container_probe.go:1759] Get pod busybox-37590268-c358-423f-be76-4ee6b944b224 in namespace container-probe-245
  E0419 17:25:19.794267      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:20.795133      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 04/19/24 17:25:21.035
  I0419 17:25:21.071434 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-245" for this suite. @ 04/19/24 17:25:21.102
• [243.578 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:97
  STEP: Creating a kubernetes client @ 04/19/24 17:25:21.129
  I0419 17:25:21.129258 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename cronjob @ 04/19/24 17:25:21.132
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:25:21.176
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:25:21.184
  STEP: Creating a suspended cronjob @ 04/19/24 17:25:21.193
  STEP: Ensuring no jobs are scheduled @ 04/19/24 17:25:21.205
  E0419 17:25:21.795376      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:22.795640      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:23.796190      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:24.796440      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:25.797095      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:26.797898      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:27.798330      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:28.798498      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:29.798802      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:30.799615      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:31.801174      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:32.801364      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:33.802545      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:34.802704      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:35.803002      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:36.803993      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:37.804163      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:38.804458      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:39.804832      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:40.805097      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:41.806182      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:42.806346      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:43.806567      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:44.807329      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:45.807607      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:46.808667      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:47.809027      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:48.809187      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:49.809538      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:50.809693      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:51.810196      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:52.810481      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:53.811388      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:54.812083      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:55.812269      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:56.812990      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:57.813232      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:58.813825      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:59.814065      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:00.814893      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:01.815628      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:02.815341      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:03.816522      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:04.817325      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:05.818016      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:06.818328      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:07.818439      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:08.821254      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:09.821953      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:10.822407      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:11.822977      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:12.823642      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:13.824303      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:14.824593      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:15.824768      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:16.824997      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:17.825091      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:18.825645      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:19.826582      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:20.826834      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:21.827475      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:22.827770      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:23.828103      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:24.828335      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:25.829434      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:26.830103      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:27.830293      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:28.831156      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:29.831323      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:30.831863      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:31.831929      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:32.832693      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:33.832765      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:34.833298      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:35.833453      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:36.834957      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:37.836118      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:38.836289      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:39.836616      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:40.837396      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:41.837267      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:42.837695      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:43.838463      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:44.838966      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:45.839582      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:46.840611      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:47.841546      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:48.842126      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:49.842797      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:50.842778      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:51.843890      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:52.844529      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:53.845319      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:54.845326      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:55.846178      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:56.846790      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:57.847829      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:58.847667      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:59.849475      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:00.850061      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:01.851174      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:02.851363      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:03.851632      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:04.851999      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:05.852550      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:06.853604      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:07.854232      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:08.855360      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:09.855525      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:10.855696      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:11.856572      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:12.856794      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:13.857075      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:14.858206      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:15.858517      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:16.858751      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:17.858705      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:18.858968      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:19.859023      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:20.859311      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:21.859516      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:22.859959      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:23.860379      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:24.860559      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:25.861717      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:26.862554      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:27.863454      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:28.864604      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:29.865003      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:30.865263      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:31.866028      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:32.866639      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:33.866874      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:34.867233      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:35.867250      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:36.867563      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:37.867790      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:38.868706      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:39.868953      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:40.869398      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:41.870240      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:42.870556      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:43.870887      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:44.871595      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:45.872211      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:46.872688      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:47.873751      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:48.874192      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:49.875724      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:50.875753      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:51.875942      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:52.876340      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:53.876391      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:54.877622      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:55.876965      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:56.877538      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:57.877752      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:58.878020      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:59.878538      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:00.878772      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:01.879091      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:02.879233      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:03.880087      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:04.880724      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:05.880975      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:06.881173      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:07.881388      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:08.882057      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:09.883387      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:10.883571      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:11.883656      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:12.883660      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:13.884293      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:14.884382      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:15.884515      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:16.885617      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:17.885997      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:18.893295      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:19.894557      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:20.891199      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:21.891782      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:22.893192      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:23.893074      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:24.893119      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:25.893688      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:26.893559      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:27.894133      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:28.894539      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:29.894931      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:30.895287      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:31.895460      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:32.895895      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:33.896119      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:34.897026      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:35.897359      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:36.898198      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:37.898773      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:38.899368      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:39.899399      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:40.900109      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:41.900569      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:42.900538      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:43.901020      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:44.901198      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:45.902436      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:46.902815      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:47.903129      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:48.903987      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:49.904358      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:50.904660      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:51.904753      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:52.905362      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:53.905670      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:54.906377      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:55.906512      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:56.907473      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:57.907985      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:58.907978      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:59.908161      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:00.909494      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:01.909116      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:02.909478      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:03.910276      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:04.910577      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:05.911733      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:06.912753      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:07.913774      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:08.916441      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:09.916756      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:10.918287      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:11.917865      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:12.918571      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:13.919083      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:14.919454      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:15.919501      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:16.920373      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:17.920785      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:18.921168      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:19.921036      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:20.921494      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:21.921442      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:22.922091      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:23.922920      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:24.923060      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:25.923511      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:26.923791      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:27.923994      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:28.924497      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:29.925409      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:30.926536      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:31.926498      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:32.927550      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:33.927927      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:34.928158      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:35.928389      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:36.929523      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:37.929584      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:38.929965      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:39.930696      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:40.931334      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:41.931526      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:42.932258      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:43.933037      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:44.933222      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:45.933517      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:46.934475      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:47.934655      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:48.934718      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:49.935715      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:50.936450      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:51.937536      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:52.937639      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:53.938062      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:54.939071      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:55.939268      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:56.940266      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:57.940631      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:58.940747      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:59.940944      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:00.942021      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:01.942717      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:02.942928      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:03.943457      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:04.944292      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:05.945295      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:06.945542      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:07.945702      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:08.946293      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:09.946665      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:10.947508      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:11.947634      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:12.947670      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:13.948072      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:14.948979      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:15.949072      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:16.949981      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:17.950610      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:18.950736      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:19.951623      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:20.952372      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring no job exists by listing jobs explicitly @ 04/19/24 17:30:21.206
  STEP: Removing cronjob @ 04/19/24 17:30:21.216
  I0419 17:30:21.233784 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-1971" for this suite. @ 04/19/24 17:30:21.249
• [300.144 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:195
  STEP: Creating a kubernetes client @ 04/19/24 17:30:21.274
  I0419 17:30:21.274876 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename downward-api @ 04/19/24 17:30:21.278
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:30:21.311
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:30:21.315
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 17:30:21.322
  E0419 17:30:21.953326      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:22.953500      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:23.953627      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:24.953785      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:30:25.362
  I0419 17:30:25.369174 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod downwardapi-volume-eb53cbc3-d5a3-4d0c-bc4a-153b2cc991b1 container client-container: <nil>
  STEP: delete the pod @ 04/19/24 17:30:25.423
  I0419 17:30:25.454733 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5638" for this suite. @ 04/19/24 17:30:25.464
• [4.205 seconds]
------------------------------
SS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:263
  STEP: Creating a kubernetes client @ 04/19/24 17:30:25.48
  I0419 17:30:25.480337 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename downward-api @ 04/19/24 17:30:25.484
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:30:25.514
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:30:25.52
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 17:30:25.527
  E0419 17:30:25.954137      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:26.954270      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:27.954411      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:28.954502      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:30:29.575
  I0419 17:30:29.583924 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod downwardapi-volume-e6883c0f-155b-4894-a464-d678cc0fd573 container client-container: <nil>
  STEP: delete the pod @ 04/19/24 17:30:29.597
  I0419 17:30:29.629515 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5156" for this suite. @ 04/19/24 17:30:29.638
• [4.171 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:321
  STEP: Creating a kubernetes client @ 04/19/24 17:30:29.653
  I0419 17:30:29.653293 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename statefulset @ 04/19/24 17:30:29.659
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:30:29.688
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:30:29.691
  STEP: Creating service test in namespace statefulset-4853 @ 04/19/24 17:30:29.696
  STEP: Creating a new StatefulSet @ 04/19/24 17:30:29.713
  I0419 17:30:29.734368 14 wait.go:40] Found 0 stateful pods, waiting for 3
  E0419 17:30:29.955121      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:30.955813      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:31.956738      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:32.956863      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:33.958098      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:34.958368      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:35.958546      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:36.959228      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:37.959824      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:38.959947      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:30:39.739137 14 wait.go:50] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I0419 17:30:39.739263 14 wait.go:50] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I0419 17:30:39.739338 14 wait.go:50] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  I0419 17:30:39.763935 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=statefulset-4853 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  E0419 17:30:39.960858      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:30:40.155069 14 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0419 17:30:40.155143 14 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0419 17:30:40.155169 14 statefulset.go:2184] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0419 17:30:40.961242      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:41.961746      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:42.962095      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:43.963133      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:44.963307      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:45.963591      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:46.964334      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:47.964868      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:48.965369      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:49.965605      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 04/19/24 17:30:50.183
  I0419 17:30:50.224176 14 statefulset.go:2241] Updating stateful set ss2
  STEP: Creating a new revision @ 04/19/24 17:30:50.224
  E0419 17:30:50.965853      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:51.966446      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:52.966838      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:53.967205      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:54.966937      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:55.967256      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:56.967426      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:57.967733      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:58.968614      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:59.969048      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating Pods in reverse ordinal order @ 04/19/24 17:31:00.245
  I0419 17:31:00.253741 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=statefulset-4853 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0419 17:31:00.553593 14 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0419 17:31:00.553679 14 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0419 17:31:00.553708 14 statefulset.go:2208] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0419 17:31:00.969116      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:01.969297      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:02.970452      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:03.970648      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:04.970902      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:05.971170      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:06.971220      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:07.971776      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:08.971939      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:09.972281      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Rolling back to a previous revision @ 04/19/24 17:31:10.613
  I0419 17:31:10.613517 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=statefulset-4853 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0419 17:31:10.936307 14 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0419 17:31:10.936381 14 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0419 17:31:10.936406 14 statefulset.go:2184] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0419 17:31:10.972769      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:11.973563      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:12.973653      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:13.973956      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:14.974021      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:15.974303      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:16.974770      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:17.975127      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:18.976082      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:19.976445      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:20.976397      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:31:20.994904 14 statefulset.go:2241] Updating stateful set ss2
  E0419 17:31:21.977066      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:22.977296      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:23.977579      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:24.978053      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:25.977785      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:26.978635      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:27.979329      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:28.979282      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:29.979761      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:30.980384      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Rolling back update in reverse ordinal order @ 04/19/24 17:31:31.014
  I0419 17:31:31.028107 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=statefulset-4853 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0419 17:31:31.335763 14 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0419 17:31:31.335883 14 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0419 17:31:31.335921 14 statefulset.go:2208] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0419 17:31:31.980574      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:32.981445      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:33.982131      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:34.982468      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:35.983702      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:36.984356      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:37.985095      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:38.985405      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:39.985725      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:40.986106      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:31:41.381976 14 statefulset.go:135] Deleting all statefulset in ns statefulset-4853
  I0419 17:31:41.392415 14 rest.go:150] Scaling statefulset ss2 to 0
  E0419 17:31:41.986779      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:42.987603      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:43.987679      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:44.988082      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:45.988771      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:46.990107      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:47.990834      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:48.991218      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:49.991471      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:50.991741      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:31:51.432365 14 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0419 17:31:51.438667 14 rest.go:88] Deleting statefulset ss2
  I0419 17:31:51.479566 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-4853" for this suite. @ 04/19/24 17:31:51.49
• [81.853 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pods.go:163
  STEP: Creating a kubernetes client @ 04/19/24 17:31:51.519
  I0419 17:31:51.519409 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename pods @ 04/19/24 17:31:51.522
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:31:51.548
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:31:51.554
  STEP: creating the pod @ 04/19/24 17:31:51.56
  STEP: submitting the pod to kubernetes @ 04/19/24 17:31:51.561
  STEP: verifying QOS class is set on the pod @ 04/19/24 17:31:51.581
  I0419 17:31:51.589992 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-1028" for this suite. @ 04/19/24 17:31:51.606
• [0.101 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:100
  STEP: Creating a kubernetes client @ 04/19/24 17:31:51.622
  I0419 17:31:51.622602 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename projected @ 04/19/24 17:31:51.626
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:31:51.65
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:31:51.655
  STEP: Creating configMap with name projected-configmap-test-volume-map-a2c76dad-67e5-4e98-ab6a-80d8a25302a5 @ 04/19/24 17:31:51.66
  STEP: Creating a pod to test consume configMaps @ 04/19/24 17:31:51.67
  E0419 17:31:51.992610      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:52.992474      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:53.993682      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:54.994681      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:31:55.722
  I0419 17:31:55.731735 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-projected-configmaps-103a5838-f825-45f9-a58a-7f96f78c9992 container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/24 17:31:55.756
  I0419 17:31:55.800750 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3165" for this suite. @ 04/19/24 17:31:55.818
• [4.209 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:619
  STEP: Creating a kubernetes client @ 04/19/24 17:31:55.833
  I0419 17:31:55.833802 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename pods @ 04/19/24 17:31:55.837
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:31:55.905
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:31:55.91
  I0419 17:31:55.918092 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: creating the pod @ 04/19/24 17:31:55.921
  STEP: submitting the pod to kubernetes @ 04/19/24 17:31:55.922
  E0419 17:31:55.995060      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:56.995817      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:57.996987      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:31:58.035466 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7780" for this suite. @ 04/19/24 17:31:58.05
• [2.234 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:68
  STEP: Creating a kubernetes client @ 04/19/24 17:31:58.074
  I0419 17:31:58.074803 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename secrets @ 04/19/24 17:31:58.078
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:31:58.114
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:31:58.119
  STEP: Creating secret with name secret-test-0fdabee1-7d4f-4ff6-aaa1-be8d9ef11b22 @ 04/19/24 17:31:58.125
  STEP: Creating a pod to test consume secrets @ 04/19/24 17:31:58.139
  E0419 17:31:58.997306      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:59.998769      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:00.998909      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:01.999811      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:32:02.195
  I0419 17:32:02.201607 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-secrets-d2a06bfa-46da-4e41-8318-3531390a1bdc container secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/24 17:32:02.217
  I0419 17:32:02.246489 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3165" for this suite. @ 04/19/24 17:32:02.256
• [4.193 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:459
  STEP: Creating a kubernetes client @ 04/19/24 17:32:02.268
  I0419 17:32:02.268824 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename init-container @ 04/19/24 17:32:02.273
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:32:02.302
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:32:02.308
  STEP: creating the pod @ 04/19/24 17:32:02.314
  I0419 17:32:02.314436 14 init_container.go:499] PodSpec: initContainers in spec.initContainers
  E0419 17:32:03.004382      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:04.005626      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:05.006564      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:32:05.629105 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-5621" for this suite. @ 04/19/24 17:32:05.637
• [3.383 seconds]
------------------------------
SSSSS
------------------------------
[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/events.go:98
  STEP: Creating a kubernetes client @ 04/19/24 17:32:05.656
  I0419 17:32:05.657340 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename events @ 04/19/24 17:32:05.662
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:32:05.693
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:32:05.699
  STEP: creating a test event @ 04/19/24 17:32:05.705
  STEP: listing events in all namespaces @ 04/19/24 17:32:05.719
  STEP: listing events in test namespace @ 04/19/24 17:32:05.727
  STEP: listing events with field selection filtering on source @ 04/19/24 17:32:05.735
  STEP: listing events with field selection filtering on reportingController @ 04/19/24 17:32:05.741
  STEP: getting the test event @ 04/19/24 17:32:05.746
  STEP: patching the test event @ 04/19/24 17:32:05.752
  STEP: getting the test event @ 04/19/24 17:32:05.775
  STEP: updating the test event @ 04/19/24 17:32:05.782
  STEP: getting the test event @ 04/19/24 17:32:05.796
  STEP: deleting the test event @ 04/19/24 17:32:05.803
  STEP: listing events in all namespaces @ 04/19/24 17:32:05.818
  STEP: listing events in test namespace @ 04/19/24 17:32:05.831
  I0419 17:32:05.837163 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-6606" for this suite. @ 04/19/24 17:32:05.848
• [0.210 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:91
  STEP: Creating a kubernetes client @ 04/19/24 17:32:05.87
  I0419 17:32:05.870492 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename subpath @ 04/19/24 17:32:05.875
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:32:05.899
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:32:05.904
  STEP: Setting up data @ 04/19/24 17:32:05.91
  STEP: Creating pod pod-subpath-test-downwardapi-pgw8 @ 04/19/24 17:32:05.929
  STEP: Creating a pod to test atomic-volume-subpath @ 04/19/24 17:32:05.929
  E0419 17:32:06.007958      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:07.009072      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:08.009796      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:09.009809      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:10.010627      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:11.011487      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:12.012134      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:13.012953      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:14.013530      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:15.013652      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:16.014590      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:17.015680      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:18.015726      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:19.016479      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:20.016777      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:21.017298      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:22.017199      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:23.017413      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:24.017727      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:25.018065      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:26.018382      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:27.018689      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:28.019740      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:29.019983      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:30.020214      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:32:30.083
  I0419 17:32:30.093990 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod pod-subpath-test-downwardapi-pgw8 container test-container-subpath-downwardapi-pgw8: <nil>
  STEP: delete the pod @ 04/19/24 17:32:30.113
  STEP: Deleting pod pod-subpath-test-downwardapi-pgw8 @ 04/19/24 17:32:30.152
  I0419 17:32:30.152494 14 delete.go:62] Deleting pod "pod-subpath-test-downwardapi-pgw8" in namespace "subpath-5158"
  I0419 17:32:30.160753 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-5158" for this suite. @ 04/19/24 17:32:30.169
• [24.316 seconds]
------------------------------
S
------------------------------
[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet_etc_hosts.go:64
  STEP: Creating a kubernetes client @ 04/19/24 17:32:30.186
  I0419 17:32:30.187207 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts @ 04/19/24 17:32:30.189
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:32:30.218
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:32:30.226
  STEP: Setting up the test @ 04/19/24 17:32:30.232
  STEP: Creating hostNetwork=false pod @ 04/19/24 17:32:30.232
  E0419 17:32:31.020746      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:32.021681      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating hostNetwork=true pod @ 04/19/24 17:32:32.285
  E0419 17:32:33.021778      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:34.022440      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Running the test @ 04/19/24 17:32:34.336
  STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false @ 04/19/24 17:32:34.336
  I0419 17:32:34.336865 14 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6810 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0419 17:32:34.337384 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 17:32:34.340421 14 exec_util.go:62] ExecWithOptions: Clientset creation
  I0419 17:32:34.341133 14 exec_util.go:79] ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6810/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  I0419 17:32:34.511734 14 exec_util.go:106] Exec stderr: ""
  I0419 17:32:34.512124 14 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6810 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0419 17:32:34.512403 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 17:32:34.515071 14 exec_util.go:62] ExecWithOptions: Clientset creation
  I0419 17:32:34.515393 14 exec_util.go:79] ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6810/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  I0419 17:32:34.602500 14 exec_util.go:106] Exec stderr: ""
  I0419 17:32:34.602595 14 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6810 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0419 17:32:34.602619 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 17:32:34.610967 14 exec_util.go:62] ExecWithOptions: Clientset creation
  I0419 17:32:34.611103 14 exec_util.go:79] ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6810/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  I0419 17:32:34.727521 14 exec_util.go:106] Exec stderr: ""
  I0419 17:32:34.728264 14 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6810 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0419 17:32:34.728342 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 17:32:34.730329 14 exec_util.go:62] ExecWithOptions: Clientset creation
  I0419 17:32:34.730464 14 exec_util.go:79] ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6810/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  I0419 17:32:34.846069 14 exec_util.go:106] Exec stderr: ""
  STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount @ 04/19/24 17:32:34.846
  I0419 17:32:34.847047 14 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6810 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0419 17:32:34.847077 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 17:32:34.849157 14 exec_util.go:62] ExecWithOptions: Clientset creation
  I0419 17:32:34.849356 14 exec_util.go:79] ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6810/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  I0419 17:32:34.979009 14 exec_util.go:106] Exec stderr: ""
  I0419 17:32:34.979146 14 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6810 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0419 17:32:34.979223 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 17:32:34.981538 14 exec_util.go:62] ExecWithOptions: Clientset creation
  I0419 17:32:34.981717 14 exec_util.go:79] ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6810/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  E0419 17:32:35.022600      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:32:35.082151 14 exec_util.go:106] Exec stderr: ""
  STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true @ 04/19/24 17:32:35.083
  I0419 17:32:35.083772 14 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6810 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0419 17:32:35.084304 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 17:32:35.086657 14 exec_util.go:62] ExecWithOptions: Clientset creation
  I0419 17:32:35.087339 14 exec_util.go:79] ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6810/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  I0419 17:32:35.226001 14 exec_util.go:106] Exec stderr: ""
  I0419 17:32:35.226246 14 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6810 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0419 17:32:35.226364 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 17:32:35.229381 14 exec_util.go:62] ExecWithOptions: Clientset creation
  I0419 17:32:35.229598 14 exec_util.go:79] ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6810/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  I0419 17:32:35.350754 14 exec_util.go:106] Exec stderr: ""
  I0419 17:32:35.350941 14 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6810 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0419 17:32:35.350966 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 17:32:35.353683 14 exec_util.go:62] ExecWithOptions: Clientset creation
  I0419 17:32:35.353953 14 exec_util.go:79] ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6810/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  I0419 17:32:35.468476 14 exec_util.go:106] Exec stderr: ""
  I0419 17:32:35.468760 14 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6810 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0419 17:32:35.469058 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  I0419 17:32:35.470860 14 exec_util.go:62] ExecWithOptions: Clientset creation
  I0419 17:32:35.471121 14 exec_util.go:79] ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6810/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  I0419 17:32:35.572599 14 exec_util.go:106] Exec stderr: ""
  I0419 17:32:35.573209 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "e2e-kubelet-etc-hosts-6810" for this suite. @ 04/19/24 17:32:35.583
• [5.410 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicy API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:406
  STEP: Creating a kubernetes client @ 04/19/24 17:32:35.601
  I0419 17:32:35.602040 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename validating-admission-policy @ 04/19/24 17:32:35.605
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:32:35.633
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:32:35.638
  STEP: getting /apis @ 04/19/24 17:32:35.656
  STEP: getting /apis/admissionregistration.k8s.io @ 04/19/24 17:32:35.665
  STEP: getting /apis/admissionregistration.k8s.io/v1 @ 04/19/24 17:32:35.667
  STEP: creating @ 04/19/24 17:32:35.67
  STEP: getting @ 04/19/24 17:32:35.71
  STEP: listing @ 04/19/24 17:32:35.717
  STEP: watching @ 04/19/24 17:32:35.725
  I0419 17:32:35.725915 14 validatingadmissionpolicy.go:523] starting watch
  STEP: patching @ 04/19/24 17:32:35.732
  STEP: updating @ 04/19/24 17:32:35.742
  I0419 17:32:35.763312 14 validatingadmissionpolicy.go:552] waiting for watch events with expected annotations
  STEP: getting /status @ 04/19/24 17:32:35.765
  STEP: patching /status @ 04/19/24 17:32:35.777
  STEP: updating /status @ 04/19/24 17:32:35.804
  STEP: deleting @ 04/19/24 17:32:35.88
  STEP: deleting a collection @ 04/19/24 17:32:35.902
  I0419 17:32:35.942275 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-6722" for this suite. @ 04/19/24 17:32:35.958
• [0.368 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:624
  STEP: Creating a kubernetes client @ 04/19/24 17:32:35.982
  I0419 17:32:35.982312 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename sched-preemption @ 04/19/24 17:32:35.985
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:32:36.01
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:32:36.016
  E0419 17:32:36.022855      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:32:36.053910 14 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0419 17:32:37.023731      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:38.023980      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:39.024367      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:40.024593      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:41.025121      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:42.025936      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:43.026964      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:44.027335      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:45.028347      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:46.028788      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:47.029670      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:48.030122      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:49.030330      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:50.031171      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:51.031200      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:52.031747      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:53.031842      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:54.032136      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:55.032574      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:56.032548      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:57.033107      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:58.033396      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:59.033795      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:00.034074      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:01.034238      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:02.034740      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:03.035684      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:04.035808      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:05.036048      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:06.037584      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:07.040239      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:08.041906      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:09.041774      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:10.042324      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:11.042582      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:12.052993      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:13.047233      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:14.047196      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:15.047473      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:16.047640      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:17.048608      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:18.049251      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:19.049559      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:20.049929      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:21.050524      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:22.051403      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:23.052538      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:24.053414      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:25.054093      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:26.054131      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:27.054910      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:28.054890      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:29.055242      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:30.055445      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:31.055701      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:32.055970      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:33.056411      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:34.056613      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:35.057005      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:36.057618      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:33:36.065404 14 util.go:400] Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 04/19/24 17:33:36.073
  I0419 17:33:36.074356 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename sched-preemption-path @ 04/19/24 17:33:36.079
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:33:36.123
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:33:36.131
  STEP: Finding an available node @ 04/19/24 17:33:36.139
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 04/19/24 17:33:36.139
  E0419 17:33:37.057808      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:38.058197      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 04/19/24 17:33:38.188
  I0419 17:33:38.229575 14 preemption.go:583] found a healthy node: eipo9quoh3ef-3
  E0419 17:33:39.059192      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:40.059834      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:41.060807      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:42.061584      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:43.062775      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:44.063810      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:33:44.422744 14 preemption.go:706] pods created so far: [1 1 1]
  I0419 17:33:44.422935 14 preemption.go:707] length of pods created so far: 3
  E0419 17:33:45.064790      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:46.065066      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:33:46.464063 14 preemption.go:724] pods created so far: [2 2 1]
  E0419 17:33:47.065695      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:48.066181      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:49.066648      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:50.075012      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:51.069982      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:52.070291      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:53.070592      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:33:53.674932 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-4218" for this suite. @ 04/19/24 17:33:53.687
  I0419 17:33:53.701228 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-5376" for this suite. @ 04/19/24 17:33:53.712
• [77.748 seconds]
------------------------------
SSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount projected service account token [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:277
  STEP: Creating a kubernetes client @ 04/19/24 17:33:53.732
  I0419 17:33:53.733165 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename svcaccounts @ 04/19/24 17:33:53.74
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:33:53.769
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:33:53.777
  STEP: Creating a pod to test service account token:  @ 04/19/24 17:33:53.785
  E0419 17:33:54.076962      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:55.072158      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:56.072436      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:57.078176      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:33:57.847
  I0419 17:33:57.860239 14 output.go:196] Trying to get logs from node eipo9quoh3ef-3 pod test-pod-bc0d7e2e-d790-4281-bb2a-31fe7dcb4284 container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/24 17:33:57.893
  I0419 17:33:57.947043 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-7997" for this suite. @ 04/19/24 17:33:57.97
• [4.260 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency should not be very high [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service_latency.go:59
  STEP: Creating a kubernetes client @ 04/19/24 17:33:58.008
  I0419 17:33:58.009237 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename svc-latency @ 04/19/24 17:33:58.013
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:33:58.048
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:33:58.057
  I0419 17:33:58.066368 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: creating replication controller svc-latency-rc in namespace svc-latency-7311 @ 04/19/24 17:33:58.07
  E0419 17:33:58.072806      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:33:58.086044      14 runners.go:198] Created replication controller with name: svc-latency-rc, namespace: svc-latency-7311, replica count: 1
  E0419 17:33:59.073197      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:33:59.137949      14 runners.go:198] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E0419 17:34:00.074247      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:34:00.138966      14 runners.go:198] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0419 17:34:00.261040 14 service_latency.go:356] Created: latency-svc-p4kmq
  I0419 17:34:00.279485 14 service_latency.go:363] Got endpoints: latency-svc-p4kmq [39.552617ms]
  I0419 17:34:00.313293 14 service_latency.go:356] Created: latency-svc-2574z
  I0419 17:34:00.328842 14 service_latency.go:363] Got endpoints: latency-svc-2574z [47.204102ms]
  I0419 17:34:00.505599 14 service_latency.go:356] Created: latency-svc-bv8lp
  I0419 17:34:00.505948 14 service_latency.go:356] Created: latency-svc-g6r82
  I0419 17:34:00.506471 14 service_latency.go:356] Created: latency-svc-qkdgz
  I0419 17:34:00.506810 14 service_latency.go:356] Created: latency-svc-x2flw
  I0419 17:34:00.507113 14 service_latency.go:356] Created: latency-svc-n9pnn
  I0419 17:34:00.514355 14 service_latency.go:356] Created: latency-svc-rw7n4
  I0419 17:34:00.516058 14 service_latency.go:356] Created: latency-svc-cdm75
  I0419 17:34:00.516657 14 service_latency.go:356] Created: latency-svc-ngbbp
  I0419 17:34:00.516950 14 service_latency.go:356] Created: latency-svc-2thfr
  I0419 17:34:00.524831 14 service_latency.go:356] Created: latency-svc-89jlx
  I0419 17:34:00.533296 14 service_latency.go:356] Created: latency-svc-6pr9s
  I0419 17:34:00.533712 14 service_latency.go:356] Created: latency-svc-rhl7j
  I0419 17:34:00.534075 14 service_latency.go:356] Created: latency-svc-cqk64
  I0419 17:34:00.534303 14 service_latency.go:356] Created: latency-svc-4cx5m
  I0419 17:34:00.534812 14 service_latency.go:356] Created: latency-svc-blsjb
  I0419 17:34:00.572848 14 service_latency.go:363] Got endpoints: latency-svc-bv8lp [289.932255ms]
  I0419 17:34:00.607067 14 service_latency.go:363] Got endpoints: latency-svc-rhl7j [322.52503ms]
  I0419 17:34:00.608055 14 service_latency.go:363] Got endpoints: latency-svc-blsjb [279.004424ms]
  I0419 17:34:00.608467 14 service_latency.go:363] Got endpoints: latency-svc-4cx5m [325.272876ms]
  I0419 17:34:00.608541 14 service_latency.go:363] Got endpoints: latency-svc-cqk64 [325.971709ms]
  I0419 17:34:00.634502 14 service_latency.go:363] Got endpoints: latency-svc-g6r82 [351.221006ms]
  I0419 17:34:00.659427 14 service_latency.go:363] Got endpoints: latency-svc-x2flw [375.061311ms]
  I0419 17:34:00.660259 14 service_latency.go:363] Got endpoints: latency-svc-qkdgz [378.00966ms]
  I0419 17:34:00.660619 14 service_latency.go:363] Got endpoints: latency-svc-n9pnn [375.916016ms]
  I0419 17:34:00.677107 14 service_latency.go:363] Got endpoints: latency-svc-cdm75 [392.906497ms]
  I0419 17:34:00.731321 14 service_latency.go:356] Created: latency-svc-gcrbt
  I0419 17:34:00.731793 14 service_latency.go:363] Got endpoints: latency-svc-2thfr [448.089667ms]
  I0419 17:34:00.740974 14 service_latency.go:363] Got endpoints: latency-svc-ngbbp [457.044551ms]
  I0419 17:34:00.741955 14 service_latency.go:363] Got endpoints: latency-svc-89jlx [457.890939ms]
  I0419 17:34:00.742306 14 service_latency.go:363] Got endpoints: latency-svc-rw7n4 [458.722783ms]
  I0419 17:34:00.777514 14 service_latency.go:356] Created: latency-svc-9fjw5
  I0419 17:34:00.821259 14 service_latency.go:363] Got endpoints: latency-svc-6pr9s [536.42513ms]
  I0419 17:34:00.821311 14 service_latency.go:363] Got endpoints: latency-svc-gcrbt [248.257265ms]
  I0419 17:34:00.839107 14 service_latency.go:356] Created: latency-svc-sxxwb
  I0419 17:34:00.839389 14 service_latency.go:363] Got endpoints: latency-svc-9fjw5 [231.246206ms]
  I0419 17:34:00.873738 14 service_latency.go:363] Got endpoints: latency-svc-sxxwb [266.494548ms]
  I0419 17:34:00.877108 14 service_latency.go:356] Created: latency-svc-9kqn7
  I0419 17:34:00.897505 14 service_latency.go:363] Got endpoints: latency-svc-9kqn7 [288.482235ms]
  I0419 17:34:01.038762 14 service_latency.go:356] Created: latency-svc-jcq98
  I0419 17:34:01.050027 14 service_latency.go:356] Created: latency-svc-2rbv8
  I0419 17:34:01.050319 14 service_latency.go:356] Created: latency-svc-zpqwb
  I0419 17:34:01.050618 14 service_latency.go:356] Created: latency-svc-42l48
  I0419 17:34:01.051197 14 service_latency.go:356] Created: latency-svc-7fqv9
  I0419 17:34:01.051409 14 service_latency.go:356] Created: latency-svc-kwzdf
  I0419 17:34:01.051729 14 service_latency.go:356] Created: latency-svc-f8pbt
  I0419 17:34:01.051800 14 service_latency.go:356] Created: latency-svc-sb45b
  I0419 17:34:01.050970 14 service_latency.go:356] Created: latency-svc-hxh55
  I0419 17:34:01.051996 14 service_latency.go:356] Created: latency-svc-qdn2p
  I0419 17:34:01.050765 14 service_latency.go:356] Created: latency-svc-vvxzv
  I0419 17:34:01.056193 14 service_latency.go:356] Created: latency-svc-h9lzv
  I0419 17:34:01.056209 14 service_latency.go:356] Created: latency-svc-rszns
  I0419 17:34:01.057144 14 service_latency.go:356] Created: latency-svc-475pn
  I0419 17:34:01.058415 14 service_latency.go:356] Created: latency-svc-rszp2
  E0419 17:34:01.075653      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:34:01.086560 14 service_latency.go:363] Got endpoints: latency-svc-jcq98 [409.352656ms]
  I0419 17:34:01.089708 14 service_latency.go:363] Got endpoints: latency-svc-rszns [347.023798ms]
  I0419 17:34:01.090125 14 service_latency.go:363] Got endpoints: latency-svc-475pn [428.745066ms]
  I0419 17:34:01.099030 14 service_latency.go:363] Got endpoints: latency-svc-rszp2 [259.495455ms]
  I0419 17:34:01.114880 14 service_latency.go:363] Got endpoints: latency-svc-h9lzv [240.966856ms]
  I0419 17:34:01.138149 14 service_latency.go:356] Created: latency-svc-vddsb
  I0419 17:34:01.139115 14 service_latency.go:363] Got endpoints: latency-svc-qdn2p [398.04132ms]
  I0419 17:34:01.139398 14 service_latency.go:363] Got endpoints: latency-svc-42l48 [241.823854ms]
  I0419 17:34:01.139233 14 service_latency.go:363] Got endpoints: latency-svc-2rbv8 [478.915187ms]
  I0419 17:34:01.166333 14 service_latency.go:363] Got endpoints: latency-svc-hxh55 [557.368737ms]
  I0419 17:34:01.166354 14 service_latency.go:363] Got endpoints: latency-svc-zpqwb [344.569399ms]
  I0419 17:34:01.191609 14 service_latency.go:363] Got endpoints: latency-svc-kwzdf [556.888561ms]
  I0419 17:34:01.194060 14 service_latency.go:356] Created: latency-svc-7xn26
  I0419 17:34:01.197285 14 service_latency.go:363] Got endpoints: latency-svc-sb45b [464.888476ms]
  I0419 17:34:01.199150 14 service_latency.go:363] Got endpoints: latency-svc-f8pbt [377.260168ms]
  I0419 17:34:01.199434 14 service_latency.go:363] Got endpoints: latency-svc-vvxzv [539.884472ms]
  I0419 17:34:01.220650 14 service_latency.go:363] Got endpoints: latency-svc-7fqv9 [478.633482ms]
  I0419 17:34:01.237096 14 service_latency.go:363] Got endpoints: latency-svc-7xn26 [147.275612ms]
  I0419 17:34:01.237370 14 service_latency.go:356] Created: latency-svc-pm6qr
  I0419 17:34:01.238608 14 service_latency.go:363] Got endpoints: latency-svc-vddsb [151.969121ms]
  I0419 17:34:01.253517 14 service_latency.go:363] Got endpoints: latency-svc-pm6qr [162.722473ms]
  I0419 17:34:01.278301 14 service_latency.go:356] Created: latency-svc-wgsdz
  I0419 17:34:01.278426 14 service_latency.go:363] Got endpoints: latency-svc-wgsdz [177.582886ms]
  I0419 17:34:01.290994 14 service_latency.go:356] Created: latency-svc-8vqxr
  I0419 17:34:01.293101 14 service_latency.go:356] Created: latency-svc-xz7hm
  I0419 17:34:01.308124 14 service_latency.go:363] Got endpoints: latency-svc-8vqxr [192.019361ms]
  I0419 17:34:01.328311 14 service_latency.go:363] Got endpoints: latency-svc-xz7hm [188.28048ms]
  I0419 17:34:01.330214 14 service_latency.go:356] Created: latency-svc-6zgb5
  I0419 17:34:01.338463 14 service_latency.go:363] Got endpoints: latency-svc-6zgb5 [197.034735ms]
  I0419 17:34:01.346911 14 service_latency.go:356] Created: latency-svc-tk6fc
  I0419 17:34:01.350542 14 service_latency.go:356] Created: latency-svc-ftx5x
  I0419 17:34:01.352531 14 service_latency.go:363] Got endpoints: latency-svc-tk6fc [210.932506ms]
  I0419 17:34:01.361431 14 service_latency.go:363] Got endpoints: latency-svc-ftx5x [194.842361ms]
  I0419 17:34:01.510559 14 service_latency.go:356] Created: latency-svc-l495t
  I0419 17:34:01.510966 14 service_latency.go:356] Created: latency-svc-89tbj
  I0419 17:34:01.511206 14 service_latency.go:356] Created: latency-svc-7hkqk
  I0419 17:34:01.511455 14 service_latency.go:356] Created: latency-svc-9gwjk
  I0419 17:34:01.511710 14 service_latency.go:356] Created: latency-svc-8pjsp
  I0419 17:34:01.522264 14 service_latency.go:356] Created: latency-svc-zp4b6
  I0419 17:34:01.523934 14 service_latency.go:356] Created: latency-svc-vlk66
  I0419 17:34:01.524558 14 service_latency.go:356] Created: latency-svc-sjbnd
  I0419 17:34:01.525205 14 service_latency.go:356] Created: latency-svc-bmvrk
  I0419 17:34:01.525479 14 service_latency.go:356] Created: latency-svc-sst7v
  I0419 17:34:01.563259 14 service_latency.go:356] Created: latency-svc-brbtm
  I0419 17:34:01.563795 14 service_latency.go:356] Created: latency-svc-tn9tc
  I0419 17:34:01.564020 14 service_latency.go:356] Created: latency-svc-ktspm
  I0419 17:34:01.564345 14 service_latency.go:356] Created: latency-svc-4qqtv
  I0419 17:34:01.564345 14 service_latency.go:356] Created: latency-svc-l98c7
  I0419 17:34:01.564422 14 service_latency.go:363] Got endpoints: latency-svc-7hkqk [326.736576ms]
  I0419 17:34:01.564429 14 service_latency.go:363] Got endpoints: latency-svc-l495t [397.966026ms]
  I0419 17:34:01.568722 14 service_latency.go:363] Got endpoints: latency-svc-9gwjk [290.070197ms]
  I0419 17:34:01.569522 14 service_latency.go:363] Got endpoints: latency-svc-89tbj [370.292553ms]
  I0419 17:34:01.579429 14 service_latency.go:363] Got endpoints: latency-svc-l98c7 [387.406466ms]
  I0419 17:34:01.579498 14 service_latency.go:363] Got endpoints: latency-svc-8pjsp [226.525895ms]
  I0419 17:34:01.596864 14 service_latency.go:363] Got endpoints: latency-svc-4qqtv [258.316001ms]
  I0419 17:34:01.599123 14 service_latency.go:363] Got endpoints: latency-svc-tn9tc [398.363375ms]
  I0419 17:34:01.617387 14 service_latency.go:363] Got endpoints: latency-svc-bmvrk [255.852324ms]
  I0419 17:34:01.618711 14 service_latency.go:356] Created: latency-svc-cllf9
  I0419 17:34:01.640176 14 service_latency.go:356] Created: latency-svc-hb2t2
  I0419 17:34:01.649813 14 service_latency.go:356] Created: latency-svc-k7tf4
  I0419 17:34:01.662153 14 service_latency.go:356] Created: latency-svc-tnjsn
  I0419 17:34:01.669507 14 service_latency.go:363] Got endpoints: latency-svc-sjbnd [341.088611ms]
  I0419 17:34:01.677768 14 service_latency.go:356] Created: latency-svc-sp52r
  I0419 17:34:01.694087 14 service_latency.go:356] Created: latency-svc-p2xdl
  I0419 17:34:01.706800 14 service_latency.go:356] Created: latency-svc-sgpmz
  I0419 17:34:01.718881 14 service_latency.go:363] Got endpoints: latency-svc-sst7v [521.208636ms]
  I0419 17:34:01.723162 14 service_latency.go:356] Created: latency-svc-7vzvd
  I0419 17:34:01.725266 14 service_latency.go:356] Created: latency-svc-z4rnt
  I0419 17:34:01.734307 14 service_latency.go:356] Created: latency-svc-p472s
  I0419 17:34:01.746092 14 service_latency.go:356] Created: latency-svc-t9rhs
  I0419 17:34:01.767761 14 service_latency.go:363] Got endpoints: latency-svc-zp4b6 [546.95372ms]
  I0419 17:34:01.781828 14 service_latency.go:356] Created: latency-svc-j45k8
  I0419 17:34:01.817077 14 service_latency.go:363] Got endpoints: latency-svc-vlk66 [563.454702ms]
  I0419 17:34:01.836992 14 service_latency.go:356] Created: latency-svc-2gxc5
  I0419 17:34:01.866494 14 service_latency.go:363] Got endpoints: latency-svc-ktspm [558.250369ms]
  I0419 17:34:01.885582 14 service_latency.go:356] Created: latency-svc-kzlfc
  I0419 17:34:01.915281 14 service_latency.go:363] Got endpoints: latency-svc-brbtm [676.280145ms]
  I0419 17:34:01.934578 14 service_latency.go:356] Created: latency-svc-jpqdf
  I0419 17:34:01.969812 14 service_latency.go:363] Got endpoints: latency-svc-cllf9 [404.330976ms]
  I0419 17:34:02.000590 14 service_latency.go:356] Created: latency-svc-8zz9x
  I0419 17:34:02.020406 14 service_latency.go:363] Got endpoints: latency-svc-hb2t2 [451.323879ms]
  I0419 17:34:02.046038 14 service_latency.go:356] Created: latency-svc-zj8b5
  I0419 17:34:02.067888 14 service_latency.go:363] Got endpoints: latency-svc-k7tf4 [498.087816ms]
  E0419 17:34:02.076171      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:34:02.086506 14 service_latency.go:356] Created: latency-svc-5kck9
  I0419 17:34:02.116279 14 service_latency.go:363] Got endpoints: latency-svc-tnjsn [536.339871ms]
  I0419 17:34:02.134720 14 service_latency.go:356] Created: latency-svc-2kcfq
  I0419 17:34:02.166828 14 service_latency.go:363] Got endpoints: latency-svc-sp52r [587.296582ms]
  I0419 17:34:02.190026 14 service_latency.go:356] Created: latency-svc-xcn94
  I0419 17:34:02.216421 14 service_latency.go:363] Got endpoints: latency-svc-p2xdl [619.388029ms]
  I0419 17:34:02.237678 14 service_latency.go:356] Created: latency-svc-nkwl2
  I0419 17:34:02.268421 14 service_latency.go:363] Got endpoints: latency-svc-sgpmz [668.818036ms]
  I0419 17:34:02.286768 14 service_latency.go:356] Created: latency-svc-9pg7s
  I0419 17:34:02.325406 14 service_latency.go:363] Got endpoints: latency-svc-7vzvd [707.653745ms]
  I0419 17:34:02.343852 14 service_latency.go:356] Created: latency-svc-r7k2k
  I0419 17:34:02.363344 14 service_latency.go:363] Got endpoints: latency-svc-z4rnt [798.14775ms]
  I0419 17:34:02.379325 14 service_latency.go:356] Created: latency-svc-hqcz7
  I0419 17:34:02.419360 14 service_latency.go:363] Got endpoints: latency-svc-p472s [749.738704ms]
  I0419 17:34:02.440779 14 service_latency.go:356] Created: latency-svc-2vmwj
  I0419 17:34:02.468661 14 service_latency.go:363] Got endpoints: latency-svc-t9rhs [749.704477ms]
  I0419 17:34:02.491190 14 service_latency.go:356] Created: latency-svc-hsf2t
  I0419 17:34:02.519187 14 service_latency.go:363] Got endpoints: latency-svc-j45k8 [750.967955ms]
  I0419 17:34:02.538575 14 service_latency.go:356] Created: latency-svc-qqg8h
  I0419 17:34:02.565920 14 service_latency.go:363] Got endpoints: latency-svc-2gxc5 [748.166869ms]
  I0419 17:34:02.582520 14 service_latency.go:356] Created: latency-svc-6rt2f
  I0419 17:34:02.617198 14 service_latency.go:363] Got endpoints: latency-svc-kzlfc [750.213789ms]
  I0419 17:34:02.633615 14 service_latency.go:356] Created: latency-svc-jk6vv
  I0419 17:34:02.665689 14 service_latency.go:363] Got endpoints: latency-svc-jpqdf [750.269353ms]
  I0419 17:34:02.681078 14 service_latency.go:356] Created: latency-svc-54m7l
  I0419 17:34:02.716941 14 service_latency.go:363] Got endpoints: latency-svc-8zz9x [746.977686ms]
  I0419 17:34:02.733520 14 service_latency.go:356] Created: latency-svc-h9hj4
  I0419 17:34:02.763140 14 service_latency.go:363] Got endpoints: latency-svc-zj8b5 [742.437986ms]
  I0419 17:34:02.784680 14 service_latency.go:356] Created: latency-svc-jsnw2
  I0419 17:34:02.814631 14 service_latency.go:363] Got endpoints: latency-svc-5kck9 [746.165909ms]
  I0419 17:34:02.831746 14 service_latency.go:356] Created: latency-svc-2lm4z
  I0419 17:34:02.862506 14 service_latency.go:363] Got endpoints: latency-svc-2kcfq [745.495035ms]
  I0419 17:34:02.881706 14 service_latency.go:356] Created: latency-svc-4khhn
  I0419 17:34:02.913910 14 service_latency.go:363] Got endpoints: latency-svc-xcn94 [746.389321ms]
  I0419 17:34:02.932284 14 service_latency.go:356] Created: latency-svc-22x54
  I0419 17:34:02.967553 14 service_latency.go:363] Got endpoints: latency-svc-nkwl2 [750.461522ms]
  I0419 17:34:02.983606 14 service_latency.go:356] Created: latency-svc-65j9n
  I0419 17:34:03.016662 14 service_latency.go:363] Got endpoints: latency-svc-9pg7s [748.144507ms]
  I0419 17:34:03.037930 14 service_latency.go:356] Created: latency-svc-8mqbn
  I0419 17:34:03.067997 14 service_latency.go:363] Got endpoints: latency-svc-r7k2k [742.326469ms]
  E0419 17:34:03.077114      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:34:03.088669 14 service_latency.go:356] Created: latency-svc-zbjg2
  I0419 17:34:03.117235 14 service_latency.go:363] Got endpoints: latency-svc-hqcz7 [753.499951ms]
  I0419 17:34:03.142219 14 service_latency.go:356] Created: latency-svc-f5qfk
  I0419 17:34:03.163592 14 service_latency.go:363] Got endpoints: latency-svc-2vmwj [743.521904ms]
  I0419 17:34:03.184804 14 service_latency.go:356] Created: latency-svc-h6jbz
  I0419 17:34:03.214920 14 service_latency.go:363] Got endpoints: latency-svc-hsf2t [744.550473ms]
  I0419 17:34:03.233347 14 service_latency.go:356] Created: latency-svc-r8vz6
  I0419 17:34:03.265016 14 service_latency.go:363] Got endpoints: latency-svc-qqg8h [744.724681ms]
  I0419 17:34:03.285053 14 service_latency.go:356] Created: latency-svc-6s86c
  I0419 17:34:03.317095 14 service_latency.go:363] Got endpoints: latency-svc-6rt2f [750.509622ms]
  I0419 17:34:03.356649 14 service_latency.go:356] Created: latency-svc-9s8hv
  I0419 17:34:03.371954 14 service_latency.go:363] Got endpoints: latency-svc-jk6vv [754.387035ms]
  I0419 17:34:03.410826 14 service_latency.go:356] Created: latency-svc-rmsxb
  I0419 17:34:03.418404 14 service_latency.go:363] Got endpoints: latency-svc-54m7l [751.851048ms]
  I0419 17:34:03.438926 14 service_latency.go:356] Created: latency-svc-d2zbq
  I0419 17:34:03.470180 14 service_latency.go:363] Got endpoints: latency-svc-h9hj4 [753.152951ms]
  I0419 17:34:03.487785 14 service_latency.go:356] Created: latency-svc-kwh9q
  I0419 17:34:03.513532 14 service_latency.go:363] Got endpoints: latency-svc-jsnw2 [750.241294ms]
  I0419 17:34:03.535151 14 service_latency.go:356] Created: latency-svc-bz7zc
  I0419 17:34:03.565960 14 service_latency.go:363] Got endpoints: latency-svc-2lm4z [751.235772ms]
  I0419 17:34:03.586184 14 service_latency.go:356] Created: latency-svc-bzzzv
  I0419 17:34:03.614692 14 service_latency.go:363] Got endpoints: latency-svc-4khhn [751.924701ms]
  I0419 17:34:03.630046 14 service_latency.go:356] Created: latency-svc-b9vqq
  I0419 17:34:03.665695 14 service_latency.go:363] Got endpoints: latency-svc-22x54 [751.252779ms]
  I0419 17:34:03.686895 14 service_latency.go:356] Created: latency-svc-qcmdd
  I0419 17:34:03.714007 14 service_latency.go:363] Got endpoints: latency-svc-65j9n [745.51019ms]
  I0419 17:34:03.734713 14 service_latency.go:356] Created: latency-svc-qlgm4
  I0419 17:34:03.763864 14 service_latency.go:363] Got endpoints: latency-svc-8mqbn [747.105465ms]
  I0419 17:34:03.778821 14 service_latency.go:356] Created: latency-svc-d9bpj
  I0419 17:34:03.818163 14 service_latency.go:363] Got endpoints: latency-svc-zbjg2 [749.701613ms]
  I0419 17:34:03.864466 14 service_latency.go:356] Created: latency-svc-782gw
  I0419 17:34:03.869216 14 service_latency.go:363] Got endpoints: latency-svc-f5qfk [751.58986ms]
  I0419 17:34:03.887143 14 service_latency.go:356] Created: latency-svc-lkgxj
  I0419 17:34:03.912976 14 service_latency.go:363] Got endpoints: latency-svc-h6jbz [749.108009ms]
  I0419 17:34:03.931690 14 service_latency.go:356] Created: latency-svc-hqkbs
  I0419 17:34:03.965956 14 service_latency.go:363] Got endpoints: latency-svc-r8vz6 [750.921194ms]
  I0419 17:34:03.989967 14 service_latency.go:356] Created: latency-svc-mgf7b
  I0419 17:34:04.014120 14 service_latency.go:363] Got endpoints: latency-svc-6s86c [748.681315ms]
  I0419 17:34:04.031567 14 service_latency.go:356] Created: latency-svc-jxf86
  I0419 17:34:04.067226 14 service_latency.go:363] Got endpoints: latency-svc-9s8hv [750.049345ms]
  E0419 17:34:04.077147      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:34:04.082535 14 service_latency.go:356] Created: latency-svc-kfw6q
  I0419 17:34:04.114827 14 service_latency.go:363] Got endpoints: latency-svc-rmsxb [742.793703ms]
  I0419 17:34:04.132941 14 service_latency.go:356] Created: latency-svc-mbsst
  I0419 17:34:04.162919 14 service_latency.go:363] Got endpoints: latency-svc-d2zbq [744.367893ms]
  I0419 17:34:04.182496 14 service_latency.go:356] Created: latency-svc-99csp
  I0419 17:34:04.214524 14 service_latency.go:363] Got endpoints: latency-svc-kwh9q [743.880742ms]
  I0419 17:34:04.229972 14 service_latency.go:356] Created: latency-svc-bwtn4
  I0419 17:34:04.264653 14 service_latency.go:363] Got endpoints: latency-svc-bz7zc [750.896735ms]
  I0419 17:34:04.279340 14 service_latency.go:356] Created: latency-svc-fhc5q
  I0419 17:34:04.316167 14 service_latency.go:363] Got endpoints: latency-svc-bzzzv [750.107082ms]
  I0419 17:34:04.335072 14 service_latency.go:356] Created: latency-svc-hg2sc
  I0419 17:34:04.368163 14 service_latency.go:363] Got endpoints: latency-svc-b9vqq [753.391582ms]
  I0419 17:34:04.382941 14 service_latency.go:356] Created: latency-svc-lrn8z
  I0419 17:34:04.414361 14 service_latency.go:363] Got endpoints: latency-svc-qcmdd [748.550361ms]
  I0419 17:34:04.431694 14 service_latency.go:356] Created: latency-svc-2b2jw
  I0419 17:34:04.466487 14 service_latency.go:363] Got endpoints: latency-svc-qlgm4 [752.36975ms]
  I0419 17:34:04.484411 14 service_latency.go:356] Created: latency-svc-2xdc5
  I0419 17:34:04.516749 14 service_latency.go:363] Got endpoints: latency-svc-d9bpj [752.82182ms]
  I0419 17:34:04.531794 14 service_latency.go:356] Created: latency-svc-mvhnb
  I0419 17:34:04.563446 14 service_latency.go:363] Got endpoints: latency-svc-782gw [744.696948ms]
  I0419 17:34:04.581567 14 service_latency.go:356] Created: latency-svc-tn4vg
  I0419 17:34:04.616570 14 service_latency.go:363] Got endpoints: latency-svc-lkgxj [747.270473ms]
  I0419 17:34:04.634755 14 service_latency.go:356] Created: latency-svc-bl7bs
  I0419 17:34:04.664636 14 service_latency.go:363] Got endpoints: latency-svc-hqkbs [751.545463ms]
  I0419 17:34:04.681948 14 service_latency.go:356] Created: latency-svc-hr67c
  I0419 17:34:04.716766 14 service_latency.go:363] Got endpoints: latency-svc-mgf7b [750.67606ms]
  I0419 17:34:04.739378 14 service_latency.go:356] Created: latency-svc-llpcw
  I0419 17:34:04.763499 14 service_latency.go:363] Got endpoints: latency-svc-jxf86 [749.265872ms]
  I0419 17:34:04.785034 14 service_latency.go:356] Created: latency-svc-h757x
  I0419 17:34:04.813175 14 service_latency.go:363] Got endpoints: latency-svc-kfw6q [745.67873ms]
  I0419 17:34:04.830349 14 service_latency.go:356] Created: latency-svc-p7tdg
  I0419 17:34:04.866425 14 service_latency.go:363] Got endpoints: latency-svc-mbsst [751.436936ms]
  I0419 17:34:04.890052 14 service_latency.go:356] Created: latency-svc-dd6tg
  I0419 17:34:04.913433 14 service_latency.go:363] Got endpoints: latency-svc-99csp [750.343793ms]
  I0419 17:34:04.946619 14 service_latency.go:356] Created: latency-svc-qzfk8
  I0419 17:34:04.965149 14 service_latency.go:363] Got endpoints: latency-svc-bwtn4 [750.498999ms]
  I0419 17:34:04.985073 14 service_latency.go:356] Created: latency-svc-mkqmk
  I0419 17:34:05.018627 14 service_latency.go:363] Got endpoints: latency-svc-fhc5q [753.127366ms]
  I0419 17:34:05.041821 14 service_latency.go:356] Created: latency-svc-knw8p
  I0419 17:34:05.063676 14 service_latency.go:363] Got endpoints: latency-svc-hg2sc [747.345798ms]
  E0419 17:34:05.077610      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:34:05.083600 14 service_latency.go:356] Created: latency-svc-gjwk6
  I0419 17:34:05.113723 14 service_latency.go:363] Got endpoints: latency-svc-lrn8z [745.475967ms]
  I0419 17:34:05.132216 14 service_latency.go:356] Created: latency-svc-xwvl4
  I0419 17:34:05.168940 14 service_latency.go:363] Got endpoints: latency-svc-2b2jw [754.106068ms]
  I0419 17:34:05.186636 14 service_latency.go:356] Created: latency-svc-q548s
  I0419 17:34:05.217706 14 service_latency.go:363] Got endpoints: latency-svc-2xdc5 [750.522323ms]
  I0419 17:34:05.234563 14 service_latency.go:356] Created: latency-svc-b7vcw
  I0419 17:34:05.263085 14 service_latency.go:363] Got endpoints: latency-svc-mvhnb [746.211471ms]
  I0419 17:34:05.283454 14 service_latency.go:356] Created: latency-svc-8hg65
  I0419 17:34:05.313890 14 service_latency.go:363] Got endpoints: latency-svc-tn4vg [750.30464ms]
  I0419 17:34:05.334500 14 service_latency.go:356] Created: latency-svc-9lhbv
  I0419 17:34:05.366519 14 service_latency.go:363] Got endpoints: latency-svc-bl7bs [749.248803ms]
  I0419 17:34:05.385690 14 service_latency.go:356] Created: latency-svc-h5n98
  I0419 17:34:05.414596 14 service_latency.go:363] Got endpoints: latency-svc-hr67c [748.906692ms]
  I0419 17:34:05.440146 14 service_latency.go:356] Created: latency-svc-9hcx7
  I0419 17:34:05.468982 14 service_latency.go:363] Got endpoints: latency-svc-llpcw [751.52949ms]
  I0419 17:34:05.485656 14 service_latency.go:356] Created: latency-svc-tzhbx
  I0419 17:34:05.512956 14 service_latency.go:363] Got endpoints: latency-svc-h757x [749.363122ms]
  I0419 17:34:05.540290 14 service_latency.go:356] Created: latency-svc-xzjsn
  I0419 17:34:05.568325 14 service_latency.go:363] Got endpoints: latency-svc-p7tdg [754.964478ms]
  I0419 17:34:05.583778 14 service_latency.go:356] Created: latency-svc-dfwhf
  I0419 17:34:05.614300 14 service_latency.go:363] Got endpoints: latency-svc-dd6tg [747.756218ms]
  I0419 17:34:05.631353 14 service_latency.go:356] Created: latency-svc-wvhxg
  I0419 17:34:05.662294 14 service_latency.go:363] Got endpoints: latency-svc-qzfk8 [748.2473ms]
  I0419 17:34:05.681147 14 service_latency.go:356] Created: latency-svc-znjtp
  I0419 17:34:05.717023 14 service_latency.go:363] Got endpoints: latency-svc-mkqmk [751.420204ms]
  I0419 17:34:05.732434 14 service_latency.go:356] Created: latency-svc-r9shc
  I0419 17:34:05.766363 14 service_latency.go:363] Got endpoints: latency-svc-knw8p [747.131126ms]
  I0419 17:34:05.788168 14 service_latency.go:356] Created: latency-svc-9lgh4
  I0419 17:34:05.818786 14 service_latency.go:363] Got endpoints: latency-svc-gjwk6 [754.637907ms]
  I0419 17:34:05.844380 14 service_latency.go:356] Created: latency-svc-g9f6t
  I0419 17:34:05.867798 14 service_latency.go:363] Got endpoints: latency-svc-xwvl4 [753.587191ms]
  I0419 17:34:05.884373 14 service_latency.go:356] Created: latency-svc-zz6jx
  I0419 17:34:05.918208 14 service_latency.go:363] Got endpoints: latency-svc-q548s [748.804657ms]
  I0419 17:34:05.937001 14 service_latency.go:356] Created: latency-svc-wbbpr
  I0419 17:34:05.969985 14 service_latency.go:363] Got endpoints: latency-svc-b7vcw [752.188012ms]
  I0419 17:34:05.993796 14 service_latency.go:356] Created: latency-svc-trb2n
  I0419 17:34:06.016258 14 service_latency.go:363] Got endpoints: latency-svc-8hg65 [752.935574ms]
  I0419 17:34:06.038732 14 service_latency.go:356] Created: latency-svc-n6vbm
  I0419 17:34:06.067385 14 service_latency.go:363] Got endpoints: latency-svc-9lhbv [752.224201ms]
  E0419 17:34:06.078832      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:34:06.092445 14 service_latency.go:356] Created: latency-svc-qnzht
  I0419 17:34:06.117785 14 service_latency.go:363] Got endpoints: latency-svc-h5n98 [750.74696ms]
  I0419 17:34:06.143415 14 service_latency.go:356] Created: latency-svc-8crmw
  I0419 17:34:06.164290 14 service_latency.go:363] Got endpoints: latency-svc-9hcx7 [749.609652ms]
  I0419 17:34:06.182106 14 service_latency.go:356] Created: latency-svc-z4szz
  I0419 17:34:06.214068 14 service_latency.go:363] Got endpoints: latency-svc-tzhbx [744.599956ms]
  I0419 17:34:06.236840 14 service_latency.go:356] Created: latency-svc-gz7km
  I0419 17:34:06.266503 14 service_latency.go:363] Got endpoints: latency-svc-xzjsn [753.331658ms]
  I0419 17:34:06.290258 14 service_latency.go:356] Created: latency-svc-p88l5
  I0419 17:34:06.317446 14 service_latency.go:363] Got endpoints: latency-svc-dfwhf [749.024927ms]
  I0419 17:34:06.335969 14 service_latency.go:356] Created: latency-svc-cc6gw
  I0419 17:34:06.368663 14 service_latency.go:363] Got endpoints: latency-svc-wvhxg [754.003692ms]
  I0419 17:34:06.387260 14 service_latency.go:356] Created: latency-svc-t45mr
  I0419 17:34:06.413311 14 service_latency.go:363] Got endpoints: latency-svc-znjtp [750.581425ms]
  I0419 17:34:06.429942 14 service_latency.go:356] Created: latency-svc-282c6
  I0419 17:34:06.465514 14 service_latency.go:363] Got endpoints: latency-svc-r9shc [748.243356ms]
  I0419 17:34:06.480397 14 service_latency.go:356] Created: latency-svc-kztq6
  I0419 17:34:06.517448 14 service_latency.go:363] Got endpoints: latency-svc-9lgh4 [750.807255ms]
  I0419 17:34:06.542369 14 service_latency.go:356] Created: latency-svc-hz7rl
  I0419 17:34:06.565517 14 service_latency.go:363] Got endpoints: latency-svc-g9f6t [745.830549ms]
  I0419 17:34:06.594022 14 service_latency.go:356] Created: latency-svc-9k4zv
  I0419 17:34:06.617365 14 service_latency.go:363] Got endpoints: latency-svc-zz6jx [749.204182ms]
  I0419 17:34:06.635826 14 service_latency.go:356] Created: latency-svc-blsv6
  I0419 17:34:06.668788 14 service_latency.go:363] Got endpoints: latency-svc-wbbpr [750.509676ms]
  I0419 17:34:06.694238 14 service_latency.go:356] Created: latency-svc-s4zkc
  I0419 17:34:06.717569 14 service_latency.go:363] Got endpoints: latency-svc-trb2n [747.482192ms]
  I0419 17:34:06.752425 14 service_latency.go:356] Created: latency-svc-c4l9m
  I0419 17:34:06.769420 14 service_latency.go:363] Got endpoints: latency-svc-n6vbm [753.088435ms]
  I0419 17:34:06.783702 14 service_latency.go:356] Created: latency-svc-9sqhs
  I0419 17:34:06.815661 14 service_latency.go:363] Got endpoints: latency-svc-qnzht [747.9218ms]
  I0419 17:34:06.833925 14 service_latency.go:356] Created: latency-svc-q4kgr
  I0419 17:34:06.862811 14 service_latency.go:363] Got endpoints: latency-svc-8crmw [744.869912ms]
  I0419 17:34:06.885103 14 service_latency.go:356] Created: latency-svc-9d92b
  I0419 17:34:06.914202 14 service_latency.go:363] Got endpoints: latency-svc-z4szz [749.726489ms]
  I0419 17:34:06.930197 14 service_latency.go:356] Created: latency-svc-26l7d
  I0419 17:34:06.964343 14 service_latency.go:363] Got endpoints: latency-svc-gz7km [750.131327ms]
  I0419 17:34:06.989754 14 service_latency.go:356] Created: latency-svc-x47qk
  I0419 17:34:07.014935 14 service_latency.go:363] Got endpoints: latency-svc-p88l5 [747.774541ms]
  I0419 17:34:07.035883 14 service_latency.go:356] Created: latency-svc-h8b2m
  I0419 17:34:07.063163 14 service_latency.go:363] Got endpoints: latency-svc-cc6gw [745.589392ms]
  E0419 17:34:07.079152      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:34:07.082437 14 service_latency.go:356] Created: latency-svc-zqkqb
  I0419 17:34:07.117713 14 service_latency.go:363] Got endpoints: latency-svc-t45mr [748.903232ms]
  I0419 17:34:07.141097 14 service_latency.go:356] Created: latency-svc-rbdzs
  I0419 17:34:07.164716 14 service_latency.go:363] Got endpoints: latency-svc-282c6 [751.141721ms]
  I0419 17:34:07.187289 14 service_latency.go:356] Created: latency-svc-6t74b
  I0419 17:34:07.215777 14 service_latency.go:363] Got endpoints: latency-svc-kztq6 [750.155291ms]
  I0419 17:34:07.235470 14 service_latency.go:356] Created: latency-svc-nx8df
  I0419 17:34:07.266460 14 service_latency.go:363] Got endpoints: latency-svc-hz7rl [748.797757ms]
  I0419 17:34:07.295642 14 service_latency.go:356] Created: latency-svc-v4fkj
  I0419 17:34:07.315422 14 service_latency.go:363] Got endpoints: latency-svc-9k4zv [749.505581ms]
  I0419 17:34:07.334536 14 service_latency.go:356] Created: latency-svc-7rdmz
  I0419 17:34:07.366865 14 service_latency.go:363] Got endpoints: latency-svc-blsv6 [748.289557ms]
  I0419 17:34:07.382945 14 service_latency.go:356] Created: latency-svc-85zbw
  I0419 17:34:07.414734 14 service_latency.go:363] Got endpoints: latency-svc-s4zkc [744.750211ms]
  I0419 17:34:07.432788 14 service_latency.go:356] Created: latency-svc-hgdzv
  I0419 17:34:07.465527 14 service_latency.go:363] Got endpoints: latency-svc-c4l9m [747.817099ms]
  I0419 17:34:07.489591 14 service_latency.go:356] Created: latency-svc-2dhc9
  I0419 17:34:07.517122 14 service_latency.go:363] Got endpoints: latency-svc-9sqhs [747.11804ms]
  I0419 17:34:07.537415 14 service_latency.go:356] Created: latency-svc-5r9qk
  I0419 17:34:07.565700 14 service_latency.go:363] Got endpoints: latency-svc-q4kgr [749.881073ms]
  I0419 17:34:07.586327 14 service_latency.go:356] Created: latency-svc-5g746
  I0419 17:34:07.615167 14 service_latency.go:363] Got endpoints: latency-svc-9d92b [752.205629ms]
  I0419 17:34:07.634186 14 service_latency.go:356] Created: latency-svc-gdwhn
  I0419 17:34:07.665330 14 service_latency.go:363] Got endpoints: latency-svc-26l7d [750.336823ms]
  I0419 17:34:07.681621 14 service_latency.go:356] Created: latency-svc-p9dg7
  I0419 17:34:07.716261 14 service_latency.go:363] Got endpoints: latency-svc-x47qk [751.428107ms]
  I0419 17:34:07.735474 14 service_latency.go:356] Created: latency-svc-h6wnc
  I0419 17:34:07.765415 14 service_latency.go:363] Got endpoints: latency-svc-h8b2m [750.121207ms]
  I0419 17:34:07.786274 14 service_latency.go:356] Created: latency-svc-c2fkn
  I0419 17:34:07.826798 14 service_latency.go:363] Got endpoints: latency-svc-zqkqb [763.150577ms]
  I0419 17:34:07.866338 14 service_latency.go:363] Got endpoints: latency-svc-rbdzs [748.141608ms]
  I0419 17:34:07.869426 14 service_latency.go:356] Created: latency-svc-hvqdq
  I0419 17:34:07.889512 14 service_latency.go:356] Created: latency-svc-frlk7
  I0419 17:34:07.915586 14 service_latency.go:363] Got endpoints: latency-svc-6t74b [750.746597ms]
  I0419 17:34:07.933398 14 service_latency.go:356] Created: latency-svc-blvx8
  I0419 17:34:07.973650 14 service_latency.go:363] Got endpoints: latency-svc-nx8df [757.484812ms]
  I0419 17:34:08.001396 14 service_latency.go:356] Created: latency-svc-mkmfh
  I0419 17:34:08.017209 14 service_latency.go:363] Got endpoints: latency-svc-v4fkj [750.613582ms]
  I0419 17:34:08.041444 14 service_latency.go:356] Created: latency-svc-hrvr4
  I0419 17:34:08.066295 14 service_latency.go:363] Got endpoints: latency-svc-7rdmz [750.801726ms]
  E0419 17:34:08.080250      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:34:08.083277 14 service_latency.go:356] Created: latency-svc-vnzxq
  I0419 17:34:08.118179 14 service_latency.go:363] Got endpoints: latency-svc-85zbw [751.148306ms]
  I0419 17:34:08.134669 14 service_latency.go:356] Created: latency-svc-kn8gx
  I0419 17:34:08.165220 14 service_latency.go:363] Got endpoints: latency-svc-hgdzv [750.102142ms]
  I0419 17:34:08.181939 14 service_latency.go:356] Created: latency-svc-bgb89
  I0419 17:34:08.219595 14 service_latency.go:363] Got endpoints: latency-svc-2dhc9 [753.941346ms]
  I0419 17:34:08.238203 14 service_latency.go:356] Created: latency-svc-bs7ht
  I0419 17:34:08.264678 14 service_latency.go:363] Got endpoints: latency-svc-5r9qk [747.345437ms]
  I0419 17:34:08.318771 14 service_latency.go:363] Got endpoints: latency-svc-5g746 [752.625179ms]
  I0419 17:34:08.368123 14 service_latency.go:363] Got endpoints: latency-svc-gdwhn [752.507588ms]
  I0419 17:34:08.416725 14 service_latency.go:363] Got endpoints: latency-svc-p9dg7 [751.278911ms]
  I0419 17:34:08.466061 14 service_latency.go:363] Got endpoints: latency-svc-h6wnc [749.642309ms]
  I0419 17:34:08.520398 14 service_latency.go:363] Got endpoints: latency-svc-c2fkn [754.805298ms]
  I0419 17:34:08.570065 14 service_latency.go:363] Got endpoints: latency-svc-hvqdq [742.884556ms]
  I0419 17:34:08.614164 14 service_latency.go:363] Got endpoints: latency-svc-frlk7 [747.70208ms]
  I0419 17:34:08.669008 14 service_latency.go:363] Got endpoints: latency-svc-blvx8 [753.276329ms]
  I0419 17:34:08.719824 14 service_latency.go:363] Got endpoints: latency-svc-mkmfh [745.506833ms]
  I0419 17:34:08.772038 14 service_latency.go:363] Got endpoints: latency-svc-hrvr4 [754.663594ms]
  I0419 17:34:08.817119 14 service_latency.go:363] Got endpoints: latency-svc-vnzxq [750.416194ms]
  I0419 17:34:08.876954 14 service_latency.go:363] Got endpoints: latency-svc-kn8gx [757.76802ms]
  I0419 17:34:08.914251 14 service_latency.go:363] Got endpoints: latency-svc-bgb89 [748.571085ms]
  I0419 17:34:08.965488 14 service_latency.go:363] Got endpoints: latency-svc-bs7ht [745.440321ms]
  I0419 17:34:08.965835 14 service_latency.go:114] Latencies: [47.204102ms 147.275612ms 151.969121ms 162.722473ms 177.582886ms 188.28048ms 192.019361ms 194.842361ms 197.034735ms 210.932506ms 226.525895ms 231.246206ms 240.966856ms 241.823854ms 248.257265ms 255.852324ms 258.316001ms 259.495455ms 266.494548ms 279.004424ms 288.482235ms 289.932255ms 290.070197ms 322.52503ms 325.272876ms 325.971709ms 326.736576ms 341.088611ms 344.569399ms 347.023798ms 351.221006ms 370.292553ms 375.061311ms 375.916016ms 377.260168ms 378.00966ms 387.406466ms 392.906497ms 397.966026ms 398.04132ms 398.363375ms 404.330976ms 409.352656ms 428.745066ms 448.089667ms 451.323879ms 457.044551ms 457.890939ms 458.722783ms 464.888476ms 478.633482ms 478.915187ms 498.087816ms 521.208636ms 536.339871ms 536.42513ms 539.884472ms 546.95372ms 556.888561ms 557.368737ms 558.250369ms 563.454702ms 587.296582ms 619.388029ms 668.818036ms 676.280145ms 707.653745ms 742.326469ms 742.437986ms 742.793703ms 742.884556ms 743.521904ms 743.880742ms 744.367893ms 744.550473ms 744.599956ms 744.696948ms 744.724681ms 744.750211ms 744.869912ms 745.440321ms 745.475967ms 745.495035ms 745.506833ms 745.51019ms 745.589392ms 745.67873ms 745.830549ms 746.165909ms 746.211471ms 746.389321ms 746.977686ms 747.105465ms 747.11804ms 747.131126ms 747.270473ms 747.345437ms 747.345798ms 747.482192ms 747.70208ms 747.756218ms 747.774541ms 747.817099ms 747.9218ms 748.141608ms 748.144507ms 748.166869ms 748.243356ms 748.2473ms 748.289557ms 748.550361ms 748.571085ms 748.681315ms 748.797757ms 748.804657ms 748.903232ms 748.906692ms 749.024927ms 749.108009ms 749.204182ms 749.248803ms 749.265872ms 749.363122ms 749.505581ms 749.609652ms 749.642309ms 749.701613ms 749.704477ms 749.726489ms 749.738704ms 749.881073ms 750.049345ms 750.102142ms 750.107082ms 750.121207ms 750.131327ms 750.155291ms 750.213789ms 750.241294ms 750.269353ms 750.30464ms 750.336823ms 750.343793ms 750.416194ms 750.461522ms 750.498999ms 750.509622ms 750.509676ms 750.522323ms 750.581425ms 750.613582ms 750.67606ms 750.746597ms 750.74696ms 750.801726ms 750.807255ms 750.896735ms 750.921194ms 750.967955ms 751.141721ms 751.148306ms 751.235772ms 751.252779ms 751.278911ms 751.420204ms 751.428107ms 751.436936ms 751.52949ms 751.545463ms 751.58986ms 751.851048ms 751.924701ms 752.188012ms 752.205629ms 752.224201ms 752.36975ms 752.507588ms 752.625179ms 752.82182ms 752.935574ms 753.088435ms 753.127366ms 753.152951ms 753.276329ms 753.331658ms 753.391582ms 753.499951ms 753.587191ms 753.941346ms 754.003692ms 754.106068ms 754.387035ms 754.637907ms 754.663594ms 754.805298ms 754.964478ms 757.484812ms 757.76802ms 763.150577ms 798.14775ms]
  I0419 17:34:08.966096 14 service_latency.go:118] 50 %ile: 747.756218ms
  I0419 17:34:08.966129 14 service_latency.go:119] 90 %ile: 753.088435ms
  I0419 17:34:08.966152 14 service_latency.go:120] 99 %ile: 763.150577ms
  I0419 17:34:08.966295 14 service_latency.go:121] Total sample count: 200
  I0419 17:34:08.966498 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svc-latency-7311" for this suite. @ 04/19/24 17:34:08.981
• [10.987 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:234
  STEP: Creating a kubernetes client @ 04/19/24 17:34:08.997
  I0419 17:34:08.997587 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename resourcequota @ 04/19/24 17:34:09.004
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:34:09.043
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:34:09.051
  STEP: Counting existing ResourceQuota @ 04/19/24 17:34:09.061
  E0419 17:34:09.080800      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:10.081729      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:11.082864      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:12.082790      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:13.083391      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 04/19/24 17:34:14.075
  E0419 17:34:14.084312      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota status is calculated @ 04/19/24 17:34:14.09
  E0419 17:34:15.084402      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:16.085140      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Pod that fits quota @ 04/19/24 17:34:16.096
  STEP: Ensuring ResourceQuota status captures the pod usage @ 04/19/24 17:34:16.126
  E0419 17:34:17.085737      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:18.086023      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Not allowing a pod to be created that exceeds remaining quota @ 04/19/24 17:34:18.143
  STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) @ 04/19/24 17:34:18.153
  STEP: Ensuring a pod cannot update its resource requirements @ 04/19/24 17:34:18.163
  STEP: Ensuring attempts to update pod resource requirements did not change quota usage @ 04/19/24 17:34:18.173
  E0419 17:34:19.087216      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:20.087439      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 04/19/24 17:34:20.183
  STEP: Ensuring resource quota status released the pod usage @ 04/19/24 17:34:20.201
  E0419 17:34:21.087579      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:22.087787      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:34:22.209527 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3682" for this suite. @ 04/19/24 17:34:22.218
• [13.229 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
k8s.io/kubernetes/test/e2e/node/taints.go:450
  STEP: Creating a kubernetes client @ 04/19/24 17:34:22.237
  I0419 17:34:22.237334 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename taint-multiple-pods @ 04/19/24 17:34:22.24
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:34:22.263
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:34:22.268
  I0419 17:34:22.275800 14 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0419 17:34:23.088481      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:24.088808      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:25.095964      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:26.096092      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:27.098841      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:28.098278      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:29.098383      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:30.098840      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:31.099729      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:32.100312      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:33.100515      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:34.101423      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:35.101259      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:36.101598      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:37.102479      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:38.102845      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:39.103418      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:40.103838      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:41.104071      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:42.104842      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:43.105728      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:44.106160      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:45.106549      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:46.106673      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:47.107485      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:48.107677      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:49.108034      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:50.108524      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:51.109493      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:52.109882      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:53.110201      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:54.110626      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:55.111062      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:56.111846      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:57.113102      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:58.113818      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:59.113766      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:00.114135      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:01.114463      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:02.115003      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:03.115542      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:04.115791      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:05.115983      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:06.116731      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:07.117322      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:08.117470      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:09.117943      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:10.118800      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:11.119379      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:12.119725      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:13.120402      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:14.120698      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:15.121313      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:16.122520      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:17.123471      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:18.123604      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:19.124718      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:20.124925      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:21.125350      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:22.126342      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:35:22.277592 14 util.go:400] Waiting for terminating namespaces to be deleted...
  I0419 17:35:22.285479 14 taints.go:150] Starting informer...
  STEP: Starting pods... @ 04/19/24 17:35:22.286
  I0419 17:35:22.543477 14 taints.go:469] Pod1 is running on eipo9quoh3ef-3. Tainting Node
  E0419 17:35:23.127295      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:24.127699      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:35:24.791958 14 taints.go:477] Pod2 is running on eipo9quoh3ef-3. Tainting Node
  STEP: Trying to apply a taint on the Node @ 04/19/24 17:35:24.792
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 04/19/24 17:35:24.823
  STEP: Waiting for Pod1 and Pod2 to be deleted @ 04/19/24 17:35:24.836
  E0419 17:35:25.128264      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:26.129105      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:27.129808      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:28.129962      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:29.130255      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:30.131011      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:35:30.931294 14 taints.go:498] Noticed Pod "taint-eviction-b1" gets evicted.
  E0419 17:35:31.132099      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:32.132389      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:33.132971      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:34.133173      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:35.133505      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:36.133738      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:37.134023      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:38.134045      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:39.134430      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:40.134697      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:41.134997      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:42.135447      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:43.135937      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:44.136205      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:45.136488      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:46.136746      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:47.137894      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:48.138313      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:49.138616      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:50.139168      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:35:51.041834 14 taints.go:498] Noticed Pod "taint-eviction-b2" gets evicted.
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 04/19/24 17:35:51.072
  I0419 17:35:51.084532 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-multiple-pods-4916" for this suite. @ 04/19/24 17:35:51.104
• [88.889 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:882
  STEP: Creating a kubernetes client @ 04/19/24 17:35:51.128
  I0419 17:35:51.128782 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename kubectl @ 04/19/24 17:35:51.146
  E0419 17:35:51.152693      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:35:51.181
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:35:51.187
  STEP: validating api versions @ 04/19/24 17:35:51.193
  I0419 17:35:51.194160 14 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257402342 --namespace=kubectl-4775 api-versions'
  I0419 17:35:51.387352 14 builder.go:146] stderr: ""
  I0419 17:35:51.387486 14 builder.go:147] stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta3\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nv1\n"
  I0419 17:35:51.387668 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4775" for this suite. @ 04/19/24 17:35:51.401
• [0.294 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:183
  STEP: Creating a kubernetes client @ 04/19/24 17:35:51.423
  I0419 17:35:51.423451 14 util.go:506] >>> kubeConfig: /tmp/kubeconfig-257402342
  STEP: Building a namespace api object, basename kubelet-test @ 04/19/24 17:35:51.43
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:35:51.464
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:35:51.469
  E0419 17:35:52.142517      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:53.142799      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:35:53.586270 14 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-4031" for this suite. @ 04/19/24 17:35:53.6
• [2.191 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[SynchronizedAfterSuite] 
k8s.io/kubernetes/test/e2e/e2e.go:80
  I0419 17:35:53.638841 14 suites.go:34] Running AfterSuite actions on node 1
  I0419 17:35:53.639011 14 util.go:614] Skipping dumping logs from cluster
[SynchronizedAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
k8s.io/kubernetes/test/e2e/e2e_test.go:161
[ReportAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
k8s.io/kubernetes/test/e2e/framework/test_context.go:612
[ReportAfterSuite] PASSED [0.171 seconds]
------------------------------

Ran 402 of 7197 Specs in 6645.067 seconds
SUCCESS! -- 402 Passed | 0 Failed | 0 Pending | 6795 Skipped
PASS

Ginkgo ran 1 suite in 1h50m47.463047408s
Test Suite Passed
