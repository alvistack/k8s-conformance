  I0419 15:42:12.839046      13 e2e.go:117] Starting e2e run "12150ae6-21c8-4ad4-878b-2f85707d31fb" on Ginkgo node 1
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1713541331 - will randomize all specs

Will run 388 of 7407 specs
------------------------------
[ReportBeforeSuite] 
k8s.io/kubernetes/test/e2e/e2e_test.go:157
[ReportBeforeSuite] PASSED [0.000 seconds]
------------------------------
[SynchronizedBeforeSuite] 
k8s.io/kubernetes/test/e2e/e2e.go:77
  Apr 19 15:42:13.321: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 15:42:13.329: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
  Apr 19 15:42:13.410: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
  Apr 19 15:42:13.419: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds' (0 seconds elapsed)
  Apr 19 15:42:13.420: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
  Apr 19 15:42:13.420: INFO: e2e test version: v1.29.4
  Apr 19 15:42:13.422: INFO: kube-apiserver version: v1.29.4
  Apr 19 15:42:13.423: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 15:42:13.437: INFO: Cluster IP family: ipv4
[SynchronizedBeforeSuite] PASSED [0.117 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:69
  STEP: Creating a kubernetes client @ 04/19/24 15:42:13.772
  Apr 19 15:42:13.772: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/19/24 15:42:13.775
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:42:13.804
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:42:13.808
  Apr 19 15:42:13.816: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: kubectl validation (kubectl create and apply) allows request with known and required properties @ 04/19/24 15:42:15.995
  Apr 19 15:42:15.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=crd-publish-openapi-5555 --namespace=crd-publish-openapi-5555 create -f -'
  Apr 19 15:42:16.478: INFO: stderr: ""
  Apr 19 15:42:16.478: INFO: stdout: "e2e-test-crd-publish-openapi-953-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  Apr 19 15:42:16.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=crd-publish-openapi-5555 --namespace=crd-publish-openapi-5555 delete e2e-test-crd-publish-openapi-953-crds test-foo'
  Apr 19 15:42:16.752: INFO: stderr: ""
  Apr 19 15:42:16.752: INFO: stdout: "e2e-test-crd-publish-openapi-953-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  Apr 19 15:42:16.753: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=crd-publish-openapi-5555 --namespace=crd-publish-openapi-5555 apply -f -'
  Apr 19 15:42:16.960: INFO: stderr: ""
  Apr 19 15:42:16.960: INFO: stdout: "e2e-test-crd-publish-openapi-953-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  Apr 19 15:42:16.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=crd-publish-openapi-5555 --namespace=crd-publish-openapi-5555 delete e2e-test-crd-publish-openapi-953-crds test-foo'
  Apr 19 15:42:17.149: INFO: stderr: ""
  Apr 19 15:42:17.149: INFO: stdout: "e2e-test-crd-publish-openapi-953-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values @ 04/19/24 15:42:17.149
  Apr 19 15:42:17.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=crd-publish-openapi-5555 --namespace=crd-publish-openapi-5555 create -f -'
  Apr 19 15:42:17.340: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema @ 04/19/24 15:42:17.341
  Apr 19 15:42:17.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=crd-publish-openapi-5555 --namespace=crd-publish-openapi-5555 create -f -'
  Apr 19 15:42:17.500: INFO: rc: 1
  Apr 19 15:42:17.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=crd-publish-openapi-5555 --namespace=crd-publish-openapi-5555 apply -f -'
  Apr 19 15:42:17.680: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request without required properties @ 04/19/24 15:42:17.68
  Apr 19 15:42:17.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=crd-publish-openapi-5555 --namespace=crd-publish-openapi-5555 create -f -'
  Apr 19 15:42:17.820: INFO: rc: 1
  Apr 19 15:42:17.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=crd-publish-openapi-5555 --namespace=crd-publish-openapi-5555 apply -f -'
  Apr 19 15:42:17.999: INFO: rc: 1
  STEP: kubectl explain works to explain CR properties @ 04/19/24 15:42:17.999
  Apr 19 15:42:18.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=crd-publish-openapi-5555 explain e2e-test-crd-publish-openapi-953-crds'
  Apr 19 15:42:18.162: INFO: stderr: ""
  Apr 19 15:42:18.163: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-953-crd\nVERSION:    v1\n\nDESCRIPTION:\n    Foo CRD for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Foo\n\n  status\t<Object>\n    Status of Foo\n\n\n"
  STEP: kubectl explain works to explain CR properties recursively @ 04/19/24 15:42:18.163
  Apr 19 15:42:18.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=crd-publish-openapi-5555 explain e2e-test-crd-publish-openapi-953-crds.metadata'
  Apr 19 15:42:18.308: INFO: stderr: ""
  Apr 19 15:42:18.308: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-953-crd\nVERSION:    v1\n\nFIELD: metadata <ObjectMeta>\n\nDESCRIPTION:\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n    ObjectMeta is metadata that all persisted resources must have, which\n    includes all objects users must create.\n    \nFIELDS:\n  annotations\t<map[string]string>\n    Annotations is an unstructured key value map stored with a resource that may\n    be set by external tools to store and retrieve arbitrary metadata. They are\n    not queryable and should be preserved when modifying objects. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations\n\n  creationTimestamp\t<string>\n    CreationTimestamp is a timestamp representing the server time when this\n    object was created. It is not guaranteed to be set in happens-before order\n    across separate operations. Clients may not set this value. It is\n    represented in RFC3339 form and is in UTC.\n    \n    Populated by the system. Read-only. Null for lists. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  deletionGracePeriodSeconds\t<integer>\n    Number of seconds allowed for this object to gracefully terminate before it\n    will be removed from the system. Only set when deletionTimestamp is also\n    set. May only be shortened. Read-only.\n\n  deletionTimestamp\t<string>\n    DeletionTimestamp is RFC 3339 date and time at which this resource will be\n    deleted. This field is set by the server when a graceful deletion is\n    requested by the user, and is not directly settable by a client. The\n    resource is expected to be deleted (no longer visible from resource lists,\n    and not reachable by name) after the time in this field, once the finalizers\n    list is empty. As long as the finalizers list contains items, deletion is\n    blocked. Once the deletionTimestamp is set, this value may not be unset or\n    be set further into the future, although it may be shortened or the resource\n    may be deleted prior to this time. For example, a user may request that a\n    pod is deleted in 30 seconds. The Kubelet will react by sending a graceful\n    termination signal to the containers in the pod. After that 30 seconds, the\n    Kubelet will send a hard termination signal (SIGKILL) to the container and\n    after cleanup, remove the pod from the API. In the presence of network\n    partitions, this object may still exist after this timestamp, until an\n    administrator or automated process can determine the resource is fully\n    terminated. If not set, graceful deletion of the object has not been\n    requested.\n    \n    Populated by the system when a graceful deletion is requested. Read-only.\n    More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  finalizers\t<[]string>\n    Must be empty before the object is deleted from the registry. Each entry is\n    an identifier for the responsible component that will remove the entry from\n    the list. If the deletionTimestamp of the object is non-nil, entries in this\n    list can only be removed. Finalizers may be processed and removed in any\n    order.  Order is NOT enforced because it introduces significant risk of\n    stuck finalizers. finalizers is a shared field, any actor with permission\n    can reorder it. If the finalizer list is processed in order, then this can\n    lead to a situation in which the component responsible for the first\n    finalizer in the list is waiting for a signal (field value, external system,\n    or other) produced by a component responsible for a finalizer later in the\n    list, resulting in a deadlock. Without enforced ordering finalizers are free\n    to order amongst themselves and are not vulnerable to ordering changes in\n    the list.\n\n  generateName\t<string>\n    GenerateName is an optional prefix, used by the server, to generate a unique\n    name ONLY IF the Name field has not been provided. If this field is used,\n    the name returned to the client will be different than the name passed. This\n    value will also be combined with a unique suffix. The provided value has the\n    same validation rules as the Name field, and may be truncated by the length\n    of the suffix required to make the value unique on the server.\n    \n    If this field is specified and the generated name exists, the server will\n    return a 409.\n    \n    Applied only if Name is not specified. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n  generation\t<integer>\n    A sequence number representing a specific generation of the desired state.\n    Populated by the system. Read-only.\n\n  labels\t<map[string]string>\n    Map of string keys and values that can be used to organize and categorize\n    (scope and select) objects. May match selectors of replication controllers\n    and services. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\n\n  managedFields\t<[]ManagedFieldsEntry>\n    ManagedFields maps workflow-id and version to the set of fields that are\n    managed by that workflow. This is mostly for internal housekeeping, and\n    users typically shouldn't need to set or understand this field. A workflow\n    can be the user's name, a controller's name, or the name of a specific apply\n    path like \"ci-cd\". The set of fields is always in the version that the\n    workflow used when modifying the object.\n\n  name\t<string>\n    Name must be unique within a namespace. Is required when creating resources,\n    although some resources may allow a client to request the generation of an\n    appropriate name automatically. Name is primarily intended for creation\n    idempotence and configuration definition. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#names\n\n  namespace\t<string>\n    Namespace defines the space within which each name must be unique. An empty\n    namespace is equivalent to the \"default\" namespace, but \"default\" is the\n    canonical representation. Not all objects are required to be scoped to a\n    namespace - the value of this field for those objects will be empty.\n    \n    Must be a DNS_LABEL. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces\n\n  ownerReferences\t<[]OwnerReference>\n    List of objects depended by this object. If ALL objects in the list have\n    been deleted, this object will be garbage collected. If this object is\n    managed by a controller, then an entry in this list will point to this\n    controller, with the controller field set to true. There cannot be more than\n    one managing controller.\n\n  resourceVersion\t<string>\n    An opaque value that represents the internal version of this object that can\n    be used by clients to determine when objects have changed. May be used for\n    optimistic concurrency, change detection, and the watch operation on a\n    resource or set of resources. Clients must treat these values as opaque and\n    passed unmodified back to the server. They may only be valid for a\n    particular resource or set of resources.\n    \n    Populated by the system. Read-only. Value must be treated as opaque by\n    clients and . More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n  selfLink\t<string>\n    Deprecated: selfLink is a legacy read-only field that is no longer populated\n    by the system.\n\n  uid\t<string>\n    UID is the unique in time and space value for this object. It is typically\n    generated by the server on successful creation of a resource and is not\n    allowed to change on PUT operations.\n    \n    Populated by the system. Read-only. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#uids\n\n\n"
  Apr 19 15:42:18.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=crd-publish-openapi-5555 explain e2e-test-crd-publish-openapi-953-crds.spec'
  Apr 19 15:42:18.467: INFO: stderr: ""
  Apr 19 15:42:18.467: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-953-crd\nVERSION:    v1\n\nFIELD: spec <Object>\n\nDESCRIPTION:\n    Specification of Foo\n    \nFIELDS:\n  bars\t<[]Object>\n    List of Bars and their specs.\n\n\n"
  Apr 19 15:42:18.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=crd-publish-openapi-5555 explain e2e-test-crd-publish-openapi-953-crds.spec.bars'
  Apr 19 15:42:18.638: INFO: stderr: ""
  Apr 19 15:42:18.638: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-953-crd\nVERSION:    v1\n\nFIELD: bars <[]Object>\n\nDESCRIPTION:\n    List of Bars and their specs.\n    \nFIELDS:\n  age\t<string>\n    Age of Bar.\n\n  bazs\t<[]string>\n    List of Bazs.\n\n  feeling\t<string>\n    Whether Bar is feeling great.\n\n  name\t<string> -required-\n    Name of Bar.\n\n\n"
  STEP: kubectl explain works to return error when explain is called on property that doesn't exist @ 04/19/24 15:42:18.639
  Apr 19 15:42:18.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=crd-publish-openapi-5555 explain e2e-test-crd-publish-openapi-953-crds.spec.bars2'
  Apr 19 15:42:18.784: INFO: rc: 1
  Apr 19 15:42:20.813: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-5555" for this suite. @ 04/19/24 15:42:20.841
• [7.087 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve a basic endpoint from pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:785
  STEP: Creating a kubernetes client @ 04/19/24 15:42:20.861
  Apr 19 15:42:20.861: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename services @ 04/19/24 15:42:20.867
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:42:20.906
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:42:20.916
  STEP: creating service endpoint-test2 in namespace services-6993 @ 04/19/24 15:42:20.929
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6993 to expose endpoints map[] @ 04/19/24 15:42:20.96
  Apr 19 15:42:20.973: INFO: Failed go get Endpoints object: endpoints "endpoint-test2" not found
  Apr 19 15:42:21.996: INFO: successfully validated that service endpoint-test2 in namespace services-6993 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-6993 @ 04/19/24 15:42:21.997
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6993 to expose endpoints map[pod1:[80]] @ 04/19/24 15:42:32.095
  Apr 19 15:42:32.127: INFO: successfully validated that service endpoint-test2 in namespace services-6993 exposes endpoints map[pod1:[80]]
  STEP: Checking if the Service forwards traffic to pod1 @ 04/19/24 15:42:32.127
  Apr 19 15:42:32.128: INFO: Creating new exec pod
  Apr 19 15:42:35.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-6993 exec execpodpp5qp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Apr 19 15:42:35.537: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Apr 19 15:42:35.537: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 15:42:35.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-6993 exec execpodpp5qp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.31.81 80'
  Apr 19 15:42:35.843: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.31.81 80\nConnection to 10.233.31.81 80 port [tcp/http] succeeded!\n"
  Apr 19 15:42:35.843: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Creating pod pod2 in namespace services-6993 @ 04/19/24 15:42:35.843
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6993 to expose endpoints map[pod1:[80] pod2:[80]] @ 04/19/24 15:42:51.978
  Apr 19 15:42:52.025: INFO: successfully validated that service endpoint-test2 in namespace services-6993 exposes endpoints map[pod1:[80] pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod1 and pod2 @ 04/19/24 15:42:52.026
  Apr 19 15:42:53.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-6993 exec execpodpp5qp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Apr 19 15:42:53.372: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Apr 19 15:42:53.372: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 15:42:53.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-6993 exec execpodpp5qp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.31.81 80'
  Apr 19 15:42:53.668: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.31.81 80\nConnection to 10.233.31.81 80 port [tcp/http] succeeded!\n"
  Apr 19 15:42:53.668: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-6993 @ 04/19/24 15:42:53.669
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6993 to expose endpoints map[pod2:[80]] @ 04/19/24 15:42:53.699
  Apr 19 15:42:53.753: INFO: successfully validated that service endpoint-test2 in namespace services-6993 exposes endpoints map[pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod2 @ 04/19/24 15:42:53.753
  Apr 19 15:42:54.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-6993 exec execpodpp5qp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Apr 19 15:42:55.109: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Apr 19 15:42:55.111: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 15:42:55.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-6993 exec execpodpp5qp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.31.81 80'
  Apr 19 15:42:55.368: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.31.81 80\nConnection to 10.233.31.81 80 port [tcp/http] succeeded!\n"
  Apr 19 15:42:55.368: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod2 in namespace services-6993 @ 04/19/24 15:42:55.368
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6993 to expose endpoints map[] @ 04/19/24 15:42:55.42
  Apr 19 15:42:55.445: INFO: successfully validated that service endpoint-test2 in namespace services-6993 exposes endpoints map[]
  Apr 19 15:42:55.482: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6993" for this suite. @ 04/19/24 15:42:55.49
• [34.643 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2177
  STEP: Creating a kubernetes client @ 04/19/24 15:42:55.507
  Apr 19 15:42:55.507: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename services @ 04/19/24 15:42:55.511
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:42:55.57
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:42:55.581
  STEP: creating service in namespace services-9872 @ 04/19/24 15:42:55.589
  STEP: creating service affinity-clusterip in namespace services-9872 @ 04/19/24 15:42:55.59
  STEP: creating replication controller affinity-clusterip in namespace services-9872 @ 04/19/24 15:42:55.617
  I0419 15:42:55.633414      13 runners.go:197] Created replication controller with name: affinity-clusterip, namespace: services-9872, replica count: 3
  I0419 15:42:58.686443      13 runners.go:197] affinity-clusterip Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0419 15:43:01.698123      13 runners.go:197] affinity-clusterip Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0419 15:43:04.701643      13 runners.go:197] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 19 15:43:04.730: INFO: Creating new exec pod
  Apr 19 15:43:07.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-9872 exec execpod-affinitycnqjv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
  Apr 19 15:43:08.166: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
  Apr 19 15:43:08.167: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 15:43:08.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-9872 exec execpod-affinitycnqjv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.29.205 80'
  Apr 19 15:43:08.471: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.29.205 80\nConnection to 10.233.29.205 80 port [tcp/http] succeeded!\n"
  Apr 19 15:43:08.471: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 15:43:08.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-9872 exec execpod-affinitycnqjv -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.29.205:80/ ; done'
  Apr 19 15:43:08.970: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.205:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.205:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.205:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.205:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.205:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.205:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.205:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.205:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.205:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.205:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.205:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.205:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.205:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.205:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.205:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.205:80/\n"
  Apr 19 15:43:08.970: INFO: stdout: "\naffinity-clusterip-4rsvd\naffinity-clusterip-4rsvd\naffinity-clusterip-4rsvd\naffinity-clusterip-4rsvd\naffinity-clusterip-4rsvd\naffinity-clusterip-4rsvd\naffinity-clusterip-4rsvd\naffinity-clusterip-4rsvd\naffinity-clusterip-4rsvd\naffinity-clusterip-4rsvd\naffinity-clusterip-4rsvd\naffinity-clusterip-4rsvd\naffinity-clusterip-4rsvd\naffinity-clusterip-4rsvd\naffinity-clusterip-4rsvd\naffinity-clusterip-4rsvd"
  Apr 19 15:43:08.970: INFO: Received response from host: affinity-clusterip-4rsvd
  Apr 19 15:43:08.970: INFO: Received response from host: affinity-clusterip-4rsvd
  Apr 19 15:43:08.970: INFO: Received response from host: affinity-clusterip-4rsvd
  Apr 19 15:43:08.970: INFO: Received response from host: affinity-clusterip-4rsvd
  Apr 19 15:43:08.970: INFO: Received response from host: affinity-clusterip-4rsvd
  Apr 19 15:43:08.970: INFO: Received response from host: affinity-clusterip-4rsvd
  Apr 19 15:43:08.970: INFO: Received response from host: affinity-clusterip-4rsvd
  Apr 19 15:43:08.970: INFO: Received response from host: affinity-clusterip-4rsvd
  Apr 19 15:43:08.970: INFO: Received response from host: affinity-clusterip-4rsvd
  Apr 19 15:43:08.971: INFO: Received response from host: affinity-clusterip-4rsvd
  Apr 19 15:43:08.971: INFO: Received response from host: affinity-clusterip-4rsvd
  Apr 19 15:43:08.971: INFO: Received response from host: affinity-clusterip-4rsvd
  Apr 19 15:43:08.971: INFO: Received response from host: affinity-clusterip-4rsvd
  Apr 19 15:43:08.971: INFO: Received response from host: affinity-clusterip-4rsvd
  Apr 19 15:43:08.971: INFO: Received response from host: affinity-clusterip-4rsvd
  Apr 19 15:43:08.971: INFO: Received response from host: affinity-clusterip-4rsvd
  Apr 19 15:43:08.971: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip in namespace services-9872, will wait for the garbage collector to delete the pods @ 04/19/24 15:43:08.992
  Apr 19 15:43:09.068: INFO: Deleting ReplicationController affinity-clusterip took: 19.784349ms
  Apr 19 15:43:09.170: INFO: Terminating ReplicationController affinity-clusterip pods took: 101.732156ms
  Apr 19 15:43:12.421: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9872" for this suite. @ 04/19/24 15:43:12.436
• [16.944 seconds]
------------------------------
SS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:90
  STEP: Creating a kubernetes client @ 04/19/24 15:43:12.455
  Apr 19 15:43:12.456: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename configmap @ 04/19/24 15:43:12.46
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:43:12.486
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:43:12.491
  STEP: Creating configMap with name configmap-test-volume-map-d306af8a-1f7a-4e56-a7a8-54beef688dae @ 04/19/24 15:43:12.496
  STEP: Creating a pod to test consume configMaps @ 04/19/24 15:43:12.505
  STEP: Saw pod success @ 04/19/24 15:43:16.551
  Apr 19 15:43:16.562: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-configmaps-549637ec-7a08-413e-b91f-288df866b6f6 container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/24 15:43:16.614
  Apr 19 15:43:16.650: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-963" for this suite. @ 04/19/24 15:43:16.662
• [4.229 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:99
  STEP: Creating a kubernetes client @ 04/19/24 15:43:16.7
  Apr 19 15:43:16.701: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename secrets @ 04/19/24 15:43:16.707
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:43:16.737
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:43:16.744
  STEP: Creating secret with name secret-test-5d679097-73b5-4093-b6cd-0a209b635220 @ 04/19/24 15:43:16.79
  STEP: Creating a pod to test consume secrets @ 04/19/24 15:43:16.799
  STEP: Saw pod success @ 04/19/24 15:43:20.847
  Apr 19 15:43:20.854: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-secrets-3ae86044-97c7-41bf-b70b-7384df51a33f container secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/24 15:43:20.882
  Apr 19 15:43:20.928: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9760" for this suite. @ 04/19/24 15:43:20.939
  STEP: Destroying namespace "secret-namespace-3037" for this suite. @ 04/19/24 15:43:20.955
• [4.271 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:285
  STEP: Creating a kubernetes client @ 04/19/24 15:43:20.972
  Apr 19 15:43:20.972: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename webhook @ 04/19/24 15:43:20.976
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:43:20.999
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:43:21.009
  STEP: Setting up server cert @ 04/19/24 15:43:21.064
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 15:43:22.512
  STEP: Deploying the webhook pod @ 04/19/24 15:43:22.54
  STEP: Wait for the deployment to be ready @ 04/19/24 15:43:22.568
  Apr 19 15:43:22.626: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/19/24 15:43:24.655
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 15:43:24.687
  Apr 19 15:43:25.689: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 19 15:43:25.706: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2653-crds.webhook.example.com via the AdmissionRegistration API @ 04/19/24 15:43:26.227
  Apr 19 15:43:26.324: INFO: Waiting for webhook configuration to be ready...
  STEP: Creating a custom resource that should be mutated by the webhook @ 04/19/24 15:43:26.448
  Apr 19 15:43:29.161: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4603" for this suite. @ 04/19/24 15:43:29.174
  STEP: Destroying namespace "webhook-markers-7606" for this suite. @ 04/19/24 15:43:29.193
• [8.235 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] Job should delete a job [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:627
  STEP: Creating a kubernetes client @ 04/19/24 15:43:29.208
  Apr 19 15:43:29.209: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename job @ 04/19/24 15:43:29.212
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:43:29.246
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:43:29.251
  STEP: Creating a job @ 04/19/24 15:43:29.259
  STEP: Ensuring active pods == parallelism @ 04/19/24 15:43:29.283
  STEP: delete a job @ 04/19/24 15:43:31.296
  STEP: deleting Job.batch foo in namespace job-2503, will wait for the garbage collector to delete the pods @ 04/19/24 15:43:31.296
  Apr 19 15:43:31.374: INFO: Deleting Job.batch foo took: 16.885579ms
  Apr 19 15:43:31.475: INFO: Terminating Job.batch foo pods took: 101.183062ms
  STEP: Ensuring job was deleted @ 04/19/24 15:43:34.177
  Apr 19 15:43:34.184: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-2503" for this suite. @ 04/19/24 15:43:34.194
• [5.004 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:86
  STEP: Creating a kubernetes client @ 04/19/24 15:43:34.216
  Apr 19 15:43:34.216: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename replication-controller @ 04/19/24 15:43:34.22
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:43:34.258
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:43:34.262
  Apr 19 15:43:34.268: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
  STEP: Creating rc "condition-test" that asks for more than the allowed pod quota @ 04/19/24 15:43:35.298
  STEP: Checking rc "condition-test" has the desired failure condition set @ 04/19/24 15:43:35.312
  STEP: Scaling down rc "condition-test" to satisfy pod quota @ 04/19/24 15:43:36.333
  Apr 19 15:43:36.357: INFO: Updating replication controller "condition-test"
  STEP: Checking rc "condition-test" has no failure condition set @ 04/19/24 15:43:36.357
  Apr 19 15:43:36.374: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-3084" for this suite. @ 04/19/24 15:43:36.389
• [2.187 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:530
  STEP: Creating a kubernetes client @ 04/19/24 15:43:36.405
  Apr 19 15:43:36.406: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename security-context-test @ 04/19/24 15:43:36.409
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:43:36.442
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:43:36.447
  Apr 19 15:43:52.600: INFO: Got logs for pod "busybox-privileged-false-48d07f7c-bd8d-4ef6-b097-ed9f3bf67d97": "ip: RTNETLINK answers: Operation not permitted\n"
  Apr 19 15:43:52.605: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-2146" for this suite. @ 04/19/24 15:43:52.625
• [16.242 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:160
  STEP: Creating a kubernetes client @ 04/19/24 15:43:52.659
  Apr 19 15:43:52.659: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename emptydir @ 04/19/24 15:43:52.666
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:43:52.711
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:43:52.719
  STEP: Creating a pod to test emptydir volume type on node default medium @ 04/19/24 15:43:52.732
  STEP: Saw pod success @ 04/19/24 15:43:56.788
  Apr 19 15:43:56.797: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-6bd71a63-d205-492f-9728-9cc3b9c66ba6 container test-container: <nil>
  STEP: delete the pod @ 04/19/24 15:43:56.809
  Apr 19 15:43:56.840: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5831" for this suite. @ 04/19/24 15:43:56.852
• [4.208 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should replace a pod template [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:177
  STEP: Creating a kubernetes client @ 04/19/24 15:43:56.868
  Apr 19 15:43:56.868: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename podtemplate @ 04/19/24 15:43:56.871
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:43:56.894
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:43:56.899
  STEP: Create a pod template @ 04/19/24 15:43:56.907
  STEP: Replace a pod template @ 04/19/24 15:43:56.923
  Apr 19 15:43:56.943: INFO: Found updated podtemplate annotation: "true"

  Apr 19 15:43:56.944: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-2117" for this suite. @ 04/19/24 15:43:56.955
• [0.098 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:75
  STEP: Creating a kubernetes client @ 04/19/24 15:43:56.968
  Apr 19 15:43:56.968: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename configmap @ 04/19/24 15:43:56.973
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:43:56.997
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:43:57.003
  STEP: Creating configMap with name configmap-test-volume-b8cd6683-a6ac-4335-9992-db8eb9bd56e9 @ 04/19/24 15:43:57.009
  STEP: Creating a pod to test consume configMaps @ 04/19/24 15:43:57.016
  STEP: Saw pod success @ 04/19/24 15:44:01.063
  Apr 19 15:44:01.073: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-configmaps-4806ff47-ebe0-43b1-ad90-f6ab88320337 container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/24 15:44:01.098
  Apr 19 15:44:01.136: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-237" for this suite. @ 04/19/24 15:44:01.148
• [4.197 seconds]
------------------------------
[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:115
  STEP: Creating a kubernetes client @ 04/19/24 15:44:01.165
  Apr 19 15:44:01.165: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename var-expansion @ 04/19/24 15:44:01.169
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:44:01.203
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:44:01.219
  STEP: Creating a pod to test substitution in volume subpath @ 04/19/24 15:44:01.232
  STEP: Saw pod success @ 04/19/24 15:44:05.285
  Apr 19 15:44:05.294: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod var-expansion-7f83ff90-3709-4344-8c21-e76bd3c71282 container dapi-container: <nil>
  STEP: delete the pod @ 04/19/24 15:44:05.311
  Apr 19 15:44:05.372: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-9826" for this suite. @ 04/19/24 15:44:05.386
• [4.236 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:125
  STEP: Creating a kubernetes client @ 04/19/24 15:44:05.404
  Apr 19 15:44:05.405: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename configmap @ 04/19/24 15:44:05.41
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:44:05.448
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:44:05.454
  STEP: Creating configMap with name configmap-test-upd-84377941-a69c-4ce7-bc69-05991c34fd65 @ 04/19/24 15:44:05.474
  STEP: Creating the pod @ 04/19/24 15:44:05.484
  STEP: Updating configmap configmap-test-upd-84377941-a69c-4ce7-bc69-05991c34fd65 @ 04/19/24 15:44:07.578
  STEP: waiting to observe update in volume @ 04/19/24 15:44:07.598
  Apr 19 15:45:22.552: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8209" for this suite. @ 04/19/24 15:45:22.588
• [77.203 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:68
  STEP: Creating a kubernetes client @ 04/19/24 15:45:22.608
  Apr 19 15:45:22.608: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename secrets @ 04/19/24 15:45:22.614
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:45:22.649
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:45:22.654
  STEP: Creating secret with name secret-test-38f945d0-ebdf-42cc-a7cb-e1145ae25ffd @ 04/19/24 15:45:22.661
  STEP: Creating a pod to test consume secrets @ 04/19/24 15:45:22.677
  STEP: Saw pod success @ 04/19/24 15:45:26.732
  Apr 19 15:45:26.745: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-secrets-7b422eba-8b6f-4508-b606-ff13d5a56d5d container secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/24 15:45:26.767
  Apr 19 15:45:26.815: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9584" for this suite. @ 04/19/24 15:45:26.839
• [4.251 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:330
  STEP: Creating a kubernetes client @ 04/19/24 15:45:26.878
  Apr 19 15:45:26.878: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename resourcequota @ 04/19/24 15:45:26.883
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:45:26.921
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:45:26.936
  STEP: Counting existing ResourceQuota @ 04/19/24 15:45:43.959
  STEP: Creating a ResourceQuota @ 04/19/24 15:45:48.968
  STEP: Ensuring resource quota status is calculated @ 04/19/24 15:45:48.984
  STEP: Creating a ConfigMap @ 04/19/24 15:45:50.996
  STEP: Ensuring resource quota status captures configMap creation @ 04/19/24 15:45:51.027
  STEP: Deleting a ConfigMap @ 04/19/24 15:45:53.038
  STEP: Ensuring resource quota status released usage @ 04/19/24 15:45:53.051
  Apr 19 15:45:55.062: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-7787" for this suite. @ 04/19/24 15:45:55.081
• [28.220 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:646
  STEP: Creating a kubernetes client @ 04/19/24 15:45:55.099
  Apr 19 15:45:55.099: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename webhook @ 04/19/24 15:45:55.104
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:45:55.183
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:45:55.189
  STEP: Setting up server cert @ 04/19/24 15:45:55.242
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 15:45:56.237
  STEP: Deploying the webhook pod @ 04/19/24 15:45:56.251
  STEP: Wait for the deployment to be ready @ 04/19/24 15:45:56.267
  Apr 19 15:45:56.281: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 04/19/24 15:45:58.309
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 15:45:58.339
  Apr 19 15:45:59.341: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 04/19/24 15:45:59.484
  STEP: Creating a configMap that should be mutated @ 04/19/24 15:45:59.521
  STEP: Deleting the collection of validation webhooks @ 04/19/24 15:45:59.594
  STEP: Creating a configMap that should not be mutated @ 04/19/24 15:45:59.699
  Apr 19 15:45:59.796: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2780" for this suite. @ 04/19/24 15:45:59.804
  STEP: Destroying namespace "webhook-markers-9218" for this suite. @ 04/19/24 15:45:59.815
• [4.729 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:96
  STEP: Creating a kubernetes client @ 04/19/24 15:45:59.829
  Apr 19 15:45:59.829: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename secrets @ 04/19/24 15:45:59.832
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:45:59.853
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:45:59.857
  STEP: creating secret secrets-5767/secret-test-3159c3b4-20a4-4c0c-bf02-0849b04dfdbd @ 04/19/24 15:45:59.862
  STEP: Creating a pod to test consume secrets @ 04/19/24 15:45:59.869
  STEP: Saw pod success @ 04/19/24 15:46:03.929
  Apr 19 15:46:03.939: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-configmaps-3a2bf373-3925-4bc1-b2e6-66c560731208 container env-test: <nil>
  STEP: delete the pod @ 04/19/24 15:46:03.962
  Apr 19 15:46:04.004: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-5767" for this suite. @ 04/19/24 15:46:04.018
• [4.217 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services should serve multiport endpoints from pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:846
  STEP: Creating a kubernetes client @ 04/19/24 15:46:04.049
  Apr 19 15:46:04.049: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename services @ 04/19/24 15:46:04.053
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:46:04.095
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:46:04.103
  STEP: creating service multi-endpoint-test in namespace services-5867 @ 04/19/24 15:46:04.112
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5867 to expose endpoints map[] @ 04/19/24 15:46:04.14
  Apr 19 15:46:04.161: INFO: successfully validated that service multi-endpoint-test in namespace services-5867 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-5867 @ 04/19/24 15:46:04.162
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5867 to expose endpoints map[pod1:[100]] @ 04/19/24 15:46:06.201
  Apr 19 15:46:06.228: INFO: successfully validated that service multi-endpoint-test in namespace services-5867 exposes endpoints map[pod1:[100]]
  STEP: Creating pod pod2 in namespace services-5867 @ 04/19/24 15:46:06.228
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5867 to expose endpoints map[pod1:[100] pod2:[101]] @ 04/19/24 15:46:08.268
  Apr 19 15:46:08.307: INFO: successfully validated that service multi-endpoint-test in namespace services-5867 exposes endpoints map[pod1:[100] pod2:[101]]
  STEP: Checking if the Service forwards traffic to pods @ 04/19/24 15:46:08.308
  Apr 19 15:46:08.308: INFO: Creating new exec pod
  Apr 19 15:46:11.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-5867 exec execpodhg8c6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
  Apr 19 15:46:11.703: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
  Apr 19 15:46:11.703: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 15:46:11.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-5867 exec execpodhg8c6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.47.60 80'
  Apr 19 15:46:11.988: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.47.60 80\nConnection to 10.233.47.60 80 port [tcp/http] succeeded!\n"
  Apr 19 15:46:11.988: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 15:46:11.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-5867 exec execpodhg8c6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
  Apr 19 15:46:12.303: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
  Apr 19 15:46:12.303: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 15:46:12.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-5867 exec execpodhg8c6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.47.60 81'
  Apr 19 15:46:12.573: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.47.60 81\nConnection to 10.233.47.60 81 port [tcp/*] succeeded!\n"
  Apr 19 15:46:12.573: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-5867 @ 04/19/24 15:46:12.573
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5867 to expose endpoints map[pod2:[101]] @ 04/19/24 15:46:12.615
  Apr 19 15:46:12.647: INFO: successfully validated that service multi-endpoint-test in namespace services-5867 exposes endpoints map[pod2:[101]]
  STEP: Deleting pod pod2 in namespace services-5867 @ 04/19/24 15:46:12.648
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5867 to expose endpoints map[] @ 04/19/24 15:46:12.698
  Apr 19 15:46:13.785: INFO: successfully validated that service multi-endpoint-test in namespace services-5867 exposes endpoints map[]
  Apr 19 15:46:13.825: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5867" for this suite. @ 04/19/24 15:46:13.836
• [9.804 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:113
  STEP: Creating a kubernetes client @ 04/19/24 15:46:13.867
  Apr 19 15:46:13.867: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename replication-controller @ 04/19/24 15:46:13.871
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:46:13.9
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:46:13.903
  STEP: creating a ReplicationController @ 04/19/24 15:46:13.925
  STEP: waiting for RC to be added @ 04/19/24 15:46:13.936
  STEP: waiting for available Replicas @ 04/19/24 15:46:13.936
  STEP: patching ReplicationController @ 04/19/24 15:46:19.183
  STEP: waiting for RC to be modified @ 04/19/24 15:46:19.203
  STEP: patching ReplicationController status @ 04/19/24 15:46:19.203
  STEP: waiting for RC to be modified @ 04/19/24 15:46:19.219
  STEP: waiting for available Replicas @ 04/19/24 15:46:19.219
  STEP: fetching ReplicationController status @ 04/19/24 15:46:19.223
  STEP: patching ReplicationController scale @ 04/19/24 15:46:19.232
  STEP: waiting for RC to be modified @ 04/19/24 15:46:19.243
  STEP: waiting for ReplicationController's scale to be the max amount @ 04/19/24 15:46:19.244
  STEP: fetching ReplicationController; ensuring that it's patched @ 04/19/24 15:46:23.757
  STEP: updating ReplicationController status @ 04/19/24 15:46:23.766
  STEP: waiting for RC to be modified @ 04/19/24 15:46:23.783
  STEP: listing all ReplicationControllers @ 04/19/24 15:46:23.785
  STEP: checking that ReplicationController has expected values @ 04/19/24 15:46:23.793
  STEP: deleting ReplicationControllers by collection @ 04/19/24 15:46:23.793
  STEP: waiting for ReplicationController to have a DELETED watchEvent @ 04/19/24 15:46:23.815
  Apr 19 15:46:23.911: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0419 15:46:23.912635      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "replication-controller-882" for this suite. @ 04/19/24 15:46:23.919
• [10.071 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:191
  STEP: Creating a kubernetes client @ 04/19/24 15:46:23.941
  Apr 19 15:46:23.942: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename runtimeclass @ 04/19/24 15:46:23.945
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:46:23.978
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:46:23.984
  STEP: getting /apis @ 04/19/24 15:46:23.99
  STEP: getting /apis/node.k8s.io @ 04/19/24 15:46:24.001
  STEP: getting /apis/node.k8s.io/v1 @ 04/19/24 15:46:24.003
  STEP: creating @ 04/19/24 15:46:24.006
  STEP: watching @ 04/19/24 15:46:24.041
  Apr 19 15:46:24.041: INFO: starting watch
  STEP: getting @ 04/19/24 15:46:24.055
  STEP: listing @ 04/19/24 15:46:24.064
  STEP: patching @ 04/19/24 15:46:24.071
  STEP: updating @ 04/19/24 15:46:24.084
  Apr 19 15:46:24.097: INFO: waiting for watch events with expected annotations
  STEP: deleting @ 04/19/24 15:46:24.098
  STEP: deleting a collection @ 04/19/24 15:46:24.127
  Apr 19 15:46:24.157: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-3553" for this suite. @ 04/19/24 15:46:24.167
• [0.241 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:164
  STEP: Creating a kubernetes client @ 04/19/24 15:46:24.186
  Apr 19 15:46:24.186: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename projected @ 04/19/24 15:46:24.19
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:46:24.214
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:46:24.219
  STEP: Creating the pod @ 04/19/24 15:46:24.225
  E0419 15:46:24.913207      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:25.914464      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:46:26.820: INFO: Successfully updated pod "annotationupdate313a2089-4c36-405d-9565-791209eb0693"
  E0419 15:46:26.915212      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:27.916366      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:46:28.864: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1424" for this suite. @ 04/19/24 15:46:28.876
• [4.706 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance] [sig-architecture, Conformance]
k8s.io/kubernetes/test/e2e/architecture/conformance.go:39
  STEP: Creating a kubernetes client @ 04/19/24 15:46:28.892
  Apr 19 15:46:28.892: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename conformance-tests @ 04/19/24 15:46:28.895
  E0419 15:46:28.916691      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:46:28.986
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:46:28.993
  STEP: Getting node addresses @ 04/19/24 15:46:29
  Apr 19 15:46:29.000: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  Apr 19 15:46:29.014: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "conformance-tests-5325" for this suite. @ 04/19/24 15:46:29.025
• [0.148 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:94
  STEP: Creating a kubernetes client @ 04/19/24 15:46:29.041
  Apr 19 15:46:29.041: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename configmap @ 04/19/24 15:46:29.044
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:46:29.07
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:46:29.076
  STEP: Creating configMap configmap-7504/configmap-test-d1531ab1-3e96-4a02-99f8-2d324a6aa870 @ 04/19/24 15:46:29.083
  STEP: Creating a pod to test consume configMaps @ 04/19/24 15:46:29.091
  E0419 15:46:29.917035      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:30.917793      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:31.918497      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:32.919470      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 15:46:33.149
  Apr 19 15:46:33.159: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-configmaps-f414838b-c8bb-4444-afbf-bfcaac908c14 container env-test: <nil>
  STEP: delete the pod @ 04/19/24 15:46:33.187
  Apr 19 15:46:33.235: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-7504" for this suite. @ 04/19/24 15:46:33.25
• [4.235 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
k8s.io/kubernetes/test/e2e/node/taints.go:290
  STEP: Creating a kubernetes client @ 04/19/24 15:46:33.277
  Apr 19 15:46:33.277: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename taint-single-pod @ 04/19/24 15:46:33.28
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:46:33.35
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:46:33.356
  Apr 19 15:46:33.361: INFO: Waiting up to 1m0s for all nodes to be ready
  E0419 15:46:33.919784      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:34.920524      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:35.921294      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:36.921765      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:37.921592      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:38.922453      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:39.922773      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:40.923416      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:41.923653      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:42.924048      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:43.925531      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:44.925228      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:45.925870      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:46.925982      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:47.928422      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:48.927235      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:49.927499      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:50.927926      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:51.928247      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:52.928775      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:53.929262      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:54.929429      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:55.930428      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:56.931454      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:57.934105      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:58.932957      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:46:59.933614      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:00.934564      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:01.935882      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:02.936710      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:03.937114      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:04.937337      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:05.938403      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:06.939412      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:07.939832      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:08.940772      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:09.941800      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:10.942463      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:11.943567      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:12.943895      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:13.944342      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:14.944646      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:15.944960      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:16.945991      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:17.947511      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:18.947416      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:19.947875      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:20.948142      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:21.948445      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:22.949711      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:23.950193      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:24.950508      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:25.953596      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:26.952414      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:27.952848      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:28.953035      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:29.953311      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:30.964278      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:31.954889      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:32.955051      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:47:33.363: INFO: Waiting for terminating namespaces to be deleted...
  Apr 19 15:47:33.373: INFO: Starting informer...
  STEP: Starting pod... @ 04/19/24 15:47:33.373
  Apr 19 15:47:33.615: INFO: Pod is running on co4fe9zoo9oc-3. Tainting Node
  STEP: Trying to apply a taint on the Node @ 04/19/24 15:47:33.616
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 04/19/24 15:47:33.666
  STEP: Waiting short time to make sure Pod is queued for deletion @ 04/19/24 15:47:33.678
  Apr 19 15:47:33.678: INFO: Pod wasn't evicted. Proceeding
  Apr 19 15:47:33.678: INFO: Removing taint from Node
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 04/19/24 15:47:33.726
  STEP: Waiting some time to make sure that toleration time passed. @ 04/19/24 15:47:33.738
  E0419 15:47:33.956127      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:34.958247      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:35.957045      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:36.957793      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:37.958587      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:38.959491      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:39.959878      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:40.960293      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:41.960695      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:42.960778      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:43.961158      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:44.961261      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:45.961593      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:46.961917      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:47.962938      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:48.963079      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:49.963462      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:50.963802      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:51.964255      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:52.964633      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:53.965013      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:54.966210      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:55.966758      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:56.967324      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:57.968448      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:58.969010      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:47:59.969567      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:00.970163      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:01.970997      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:02.972144      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:03.972743      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:04.973039      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:05.974084      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:06.974663      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:07.975488      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:08.976139      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:09.976766      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:10.977083      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:11.977450      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:12.977421      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:13.977978      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:14.978199      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:15.978856      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:16.979870      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:17.980870      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:18.981446      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:19.984103      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:20.983962      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:21.984761      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:22.985562      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:23.986171      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:24.986657      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:25.987238      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:26.988055      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:27.989026      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:28.989703      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:29.989879      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:30.990140      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:31.990531      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:32.991550      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:33.992105      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:34.992782      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:35.993004      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:36.996081      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:37.993920      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:38.994361      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:39.994636      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:40.995090      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:41.995422      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:42.995911      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:43.996193      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:44.996336      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:45.996718      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:46.996949      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:47.997802      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:48:48.739: INFO: Pod wasn't evicted. Test successful
  Apr 19 15:48:48.739: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-single-pod-4443" for this suite. @ 04/19/24 15:48:48.76
• [135.505 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:69
  STEP: Creating a kubernetes client @ 04/19/24 15:48:48.783
  Apr 19 15:48:48.783: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename endpointslice @ 04/19/24 15:48:48.787
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:48:48.821
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:48:48.828
  Apr 19 15:48:48.856: INFO: Endpoints addresses: [192.168.121.127 192.168.121.39] , ports: [6443]
  Apr 19 15:48:48.856: INFO: EndpointSlices addresses: [192.168.121.127 192.168.121.39] , ports: [6443]
  Apr 19 15:48:48.857: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-424" for this suite. @ 04/19/24 15:48:48.867
• [0.098 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Environment:NotInUserNS] [Conformance] [sig-node, NodeConformance, Environment:NotInUserNS, Conformance]
k8s.io/kubernetes/test/e2e/common/node/sysctl.go:79
  STEP: Creating a kubernetes client @ 04/19/24 15:48:48.881
  Apr 19 15:48:48.881: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename sysctl @ 04/19/24 15:48:48.884
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:48:48.907
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:48:48.916
  STEP: Creating a pod with the kernel.shm_rmid_forced sysctl @ 04/19/24 15:48:48.925
  STEP: Watching for error events or started pod @ 04/19/24 15:48:48.95
  E0419 15:48:48.998740      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:49.998778      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for pod completion @ 04/19/24 15:48:50.967
  E0419 15:48:50.999889      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:51.999472      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:52.999489      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Checking that the pod succeeded @ 04/19/24 15:48:53
  STEP: Getting logs from the pod @ 04/19/24 15:48:53
  STEP: Checking that the sysctl is actually updated @ 04/19/24 15:48:53.032
  Apr 19 15:48:53.032: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-5544" for this suite. @ 04/19/24 15:48:53.041
• [4.173 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:714
  STEP: Creating a kubernetes client @ 04/19/24 15:48:53.067
  Apr 19 15:48:53.067: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename gc @ 04/19/24 15:48:53.071
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:48:53.099
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:48:53.107
  STEP: create the rc1 @ 04/19/24 15:48:53.12
  STEP: create the rc2 @ 04/19/24 15:48:53.133
  E0419 15:48:53.999953      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:55.001090      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:56.001695      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:57.001822      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:58.001934      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:48:59.002549      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well @ 04/19/24 15:48:59.181
  E0419 15:49:00.003276      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc simpletest-rc-to-be-deleted @ 04/19/24 15:49:00.642
  STEP: wait for the rc to be deleted @ 04/19/24 15:49:00.653
  E0419 15:49:01.003621      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:02.004315      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:03.005261      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:04.005769      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:05.006564      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:49:05.793: INFO: 71 pods remaining
  Apr 19 15:49:05.794: INFO: 69 pods has nil DeletionTimestamp
  Apr 19 15:49:05.794: INFO: 
  E0419 15:49:06.008241      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:07.010651      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:08.008517      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:09.009407      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:10.009991      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 04/19/24 15:49:10.674
  Apr 19 15:49:10.956: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 19 15:49:10.957: INFO: Deleting pod "simpletest-rc-to-be-deleted-29nqj" in namespace "gc-3727"
  Apr 19 15:49:10.974: INFO: Deleting pod "simpletest-rc-to-be-deleted-2m4qf" in namespace "gc-3727"
  Apr 19 15:49:11.006: INFO: Deleting pod "simpletest-rc-to-be-deleted-2wmm8" in namespace "gc-3727"
  E0419 15:49:11.010458      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:49:11.045: INFO: Deleting pod "simpletest-rc-to-be-deleted-47f46" in namespace "gc-3727"
  Apr 19 15:49:11.074: INFO: Deleting pod "simpletest-rc-to-be-deleted-4d4sk" in namespace "gc-3727"
  Apr 19 15:49:11.100: INFO: Deleting pod "simpletest-rc-to-be-deleted-4r6xg" in namespace "gc-3727"
  Apr 19 15:49:11.134: INFO: Deleting pod "simpletest-rc-to-be-deleted-5hnh8" in namespace "gc-3727"
  Apr 19 15:49:11.204: INFO: Deleting pod "simpletest-rc-to-be-deleted-5ls5f" in namespace "gc-3727"
  Apr 19 15:49:11.243: INFO: Deleting pod "simpletest-rc-to-be-deleted-5ps5z" in namespace "gc-3727"
  Apr 19 15:49:11.270: INFO: Deleting pod "simpletest-rc-to-be-deleted-5q44n" in namespace "gc-3727"
  Apr 19 15:49:11.307: INFO: Deleting pod "simpletest-rc-to-be-deleted-5vp2z" in namespace "gc-3727"
  Apr 19 15:49:11.339: INFO: Deleting pod "simpletest-rc-to-be-deleted-5xxvm" in namespace "gc-3727"
  Apr 19 15:49:11.379: INFO: Deleting pod "simpletest-rc-to-be-deleted-6bqnz" in namespace "gc-3727"
  Apr 19 15:49:11.471: INFO: Deleting pod "simpletest-rc-to-be-deleted-6kcxw" in namespace "gc-3727"
  Apr 19 15:49:11.539: INFO: Deleting pod "simpletest-rc-to-be-deleted-7gx6f" in namespace "gc-3727"
  Apr 19 15:49:11.591: INFO: Deleting pod "simpletest-rc-to-be-deleted-7scbh" in namespace "gc-3727"
  Apr 19 15:49:11.675: INFO: Deleting pod "simpletest-rc-to-be-deleted-8qvk7" in namespace "gc-3727"
  Apr 19 15:49:11.843: INFO: Deleting pod "simpletest-rc-to-be-deleted-8w2bt" in namespace "gc-3727"
  Apr 19 15:49:11.873: INFO: Deleting pod "simpletest-rc-to-be-deleted-98zkv" in namespace "gc-3727"
  Apr 19 15:49:11.968: INFO: Deleting pod "simpletest-rc-to-be-deleted-9c77p" in namespace "gc-3727"
  E0419 15:49:12.010595      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:49:12.035: INFO: Deleting pod "simpletest-rc-to-be-deleted-9hlkd" in namespace "gc-3727"
  Apr 19 15:49:12.092: INFO: Deleting pod "simpletest-rc-to-be-deleted-9mlx6" in namespace "gc-3727"
  Apr 19 15:49:12.128: INFO: Deleting pod "simpletest-rc-to-be-deleted-9qtkv" in namespace "gc-3727"
  Apr 19 15:49:12.173: INFO: Deleting pod "simpletest-rc-to-be-deleted-9sk85" in namespace "gc-3727"
  Apr 19 15:49:12.208: INFO: Deleting pod "simpletest-rc-to-be-deleted-9vk4q" in namespace "gc-3727"
  Apr 19 15:49:12.238: INFO: Deleting pod "simpletest-rc-to-be-deleted-9wr7f" in namespace "gc-3727"
  Apr 19 15:49:12.268: INFO: Deleting pod "simpletest-rc-to-be-deleted-b8hlj" in namespace "gc-3727"
  Apr 19 15:49:12.330: INFO: Deleting pod "simpletest-rc-to-be-deleted-bjwf7" in namespace "gc-3727"
  Apr 19 15:49:12.360: INFO: Deleting pod "simpletest-rc-to-be-deleted-bnw4b" in namespace "gc-3727"
  Apr 19 15:49:12.393: INFO: Deleting pod "simpletest-rc-to-be-deleted-br9nj" in namespace "gc-3727"
  Apr 19 15:49:12.432: INFO: Deleting pod "simpletest-rc-to-be-deleted-bssnn" in namespace "gc-3727"
  Apr 19 15:49:12.458: INFO: Deleting pod "simpletest-rc-to-be-deleted-c4dhj" in namespace "gc-3727"
  Apr 19 15:49:12.515: INFO: Deleting pod "simpletest-rc-to-be-deleted-c7qv6" in namespace "gc-3727"
  Apr 19 15:49:12.584: INFO: Deleting pod "simpletest-rc-to-be-deleted-cfdct" in namespace "gc-3727"
  Apr 19 15:49:12.619: INFO: Deleting pod "simpletest-rc-to-be-deleted-cr7hn" in namespace "gc-3727"
  Apr 19 15:49:12.653: INFO: Deleting pod "simpletest-rc-to-be-deleted-ct5jx" in namespace "gc-3727"
  Apr 19 15:49:12.684: INFO: Deleting pod "simpletest-rc-to-be-deleted-d2q8z" in namespace "gc-3727"
  Apr 19 15:49:12.720: INFO: Deleting pod "simpletest-rc-to-be-deleted-d625w" in namespace "gc-3727"
  Apr 19 15:49:12.747: INFO: Deleting pod "simpletest-rc-to-be-deleted-d7cr2" in namespace "gc-3727"
  Apr 19 15:49:12.820: INFO: Deleting pod "simpletest-rc-to-be-deleted-d92cv" in namespace "gc-3727"
  Apr 19 15:49:12.842: INFO: Deleting pod "simpletest-rc-to-be-deleted-dbskh" in namespace "gc-3727"
  Apr 19 15:49:12.866: INFO: Deleting pod "simpletest-rc-to-be-deleted-dxk67" in namespace "gc-3727"
  Apr 19 15:49:12.903: INFO: Deleting pod "simpletest-rc-to-be-deleted-f5tj2" in namespace "gc-3727"
  Apr 19 15:49:12.977: INFO: Deleting pod "simpletest-rc-to-be-deleted-f8jqd" in namespace "gc-3727"
  E0419 15:49:13.011269      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:49:13.018: INFO: Deleting pod "simpletest-rc-to-be-deleted-fhds7" in namespace "gc-3727"
  Apr 19 15:49:13.060: INFO: Deleting pod "simpletest-rc-to-be-deleted-fm4rd" in namespace "gc-3727"
  Apr 19 15:49:13.086: INFO: Deleting pod "simpletest-rc-to-be-deleted-fmpww" in namespace "gc-3727"
  Apr 19 15:49:13.128: INFO: Deleting pod "simpletest-rc-to-be-deleted-g5h6v" in namespace "gc-3727"
  Apr 19 15:49:13.173: INFO: Deleting pod "simpletest-rc-to-be-deleted-gbxwp" in namespace "gc-3727"
  Apr 19 15:49:13.212: INFO: Deleting pod "simpletest-rc-to-be-deleted-gdft4" in namespace "gc-3727"
  Apr 19 15:49:13.320: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-3727" for this suite. @ 04/19/24 15:49:13.366
• [20.510 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:79
  STEP: Creating a kubernetes client @ 04/19/24 15:49:13.579
  Apr 19 15:49:13.580: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename subpath @ 04/19/24 15:49:13.584
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:49:13.71
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:49:13.714
  STEP: Setting up data @ 04/19/24 15:49:13.717
  STEP: Creating pod pod-subpath-test-configmap-84wg @ 04/19/24 15:49:13.761
  STEP: Creating a pod to test atomic-volume-subpath @ 04/19/24 15:49:13.761
  E0419 15:49:14.012213      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:15.012365      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:16.013108      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:17.014229      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:18.014690      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:19.015087      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:20.015025      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:21.016195      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:22.017033      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:23.017786      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:24.018336      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:25.018802      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:26.019206      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:27.020597      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:28.020869      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:29.021778      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:30.021854      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:31.022566      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:32.023154      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:33.023981      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:34.024903      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:35.028740      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:36.028317      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:37.028778      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 15:49:37.985
  Apr 19 15:49:37.995: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-subpath-test-configmap-84wg container test-container-subpath-configmap-84wg: <nil>
  STEP: delete the pod @ 04/19/24 15:49:38.018
  E0419 15:49:38.030703      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting pod pod-subpath-test-configmap-84wg @ 04/19/24 15:49:38.061
  Apr 19 15:49:38.061: INFO: Deleting pod "pod-subpath-test-configmap-84wg" in namespace "subpath-1028"
  Apr 19 15:49:38.072: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-1028" for this suite. @ 04/19/24 15:49:38.084
• [24.525 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1416
  STEP: Creating a kubernetes client @ 04/19/24 15:49:38.108
  Apr 19 15:49:38.108: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename services @ 04/19/24 15:49:38.114
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:49:38.161
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:49:38.167
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-5983 @ 04/19/24 15:49:38.171
  STEP: changing the ExternalName service to type=ClusterIP @ 04/19/24 15:49:38.183
  STEP: creating replication controller externalname-service in namespace services-5983 @ 04/19/24 15:49:38.207
  I0419 15:49:38.224015      13 runners.go:197] Created replication controller with name: externalname-service, namespace: services-5983, replica count: 2
  E0419 15:49:39.030602      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:40.030905      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:41.031421      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 15:49:41.275190      13 runners.go:197] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 19 15:49:41.275: INFO: Creating new exec pod
  E0419 15:49:42.031569      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:43.032627      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:44.033009      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:49:44.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-5983 exec execpod4tp5d -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Apr 19 15:49:44.668: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Apr 19 15:49:44.668: INFO: stdout: ""
  E0419 15:49:45.033660      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:49:45.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-5983 exec execpod4tp5d -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Apr 19 15:49:45.651: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Apr 19 15:49:45.651: INFO: stdout: "externalname-service-gkpft"
  Apr 19 15:49:45.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-5983 exec execpod4tp5d -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.19.23 80'
  Apr 19 15:49:45.921: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.19.23 80\nConnection to 10.233.19.23 80 port [tcp/http] succeeded!\n"
  Apr 19 15:49:45.921: INFO: stdout: ""
  E0419 15:49:46.033923      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:49:46.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-5983 exec execpod4tp5d -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.19.23 80'
  Apr 19 15:49:46.940: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.19.23 80\nConnection to 10.233.19.23 80 port [tcp/http] succeeded!\n"
  Apr 19 15:49:46.940: INFO: stdout: "externalname-service-gkpft"
  Apr 19 15:49:46.940: INFO: Cleaning up the ExternalName to ClusterIP test service
  Apr 19 15:49:46.989: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5983" for this suite. @ 04/19/24 15:49:47.002
• [8.907 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:125
  STEP: Creating a kubernetes client @ 04/19/24 15:49:47.017
  Apr 19 15:49:47.017: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename secrets @ 04/19/24 15:49:47.022
  E0419 15:49:47.034763      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:49:47.053
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:49:47.057
  STEP: Creating secret with name secret-test-7c437869-3acb-49ca-bdf7-0896cd469144 @ 04/19/24 15:49:47.063
  STEP: Creating a pod to test consume secrets @ 04/19/24 15:49:47.072
  E0419 15:49:48.035635      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:49.036642      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:50.036741      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:51.037287      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 15:49:51.136
  Apr 19 15:49:51.146: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-secrets-d77560d3-4862-4b95-b48d-a337d815071e container secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/24 15:49:51.167
  Apr 19 15:49:51.202: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8057" for this suite. @ 04/19/24 15:49:51.215
• [4.211 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:178
  STEP: Creating a kubernetes client @ 04/19/24 15:49:51.232
  Apr 19 15:49:51.232: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename init-container @ 04/19/24 15:49:51.237
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:49:51.264
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:49:51.273
  STEP: creating the pod @ 04/19/24 15:49:51.281
  Apr 19 15:49:51.282: INFO: PodSpec: initContainers in spec.initContainers
  E0419 15:49:52.037471      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:53.038140      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:54.038934      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:55.039105      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:56.040347      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:49:56.103: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-697" for this suite. @ 04/19/24 15:49:56.111
• [4.891 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:190
  STEP: Creating a kubernetes client @ 04/19/24 15:49:56.124
  Apr 19 15:49:56.124: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename emptydir @ 04/19/24 15:49:56.128
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:49:56.157
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:49:56.163
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 04/19/24 15:49:56.169
  E0419 15:49:57.040894      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:49:58.040946      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 15:49:58.2
  Apr 19 15:49:58.208: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-30273f48-1edc-4558-89ee-514ecca7f3b6 container test-container: <nil>
  STEP: delete the pod @ 04/19/24 15:49:58.23
  Apr 19 15:49:58.276: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8881" for this suite. @ 04/19/24 15:49:58.289
• [2.180 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:151
  STEP: Creating a kubernetes client @ 04/19/24 15:49:58.313
  Apr 19 15:49:58.313: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename container-probe @ 04/19/24 15:49:58.318
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:49:58.353
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:49:58.358
  STEP: Creating pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1 @ 04/19/24 15:49:58.365
  E0419 15:49:59.041858      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:00.043339      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/19/24 15:50:00.402
  Apr 19 15:50:00.412: INFO: Initial restart count of pod busybox-79bd23c8-090b-4084-b503-64965e924eba is 0
  Apr 19 15:50:00.418: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:50:01.043555      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:02.044093      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:50:02.428: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:50:03.044281      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:04.045113      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:50:04.439: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:50:05.045467      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:06.045840      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:50:06.448: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:50:07.046149      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:08.050137      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:50:08.459: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:50:09.050099      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:10.051233      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:50:10.473: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:50:11.052507      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:12.052378      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:50:12.480: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:50:13.053440      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:14.053859      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:50:14.507: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:50:15.054241      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:16.055393      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:50:16.519: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:50:17.055654      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:18.056049      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:50:18.529: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:50:19.057123      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:20.057614      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:50:20.540: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:50:21.057590      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:22.057885      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:50:22.583: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:50:23.058193      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:24.058695      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:50:24.593: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:50:25.059750      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:26.059731      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:50:26.603: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:50:27.059992      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:28.060396      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:50:28.615: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:50:29.061040      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:30.061393      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:50:30.626: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:50:31.062046      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:32.062918      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:50:32.636: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:50:33.063665      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:34.064064      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:50:34.646: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:50:35.064697      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:36.065126      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:50:36.657: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:50:37.065652      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:38.066257      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:50:38.670: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:50:39.066934      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:40.067287      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:50:40.677: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:50:41.068052      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:42.068886      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:50:42.688: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:50:43.069119      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:44.070031      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:50:44.698: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:50:45.071195      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:46.071881      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:50:46.710: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:50:47.072667      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:48.073009      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:50:48.725: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:50:49.073038      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:50.073258      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:50:50.740: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:50:51.074157      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:52.074703      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:50:52.749: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:50:53.075435      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:54.075634      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:50:54.763: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:50:55.076149      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:56.076371      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:50:56.773: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:50:57.076667      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:50:58.077175      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:50:58.789: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:50:59.078485      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:00.079382      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:51:00.802: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:51:01.079587      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:02.080038      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:51:02.812: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:51:03.080475      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:04.080442      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:51:04.823: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:51:05.081089      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:06.081968      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:51:06.835: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:51:07.082690      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:08.082915      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:51:08.845: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:51:09.083297      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:10.083967      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:51:10.858: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:51:11.084382      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:12.085433      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:51:12.869: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:51:13.086031      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:14.086610      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:51:14.882: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:51:15.086771      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:16.086737      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:51:16.896: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:51:17.087347      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:18.087621      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:51:18.910: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:51:19.088086      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:20.088801      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:51:20.919: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:51:21.089937      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:22.090662      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:51:22.936: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:51:23.091141      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:24.091044      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:51:24.947: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:51:25.092039      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:26.092587      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:51:26.958: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:51:27.092302      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:28.092753      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:51:28.969: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:51:29.093388      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:30.093915      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:51:30.984: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:51:31.094075      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:32.094541      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:51:32.998: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:51:33.095005      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:34.095871      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:51:35.011: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:51:35.098484      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:36.098411      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:51:37.022: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:51:37.099244      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:38.099434      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:51:39.036: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:51:39.099759      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:40.100762      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:51:41.047: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:51:41.101408      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:42.101734      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:51:43.059: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:51:43.102498      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:44.103383      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:51:45.068: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:51:45.104262      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:46.105350      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:51:47.082: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:51:47.105470      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:48.106545      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:51:49.094: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:51:49.107645      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:50.108480      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:51:51.107: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:51:51.108527      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:52.108795      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:53.108842      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:51:53.118: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:51:54.109343      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:55.109601      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:51:55.136: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:51:56.109697      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:57.110781      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:51:57.151: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:51:58.111943      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:51:59.112847      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:51:59.161: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:52:00.113285      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:01.113450      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:52:01.171: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:52:02.114377      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:03.114708      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:52:03.180: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:52:04.115178      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:05.116364      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:52:05.189: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:52:06.116636      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:07.117661      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:52:07.201: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:52:08.117840      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:09.118103      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:52:09.212: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:52:10.118373      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:11.118617      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:52:11.220: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:52:12.118905      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:13.119339      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:52:13.231: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:52:14.120498      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:15.120674      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:52:15.240: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:52:16.121075      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:17.121769      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:52:17.251: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:52:18.122774      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:19.123526      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:52:19.264: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:52:20.123931      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:21.126601      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:52:21.283: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:52:22.124594      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:23.124656      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:52:23.292: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:52:24.125118      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:25.126099      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:52:25.309: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:52:26.126734      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:27.127523      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:52:27.323: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:52:28.128732      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:29.129466      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:52:29.334: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:52:30.129974      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:31.131071      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:52:31.344: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:52:32.131159      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:33.131932      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:52:33.352: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:52:34.132188      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:35.132337      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:52:35.364: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:52:36.132689      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:37.132906      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:52:37.379: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:52:38.133051      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:39.133221      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:52:39.391: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:52:40.133959      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:41.134354      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:52:41.399: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:52:42.134493      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:43.134656      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:52:43.408: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:52:44.134830      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:45.135121      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:52:45.420: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:52:46.135938      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:47.136897      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:52:47.436: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:52:48.138066      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:49.138740      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:52:49.449: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:52:50.139670      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:51.140536      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:52:51.458: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:52:52.140648      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:53.140932      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:52:53.469: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:52:54.141797      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:55.143575      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:52:55.477: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:52:56.142514      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:57.142767      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:52:57.486: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:52:58.143125      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:52:59.143459      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:52:59.499: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:53:00.144077      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:01.144445      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:53:01.509: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:53:02.145071      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:03.146472      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:53:03.520: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:53:04.146758      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:05.147680      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:53:05.533: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:53:06.147989      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:07.148443      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:53:07.552: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:53:08.148810      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:09.149201      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:53:09.564: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:53:10.149974      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:11.150500      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:53:11.575: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:53:12.151610      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:13.152444      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:53:13.586: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:53:14.153334      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:15.154039      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:53:15.595: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:53:16.154509      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:17.154722      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:53:17.639: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:53:18.155661      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:19.155753      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:53:19.649: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:53:20.156952      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:21.157873      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:53:21.657: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:53:22.158009      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:23.158428      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:53:23.667: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:53:24.158545      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:25.158778      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:53:25.679: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:53:26.159079      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:27.159289      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:53:27.688: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:53:28.159497      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:29.159816      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:53:29.699: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:53:30.160760      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:31.161090      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:53:31.708: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:53:32.161332      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:33.161954      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:53:33.716: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:53:34.162942      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:35.163264      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:53:35.725: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:53:36.163646      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:37.163968      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:53:37.744: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:53:38.164095      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:39.164447      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:53:39.757: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:53:40.164548      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:41.164844      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:53:41.768: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:53:42.166057      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:43.166858      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:53:43.778: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:53:44.167984      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:45.168418      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:53:45.788: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:53:46.169401      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:47.170038      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:53:47.798: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:53:48.170062      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:49.170833      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:53:49.807: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:53:50.171326      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:51.171701      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:53:51.816: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:53:52.171789      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:53.172810      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:53:53.824: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:53:54.173784      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:55.174087      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:53:55.832: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:53:56.174810      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:57.174836      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:53:57.845: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:53:58.176252      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:53:59.176033      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:53:59.855: INFO: Get pod busybox-79bd23c8-090b-4084-b503-64965e924eba in namespace container-probe-1
  E0419 15:54:00.176897      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:01.178003      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 04/19/24 15:54:01.855
  Apr 19 15:54:01.893: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-1" for this suite. @ 04/19/24 15:54:01.907
• [243.615 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:962
  STEP: Creating a kubernetes client @ 04/19/24 15:54:01.928
  Apr 19 15:54:01.928: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename statefulset @ 04/19/24 15:54:01.932
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:54:01.972
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:54:01.979
  STEP: Creating service test in namespace statefulset-452 @ 04/19/24 15:54:01.986
  Apr 19 15:54:02.029: INFO: Found 0 stateful pods, waiting for 1
  E0419 15:54:02.178715      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:03.180129      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:04.179983      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:05.180616      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:06.180816      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:07.181049      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:08.181920      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:09.183132      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:10.183708      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:11.184922      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:54:12.036: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: patching the StatefulSet @ 04/19/24 15:54:12.055
  W0419 15:54:12.091861      13 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
  Apr 19 15:54:12.113: INFO: Found 1 stateful pods, waiting for 2
  E0419 15:54:12.185936      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:13.186837      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:14.187734      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:15.188526      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:16.188776      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:17.188909      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:18.189202      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:19.189473      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:20.189800      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:21.189947      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:54:22.114: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 19 15:54:22.114: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Listing all StatefulSets @ 04/19/24 15:54:22.139
  STEP: Delete all of the StatefulSets @ 04/19/24 15:54:22.151
  STEP: Verify that StatefulSets have been deleted @ 04/19/24 15:54:22.178
  E0419 15:54:22.189958      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:54:22.190: INFO: Deleting all statefulset in ns statefulset-452
  Apr 19 15:54:22.220: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-452" for this suite. @ 04/19/24 15:54:22.233
• [20.362 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:194
  STEP: Creating a kubernetes client @ 04/19/24 15:54:22.291
  Apr 19 15:54:22.291: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/19/24 15:54:22.294
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:54:22.327
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:54:22.331
  Apr 19 15:54:22.337: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  E0419 15:54:23.190222      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:24.190577      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 04/19/24 15:54:24.379
  Apr 19 15:54:24.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=crd-publish-openapi-1446 --namespace=crd-publish-openapi-1446 create -f -'
  Apr 19 15:54:24.729: INFO: stderr: ""
  Apr 19 15:54:24.729: INFO: stdout: "e2e-test-crd-publish-openapi-9907-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  Apr 19 15:54:24.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=crd-publish-openapi-1446 --namespace=crd-publish-openapi-1446 delete e2e-test-crd-publish-openapi-9907-crds test-cr'
  Apr 19 15:54:25.038: INFO: stderr: ""
  Apr 19 15:54:25.038: INFO: stdout: "e2e-test-crd-publish-openapi-9907-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  Apr 19 15:54:25.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=crd-publish-openapi-1446 --namespace=crd-publish-openapi-1446 apply -f -'
  E0419 15:54:25.190696      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:54:25.213: INFO: stderr: ""
  Apr 19 15:54:25.213: INFO: stdout: "e2e-test-crd-publish-openapi-9907-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  Apr 19 15:54:25.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=crd-publish-openapi-1446 --namespace=crd-publish-openapi-1446 delete e2e-test-crd-publish-openapi-9907-crds test-cr'
  Apr 19 15:54:25.387: INFO: stderr: ""
  Apr 19 15:54:25.387: INFO: stdout: "e2e-test-crd-publish-openapi-9907-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 04/19/24 15:54:25.387
  Apr 19 15:54:25.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=crd-publish-openapi-1446 explain e2e-test-crd-publish-openapi-9907-crds'
  Apr 19 15:54:25.530: INFO: stderr: ""
  Apr 19 15:54:25.530: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-at-root.example.com\nKIND:       e2e-test-crd-publish-openapi-9907-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties at root for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E0419 15:54:26.190869      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:27.191943      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:54:27.268: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-1446" for this suite. @ 04/19/24 15:54:27.3
• [5.025 seconds]
------------------------------
[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/security_context.go:170
  STEP: Creating a kubernetes client @ 04/19/24 15:54:27.318
  Apr 19 15:54:27.318: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename security-context @ 04/19/24 15:54:27.323
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:54:27.365
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:54:27.377
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 04/19/24 15:54:27.388
  E0419 15:54:28.191873      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:29.192183      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 15:54:29.439
  Apr 19 15:54:29.449: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod security-context-4ab3b7d6-e05f-45a7-9349-cdbc130c6d9e container test-container: <nil>
  STEP: delete the pod @ 04/19/24 15:54:29.501
  Apr 19 15:54:29.546: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-5647" for this suite. @ 04/19/24 15:54:29.56
• [2.257 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csistoragecapacity.go:50
  STEP: Creating a kubernetes client @ 04/19/24 15:54:29.583
  Apr 19 15:54:29.583: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename csistoragecapacity @ 04/19/24 15:54:29.586
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:54:29.652
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:54:29.657
  STEP: getting /apis @ 04/19/24 15:54:29.664
  STEP: getting /apis/storage.k8s.io @ 04/19/24 15:54:29.676
  STEP: getting /apis/storage.k8s.io/v1 @ 04/19/24 15:54:29.679
  STEP: creating @ 04/19/24 15:54:29.686
  STEP: watching @ 04/19/24 15:54:29.723
  Apr 19 15:54:29.723: INFO: starting watch
  STEP: getting @ 04/19/24 15:54:29.74
  STEP: listing in namespace @ 04/19/24 15:54:29.753
  STEP: listing across namespaces @ 04/19/24 15:54:29.761
  STEP: patching @ 04/19/24 15:54:29.769
  STEP: updating @ 04/19/24 15:54:29.778
  Apr 19 15:54:29.787: INFO: waiting for watch events with expected annotations in namespace
  Apr 19 15:54:29.788: INFO: waiting for watch events with expected annotations across namespace
  STEP: deleting @ 04/19/24 15:54:29.789
  STEP: deleting a collection @ 04/19/24 15:54:29.819
  Apr 19 15:54:29.849: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csistoragecapacity-5891" for this suite. @ 04/19/24 15:54:29.862
• [0.296 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:619
  STEP: Creating a kubernetes client @ 04/19/24 15:54:29.882
  Apr 19 15:54:29.882: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename pods @ 04/19/24 15:54:29.886
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:54:29.924
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:54:29.93
  Apr 19 15:54:29.939: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: creating the pod @ 04/19/24 15:54:29.944
  STEP: submitting the pod to kubernetes @ 04/19/24 15:54:29.945
  E0419 15:54:30.193052      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:31.193627      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:54:32.017: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2177" for this suite. @ 04/19/24 15:54:32.027
• [2.161 seconds]
------------------------------
[sig-cli] Kubectl logs logs should be able to retrieve and filter logs [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/logs.go:114
  STEP: Creating a kubernetes client @ 04/19/24 15:54:32.043
  Apr 19 15:54:32.043: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename kubectl-logs @ 04/19/24 15:54:32.048
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:54:32.093
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:54:32.098
  STEP: creating an pod @ 04/19/24 15:54:32.104
  Apr 19 15:54:32.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-logs-8830 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.47 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
  E0419 15:54:32.194468      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:54:32.298: INFO: stderr: ""
  Apr 19 15:54:32.298: INFO: stdout: "pod/logs-generator created\n"
  STEP: Waiting for log generator to start. @ 04/19/24 15:54:32.298
  Apr 19 15:54:32.299: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
  E0419 15:54:33.195231      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:34.195695      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:54:34.324: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
  STEP: checking for a matching strings @ 04/19/24 15:54:34.324
  Apr 19 15:54:34.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-logs-8830 logs logs-generator logs-generator'
  Apr 19 15:54:34.511: INFO: stderr: ""
  Apr 19 15:54:34.511: INFO: stdout: "I0419 15:54:32.971566       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/q52 265\nI0419 15:54:33.171165       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/jtr 471\nI0419 15:54:33.371688       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/mpk 228\nI0419 15:54:33.571076       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/9hv 362\nI0419 15:54:33.771797       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/c2v5 439\nI0419 15:54:33.971357       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/rd7 550\nI0419 15:54:34.170952       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/9bvq 257\nI0419 15:54:34.371554       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/t2x 541\n"
  STEP: limiting log lines @ 04/19/24 15:54:34.511
  Apr 19 15:54:34.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-logs-8830 logs logs-generator logs-generator --tail=1'
  Apr 19 15:54:34.712: INFO: stderr: ""
  Apr 19 15:54:34.712: INFO: stdout: "I0419 15:54:34.571304       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/xpf 537\n"
  Apr 19 15:54:34.712: INFO: got output "I0419 15:54:34.571304       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/xpf 537\n"
  STEP: limiting log bytes @ 04/19/24 15:54:34.712
  Apr 19 15:54:34.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-logs-8830 logs logs-generator logs-generator --limit-bytes=1'
  Apr 19 15:54:34.887: INFO: stderr: ""
  Apr 19 15:54:34.887: INFO: stdout: "I"
  Apr 19 15:54:34.887: INFO: got output "I"
  STEP: exposing timestamps @ 04/19/24 15:54:34.887
  Apr 19 15:54:34.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-logs-8830 logs logs-generator logs-generator --tail=1 --timestamps'
  Apr 19 15:54:35.046: INFO: stderr: ""
  Apr 19 15:54:35.046: INFO: stdout: "2024-04-19T15:54:34.971195452Z I0419 15:54:34.971061       1 logs_generator.go:76] 10 GET /api/v1/namespaces/default/pods/mkx9 455\n"
  Apr 19 15:54:35.046: INFO: got output "2024-04-19T15:54:34.971195452Z I0419 15:54:34.971061       1 logs_generator.go:76] 10 GET /api/v1/namespaces/default/pods/mkx9 455\n"
  STEP: restricting to a time range @ 04/19/24 15:54:35.046
  E0419 15:54:35.195760      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:36.196370      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:37.196464      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:54:37.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-logs-8830 logs logs-generator logs-generator --since=1s'
  Apr 19 15:54:37.754: INFO: stderr: ""
  Apr 19 15:54:37.754: INFO: stdout: "I0419 15:54:36.771219       1 logs_generator.go:76] 19 POST /api/v1/namespaces/default/pods/8fp2 386\nI0419 15:54:36.970679       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/dsxz 351\nI0419 15:54:37.171327       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/fdh 363\nI0419 15:54:37.371478       1 logs_generator.go:76] 22 GET /api/v1/namespaces/ns/pods/4dbb 292\nI0419 15:54:37.570806       1 logs_generator.go:76] 23 PUT /api/v1/namespaces/default/pods/2p9 559\n"
  Apr 19 15:54:37.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-logs-8830 logs logs-generator logs-generator --since=24h'
  Apr 19 15:54:37.929: INFO: stderr: ""
  Apr 19 15:54:37.929: INFO: stdout: "I0419 15:54:32.971566       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/q52 265\nI0419 15:54:33.171165       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/jtr 471\nI0419 15:54:33.371688       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/mpk 228\nI0419 15:54:33.571076       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/9hv 362\nI0419 15:54:33.771797       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/c2v5 439\nI0419 15:54:33.971357       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/rd7 550\nI0419 15:54:34.170952       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/9bvq 257\nI0419 15:54:34.371554       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/t2x 541\nI0419 15:54:34.571304       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/xpf 537\nI0419 15:54:34.770684       1 logs_generator.go:76] 9 GET /api/v1/namespaces/ns/pods/sbv 224\nI0419 15:54:34.971061       1 logs_generator.go:76] 10 GET /api/v1/namespaces/default/pods/mkx9 455\nI0419 15:54:35.171567       1 logs_generator.go:76] 11 POST /api/v1/namespaces/kube-system/pods/l96z 325\nI0419 15:54:35.372870       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/9bl 449\nI0419 15:54:35.570812       1 logs_generator.go:76] 13 POST /api/v1/namespaces/kube-system/pods/cr5 337\nI0419 15:54:35.771379       1 logs_generator.go:76] 14 GET /api/v1/namespaces/default/pods/ddw8 256\nI0419 15:54:35.970799       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/default/pods/7hvz 377\nI0419 15:54:36.171836       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/ns/pods/klbb 364\nI0419 15:54:36.371083       1 logs_generator.go:76] 17 GET /api/v1/namespaces/default/pods/x5tb 521\nI0419 15:54:36.570823       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/ns/pods/7sz 509\nI0419 15:54:36.771219       1 logs_generator.go:76] 19 POST /api/v1/namespaces/default/pods/8fp2 386\nI0419 15:54:36.970679       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/dsxz 351\nI0419 15:54:37.171327       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/fdh 363\nI0419 15:54:37.371478       1 logs_generator.go:76] 22 GET /api/v1/namespaces/ns/pods/4dbb 292\nI0419 15:54:37.570806       1 logs_generator.go:76] 23 PUT /api/v1/namespaces/default/pods/2p9 559\nI0419 15:54:37.771605       1 logs_generator.go:76] 24 PUT /api/v1/namespaces/default/pods/2qp6 505\n"
  Apr 19 15:54:37.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-logs-8830 delete pod logs-generator'
  E0419 15:54:38.197322      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:39.197707      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:54:39.308: INFO: stderr: ""
  Apr 19 15:54:39.309: INFO: stdout: "pod \"logs-generator\" deleted\n"
  Apr 19 15:54:39.309: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-logs-8830" for this suite. @ 04/19/24 15:54:39.324
• [7.297 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for ExternalName services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:329
  STEP: Creating a kubernetes client @ 04/19/24 15:54:39.348
  Apr 19 15:54:39.349: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename dns @ 04/19/24 15:54:39.352
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:54:39.39
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:54:39.397
  STEP: Creating a test externalName service @ 04/19/24 15:54:39.408
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7202.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7202.svc.cluster.local; sleep 1; done
   @ 04/19/24 15:54:39.419
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7202.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7202.svc.cluster.local; sleep 1; done
   @ 04/19/24 15:54:39.419
  STEP: creating a pod to probe DNS @ 04/19/24 15:54:39.419
  STEP: submitting the pod to kubernetes @ 04/19/24 15:54:39.419
  E0419 15:54:40.198160      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:41.198409      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:42.198649      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:43.199262      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:44.199634      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:45.199699      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:46.200206      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:47.200990      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:48.202031      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:49.202814      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:50.202783      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:51.209054      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:52.204375      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:53.204444      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:54.205240      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:55.216060      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:56.211815      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:57.211873      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:58.214363      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:54:59.214063      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/19/24 15:54:59.56
  STEP: looking for the results for each expected name from probers @ 04/19/24 15:54:59.571
  Apr 19 15:54:59.601: INFO: DNS probes using dns-test-326de230-49e0-40fd-99df-95ee5729c128 succeeded

  STEP: changing the externalName to bar.example.com @ 04/19/24 15:54:59.602
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7202.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7202.svc.cluster.local; sleep 1; done
   @ 04/19/24 15:54:59.622
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7202.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7202.svc.cluster.local; sleep 1; done
   @ 04/19/24 15:54:59.623
  STEP: creating a second pod to probe DNS @ 04/19/24 15:54:59.623
  STEP: submitting the pod to kubernetes @ 04/19/24 15:54:59.623
  E0419 15:55:00.214590      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:01.215807      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/19/24 15:55:01.675
  STEP: looking for the results for each expected name from probers @ 04/19/24 15:55:01.687
  Apr 19 15:55:01.715: INFO: File wheezy_udp@dns-test-service-3.dns-7202.svc.cluster.local from pod  dns-7202/dns-test-24a96d9e-7cbc-48b2-b33b-7cb673cf8b77 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Apr 19 15:55:01.726: INFO: File jessie_udp@dns-test-service-3.dns-7202.svc.cluster.local from pod  dns-7202/dns-test-24a96d9e-7cbc-48b2-b33b-7cb673cf8b77 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Apr 19 15:55:01.726: INFO: Lookups using dns-7202/dns-test-24a96d9e-7cbc-48b2-b33b-7cb673cf8b77 failed for: [wheezy_udp@dns-test-service-3.dns-7202.svc.cluster.local jessie_udp@dns-test-service-3.dns-7202.svc.cluster.local]

  Apr 19 15:55:01.747: INFO: Pod client logs for webserver: 
  Apr 19 15:55:01.770: INFO: Pod client logs for querier: 
  Apr 19 15:55:01.791: INFO: Pod client logs for jessie-querier: 
  E0419 15:55:02.217398      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:03.216965      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:04.217282      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:05.217375      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:06.217670      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:55:06.704: INFO: File wheezy_udp@dns-test-service-3.dns-7202.svc.cluster.local from pod  dns-7202/dns-test-24a96d9e-7cbc-48b2-b33b-7cb673cf8b77 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Apr 19 15:55:06.715: INFO: File jessie_udp@dns-test-service-3.dns-7202.svc.cluster.local from pod  dns-7202/dns-test-24a96d9e-7cbc-48b2-b33b-7cb673cf8b77 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Apr 19 15:55:06.717: INFO: Lookups using dns-7202/dns-test-24a96d9e-7cbc-48b2-b33b-7cb673cf8b77 failed for: [wheezy_udp@dns-test-service-3.dns-7202.svc.cluster.local jessie_udp@dns-test-service-3.dns-7202.svc.cluster.local]

  Apr 19 15:55:06.747: INFO: Pod client logs for webserver: 
  Apr 19 15:55:06.768: INFO: Pod client logs for querier: 
  Apr 19 15:55:06.787: INFO: Pod client logs for jessie-querier: 
  E0419 15:55:07.218603      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:08.219342      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:09.219813      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:10.220366      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:11.221272      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:55:11.711: INFO: DNS probes using dns-test-24a96d9e-7cbc-48b2-b33b-7cb673cf8b77 succeeded

  STEP: changing the service to type=ClusterIP @ 04/19/24 15:55:11.711
  W0419 15:55:11.751939      13 warnings.go:70] spec.externalName is ignored when spec.type is not "ExternalName"
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7202.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-7202.svc.cluster.local; sleep 1; done
   @ 04/19/24 15:55:11.752
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7202.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-7202.svc.cluster.local; sleep 1; done
   @ 04/19/24 15:55:11.752
  STEP: creating a third pod to probe DNS @ 04/19/24 15:55:11.752
  STEP: submitting the pod to kubernetes @ 04/19/24 15:55:11.765
  E0419 15:55:12.221509      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:13.222603      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:14.223559      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:15.224409      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:16.224167      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:17.224881      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:18.224977      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:19.225915      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:20.225802      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:21.226059      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:22.226521      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:23.226796      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:24.227125      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:25.228045      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:26.228059      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:27.228608      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:28.229211      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:29.229451      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:30.230699      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:31.231020      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:32.231865      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:33.232718      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:34.233242      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:35.233481      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/19/24 15:55:35.958
  STEP: looking for the results for each expected name from probers @ 04/19/24 15:55:35.975
  Apr 19 15:55:36.021: INFO: DNS probes using dns-test-fd55da6a-167f-418f-b3d0-ad5dec315f63 succeeded

  STEP: deleting the pod @ 04/19/24 15:55:36.022
  STEP: deleting the pod @ 04/19/24 15:55:36.051
  STEP: deleting the pod @ 04/19/24 15:55:36.097
  STEP: deleting the test externalName service @ 04/19/24 15:55:36.131
  Apr 19 15:55:36.167: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-7202" for this suite. @ 04/19/24 15:55:36.175
• [56.847 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:51
  STEP: Creating a kubernetes client @ 04/19/24 15:55:36.198
  Apr 19 15:55:36.199: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename kubelet-test @ 04/19/24 15:55:36.219
  E0419 15:55:36.234010      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:55:36.247
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:55:36.251
  E0419 15:55:37.234753      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:38.235329      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:55:38.329: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-465" for this suite. @ 04/19/24 15:55:38.34
• [2.155 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:164
  STEP: Creating a kubernetes client @ 04/19/24 15:55:38.358
  Apr 19 15:55:38.358: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename disruption @ 04/19/24 15:55:38.374
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:55:38.411
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:55:38.417
  STEP: Waiting for the pdb to be processed @ 04/19/24 15:55:38.431
  E0419 15:55:39.235937      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:40.235842      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating PodDisruptionBudget status @ 04/19/24 15:55:40.443
  STEP: Waiting for all pods to be running @ 04/19/24 15:55:40.472
  Apr 19 15:55:40.485: INFO: running pods: 0 < 1
  E0419 15:55:41.235829      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:42.236935      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 04/19/24 15:55:42.481
  STEP: Waiting for the pdb to be processed @ 04/19/24 15:55:42.51
  STEP: Patching PodDisruptionBudget status @ 04/19/24 15:55:42.534
  STEP: Waiting for the pdb to be processed @ 04/19/24 15:55:42.574
  Apr 19 15:55:42.580: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-6888" for this suite. @ 04/19/24 15:55:42.601
• [4.261 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:106
  STEP: Creating a kubernetes client @ 04/19/24 15:55:42.621
  Apr 19 15:55:42.621: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename runtimeclass @ 04/19/24 15:55:42.624
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:55:42.66
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:55:42.664
  E0419 15:55:43.238668      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:44.238225      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:55:44.734: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-3959" for this suite. @ 04/19/24 15:55:44.749
• [2.155 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:59
  STEP: Creating a kubernetes client @ 04/19/24 15:55:44.778
  Apr 19 15:55:44.778: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename subpath @ 04/19/24 15:55:44.783
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:55:44.827
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:55:44.835
  STEP: Setting up data @ 04/19/24 15:55:44.845
  STEP: Creating pod pod-subpath-test-secret-68nv @ 04/19/24 15:55:44.871
  STEP: Creating a pod to test atomic-volume-subpath @ 04/19/24 15:55:44.871
  E0419 15:55:45.239036      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:46.239897      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:47.240501      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:48.241396      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:49.242116      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:50.243065      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:51.243386      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:52.244553      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:53.245288      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:54.245672      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:55.246459      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:56.247094      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:57.248072      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:58.248731      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:55:59.249354      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:00.249626      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:01.250596      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:02.251262      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:03.252403      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:04.253395      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:05.254210      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:06.255573      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 15:56:07.056
  Apr 19 15:56:07.065: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-subpath-test-secret-68nv container test-container-subpath-secret-68nv: <nil>
  STEP: delete the pod @ 04/19/24 15:56:07.095
  STEP: Deleting pod pod-subpath-test-secret-68nv @ 04/19/24 15:56:07.142
  Apr 19 15:56:07.142: INFO: Deleting pod "pod-subpath-test-secret-68nv" in namespace "subpath-5914"
  Apr 19 15:56:07.148: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-5914" for this suite. @ 04/19/24 15:56:07.157
• [22.393 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:150
  STEP: Creating a kubernetes client @ 04/19/24 15:56:07.175
  Apr 19 15:56:07.175: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename emptydir @ 04/19/24 15:56:07.179
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:56:07.21
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:56:07.216
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 04/19/24 15:56:07.221
  E0419 15:56:07.257209      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:08.256269      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:09.256874      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:10.257696      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:11.258077      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 15:56:11.275
  Apr 19 15:56:11.282: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-3cf9c118-34d4-4ff8-bdb1-5ba8d8554892 container test-container: <nil>
  STEP: delete the pod @ 04/19/24 15:56:11.297
  Apr 19 15:56:11.325: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-3656" for this suite. @ 04/19/24 15:56:11.335
• [4.175 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:55
  STEP: Creating a kubernetes client @ 04/19/24 15:56:11.352
  Apr 19 15:56:11.352: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename projected @ 04/19/24 15:56:11.356
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:56:11.391
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:56:11.397
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 15:56:11.402
  E0419 15:56:12.258705      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:13.258829      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:14.260593      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:15.260766      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 15:56:15.456
  Apr 19 15:56:15.462: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod downwardapi-volume-9dcba1b1-7fc0-4be8-8d83-f29252f5c2f2 container client-container: <nil>
  STEP: delete the pod @ 04/19/24 15:56:15.475
  Apr 19 15:56:15.505: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5868" for this suite. @ 04/19/24 15:56:15.516
• [4.179 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/controller_revision.go:126
  STEP: Creating a kubernetes client @ 04/19/24 15:56:15.535
  Apr 19 15:56:15.536: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename controllerrevisions @ 04/19/24 15:56:15.54
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:56:15.576
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:56:15.583
  STEP: Creating DaemonSet "e2e-hr8nd-daemon-set" @ 04/19/24 15:56:15.633
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/19/24 15:56:15.653
  Apr 19 15:56:15.669: INFO: Number of nodes with available pods controlled by daemonset e2e-hr8nd-daemon-set: 0
  Apr 19 15:56:15.670: INFO: Node co4fe9zoo9oc-1 is running 0 daemon pod, expected 1
  E0419 15:56:16.261023      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:56:16.668: INFO: Number of nodes with available pods controlled by daemonset e2e-hr8nd-daemon-set: 0
  Apr 19 15:56:16.668: INFO: Node co4fe9zoo9oc-1 is running 0 daemon pod, expected 1
  E0419 15:56:17.262832      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:56:17.678: INFO: Number of nodes with available pods controlled by daemonset e2e-hr8nd-daemon-set: 2
  Apr 19 15:56:17.678: INFO: Node co4fe9zoo9oc-1 is running 0 daemon pod, expected 1
  E0419 15:56:18.262490      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:56:18.672: INFO: Number of nodes with available pods controlled by daemonset e2e-hr8nd-daemon-set: 2
  Apr 19 15:56:18.672: INFO: Node co4fe9zoo9oc-1 is running 0 daemon pod, expected 1
  E0419 15:56:19.262740      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:56:19.671: INFO: Number of nodes with available pods controlled by daemonset e2e-hr8nd-daemon-set: 2
  Apr 19 15:56:19.671: INFO: Node co4fe9zoo9oc-1 is running 0 daemon pod, expected 1
  E0419 15:56:20.262904      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:56:20.670: INFO: Number of nodes with available pods controlled by daemonset e2e-hr8nd-daemon-set: 2
  Apr 19 15:56:20.670: INFO: Node co4fe9zoo9oc-1 is running 0 daemon pod, expected 1
  E0419 15:56:21.263316      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:56:21.672: INFO: Number of nodes with available pods controlled by daemonset e2e-hr8nd-daemon-set: 2
  Apr 19 15:56:21.672: INFO: Node co4fe9zoo9oc-1 is running 0 daemon pod, expected 1
  E0419 15:56:22.263448      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:56:22.670: INFO: Number of nodes with available pods controlled by daemonset e2e-hr8nd-daemon-set: 2
  Apr 19 15:56:22.670: INFO: Node co4fe9zoo9oc-1 is running 0 daemon pod, expected 1
  E0419 15:56:23.264435      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:56:23.668: INFO: Number of nodes with available pods controlled by daemonset e2e-hr8nd-daemon-set: 2
  Apr 19 15:56:23.668: INFO: Node co4fe9zoo9oc-1 is running 0 daemon pod, expected 1
  E0419 15:56:24.265213      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:56:24.667: INFO: Number of nodes with available pods controlled by daemonset e2e-hr8nd-daemon-set: 2
  Apr 19 15:56:24.667: INFO: Node co4fe9zoo9oc-1 is running 0 daemon pod, expected 1
  E0419 15:56:25.265686      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:56:25.671: INFO: Number of nodes with available pods controlled by daemonset e2e-hr8nd-daemon-set: 3
  Apr 19 15:56:25.671: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-hr8nd-daemon-set
  STEP: Confirm DaemonSet "e2e-hr8nd-daemon-set" successfully created with "daemonset-name=e2e-hr8nd-daemon-set" label @ 04/19/24 15:56:25.677
  STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-hr8nd-daemon-set" @ 04/19/24 15:56:25.694
  Apr 19 15:56:25.703: INFO: Located ControllerRevision: "e2e-hr8nd-daemon-set-5d89487ff"
  STEP: Patching ControllerRevision "e2e-hr8nd-daemon-set-5d89487ff" @ 04/19/24 15:56:25.71
  Apr 19 15:56:25.729: INFO: e2e-hr8nd-daemon-set-5d89487ff has been patched
  STEP: Create a new ControllerRevision @ 04/19/24 15:56:25.729
  Apr 19 15:56:25.743: INFO: Created ControllerRevision: e2e-hr8nd-daemon-set-5b5bc857bc
  STEP: Confirm that there are two ControllerRevisions @ 04/19/24 15:56:25.743
  Apr 19 15:56:25.744: INFO: Requesting list of ControllerRevisions to confirm quantity
  Apr 19 15:56:25.753: INFO: Found 2 ControllerRevisions
  STEP: Deleting ControllerRevision "e2e-hr8nd-daemon-set-5d89487ff" @ 04/19/24 15:56:25.753
  STEP: Confirm that there is only one ControllerRevision @ 04/19/24 15:56:25.773
  Apr 19 15:56:25.773: INFO: Requesting list of ControllerRevisions to confirm quantity
  Apr 19 15:56:25.793: INFO: Found 1 ControllerRevisions
  STEP: Updating ControllerRevision "e2e-hr8nd-daemon-set-5b5bc857bc" @ 04/19/24 15:56:25.805
  Apr 19 15:56:25.827: INFO: e2e-hr8nd-daemon-set-5b5bc857bc has been updated
  STEP: Generate another ControllerRevision by patching the Daemonset @ 04/19/24 15:56:25.827
  W0419 15:56:25.847561      13 warnings.go:70] unknown field "updateStrategy"
  STEP: Confirm that there are two ControllerRevisions @ 04/19/24 15:56:25.847
  Apr 19 15:56:25.848: INFO: Requesting list of ControllerRevisions to confirm quantity
  E0419 15:56:26.274843      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:56:26.849: INFO: Requesting list of ControllerRevisions to confirm quantity
  Apr 19 15:56:26.858: INFO: Found 2 ControllerRevisions
  STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-hr8nd-daemon-set-5b5bc857bc=updated" @ 04/19/24 15:56:26.858
  STEP: Confirm that there is only one ControllerRevision @ 04/19/24 15:56:26.878
  Apr 19 15:56:26.878: INFO: Requesting list of ControllerRevisions to confirm quantity
  Apr 19 15:56:26.884: INFO: Found 1 ControllerRevisions
  Apr 19 15:56:26.891: INFO: ControllerRevision "e2e-hr8nd-daemon-set-655cdd5458" has revision 3
  STEP: Deleting DaemonSet "e2e-hr8nd-daemon-set" @ 04/19/24 15:56:26.898
  STEP: deleting DaemonSet.extensions e2e-hr8nd-daemon-set in namespace controllerrevisions-3945, will wait for the garbage collector to delete the pods @ 04/19/24 15:56:26.899
  Apr 19 15:56:26.971: INFO: Deleting DaemonSet.extensions e2e-hr8nd-daemon-set took: 13.491625ms
  Apr 19 15:56:27.073: INFO: Terminating DaemonSet.extensions e2e-hr8nd-daemon-set pods took: 101.239502ms
  E0419 15:56:27.270429      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:28.271695      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:56:28.382: INFO: Number of nodes with available pods controlled by daemonset e2e-hr8nd-daemon-set: 0
  Apr 19 15:56:28.382: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-hr8nd-daemon-set
  Apr 19 15:56:28.389: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"7707"},"items":null}

  Apr 19 15:56:28.399: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"7707"},"items":null}

  Apr 19 15:56:28.449: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "controllerrevisions-3945" for this suite. @ 04/19/24 15:56:28.463
• [12.947 seconds]
------------------------------
S
------------------------------
[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:219
  STEP: Creating a kubernetes client @ 04/19/24 15:56:28.484
  Apr 19 15:56:28.484: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename downward-api @ 04/19/24 15:56:28.49
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:56:28.533
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:56:28.541
  STEP: Creating a pod to test downward api env vars @ 04/19/24 15:56:28.549
  E0419 15:56:29.271931      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:30.272574      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:31.273031      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:32.273206      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 15:56:32.612
  Apr 19 15:56:32.623: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod downward-api-ab39d379-8942-4cec-8648-b528b68edeff container dapi-container: <nil>
  STEP: delete the pod @ 04/19/24 15:56:32.643
  Apr 19 15:56:32.679: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-262" for this suite. @ 04/19/24 15:56:32.691
• [4.225 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:403
  STEP: Creating a kubernetes client @ 04/19/24 15:56:32.711
  Apr 19 15:56:32.712: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename webhook @ 04/19/24 15:56:32.716
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:56:32.759
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:56:32.765
  STEP: Setting up server cert @ 04/19/24 15:56:32.82
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 15:56:33.199
  STEP: Deploying the webhook pod @ 04/19/24 15:56:33.223
  STEP: Wait for the deployment to be ready @ 04/19/24 15:56:33.257
  Apr 19 15:56:33.267: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0419 15:56:33.273839      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:34.274117      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:35.275229      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 15:56:35.295
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 15:56:35.323
  E0419 15:56:36.274795      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:56:36.324: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a validating webhook configuration @ 04/19/24 15:56:36.342
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/19/24 15:56:36.404
  STEP: Updating a validating webhook configuration's rules to not include the create operation @ 04/19/24 15:56:36.43
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/19/24 15:56:36.459
  STEP: Patching a validating webhook configuration's rules to include the create operation @ 04/19/24 15:56:36.597
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/19/24 15:56:36.613
  Apr 19 15:56:36.725: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6158" for this suite. @ 04/19/24 15:56:36.732
  STEP: Destroying namespace "webhook-markers-3892" for this suite. @ 04/19/24 15:56:36.75
• [4.047 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:195
  STEP: Creating a kubernetes client @ 04/19/24 15:56:36.759
  Apr 19 15:56:36.759: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename container-runtime @ 04/19/24 15:56:36.761
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:56:36.786
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:56:36.791
  STEP: create the container @ 04/19/24 15:56:36.796
  W0419 15:56:36.812443      13 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 04/19/24 15:56:36.813
  E0419 15:56:37.275110      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:38.275150      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:39.276205      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 04/19/24 15:56:39.849
  STEP: the container should be terminated @ 04/19/24 15:56:39.861
  STEP: the termination message should be set @ 04/19/24 15:56:39.862
  Apr 19 15:56:39.862: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 04/19/24 15:56:39.863
  Apr 19 15:56:39.900: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-763" for this suite. @ 04/19/24 15:56:39.922
• [3.183 seconds]
------------------------------
S
------------------------------
[sig-node] Pods should get a host IP [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:205
  STEP: Creating a kubernetes client @ 04/19/24 15:56:39.944
  Apr 19 15:56:39.945: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename pods @ 04/19/24 15:56:39.952
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:56:39.998
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:56:40.008
  STEP: creating pod @ 04/19/24 15:56:40.02
  E0419 15:56:40.276932      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:41.277528      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:56:42.073: INFO: Pod pod-hostip-f75bbe32-207a-4f59-b71e-d0eef68e0e0f has hostIP: 192.168.121.60
  Apr 19 15:56:42.074: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-4420" for this suite. @ 04/19/24 15:56:42.082
• [2.150 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:321
  STEP: Creating a kubernetes client @ 04/19/24 15:56:42.096
  Apr 19 15:56:42.097: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename statefulset @ 04/19/24 15:56:42.1
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:56:42.127
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:56:42.132
  STEP: Creating service test in namespace statefulset-9937 @ 04/19/24 15:56:42.139
  STEP: Creating a new StatefulSet @ 04/19/24 15:56:42.145
  Apr 19 15:56:42.168: INFO: Found 0 stateful pods, waiting for 3
  E0419 15:56:42.278309      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:43.279679      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:44.279408      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:45.280186      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:46.281001      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:47.282081      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:48.282405      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:49.282664      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:50.282782      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:51.283015      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:56:52.176: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 19 15:56:52.176: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 19 15:56:52.177: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  Apr 19 15:56:52.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=statefulset-9937 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  E0419 15:56:52.283830      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:56:52.595: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 19 15:56:52.595: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 19 15:56:52.595: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0419 15:56:53.284478      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:54.285372      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:55.286408      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:56.286783      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:57.287551      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:58.287718      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:56:59.288070      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:00.288339      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:01.288838      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:02.289139      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 04/19/24 15:57:02.615
  Apr 19 15:57:02.648: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 04/19/24 15:57:02.648
  E0419 15:57:03.289800      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:04.290188      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:05.290706      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:06.290771      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:07.290955      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:08.292137      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:09.292464      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:10.292723      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:11.293637      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:12.293873      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating Pods in reverse ordinal order @ 04/19/24 15:57:12.672
  Apr 19 15:57:12.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=statefulset-9937 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 19 15:57:13.021: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 19 15:57:13.021: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 19 15:57:13.021: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0419 15:57:13.293689      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:14.294333      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:15.294477      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:16.295332      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:17.296545      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:18.296843      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:19.297783      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:20.298495      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:21.299016      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:22.299571      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:57:23.066: INFO: Waiting for StatefulSet statefulset-9937/ss2 to complete update
  Apr 19 15:57:23.067: INFO: Waiting for Pod statefulset-9937/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Apr 19 15:57:23.067: INFO: Waiting for Pod statefulset-9937/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0419 15:57:23.299988      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:24.300870      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:25.301686      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:26.302199      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:27.302384      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:28.311713      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:29.304574      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:30.305590      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:31.306195      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:32.308211      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:57:33.064: INFO: Waiting for StatefulSet statefulset-9937/ss2 to complete update
  Apr 19 15:57:33.064: INFO: Waiting for Pod statefulset-9937/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0419 15:57:33.324719      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:34.312890      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:35.314011      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:36.316647      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:37.338894      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:38.327952      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:39.324061      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:40.324271      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:41.324945      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:42.325122      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:57:43.063: INFO: Waiting for StatefulSet statefulset-9937/ss2 to complete update
  E0419 15:57:43.326154      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:44.326218      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:45.326715      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:46.327647      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:47.328427      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:48.329578      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:49.329670      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:50.330028      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:51.330722      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:52.331011      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Rolling back to a previous revision @ 04/19/24 15:57:53.058
  Apr 19 15:57:53.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=statefulset-9937 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  E0419 15:57:53.331417      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:57:53.430: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 19 15:57:53.430: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 19 15:57:53.430: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0419 15:57:54.332329      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:55.333418      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:56.333950      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:57.334581      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:58.334731      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:57:59.335100      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:00.335315      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:01.336044      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:02.336529      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:03.336835      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:58:03.496: INFO: Updating stateful set ss2
  E0419 15:58:04.337101      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:05.337928      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:06.338188      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:07.338614      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:08.338863      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:09.339661      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:10.340123      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:11.340859      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:12.341201      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:13.342123      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Rolling back update in reverse ordinal order @ 04/19/24 15:58:13.53
  Apr 19 15:58:13.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=statefulset-9937 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 19 15:58:13.869: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 19 15:58:13.869: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 19 15:58:13.869: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0419 15:58:14.343168      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:15.344234      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:16.344626      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:17.345678      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:18.346115      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:19.346712      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:20.346571      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:21.347067      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:22.347450      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:23.347583      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:58:23.909: INFO: Deleting all statefulset in ns statefulset-9937
  Apr 19 15:58:23.921: INFO: Scaling statefulset ss2 to 0
  E0419 15:58:24.347713      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:25.348475      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:26.348638      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:27.349398      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:28.349611      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:29.349587      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:30.349937      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:31.350675      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:32.351112      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:33.351331      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:58:33.957: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 19 15:58:33.967: INFO: Deleting statefulset ss2
  Apr 19 15:58:34.005: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-9937" for this suite. @ 04/19/24 15:58:34.021
• [111.953 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:48
  STEP: Creating a kubernetes client @ 04/19/24 15:58:34.068
  Apr 19 15:58:34.069: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename projected @ 04/19/24 15:58:34.076
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:58:34.124
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:58:34.131
  STEP: Creating configMap with name projected-configmap-test-volume-7f75f5bb-710f-462e-818f-0b6d463f395d @ 04/19/24 15:58:34.141
  STEP: Creating a pod to test consume configMaps @ 04/19/24 15:58:34.156
  E0419 15:58:34.352622      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:35.352543      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:36.354477      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:37.354674      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 15:58:38.224
  Apr 19 15:58:38.233: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-projected-configmaps-51564ff3-dd5d-4b55-8f9f-1d988990098b container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/24 15:58:38.284
  Apr 19 15:58:38.317: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9082" for this suite. @ 04/19/24 15:58:38.33
• [4.274 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:88
  E0419 15:58:38.355708      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a kubernetes client @ 04/19/24 15:58:38.357
  Apr 19 15:58:38.358: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename projected @ 04/19/24 15:58:38.363
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:58:38.403
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:58:38.408
  STEP: Creating projection with secret that has name projected-secret-test-map-2fde5d5b-ae83-496e-8545-cf6612a846ce @ 04/19/24 15:58:38.414
  STEP: Creating a pod to test consume secrets @ 04/19/24 15:58:38.426
  E0419 15:58:39.356982      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:40.356782      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:41.357881      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:42.358602      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 15:58:42.495
  Apr 19 15:58:42.503: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-projected-secrets-8e6985f8-368e-4fcd-865d-a6b9f57e59c3 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/24 15:58:42.529
  Apr 19 15:58:42.595: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7126" for this suite. @ 04/19/24 15:58:42.606
• [4.265 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:408
  STEP: Creating a kubernetes client @ 04/19/24 15:58:42.644
  Apr 19 15:58:42.645: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename job @ 04/19/24 15:58:42.65
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:58:42.701
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:58:42.711
  STEP: Creating Indexed job @ 04/19/24 15:58:42.717
  STEP: Ensuring job reaches completions @ 04/19/24 15:58:42.733
  E0419 15:58:43.358895      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:44.360098      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:45.360583      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:46.362726      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:47.363515      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:48.364090      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:49.364076      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:50.364526      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring pods with index for job exist @ 04/19/24 15:58:50.746
  Apr 19 15:58:50.756: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-4716" for this suite. @ 04/19/24 15:58:50.766
• [8.135 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:386
  STEP: Creating a kubernetes client @ 04/19/24 15:58:50.782
  Apr 19 15:58:50.782: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename secrets @ 04/19/24 15:58:50.786
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:58:50.817
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:58:50.824
  Apr 19 15:58:50.915: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-7424" for this suite. @ 04/19/24 15:58:50.925
• [0.154 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:175
  STEP: Creating a kubernetes client @ 04/19/24 15:58:50.937
  Apr 19 15:58:50.937: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename projected @ 04/19/24 15:58:50.939
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:58:50.969
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:58:50.974
  STEP: Creating configMap with name cm-test-opt-del-16e9bec0-5a05-4a0e-b4dd-acb42869a8b4 @ 04/19/24 15:58:50.988
  STEP: Creating configMap with name cm-test-opt-upd-e8563d7e-ac21-40ad-90d1-f6fef2d1081b @ 04/19/24 15:58:51
  STEP: Creating the pod @ 04/19/24 15:58:51.008
  E0419 15:58:51.365174      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:52.365298      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-16e9bec0-5a05-4a0e-b4dd-acb42869a8b4 @ 04/19/24 15:58:53.139
  STEP: Updating configmap cm-test-opt-upd-e8563d7e-ac21-40ad-90d1-f6fef2d1081b @ 04/19/24 15:58:53.158
  STEP: Creating configMap with name cm-test-opt-create-a7cea3c0-0e92-4fb9-ad43-4cf990578a43 @ 04/19/24 15:58:53.172
  STEP: waiting to observe update in volume @ 04/19/24 15:58:53.183
  E0419 15:58:53.366351      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:54.366963      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:55.367584      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:56.367889      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:58:57.274: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7850" for this suite. @ 04/19/24 15:58:57.291
• [6.384 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:380
  STEP: Creating a kubernetes client @ 04/19/24 15:58:57.322
  Apr 19 15:58:57.322: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename gc @ 04/19/24 15:58:57.328
  E0419 15:58:57.368230      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:58:57.377
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:58:57.382
  STEP: create the rc @ 04/19/24 15:58:57.394
  W0419 15:58:57.404280      13 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0419 15:58:58.368543      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:58:59.368880      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:00.368925      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:01.369255      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:02.371910      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:03.373481      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 04/19/24 15:59:03.412
  STEP: wait for the rc to be deleted @ 04/19/24 15:59:03.434
  E0419 15:59:04.374431      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:05.374185      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:06.374833      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:07.375679      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:08.376633      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods @ 04/19/24 15:59:08.445
  E0419 15:59:09.377256      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:10.377755      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:11.377942      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:12.379221      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:13.379524      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:14.380542      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:15.381492      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:16.381645      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:17.382481      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:18.382706      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:19.382942      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:20.383388      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:21.383606      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:22.384242      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:23.385058      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:24.385665      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:25.386551      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:26.386805      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:27.387040      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:28.388048      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:29.388990      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:30.389503      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:31.390582      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:32.391480      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:33.392339      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:34.392790      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:35.393540      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:36.394066      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:37.394660      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:38.394938      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 04/19/24 15:59:38.511
  Apr 19 15:59:38.770: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 19 15:59:38.781: INFO: Deleting pod "simpletest.rc-25l5l" in namespace "gc-9864"
  Apr 19 15:59:38.813: INFO: Deleting pod "simpletest.rc-26b2q" in namespace "gc-9864"
  Apr 19 15:59:38.883: INFO: Deleting pod "simpletest.rc-26cmh" in namespace "gc-9864"
  Apr 19 15:59:38.926: INFO: Deleting pod "simpletest.rc-27f7t" in namespace "gc-9864"
  Apr 19 15:59:38.969: INFO: Deleting pod "simpletest.rc-2dqdm" in namespace "gc-9864"
  Apr 19 15:59:39.023: INFO: Deleting pod "simpletest.rc-2gxs4" in namespace "gc-9864"
  Apr 19 15:59:39.084: INFO: Deleting pod "simpletest.rc-2wsnm" in namespace "gc-9864"
  Apr 19 15:59:39.145: INFO: Deleting pod "simpletest.rc-4c9sr" in namespace "gc-9864"
  Apr 19 15:59:39.280: INFO: Deleting pod "simpletest.rc-4gh2k" in namespace "gc-9864"
  Apr 19 15:59:39.381: INFO: Deleting pod "simpletest.rc-4p4cl" in namespace "gc-9864"
  E0419 15:59:39.395624      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:59:39.427: INFO: Deleting pod "simpletest.rc-54xjh" in namespace "gc-9864"
  Apr 19 15:59:39.466: INFO: Deleting pod "simpletest.rc-56gbn" in namespace "gc-9864"
  Apr 19 15:59:39.495: INFO: Deleting pod "simpletest.rc-59ks5" in namespace "gc-9864"
  Apr 19 15:59:39.520: INFO: Deleting pod "simpletest.rc-5vz4h" in namespace "gc-9864"
  Apr 19 15:59:39.578: INFO: Deleting pod "simpletest.rc-68h4q" in namespace "gc-9864"
  Apr 19 15:59:39.627: INFO: Deleting pod "simpletest.rc-6ld9m" in namespace "gc-9864"
  Apr 19 15:59:39.666: INFO: Deleting pod "simpletest.rc-6lsrn" in namespace "gc-9864"
  Apr 19 15:59:39.736: INFO: Deleting pod "simpletest.rc-6zrkm" in namespace "gc-9864"
  Apr 19 15:59:39.767: INFO: Deleting pod "simpletest.rc-7m2sf" in namespace "gc-9864"
  Apr 19 15:59:39.828: INFO: Deleting pod "simpletest.rc-7pg7n" in namespace "gc-9864"
  Apr 19 15:59:39.862: INFO: Deleting pod "simpletest.rc-8b8cm" in namespace "gc-9864"
  Apr 19 15:59:39.917: INFO: Deleting pod "simpletest.rc-8l5sc" in namespace "gc-9864"
  Apr 19 15:59:39.958: INFO: Deleting pod "simpletest.rc-8nll8" in namespace "gc-9864"
  Apr 19 15:59:40.022: INFO: Deleting pod "simpletest.rc-96v2z" in namespace "gc-9864"
  Apr 19 15:59:40.063: INFO: Deleting pod "simpletest.rc-99v2z" in namespace "gc-9864"
  Apr 19 15:59:40.101: INFO: Deleting pod "simpletest.rc-9cjqs" in namespace "gc-9864"
  Apr 19 15:59:40.172: INFO: Deleting pod "simpletest.rc-9w2bx" in namespace "gc-9864"
  Apr 19 15:59:40.212: INFO: Deleting pod "simpletest.rc-b7nz6" in namespace "gc-9864"
  Apr 19 15:59:40.238: INFO: Deleting pod "simpletest.rc-bjx2z" in namespace "gc-9864"
  Apr 19 15:59:40.274: INFO: Deleting pod "simpletest.rc-bkdwn" in namespace "gc-9864"
  Apr 19 15:59:40.319: INFO: Deleting pod "simpletest.rc-bnp9p" in namespace "gc-9864"
  Apr 19 15:59:40.396: INFO: Deleting pod "simpletest.rc-bqtfq" in namespace "gc-9864"
  E0419 15:59:40.397487      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:59:40.447: INFO: Deleting pod "simpletest.rc-bqwc6" in namespace "gc-9864"
  Apr 19 15:59:40.511: INFO: Deleting pod "simpletest.rc-bslbk" in namespace "gc-9864"
  Apr 19 15:59:40.548: INFO: Deleting pod "simpletest.rc-c675l" in namespace "gc-9864"
  Apr 19 15:59:40.618: INFO: Deleting pod "simpletest.rc-c6nc2" in namespace "gc-9864"
  Apr 19 15:59:40.663: INFO: Deleting pod "simpletest.rc-c7ft5" in namespace "gc-9864"
  Apr 19 15:59:40.734: INFO: Deleting pod "simpletest.rc-ck8kk" in namespace "gc-9864"
  Apr 19 15:59:40.789: INFO: Deleting pod "simpletest.rc-cnrlh" in namespace "gc-9864"
  Apr 19 15:59:40.830: INFO: Deleting pod "simpletest.rc-cwgk6" in namespace "gc-9864"
  Apr 19 15:59:40.875: INFO: Deleting pod "simpletest.rc-d2lpj" in namespace "gc-9864"
  Apr 19 15:59:40.934: INFO: Deleting pod "simpletest.rc-ddc54" in namespace "gc-9864"
  Apr 19 15:59:40.987: INFO: Deleting pod "simpletest.rc-ddprd" in namespace "gc-9864"
  Apr 19 15:59:41.040: INFO: Deleting pod "simpletest.rc-dldhg" in namespace "gc-9864"
  Apr 19 15:59:41.091: INFO: Deleting pod "simpletest.rc-dlr6k" in namespace "gc-9864"
  Apr 19 15:59:41.219: INFO: Deleting pod "simpletest.rc-fs7dn" in namespace "gc-9864"
  Apr 19 15:59:41.286: INFO: Deleting pod "simpletest.rc-fsd7k" in namespace "gc-9864"
  Apr 19 15:59:41.346: INFO: Deleting pod "simpletest.rc-fvqtm" in namespace "gc-9864"
  E0419 15:59:41.398089      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:59:41.411: INFO: Deleting pod "simpletest.rc-fwbfp" in namespace "gc-9864"
  Apr 19 15:59:41.483: INFO: Deleting pod "simpletest.rc-g58bp" in namespace "gc-9864"
  Apr 19 15:59:41.583: INFO: Deleting pod "simpletest.rc-g7pfj" in namespace "gc-9864"
  Apr 19 15:59:41.666: INFO: Deleting pod "simpletest.rc-gfqwj" in namespace "gc-9864"
  Apr 19 15:59:41.832: INFO: Deleting pod "simpletest.rc-gsrdv" in namespace "gc-9864"
  Apr 19 15:59:41.922: INFO: Deleting pod "simpletest.rc-hjnx8" in namespace "gc-9864"
  Apr 19 15:59:41.969: INFO: Deleting pod "simpletest.rc-hpw6c" in namespace "gc-9864"
  Apr 19 15:59:42.025: INFO: Deleting pod "simpletest.rc-hvj62" in namespace "gc-9864"
  Apr 19 15:59:42.089: INFO: Deleting pod "simpletest.rc-hxv6v" in namespace "gc-9864"
  Apr 19 15:59:42.176: INFO: Deleting pod "simpletest.rc-jmvbw" in namespace "gc-9864"
  Apr 19 15:59:42.209: INFO: Deleting pod "simpletest.rc-jpwwf" in namespace "gc-9864"
  Apr 19 15:59:42.261: INFO: Deleting pod "simpletest.rc-k2lgk" in namespace "gc-9864"
  Apr 19 15:59:42.295: INFO: Deleting pod "simpletest.rc-k7rzb" in namespace "gc-9864"
  Apr 19 15:59:42.363: INFO: Deleting pod "simpletest.rc-l4gnp" in namespace "gc-9864"
  E0419 15:59:42.398803      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:59:42.406: INFO: Deleting pod "simpletest.rc-l4tct" in namespace "gc-9864"
  Apr 19 15:59:42.458: INFO: Deleting pod "simpletest.rc-lf9gd" in namespace "gc-9864"
  Apr 19 15:59:42.482: INFO: Deleting pod "simpletest.rc-mw7rx" in namespace "gc-9864"
  Apr 19 15:59:42.556: INFO: Deleting pod "simpletest.rc-mztvr" in namespace "gc-9864"
  Apr 19 15:59:42.605: INFO: Deleting pod "simpletest.rc-nhlz2" in namespace "gc-9864"
  Apr 19 15:59:42.731: INFO: Deleting pod "simpletest.rc-p44p6" in namespace "gc-9864"
  Apr 19 15:59:42.807: INFO: Deleting pod "simpletest.rc-pdnlz" in namespace "gc-9864"
  Apr 19 15:59:42.879: INFO: Deleting pod "simpletest.rc-q4fcl" in namespace "gc-9864"
  Apr 19 15:59:42.914: INFO: Deleting pod "simpletest.rc-q67kt" in namespace "gc-9864"
  Apr 19 15:59:42.980: INFO: Deleting pod "simpletest.rc-q6mqf" in namespace "gc-9864"
  Apr 19 15:59:43.044: INFO: Deleting pod "simpletest.rc-q7j7d" in namespace "gc-9864"
  Apr 19 15:59:43.091: INFO: Deleting pod "simpletest.rc-q9vqp" in namespace "gc-9864"
  Apr 19 15:59:43.153: INFO: Deleting pod "simpletest.rc-qpgbx" in namespace "gc-9864"
  Apr 19 15:59:43.260: INFO: Deleting pod "simpletest.rc-rns5x" in namespace "gc-9864"
  Apr 19 15:59:43.291: INFO: Deleting pod "simpletest.rc-rq7kz" in namespace "gc-9864"
  Apr 19 15:59:43.344: INFO: Deleting pod "simpletest.rc-s5jkj" in namespace "gc-9864"
  E0419 15:59:43.399085      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:59:43.399: INFO: Deleting pod "simpletest.rc-s8cpk" in namespace "gc-9864"
  Apr 19 15:59:43.453: INFO: Deleting pod "simpletest.rc-skhcl" in namespace "gc-9864"
  Apr 19 15:59:43.488: INFO: Deleting pod "simpletest.rc-snf64" in namespace "gc-9864"
  Apr 19 15:59:43.534: INFO: Deleting pod "simpletest.rc-srwg8" in namespace "gc-9864"
  Apr 19 15:59:43.658: INFO: Deleting pod "simpletest.rc-t82vj" in namespace "gc-9864"
  Apr 19 15:59:43.757: INFO: Deleting pod "simpletest.rc-tgcwr" in namespace "gc-9864"
  Apr 19 15:59:43.842: INFO: Deleting pod "simpletest.rc-tm7tr" in namespace "gc-9864"
  Apr 19 15:59:43.881: INFO: Deleting pod "simpletest.rc-vgk86" in namespace "gc-9864"
  Apr 19 15:59:43.977: INFO: Deleting pod "simpletest.rc-vpp78" in namespace "gc-9864"
  Apr 19 15:59:44.018: INFO: Deleting pod "simpletest.rc-w5fzl" in namespace "gc-9864"
  Apr 19 15:59:44.062: INFO: Deleting pod "simpletest.rc-w7mll" in namespace "gc-9864"
  Apr 19 15:59:44.117: INFO: Deleting pod "simpletest.rc-wb7mj" in namespace "gc-9864"
  Apr 19 15:59:44.185: INFO: Deleting pod "simpletest.rc-xfdh2" in namespace "gc-9864"
  Apr 19 15:59:44.211: INFO: Deleting pod "simpletest.rc-xfs6q" in namespace "gc-9864"
  Apr 19 15:59:44.269: INFO: Deleting pod "simpletest.rc-xk7v4" in namespace "gc-9864"
  Apr 19 15:59:44.304: INFO: Deleting pod "simpletest.rc-z9pw6" in namespace "gc-9864"
  E0419 15:59:44.400224      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:59:44.461: INFO: Deleting pod "simpletest.rc-zb4wr" in namespace "gc-9864"
  Apr 19 15:59:44.503: INFO: Deleting pod "simpletest.rc-zcnm8" in namespace "gc-9864"
  Apr 19 15:59:44.548: INFO: Deleting pod "simpletest.rc-zfs48" in namespace "gc-9864"
  Apr 19 15:59:44.586: INFO: Deleting pod "simpletest.rc-zmdjs" in namespace "gc-9864"
  Apr 19 15:59:44.671: INFO: Deleting pod "simpletest.rc-zmk5n" in namespace "gc-9864"
  Apr 19 15:59:44.740: INFO: Deleting pod "simpletest.rc-zs8z2" in namespace "gc-9864"
  Apr 19 15:59:44.807: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-9864" for this suite. @ 04/19/24 15:59:44.862
• [47.609 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1798
  STEP: Creating a kubernetes client @ 04/19/24 15:59:44.932
  Apr 19 15:59:44.932: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename kubectl @ 04/19/24 15:59:44.935
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:59:44.998
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:59:45.003
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 04/19/24 15:59:45.006
  Apr 19 15:59:45.007: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-3722 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  Apr 19 15:59:45.214: INFO: stderr: ""
  Apr 19 15:59:45.214: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod is running @ 04/19/24 15:59:45.214
  E0419 15:59:45.400662      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:46.400910      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:47.401808      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:48.402238      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:49.403231      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 04/19/24 15:59:50.265
  Apr 19 15:59:50.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-3722 get pod e2e-test-httpd-pod -o json'
  E0419 15:59:50.404120      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:59:50.451: INFO: stderr: ""
  Apr 19 15:59:50.451: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2024-04-19T15:59:45Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-3722\",\n        \"resourceVersion\": \"10110\",\n        \"uid\": \"64bfd330-a0bd-4a6d-8942-9eb798bfb430\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-fvmjb\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"co4fe9zoo9oc-3\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-fvmjb\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-04-19T15:59:46Z\",\n                \"status\": \"True\",\n                \"type\": \"PodReadyToStartContainers\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-04-19T15:59:45Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-04-19T15:59:46Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-04-19T15:59:46Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-04-19T15:59:45Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"cri-o://1efed32e3a9eaab712b70a4ab745b04932c9810116dbfc990d66a2c031f2efc6\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2024-04-19T15:59:45Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.121.60\",\n        \"hostIPs\": [\n            {\n                \"ip\": \"192.168.121.60\"\n            }\n        ],\n        \"phase\": \"Running\",\n        \"podIP\": \"10.233.66.135\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.233.66.135\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2024-04-19T15:59:45Z\"\n    }\n}\n"
  STEP: replace the image in the pod @ 04/19/24 15:59:50.453
  Apr 19 15:59:50.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-3722 replace -f -'
  Apr 19 15:59:50.851: INFO: stderr: ""
  Apr 19 15:59:50.851: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.36.1-1 @ 04/19/24 15:59:50.851
  Apr 19 15:59:50.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-3722 delete pods e2e-test-httpd-pod'
  E0419 15:59:51.404913      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:52.405102      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 15:59:52.613: INFO: stderr: ""
  Apr 19 15:59:52.613: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Apr 19 15:59:52.613: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3722" for this suite. @ 04/19/24 15:59:52.627
• [7.706 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:52
  STEP: Creating a kubernetes client @ 04/19/24 15:59:52.64
  Apr 19 15:59:52.640: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename container-runtime @ 04/19/24 15:59:52.643
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 15:59:52.67
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 15:59:52.678
  STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' @ 04/19/24 15:59:52.698
  E0419 15:59:53.406403      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:54.406726      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:55.406581      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:56.407826      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:57.409316      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:58.409771      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 15:59:59.410153      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:00.410870      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:01.411303      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:02.411848      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:03.411674      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:04.412446      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:05.412615      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:06.412835      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:07.413156      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' @ 04/19/24 16:00:07.853
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition @ 04/19/24 16:00:07.863
  STEP: Container 'terminate-cmd-rpa': should get the expected 'State' @ 04/19/24 16:00:07.881
  STEP: Container 'terminate-cmd-rpa': should be possible to delete @ 04/19/24 16:00:07.881
  STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' @ 04/19/24 16:00:07.934
  E0419 16:00:08.413546      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:09.413984      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:10.414025      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' @ 04/19/24 16:00:10.993
  E0419 16:00:11.414513      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition @ 04/19/24 16:00:12.01
  STEP: Container 'terminate-cmd-rpof': should get the expected 'State' @ 04/19/24 16:00:12.031
  STEP: Container 'terminate-cmd-rpof': should be possible to delete @ 04/19/24 16:00:12.034
  STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' @ 04/19/24 16:00:12.098
  E0419 16:00:12.415734      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' @ 04/19/24 16:00:13.13
  E0419 16:00:13.416730      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:14.416963      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition @ 04/19/24 16:00:15.161
  STEP: Container 'terminate-cmd-rpn': should get the expected 'State' @ 04/19/24 16:00:15.182
  STEP: Container 'terminate-cmd-rpn': should be possible to delete @ 04/19/24 16:00:15.182
  Apr 19 16:00:15.257: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-1044" for this suite. @ 04/19/24 16:00:15.273
• [22.659 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:140
  STEP: Creating a kubernetes client @ 04/19/24 16:00:15.301
  Apr 19 16:00:15.301: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename emptydir @ 04/19/24 16:00:15.304
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:00:15.344
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:00:15.349
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 04/19/24 16:00:15.354
  E0419 16:00:15.417408      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:16.418101      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:17.418702      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:18.418838      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:00:19.397
  Apr 19 16:00:19.415: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-2f80da48-41cb-487b-93f0-1d1836187747 container test-container: <nil>
  E0419 16:00:19.419322      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod @ 04/19/24 16:00:19.441
  Apr 19 16:00:19.488: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4074" for this suite. @ 04/19/24 16:00:19.499
• [4.224 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:234
  STEP: Creating a kubernetes client @ 04/19/24 16:00:19.527
  Apr 19 16:00:19.527: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename resourcequota @ 04/19/24 16:00:19.53
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:00:19.558
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:00:19.562
  STEP: Counting existing ResourceQuota @ 04/19/24 16:00:19.567
  E0419 16:00:20.419686      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:21.420428      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:22.421372      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:23.421203      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:24.421831      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 04/19/24 16:00:24.578
  STEP: Ensuring resource quota status is calculated @ 04/19/24 16:00:24.589
  E0419 16:00:25.422091      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:26.422720      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Pod that fits quota @ 04/19/24 16:00:26.603
  STEP: Ensuring ResourceQuota status captures the pod usage @ 04/19/24 16:00:26.644
  E0419 16:00:27.422776      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:28.423137      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Not allowing a pod to be created that exceeds remaining quota @ 04/19/24 16:00:28.653
  STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) @ 04/19/24 16:00:28.66
  STEP: Ensuring a pod cannot update its resource requirements @ 04/19/24 16:00:28.668
  STEP: Ensuring attempts to update pod resource requirements did not change quota usage @ 04/19/24 16:00:28.679
  E0419 16:00:29.423404      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:30.423758      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 04/19/24 16:00:30.694
  STEP: Ensuring resource quota status released the pod usage @ 04/19/24 16:00:30.746
  E0419 16:00:31.424124      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:32.425444      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:00:32.763: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3226" for this suite. @ 04/19/24 16:00:32.78
• [13.274 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:147
  STEP: Creating a kubernetes client @ 04/19/24 16:00:32.805
  Apr 19 16:00:32.806: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename kubelet-test @ 04/19/24 16:00:32.809
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:00:32.844
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:00:32.854
  STEP: Waiting for pod completion @ 04/19/24 16:00:32.879
  E0419 16:00:33.426205      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:34.426526      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:35.427608      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:36.428606      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:00:36.926: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-3614" for this suite. @ 04/19/24 16:00:36.946
• [4.153 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:230
  STEP: Creating a kubernetes client @ 04/19/24 16:00:36.964
  Apr 19 16:00:36.965: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename emptydir @ 04/19/24 16:00:36.969
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:00:37.003
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:00:37.007
  STEP: Creating Pod @ 04/19/24 16:00:37.018
  E0419 16:00:37.428646      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:38.428854      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Reading file content from the nginx-container @ 04/19/24 16:00:39.058
  Apr 19 16:00:39.058: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-6258 PodName:pod-sharedvolume-56d70c59-6a0a-4a72-a5e3-e8edfbbe7b6c ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 16:00:39.058: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 16:00:39.061: INFO: ExecWithOptions: Clientset creation
  Apr 19 16:00:39.061: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/emptydir-6258/pods/pod-sharedvolume-56d70c59-6a0a-4a72-a5e3-e8edfbbe7b6c/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
  Apr 19 16:00:39.247: INFO: Exec stderr: ""
  Apr 19 16:00:39.248: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6258" for this suite. @ 04/19/24 16:00:39.26
• [2.315 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:130
  STEP: Creating a kubernetes client @ 04/19/24 16:00:39.28
  Apr 19 16:00:39.280: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename emptydir @ 04/19/24 16:00:39.284
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:00:39.322
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:00:39.329
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 04/19/24 16:00:39.337
  E0419 16:00:39.429563      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:40.430385      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:41.430594      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:42.431082      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:00:43.416
  Apr 19 16:00:43.426: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-cfc80d46-7843-4898-9b2b-3beea5049f35 container test-container: <nil>
  E0419 16:00:43.431370      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod @ 04/19/24 16:00:43.45
  Apr 19 16:00:43.496: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6845" for this suite. @ 04/19/24 16:00:43.514
• [4.257 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:300
  STEP: Creating a kubernetes client @ 04/19/24 16:00:43.544
  Apr 19 16:00:43.544: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename var-expansion @ 04/19/24 16:00:43.549
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:00:43.588
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:00:43.596
  STEP: creating the pod @ 04/19/24 16:00:43.604
  STEP: waiting for pod running @ 04/19/24 16:00:43.625
  E0419 16:00:44.433491      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:45.433142      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating a file in subpath @ 04/19/24 16:00:45.651
  Apr 19 16:00:45.660: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-985 PodName:var-expansion-3cf00388-c846-43e3-b0e8-6f11b8ae742e ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 16:00:45.661: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 16:00:45.666: INFO: ExecWithOptions: Clientset creation
  Apr 19 16:00:45.666: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/var-expansion-985/pods/var-expansion-3cf00388-c846-43e3-b0e8-6f11b8ae742e/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: test for file in mounted path @ 04/19/24 16:00:45.8
  Apr 19 16:00:45.811: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-985 PodName:var-expansion-3cf00388-c846-43e3-b0e8-6f11b8ae742e ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 16:00:45.812: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 16:00:45.814: INFO: ExecWithOptions: Clientset creation
  Apr 19 16:00:45.815: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/var-expansion-985/pods/var-expansion-3cf00388-c846-43e3-b0e8-6f11b8ae742e/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: updating the annotation value @ 04/19/24 16:00:45.914
  E0419 16:00:46.433115      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:00:46.448: INFO: Successfully updated pod "var-expansion-3cf00388-c846-43e3-b0e8-6f11b8ae742e"
  STEP: waiting for annotated pod running @ 04/19/24 16:00:46.449
  STEP: deleting the pod gracefully @ 04/19/24 16:00:46.461
  Apr 19 16:00:46.461: INFO: Deleting pod "var-expansion-3cf00388-c846-43e3-b0e8-6f11b8ae742e" in namespace "var-expansion-985"
  Apr 19 16:00:46.481: INFO: Wait up to 5m0s for pod "var-expansion-3cf00388-c846-43e3-b0e8-6f11b8ae742e" to be fully deleted
  E0419 16:00:47.435269      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:48.434884      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:49.451780      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:50.439562      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:51.440545      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:52.441162      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:53.442639      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:54.443800      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:55.442094      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:56.442756      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:57.443595      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:58.443984      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:00:59.444806      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:00.445026      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:01.445606      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:02.445881      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:03.446717      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:04.448091      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:05.448963      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:06.450032      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:07.450376      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:08.450685      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:09.451715      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:10.452691      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:11.453259      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:12.454457      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:13.455425      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:14.456360      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:15.456877      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:16.457981      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:17.458725      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:18.459246      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:01:18.692: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-985" for this suite. @ 04/19/24 16:01:18.706
• [35.179 seconds]
------------------------------
S
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:58
  STEP: Creating a kubernetes client @ 04/19/24 16:01:18.725
  Apr 19 16:01:18.725: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename configmap @ 04/19/24 16:01:18.732
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:01:18.769
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:01:18.777
  STEP: Creating configMap with name configmap-test-volume-4e80b4d8-71f4-41eb-8fa1-61609408d094 @ 04/19/24 16:01:18.785
  STEP: Creating a pod to test consume configMaps @ 04/19/24 16:01:18.796
  E0419 16:01:19.459270      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:20.459625      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:21.460476      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:22.460852      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:01:22.846
  Apr 19 16:01:22.855: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-configmaps-ae004f27-ce9f-40bc-91a6-de0cbb91dc8e container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/24 16:01:22.88
  Apr 19 16:01:22.909: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5206" for this suite. @ 04/19/24 16:01:22.923
• [4.215 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:132
  STEP: Creating a kubernetes client @ 04/19/24 16:01:22.945
  Apr 19 16:01:22.945: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename projected @ 04/19/24 16:01:22.95
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:01:22.987
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:01:22.992
  STEP: Creating the pod @ 04/19/24 16:01:22.999
  E0419 16:01:23.461886      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:24.462724      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:25.463137      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:01:25.588: INFO: Successfully updated pod "labelsupdatef913c06f-31b5-43b5-8508-d59aaf1c9bde"
  E0419 16:01:26.463899      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:27.463773      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:01:27.650: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2362" for this suite. @ 04/19/24 16:01:27.665
• [4.740 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:142
  STEP: Creating a kubernetes client @ 04/19/24 16:01:27.688
  Apr 19 16:01:27.688: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename crd-webhook @ 04/19/24 16:01:27.695
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:01:27.743
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:01:27.751
  STEP: Setting up server cert @ 04/19/24 16:01:27.761
  E0419 16:01:28.463750      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 04/19/24 16:01:29.095
  STEP: Deploying the custom resource conversion webhook pod @ 04/19/24 16:01:29.115
  STEP: Wait for the deployment to be ready @ 04/19/24 16:01:29.135
  Apr 19 16:01:29.152: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E0419 16:01:29.464162      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:30.464769      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 16:01:31.182
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 16:01:31.22
  E0419 16:01:31.465053      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:01:32.221: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Apr 19 16:01:32.244: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  E0419 16:01:32.465710      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:33.466127      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:34.467126      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 04/19/24 16:01:35.096
  STEP: v2 custom resource should be converted @ 04/19/24 16:01:35.112
  E0419 16:01:35.467547      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:01:35.744: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-2496" for this suite. @ 04/19/24 16:01:35.756
• [8.089 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Lease lease API should be available [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lease.go:73
  STEP: Creating a kubernetes client @ 04/19/24 16:01:35.778
  Apr 19 16:01:35.778: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename lease-test @ 04/19/24 16:01:35.781
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:01:35.848
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:01:35.854
  Apr 19 16:01:35.950: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "lease-test-9001" for this suite. @ 04/19/24 16:01:35.964
• [0.198 seconds]
------------------------------
[sig-auth] ServiceAccounts should mount projected service account token [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:277
  STEP: Creating a kubernetes client @ 04/19/24 16:01:35.976
  Apr 19 16:01:35.976: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename svcaccounts @ 04/19/24 16:01:35.979
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:01:36.004
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:01:36.008
  STEP: Creating a pod to test service account token:  @ 04/19/24 16:01:36.013
  E0419 16:01:36.467883      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:37.468758      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:38.469060      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:39.469307      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:01:40.056
  Apr 19 16:01:40.062: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod test-pod-48e22f35-aeda-455e-aded-8b29ef33b484 container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/24 16:01:40.085
  Apr 19 16:01:40.114: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-5298" for this suite. @ 04/19/24 16:01:40.138
• [4.176 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Servers with support for API chunking should support continue listing from the last key if the original version has been compacted away, though the list is inconsistent [Slow] [Conformance] [sig-api-machinery, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/chunking.go:144
  STEP: Creating a kubernetes client @ 04/19/24 16:01:40.153
  Apr 19 16:01:40.153: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename chunking @ 04/19/24 16:01:40.156
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:01:40.198
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:01:40.207
  STEP: creating a large number of resources @ 04/19/24 16:01:40.216
  E0419 16:01:40.469382      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:41.469529      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:42.470645      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:43.471267      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:44.471507      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:45.472104      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:46.473291      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:47.473975      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:48.474648      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:49.475161      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:50.475423      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:51.476072      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:52.476825      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:53.477175      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:54.477860      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:55.478757      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:56.479624      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:57.480633      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the first page @ 04/19/24 16:01:57.868
  Apr 19 16:01:57.919: INFO: Retrieved 40/40 results with rv 11648 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTE2NDgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page until the token expires @ 04/19/24 16:01:57.919
  E0419 16:01:58.480623      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:01:59.480928      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:00.481920      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:01.482216      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:02.482524      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:03.483087      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:04.483660      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:05.483916      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:06.484626      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:07.485119      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:08.485036      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:09.485383      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:10.485692      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:11.486728      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:12.487206      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:13.487867      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:14.488360      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:15.489250      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:16.489532      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:17.489704      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:02:17.942: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTE2NDgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:02:18.505814      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:19.499676      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:20.499422      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:21.500525      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:22.500764      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:23.502702      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:24.503152      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:25.504044      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:26.504370      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:27.504714      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:28.505689      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:29.509188      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:30.508458      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:31.509664      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:32.510536      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:33.511032      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:34.513695      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:35.512788      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:36.513440      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:37.513662      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:02:37.935: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTE2NDgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:02:38.513926      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:39.517114      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:40.517340      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:41.518256      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:42.518846      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:43.519218      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:44.520481      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:45.520790      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:46.520847      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:47.522029      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:48.522636      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:49.522871      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:50.524018      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:51.524369      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:52.524573      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:53.525735      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:54.526214      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:55.526983      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:56.527444      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:57.528495      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:02:57.941: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTE2NDgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:02:58.528699      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:02:59.529552      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:00.530573      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:01.530704      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:02.531009      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:03.531759      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:04.532456      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:05.533633      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:06.534464      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:07.534843      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:08.535422      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:09.536619      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:10.537273      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:11.537513      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:12.537824      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:13.538215      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:14.538779      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:15.539354      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:16.540140      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:17.540690      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:03:17.939: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTE2NDgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:03:18.541035      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:19.541704      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:20.541731      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:21.541907      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:22.542588      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:23.542684      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:24.543020      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:25.543145      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:26.544064      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:27.544458      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:28.545657      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:29.546810      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:30.546894      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:31.547408      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:32.547569      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:33.548546      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:34.549485      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:35.549892      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:36.550204      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:37.550641      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:03:37.943: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTE2NDgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:03:38.551717      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:39.552116      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:40.552278      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:41.553346      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:42.553457      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:43.554045      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:44.554975      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:45.554721      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:46.554984      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:47.555921      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:48.557114      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:49.557775      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:50.557939      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:51.558893      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:52.559202      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:53.560068      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:54.560387      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:55.560398      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:56.561235      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:57.564038      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:03:57.948: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTE2NDgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:03:58.563409      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:03:59.564627      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:00.564181      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:01.565279      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:02.566389      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:03.566967      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:04.567438      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:05.568230      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:06.568714      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:07.568923      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:08.570014      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:09.570422      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:10.570734      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:11.571483      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:12.571335      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:13.571750      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:14.571965      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:15.572372      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:16.572670      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:17.573079      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:04:17.936: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTE2NDgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:04:18.573577      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:19.574370      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:20.574455      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:21.577495      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:22.577704      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:23.578867      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:24.580709      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:25.580803      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:26.580978      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:27.581300      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:28.586050      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:29.591052      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:30.586669      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:31.587677      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:32.588327      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:33.589280      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:34.589735      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:35.590188      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:36.590960      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:37.591265      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:04:37.942: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTE2NDgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:04:38.591278      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:39.592264      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:40.592564      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:41.593552      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:42.594002      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:43.594706      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:44.595239      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:45.595591      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:46.596246      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:47.596601      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:48.596827      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:49.597082      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:50.597284      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:51.598393      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:52.599013      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:53.599093      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:54.599286      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:55.599658      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:56.599957      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:57.600328      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:04:57.940: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTE2NDgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:04:58.600586      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:04:59.601321      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:00.602027      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:01.602195      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:02.602627      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:03.603171      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:04.603379      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:05.604022      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:06.604283      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:07.604778      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:08.605148      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:09.605242      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:10.605386      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:11.606592      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:12.606745      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:13.607012      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:14.607152      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:15.607341      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:16.607652      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:17.607958      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:05:17.937: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTE2NDgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:05:18.608651      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:19.608871      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:20.609189      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:21.609313      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:22.609550      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:23.609998      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:24.610253      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:25.610415      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:26.610606      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:27.610981      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:28.612206      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:29.612538      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:30.612697      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:31.613011      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:32.613400      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:33.614550      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:34.615282      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:35.619609      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:36.617305      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:37.618570      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:05:37.940: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTE2NDgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:05:38.618868      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:39.618971      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:40.619761      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:41.620391      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:42.620856      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:43.621244      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:44.622419      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:45.625235      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:46.624196      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:47.624758      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:48.625949      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:49.626617      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:50.627047      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:51.645158      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:52.632704      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:53.632806      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:54.633215      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:55.633910      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:56.634609      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:57.634855      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:05:57.944: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTE2NDgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:05:58.635525      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:05:59.635927      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:00.636061      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:01.638794      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:02.637841      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:03.638188      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:04.638597      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:05.639611      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:06.640043      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:07.640691      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:08.642124      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:09.641170      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:10.641616      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:11.642530      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:12.642772      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:13.643779      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:14.644169      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:15.644716      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:16.645353      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:17.645953      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:06:17.935: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTE2NDgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:06:18.646728      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:19.647861      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:20.648477      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:21.649602      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:22.650063      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:23.651250      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:24.651817      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:25.652505      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:26.652954      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:27.653595      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:28.654568      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:29.654876      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:30.655481      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:31.656576      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:32.657331      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:33.658332      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:34.658511      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:35.659011      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:36.660292      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:37.661026      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:06:37.943: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTE2NDgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:06:38.661920      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:39.662700      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:40.663004      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:41.664015      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:42.664291      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:43.665179      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:44.665764      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:45.666550      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:46.666722      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:47.666937      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:48.667117      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:49.667407      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:50.667466      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:51.669013      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:52.669538      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:53.670454      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:54.670586      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:55.671136      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:56.671706      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:57.672282      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:06:57.938: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTE2NDgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:06:58.672477      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:06:59.673256      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:00.674227      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:01.675436      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:02.675503      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:03.675709      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:04.675976      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:05.676366      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:06.676516      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:07.676880      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:08.677068      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:09.677386      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:10.677728      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:11.678860      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:12.679568      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:13.679900      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:14.680588      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:15.680911      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:16.681341      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:17.681571      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:07:17.953: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTE2NDgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:07:18.682730      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:19.683563      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:20.684232      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:21.684430      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:22.684838      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:23.685625      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:24.686242      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:25.686561      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:26.687736      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:27.688893      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:28.689134      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:29.690023      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:30.690004      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:31.690350      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:32.690814      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:33.691136      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:34.691521      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:35.691679      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:36.692076      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:37.692328      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:07:37.938: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTE2NDgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:07:38.692805      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:39.693348      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:40.693712      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:41.694561      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:42.694561      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:43.694834      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:44.695303      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:45.697287      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:46.707796      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:47.698963      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:48.699940      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:49.700959      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:50.700753      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:51.701045      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:52.704459      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:53.703044      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:54.703337      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:55.703897      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:56.705238      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:57.710767      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:07:57.949: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTE2NDgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:07:58.706786      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:07:59.707711      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:00.708003      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:01.708177      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:02.709965      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:03.710205      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:04.712024      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:05.711255      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:06.712081      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:07.712763      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:08.713183      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:09.715270      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:10.713868      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:11.714401      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:12.714652      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:13.717407      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:14.715378      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:15.715839      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:16.716138      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:17.716440      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:08:17.945: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTE2NDgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:08:18.716727      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:19.717034      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:20.717692      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:21.718131      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:22.718658      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:23.718924      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:24.719271      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:25.719548      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:26.719675      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:27.720036      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:28.720328      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:29.720660      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:30.720820      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:31.721207      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:32.721424      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:33.721762      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:34.721871      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:35.722261      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:36.722405      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:37.723035      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:08:37.937: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTE2NDgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:08:38.724152      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:39.724725      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:40.725594      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:41.725552      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:42.725695      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:43.726595      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:44.726835      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:45.727171      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:46.727368      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:47.728081      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:48.728347      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:49.728716      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:50.728812      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:51.729128      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:52.729452      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:53.729618      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:54.729795      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:55.730163      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:56.730465      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:57.731318      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:08:57.941: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTE2NDgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:08:58.731707      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:08:59.732643      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:00.733394      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:01.733214      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:02.733328      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:03.733633      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:04.733938      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:05.734392      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:06.735307      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:07.735699      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:08.735977      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:09.736293      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:10.736985      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:11.737058      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:12.737441      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:13.737602      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:14.737850      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:15.738060      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:16.738428      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:17.739296      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:09:17.942: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTE2NDgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:09:18.739420      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:19.739826      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:20.740112      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:21.741329      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:22.741702      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:23.741745      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:24.742070      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:25.742600      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:26.742850      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:27.743295      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:28.744235      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:29.745025      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:30.745520      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:31.746566      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:32.746971      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:33.748243      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:34.749057      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:35.749150      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:36.749732      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:37.750695      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:09:37.945: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTE2NDgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:09:38.750971      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:39.751267      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:40.751845      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:41.752175      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:42.752594      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:43.753169      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:44.753706      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:45.754418      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:46.754745      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:47.755621      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:48.756319      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:49.756305      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:50.756873      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:51.757650      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:52.757680      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:53.757835      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:54.757951      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:55.758150      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:56.758577      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:57.758855      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:09:57.946: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTE2NDgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:09:58.759821      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:09:59.761030      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:00.761949      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:01.762799      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:02.762727      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:03.763001      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:04.763299      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:05.763794      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:06.763895      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:07.764241      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:08.764591      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:09.764997      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:10.765800      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:11.767858      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:12.768046      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:13.768407      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:14.769032      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:15.769130      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:16.769498      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:17.770400      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:10:17.935: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTE2NDgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:10:18.771006      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:19.771189      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:20.771593      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:21.771718      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:22.772774      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:23.773833      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:24.774489      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:25.774716      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:26.774840      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:27.775978      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:28.776053      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:29.776583      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:30.777249      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:31.777327      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:32.777584      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:33.777802      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:34.778159      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:35.778549      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:36.779534      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:37.781288      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:10:37.945: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTE2NDgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:10:38.781078      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:39.781553      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:40.781575      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:41.782628      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:42.782812      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:43.783169      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:44.783522      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:45.783748      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:46.783899      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:47.784328      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:48.784692      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:49.785018      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:50.785169      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:51.785439      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:52.785749      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:53.788847      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:54.787557      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:55.787983      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:56.788532      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:57.789166      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:10:57.935: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTE2NDgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:10:58.789290      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:10:59.790390      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:00.790760      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:01.791783      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:02.794152      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:03.792609      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:04.792887      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:05.793260      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:06.793383      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:07.799042      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:08.794223      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:09.794513      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:10.795026      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:11.795156      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:12.796070      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:13.796602      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:14.796547      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:15.796940      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:16.797141      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:17.799179      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:11:17.951: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTE2NDgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:11:18.797936      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:19.798720      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:20.799427      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:21.799608      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:22.799846      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:23.800092      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:24.800567      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:25.801388      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:26.801634      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:27.802518      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:28.803338      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:29.803796      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:30.804120      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:31.804291      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:32.804956      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:33.805261      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:34.805544      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:35.806088      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:36.806431      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:37.807242      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:11:37.939: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTE2NDgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0419 16:11:38.807361      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:39.808141      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:40.807989      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:41.808362      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:42.808998      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:43.810106      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:44.810769      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:45.811026      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:46.811280      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:47.811820      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:48.812519      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:49.813458      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:50.813206      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:51.813391      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:52.814199      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:53.814105      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:54.814198      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:55.815044      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:56.815115      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:57.815354      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:11:57.935: INFO: got error The provided continue parameter is too old to display a consistent list result. You can start a new list without the continue parameter, or use the continue token in this response to retrieve the remainder of the results. Continuing with the provided token results in an inconsistent list - objects that were created, modified, or deleted between the time the first chunk was returned and now may show up in the list.
  Apr 19 16:11:57.935: INFO: Retrieved inconsistent continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6LTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page again with the token received with the error message @ 04/19/24 16:11:57.936
  STEP: retrieving all remaining pages @ 04/19/24 16:11:57.958
  Apr 19 16:11:57.972: INFO: Retrieved 40/40 results with rv 12662 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI2NjIsInN0YXJ0IjoidGVtcGxhdGUtMDExOVx1MDAwMCJ9
  Apr 19 16:11:57.985: INFO: Retrieved 40/40 results with rv 12662 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI2NjIsInN0YXJ0IjoidGVtcGxhdGUtMDE1OVx1MDAwMCJ9
  Apr 19 16:11:58.004: INFO: Retrieved 40/40 results with rv 12662 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI2NjIsInN0YXJ0IjoidGVtcGxhdGUtMDE5OVx1MDAwMCJ9
  Apr 19 16:11:58.024: INFO: Retrieved 40/40 results with rv 12662 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI2NjIsInN0YXJ0IjoidGVtcGxhdGUtMDIzOVx1MDAwMCJ9
  Apr 19 16:11:58.038: INFO: Retrieved 40/40 results with rv 12662 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI2NjIsInN0YXJ0IjoidGVtcGxhdGUtMDI3OVx1MDAwMCJ9
  Apr 19 16:11:58.055: INFO: Retrieved 40/40 results with rv 12662 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI2NjIsInN0YXJ0IjoidGVtcGxhdGUtMDMxOVx1MDAwMCJ9
  Apr 19 16:11:58.072: INFO: Retrieved 40/40 results with rv 12662 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI2NjIsInN0YXJ0IjoidGVtcGxhdGUtMDM1OVx1MDAwMCJ9
  Apr 19 16:11:58.082: INFO: Retrieved 40/40 results with rv 12662 and continue 
  Apr 19 16:11:58.083: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-7069" for this suite. @ 04/19/24 16:11:58.097
• [617.961 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:108
  STEP: Creating a kubernetes client @ 04/19/24 16:11:58.117
  Apr 19 16:11:58.117: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename pod-network-test @ 04/19/24 16:11:58.122
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:11:58.161
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:11:58.167
  STEP: Performing setup for networking test in namespace pod-network-test-3979 @ 04/19/24 16:11:58.174
  STEP: creating a selector @ 04/19/24 16:11:58.175
  STEP: Creating the service pods in kubernetes @ 04/19/24 16:11:58.175
  Apr 19 16:11:58.175: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0419 16:11:58.816163      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:11:59.816486      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:00.817121      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:01.817238      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:02.818470      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:03.818543      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:04.818838      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:05.819068      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:06.819269      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:07.820292      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:08.820757      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:09.821680      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:10.822556      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:11.822851      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:12.822912      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:13.823410      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:14.824035      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:15.824294      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:16.824657      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:17.824867      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:18.825785      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:19.826209      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 04/19/24 16:12:20.44
  E0419 16:12:20.826998      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:21.827783      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:12:22.536: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Apr 19 16:12:22.536: INFO: Going to poll 10.233.64.75 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  Apr 19 16:12:22.582: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.64.75:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3979 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 16:12:22.582: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 16:12:22.584: INFO: ExecWithOptions: Clientset creation
  Apr 19 16:12:22.584: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-3979/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.64.75%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Apr 19 16:12:22.788: INFO: Found all 1 expected endpoints: [netserver-0]
  Apr 19 16:12:22.788: INFO: Going to poll 10.233.65.78 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  Apr 19 16:12:22.797: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.65.78:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3979 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 16:12:22.797: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 16:12:22.799: INFO: ExecWithOptions: Clientset creation
  Apr 19 16:12:22.800: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-3979/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.65.78%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0419 16:12:22.828203      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:12:22.965: INFO: Found all 1 expected endpoints: [netserver-1]
  Apr 19 16:12:22.965: INFO: Going to poll 10.233.66.148 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  Apr 19 16:12:22.976: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.66.148:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3979 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 16:12:22.976: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 16:12:22.979: INFO: ExecWithOptions: Clientset creation
  Apr 19 16:12:22.979: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-3979/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.66.148%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Apr 19 16:12:23.137: INFO: Found all 1 expected endpoints: [netserver-2]
  Apr 19 16:12:23.137: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-3979" for this suite. @ 04/19/24 16:12:23.15
• [25.050 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:639
  STEP: Creating a kubernetes client @ 04/19/24 16:12:23.169
  Apr 19 16:12:23.169: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename gc @ 04/19/24 16:12:23.173
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:12:23.221
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:12:23.231
  STEP: create the rc @ 04/19/24 16:12:23.249
  W0419 16:12:23.260824      13 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0419 16:12:23.828587      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:24.828981      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:25.830801      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:26.830971      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:27.831748      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:28.831751      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 04/19/24 16:12:29.286
  STEP: wait for the rc to be deleted @ 04/19/24 16:12:29.442
  E0419 16:12:29.832174      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:12:30.509: INFO: 81 pods remaining
  Apr 19 16:12:30.509: INFO: 80 pods has nil DeletionTimestamp
  Apr 19 16:12:30.509: INFO: 
  E0419 16:12:30.832486      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:12:31.484: INFO: 69 pods remaining
  Apr 19 16:12:31.484: INFO: 69 pods has nil DeletionTimestamp
  Apr 19 16:12:31.484: INFO: 
  E0419 16:12:31.832757      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:12:32.495: INFO: 60 pods remaining
  Apr 19 16:12:32.495: INFO: 60 pods has nil DeletionTimestamp
  Apr 19 16:12:32.495: INFO: 
  E0419 16:12:32.832792      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:12:33.558: INFO: 42 pods remaining
  Apr 19 16:12:33.558: INFO: 41 pods has nil DeletionTimestamp
  Apr 19 16:12:33.558: INFO: 
  E0419 16:12:33.832875      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:12:34.479: INFO: 29 pods remaining
  Apr 19 16:12:34.479: INFO: 29 pods has nil DeletionTimestamp
  Apr 19 16:12:34.479: INFO: 
  E0419 16:12:34.835063      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:12:35.499: INFO: 19 pods remaining
  Apr 19 16:12:35.499: INFO: 18 pods has nil DeletionTimestamp
  Apr 19 16:12:35.499: INFO: 
  E0419 16:12:35.835118      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 04/19/24 16:12:36.48
  E0419 16:12:36.835995      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:12:36.966: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 19 16:12:36.970: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-4622" for this suite. @ 04/19/24 16:12:36.993
• [13.850 seconds]
------------------------------
[sig-apps] Deployment deployment should support rollover [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:132
  STEP: Creating a kubernetes client @ 04/19/24 16:12:37.019
  Apr 19 16:12:37.019: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename deployment @ 04/19/24 16:12:37.021
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:12:37.105
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:12:37.119
  Apr 19 16:12:37.167: INFO: Pod name rollover-pod: Found 0 pods out of 1
  E0419 16:12:37.836218      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:38.836428      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:39.837073      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:40.837205      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:41.837543      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:12:42.175: INFO: Pod name rollover-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/19/24 16:12:42.175
  Apr 19 16:12:42.175: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
  E0419 16:12:42.837724      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:43.838531      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:12:44.183: INFO: Creating deployment "test-rollover-deployment"
  Apr 19 16:12:44.206: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
  E0419 16:12:44.838779      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:45.839114      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:12:46.224: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
  Apr 19 16:12:46.243: INFO: Ensure that both replica sets have 1 created replica
  Apr 19 16:12:46.259: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
  Apr 19 16:12:46.280: INFO: Updating deployment test-rollover-deployment
  Apr 19 16:12:46.280: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
  E0419 16:12:46.839296      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:47.840356      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:12:48.298: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
  Apr 19 16:12:48.315: INFO: Make sure deployment "test-rollover-deployment" is complete
  Apr 19 16:12:48.332: INFO: all replica sets need to contain the pod-template-hash label
  Apr 19 16:12:48.333: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 12, 44, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 12, 44, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 12, 47, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 12, 44, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 16:12:48.840552      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:49.840940      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:12:50.355: INFO: all replica sets need to contain the pod-template-hash label
  Apr 19 16:12:50.356: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 12, 44, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 12, 44, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 12, 47, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 12, 44, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 16:12:50.841757      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:51.843165      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:12:52.353: INFO: all replica sets need to contain the pod-template-hash label
  Apr 19 16:12:52.353: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 12, 44, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 12, 44, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 12, 47, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 12, 44, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 16:12:52.843854      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:53.846235      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:12:54.356: INFO: all replica sets need to contain the pod-template-hash label
  Apr 19 16:12:54.356: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 12, 44, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 12, 44, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 12, 47, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 12, 44, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 16:12:54.846768      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:55.847753      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:12:56.355: INFO: all replica sets need to contain the pod-template-hash label
  Apr 19 16:12:56.356: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 12, 44, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 12, 44, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 12, 47, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 12, 44, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 16:12:56.848950      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:12:57.849341      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:12:58.358: INFO: 
  Apr 19 16:12:58.359: INFO: Ensure that both old replica sets have no replicas
  Apr 19 16:12:58.398: INFO: Deployment "test-rollover-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3948",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "aacea71f-d4d1-44b4-bb48-624abffc2fae",
      ResourceVersion: (string) (len=5) "14863",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849139964,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139966,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000040  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000050  2c 22 66 3a 70 72 6f 67  72 65 73 73 44 65 61 64  |,"f:progressDead|
              00000060  6c 69 6e 65 53 65 63 6f  6e 64 73 22 3a 7b 7d 2c  |lineSeconds":{},|
              00000070  22 66 3a 72 65 70 6c 69  63 61 73 22 3a 7b 7d 2c  |"f:replicas":{},|
              00000080  22 66 3a 72 65 76 69 73  69 6f 6e 48 69 73 74 6f  |"f:revisionHisto|
              00000090  72 79 4c 69 6d 69 74 22  3a 7b 7d 2c 22 66 3a 73  |ryLimit":{},"f:s|
              000000a0  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 73  |elector":{},"f:s|
              000000b0  74 72 61 74 65 67 79 22  3a 7b 22 66 3a 72 6f 6c  |trategy":{"f:rol|
              000000c0  6c 69 6e 67 55 70 64 61  74 65 22 3a 7b 22 2e 22  |lingUpdate":{"."|
              000000d0  3a 7b 7d 2c 22 66 3a 6d  61 78 53 75 72 67 65 22  |:{},"f:maxSurge"|
              000000e0  3a 7b 7d 2c 22 66 3a 6d  61 78 55 6e 61 76 61 69  |:{},"f:maxUnavai|
              000000f0  6c 61 62 6c 65 22 3a 7b  7d 7d 2c 22 66 3a 74 79  |lable":{}},"f:ty|
              00000100  70 65 22 3a 7b 7d 7d 2c  22 66 3a 74 65 6d 70 6c  |pe":{}},"f:templ|
              00000110  61 74 65 22 3a 7b 22 66  3a 6d 65 74 61 64 61 74  |ate":{"f:metadat|
              00000120  61 22 3a 7b 22 66 3a 6c  61 62 65 6c 73 22 3a 7b  |a":{"f:labels":{|
              00000130  22 2e 22 3a 7b 7d 2c 22  66 3a 6e 61 6d 65 22 3a  |".":{},"f:name":|
              00000140  7b 7d 7d 7d 2c 22 66 3a  73 70 65 63 22 3a 7b 22  |{}}},"f:spec":{"|
              00000150  66 3a 63 6f 6e 74 61 69  6e 65 72 73 22 3a 7b 22  |f:containers":{"|
              00000160  6b 3a 7b 5c 22 6e 61 6d  65 5c 22 3a 5c 22 61 67  |k:{\"name\":\"ag|
              00000170  6e 68 6f 73 74 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |nhost\"}":{".":{|
              00000180  7d 2c 22 66 3a 69 6d 61  67 65 22 3a 7b 7d 2c 22  |},"f:image":{},"|
              00000190  66 3a 69 6d 61 67 65 50  75 6c 6c 50 6f 6c 69 63  |f:imagePullPolic|
              000001a0  79 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |y":{},"f:name":{|
              000001b0  7d 2c 22 66 3a 72 65 73  6f 75 72 63 65 73 22 3a  |},"f:resources":|
              000001c0  7b 7d 2c 22 66 3a 73 65  63 75 72 69 74 79 43 6f  |{},"f:securityCo|
              000001d0  6e 74 65 78 74 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ntext":{},"f:ter|
              000001e0  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000001f0  61 74 68 22 3a 7b 7d 2c  22 66 3a 74 65 72 6d 69  |ath":{},"f:termi|
              00000200  6e 61 74 69 6f 6e 4d 65  73 73 61 67 65 50 6f 6c  |nationMessagePol|
              00000210  69 63 79 22 3a 7b 7d 7d  7d 2c 22 66 3a 64 6e 73  |icy":{}}},"f:dns|
              00000220  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 72 65  |Policy":{},"f:re|
              00000230  73 74 61 72 74 50 6f 6c  69 63 79 22 3a 7b 7d 2c  |startPolicy":{},|
              00000240  22 66 3a 73 63 68 65 64  75 6c 65 72 4e 61 6d 65  |"f:schedulerName|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 47 72 61 63 65 50  |erminationGraceP|
              00000280  65 72 69 6f 64 53 65 63  6f 6e 64 73 22 3a 7b 7d  |eriodSeconds":{}|
              00000290  7d 7d 7d 7d                                       |}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139977,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 0,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 1,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 10,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139964,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139964,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139977,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139964,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=77) "ReplicaSet \"test-rollover-deployment-68774655d5\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Apr 19 16:12:58.424: INFO: New ReplicaSet "test-rollover-deployment-68774655d5" of Deployment "test-rollover-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-68774655d5",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3948",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "66d3a850-02d6-4898-8a2f-a9acd9101f7c",
      ResourceVersion: (string) (len=5) "14853",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849139966,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "68774655d5"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "aacea71f-d4d1-44b4-bb48-624abffc2fae",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139966,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=806) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 61 61 63 65 61 37  31 66 2d 64 34 64 31 2d  |\"aacea71f-d4d1-|
              00000120  34 34 62 34 2d 62 62 34  38 2d 36 32 34 61 62 66  |44b4-bb48-624abf|
              00000130  66 63 32 66 61 65 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |fc2fae\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  61 67 6e 68 6f 73 74 5c  22 7d 22 3a 7b 22 2e 22  |agnhost\"}":{"."|
              00000210  3a 7b 7d 2c 22 66 3a 69  6d 61 67 65 22 3a 7b 7d  |:{},"f:image":{}|
              00000220  2c 22 66 3a 69 6d 61 67  65 50 75 6c 6c 50 6f 6c  |,"f:imagePullPol|
              00000230  69 63 79 22 3a 7b 7d 2c  22 66 3a 6e 61 6d 65 22  |icy":{},"f:name"|
              00000240  3a 7b 7d 2c 22 66 3a 72  65 73 6f 75 72 63 65 73  |:{},"f:resources|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 4d 65 73 73 61 67  |erminationMessag|
              00000280  65 50 61 74 68 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ePath":{},"f:ter|
              00000290  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000002a0  6f 6c 69 63 79 22 3a 7b  7d 7d 7d 2c 22 66 3a 64  |olicy":{}}},"f:d|
              000002b0  6e 73 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |nsPolicy":{},"f:|
              000002c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000002d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000002e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000002f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000300  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000310  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000320  7b 7d 7d 7d 7d 7d                                 |{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139977,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "68774655d5"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "68774655d5"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 19 16:12:58.428: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
  Apr 19 16:12:58.429: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3948",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4aefe729-00bd-4473-be3a-8df43a612b13",
      ResourceVersion: (string) (len=5) "14862",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849139957,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=3) "pod": (string) (len=5) "httpd",
        (string) (len=4) "name": (string) (len=12) "rollover-pod"
      },
      Annotations: (map[string]string) (len=2) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "aacea71f-d4d1-44b4-bb48-624abffc2fae",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=467) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  73 65 6c 65 63 74 6f 72  |ec":{"f:selector|
              00000050  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000060  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000070  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000080  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000090  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000a0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000b0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000c0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000d0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000e0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              000000f0  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000100  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000110  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000120  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000130  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000140  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000150  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000160  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000170  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000180  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              00000190  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001a0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001b0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001c0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001d0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139977,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=249) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 7d 2c 22 66  3a 6f 77 6e 65 72 52 65  |":{}},"f:ownerRe|
              00000090  66 65 72 65 6e 63 65 73  22 3a 7b 22 2e 22 3a 7b  |ferences":{".":{|
              000000a0  7d 2c 22 6b 3a 7b 5c 22  75 69 64 5c 22 3a 5c 22  |},"k:{\"uid\":\"|
              000000b0  61 61 63 65 61 37 31 66  2d 64 34 64 31 2d 34 34  |aacea71f-d4d1-44|
              000000c0  62 34 2d 62 62 34 38 2d  36 32 34 61 62 66 66 63  |b4-bb48-624abffc|
              000000d0  32 66 61 65 5c 22 7d 22  3a 7b 7d 7d 7d 2c 22 66  |2fae\"}":{}}},"f|
              000000e0  3a 73 70 65 63 22 3a 7b  22 66 3a 72 65 70 6c 69  |:spec":{"f:repli|
              000000f0  63 61 73 22 3a 7b 7d 7d  7d                       |cas":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139977,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=3) "pod": (string) (len=5) "httpd",
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 19 16:12:58.432: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-664fc6c874",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3948",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "28d63c2e-74b2-4231-b9d5-1332d1957657",
      ResourceVersion: (string) (len=5) "14751",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849139964,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "aacea71f-d4d1-44b4-bb48-624abffc2fae",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139966,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=810) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 61 61 63 65 61 37  31 66 2d 64 34 64 31 2d  |\"aacea71f-d4d1-|
              00000120  34 34 62 34 2d 62 62 34  38 2d 36 32 34 61 62 66  |44b4-bb48-624abf|
              00000130  66 63 32 66 61 65 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |fc2fae\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  72 65 64 69 73 2d 73 6c  61 76 65 5c 22 7d 22 3a  |redis-slave\"}":|
              00000210  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000220  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000230  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000240  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000250  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000260  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000270  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000280  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              00000290  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000002a0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000002b0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000002c0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000002d0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000002e0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              000002f0  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000300  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000310  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000320  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139966,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=11) "redis-slave",
              Image: (string) (len=47) "gcr.io/google_samples/gb-redisslave:nonexistent",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 19 16:12:58.443: INFO: Pod "test-rollover-deployment-68774655d5-7627x" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rollover-deployment-68774655d5-7627x",
      GenerateName: (string) (len=36) "test-rollover-deployment-68774655d5-",
      Namespace: (string) (len=15) "deployment-3948",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "76a66daa-fbd4-4fd3-aa0e-46c65316c504",
      ResourceVersion: (string) (len=5) "14830",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849139966,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "68774655d5"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=35) "test-rollover-deployment-68774655d5",
          UID: (types.UID) (len=36) "66d3a850-02d6-4898-8a2f-a9acd9101f7c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139966,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 36 36  64 33 61 38 35 30 2d 30  |d\":\"66d3a850-0|
              00000090  32 64 36 2d 34 38 39 38  2d 38 61 32 66 2d 61 39  |2d6-4898-8a2f-a9|
              000000a0  61 63 64 39 31 30 31 66  37 63 5c 22 7d 22 3a 7b  |acd9101f7c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139967,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 36 2e  31 38 38 5c 22 7d 22 3a  |.233.66.188\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-xbhkr",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-xbhkr",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "co4fe9zoo9oc-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139967,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139966,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139967,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139967,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849139966,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.60",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.60"
        }
      },
      PodIP: (string) (len=13) "10.233.66.188",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.66.188"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849139966,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63849139966,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:c9997bf8d2e223d7d2a0078dcfb11a653e9b16cf09418829ec03e1d57ca9628a",
          ContainerID: (string) (len=72) "cri-o://2866b1854626a2cc675437c44fb7d283b04b49a5486968b08967fd102812430f",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 19 16:12:58.461: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-3948" for this suite. @ 04/19/24 16:12:58.477
• [21.474 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:177
  STEP: Creating a kubernetes client @ 04/19/24 16:12:58.494
  Apr 19 16:12:58.494: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename crd-webhook @ 04/19/24 16:12:58.521
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:12:58.56
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:12:58.565
  STEP: Setting up server cert @ 04/19/24 16:12:58.572
  E0419 16:12:58.849125      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 04/19/24 16:12:59.33
  STEP: Deploying the custom resource conversion webhook pod @ 04/19/24 16:12:59.356
  STEP: Wait for the deployment to be ready @ 04/19/24 16:12:59.39
  Apr 19 16:12:59.417: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E0419 16:12:59.852316      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:00.852599      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 16:13:01.446
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 16:13:01.471
  E0419 16:13:01.852084      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:13:02.472: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Apr 19 16:13:02.505: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  E0419 16:13:02.851798      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:03.852487      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:04.853543      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 04/19/24 16:13:05.391
  STEP: Create a v2 custom resource @ 04/19/24 16:13:05.428
  STEP: List CRs in v1 @ 04/19/24 16:13:05.758
  STEP: List CRs in v2 @ 04/19/24 16:13:05.767
  E0419 16:13:05.854293      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:13:06.431: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-7640" for this suite. @ 04/19/24 16:13:06.452
• [7.976 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:48
  STEP: Creating a kubernetes client @ 04/19/24 16:13:06.498
  Apr 19 16:13:06.498: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename configmap @ 04/19/24 16:13:06.535
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:13:06.571
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:13:06.576
  STEP: Creating configMap with name configmap-test-volume-e330edf4-8014-4e1a-b5ff-5e2f0ddf66c6 @ 04/19/24 16:13:06.581
  STEP: Creating a pod to test consume configMaps @ 04/19/24 16:13:06.59
  E0419 16:13:06.854555      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:07.854986      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:08.856228      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:09.856853      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:13:10.652
  Apr 19 16:13:10.664: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-configmaps-349fa628-7536-43ce-866a-18e12c5fcfcb container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/24 16:13:10.722
  Apr 19 16:13:10.768: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4367" for this suite. @ 04/19/24 16:13:10.783
• [4.323 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services should be able to create a functioning NodePort service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1280
  STEP: Creating a kubernetes client @ 04/19/24 16:13:10.806
  Apr 19 16:13:10.806: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename services @ 04/19/24 16:13:10.813
  E0419 16:13:10.858204      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:13:10.871
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:13:10.879
  STEP: creating service nodeport-test with type=NodePort in namespace services-4879 @ 04/19/24 16:13:10.887
  STEP: creating replication controller nodeport-test in namespace services-4879 @ 04/19/24 16:13:10.932
  I0419 16:13:10.945472      13 runners.go:197] Created replication controller with name: nodeport-test, namespace: services-4879, replica count: 2
  E0419 16:13:11.858510      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:12.859079      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:13.860065      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:13:13.999341      13 runners.go:197] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 19 16:13:13.999: INFO: Creating new exec pod
  E0419 16:13:14.860923      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:15.861127      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:16.862059      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:13:17.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-4879 exec execpodl5t5q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  Apr 19 16:13:17.441: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  Apr 19 16:13:17.441: INFO: stdout: "nodeport-test-tv2pq"
  Apr 19 16:13:17.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-4879 exec execpodl5t5q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.25.206 80'
  Apr 19 16:13:17.746: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.25.206 80\nConnection to 10.233.25.206 80 port [tcp/http] succeeded!\n"
  Apr 19 16:13:17.746: INFO: stdout: ""
  E0419 16:13:17.861818      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:13:18.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-4879 exec execpodl5t5q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.25.206 80'
  Apr 19 16:13:18.768: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.25.206 80\nConnection to 10.233.25.206 80 port [tcp/http] succeeded!\n"
  Apr 19 16:13:18.768: INFO: stdout: "nodeport-test-tv2pq"
  Apr 19 16:13:18.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-4879 exec execpodl5t5q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.39 30210'
  E0419 16:13:18.862128      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:13:19.066: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.39 30210\nConnection to 192.168.121.39 30210 port [tcp/*] succeeded!\n"
  Apr 19 16:13:19.066: INFO: stdout: ""
  Apr 19 16:13:19.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-4879 exec execpodl5t5q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.39 30210'
  E0419 16:13:19.862360      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:13:20.109: INFO: stderr: "+ echo+  hostName\nnc -v -t -w 2 192.168.121.39 30210\nConnection to 192.168.121.39 30210 port [tcp/*] succeeded!\n"
  Apr 19 16:13:20.109: INFO: stdout: ""
  Apr 19 16:13:20.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-4879 exec execpodl5t5q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.39 30210'
  E0419 16:13:20.862390      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:13:21.107: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.39 30210\nConnection to 192.168.121.39 30210 port [tcp/*] succeeded!\n"
  Apr 19 16:13:21.107: INFO: stdout: ""
  Apr 19 16:13:21.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-4879 exec execpodl5t5q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.39 30210'
  E0419 16:13:21.862848      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:13:22.117: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.39 30210\nConnection to 192.168.121.39 30210 port [tcp/*] succeeded!\n"
  Apr 19 16:13:22.117: INFO: stdout: ""
  Apr 19 16:13:22.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-4879 exec execpodl5t5q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.39 30210'
  E0419 16:13:22.863318      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:13:23.130: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.39 30210\nConnection to 192.168.121.39 30210 port [tcp/*] succeeded!\n"
  Apr 19 16:13:23.130: INFO: stdout: ""
  Apr 19 16:13:23.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-4879 exec execpodl5t5q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.39 30210'
  E0419 16:13:23.864518      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:13:24.143: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.39 30210\nConnection to 192.168.121.39 30210 port [tcp/*] succeeded!\n"
  Apr 19 16:13:24.144: INFO: stdout: ""
  Apr 19 16:13:24.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-4879 exec execpodl5t5q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.39 30210'
  E0419 16:13:24.865152      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:13:25.124: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.39 30210\nConnection to 192.168.121.39 30210 port [tcp/*] succeeded!\n"
  Apr 19 16:13:25.124: INFO: stdout: "nodeport-test-tv2pq"
  Apr 19 16:13:25.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-4879 exec execpodl5t5q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.127 30210'
  Apr 19 16:13:25.426: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.127 30210\nConnection to 192.168.121.127 30210 port [tcp/*] succeeded!\n"
  Apr 19 16:13:25.426: INFO: stdout: ""
  E0419 16:13:25.866428      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:13:26.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-4879 exec execpodl5t5q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.127 30210'
  Apr 19 16:13:26.497: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.127 30210\nConnection to 192.168.121.127 30210 port [tcp/*] succeeded!\n"
  Apr 19 16:13:26.497: INFO: stdout: "nodeport-test-tv2pq"
  Apr 19 16:13:26.498: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4879" for this suite. @ 04/19/24 16:13:26.515
• [15.729 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance] [sig-scheduling, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/limit_range.go:62
  STEP: Creating a kubernetes client @ 04/19/24 16:13:26.538
  Apr 19 16:13:26.538: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename limitrange @ 04/19/24 16:13:26.542
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:13:26.59
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:13:26.594
  STEP: Creating a LimitRange @ 04/19/24 16:13:26.601
  STEP: Setting up watch @ 04/19/24 16:13:26.601
  STEP: Submitting a LimitRange @ 04/19/24 16:13:26.708
  STEP: Verifying LimitRange creation was observed @ 04/19/24 16:13:26.721
  STEP: Fetching the LimitRange to ensure it has proper values @ 04/19/24 16:13:26.721
  Apr 19 16:13:26.731: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  Apr 19 16:13:26.732: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with no resource requirements @ 04/19/24 16:13:26.732
  STEP: Ensuring Pod has resource requirements applied from LimitRange @ 04/19/24 16:13:26.748
  Apr 19 16:13:26.759: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  Apr 19 16:13:26.759: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with partial resource requirements @ 04/19/24 16:13:26.76
  STEP: Ensuring Pod has merged resource requirements applied from LimitRange @ 04/19/24 16:13:26.779
  Apr 19 16:13:26.791: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
  Apr 19 16:13:26.792: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Failing to create a Pod with less than min resources @ 04/19/24 16:13:26.792
  STEP: Failing to create a Pod with more than max resources @ 04/19/24 16:13:26.799
  STEP: Updating a LimitRange @ 04/19/24 16:13:26.804
  STEP: Verifying LimitRange updating is effective @ 04/19/24 16:13:26.82
  E0419 16:13:26.866723      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:27.867755      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Pod with less than former min resources @ 04/19/24 16:13:28.829
  STEP: Failing to create a Pod with more than max resources @ 04/19/24 16:13:28.844
  STEP: Deleting a LimitRange @ 04/19/24 16:13:28.85
  E0419 16:13:28.871040      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying the LimitRange was deleted @ 04/19/24 16:13:28.88
  E0419 16:13:29.871873      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:30.872298      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:31.872646      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:32.873062      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:33.873944      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:13:33.886: INFO: limitRange is already deleted
  STEP: Creating a Pod with more than former max resources @ 04/19/24 16:13:33.887
  Apr 19 16:13:33.903: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-2703" for this suite. @ 04/19/24 16:13:33.915
• [7.385 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1493
  STEP: Creating a kubernetes client @ 04/19/24 16:13:33.925
  Apr 19 16:13:33.925: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename services @ 04/19/24 16:13:33.927
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:13:33.956
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:13:33.96
  STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-7007 @ 04/19/24 16:13:33.965
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 04/19/24 16:13:34.029
  STEP: creating service externalsvc in namespace services-7007 @ 04/19/24 16:13:34.029
  STEP: creating replication controller externalsvc in namespace services-7007 @ 04/19/24 16:13:34.083
  I0419 16:13:34.106624      13 runners.go:197] Created replication controller with name: externalsvc, namespace: services-7007, replica count: 2
  E0419 16:13:34.874840      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:35.875362      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:36.877029      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:13:37.165649      13 runners.go:197] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the ClusterIP service to type=ExternalName @ 04/19/24 16:13:37.174
  Apr 19 16:13:37.210: INFO: Creating new exec pod
  E0419 16:13:37.880300      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:38.878871      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:13:39.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-7007 exec execpodbxwk7 -- /bin/sh -x -c nslookup clusterip-service.services-7007.svc.cluster.local'
  Apr 19 16:13:39.693: INFO: stderr: "+ nslookup clusterip-service.services-7007.svc.cluster.local\n"
  Apr 19 16:13:39.693: INFO: stdout: "Server:\t\t10.233.0.10\nAddress:\t10.233.0.10#53\n\nclusterip-service.services-7007.svc.cluster.local\tcanonical name = externalsvc.services-7007.svc.cluster.local.\nName:\texternalsvc.services-7007.svc.cluster.local\nAddress: 10.233.47.151\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-7007, will wait for the garbage collector to delete the pods @ 04/19/24 16:13:39.693
  Apr 19 16:13:39.770: INFO: Deleting ReplicationController externalsvc took: 15.750575ms
  Apr 19 16:13:39.871: INFO: Terminating ReplicationController externalsvc pods took: 101.216988ms
  E0419 16:13:39.879911      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:40.880735      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:41.881040      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:42.880900      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:13:43.018: INFO: Cleaning up the ClusterIP to ExternalName test service
  Apr 19 16:13:43.058: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7007" for this suite. @ 04/19/24 16:13:43.068
• [9.156 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:237
  STEP: Creating a kubernetes client @ 04/19/24 16:13:43.084
  Apr 19 16:13:43.084: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename downward-api @ 04/19/24 16:13:43.089
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:13:43.116
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:13:43.121
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 16:13:43.127
  E0419 16:13:43.888532      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:44.886598      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:45.884594      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:46.886875      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:13:47.189
  Apr 19 16:13:47.204: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod downwardapi-volume-27471cf4-0219-4445-b371-9a032edb5e2f container client-container: <nil>
  STEP: delete the pod @ 04/19/24 16:13:47.227
  Apr 19 16:13:47.271: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4843" for this suite. @ 04/19/24 16:13:47.284
• [4.217 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:105
  STEP: Creating a kubernetes client @ 04/19/24 16:13:47.325
  Apr 19 16:13:47.325: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename endpointslice @ 04/19/24 16:13:47.33
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:13:47.372
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:13:47.377
  E0419 16:13:47.885973      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:48.886421      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:13:49.495: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-2551" for this suite. @ 04/19/24 16:13:49.503
• [2.190 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:334
  STEP: Creating a kubernetes client @ 04/19/24 16:13:49.517
  Apr 19 16:13:49.517: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename watch @ 04/19/24 16:13:49.521
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:13:49.547
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:13:49.555
  STEP: getting a starting resourceVersion @ 04/19/24 16:13:49.56
  STEP: starting a background goroutine to produce watch events @ 04/19/24 16:13:49.565
  STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order @ 04/19/24 16:13:49.565
  E0419 16:13:49.886961      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:50.887342      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:51.887297      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:13:52.339: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-8501" for this suite. @ 04/19/24 16:13:52.382
• [2.918 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:125
  STEP: Creating a kubernetes client @ 04/19/24 16:13:52.438
  Apr 19 16:13:52.438: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename cronjob @ 04/19/24 16:13:52.442
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:13:52.478
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:13:52.484
  STEP: Creating a ForbidConcurrent cronjob @ 04/19/24 16:13:52.491
  STEP: Ensuring a job is scheduled @ 04/19/24 16:13:52.509
  E0419 16:13:52.887496      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:53.887924      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:54.888167      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:55.888446      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:56.888580      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:57.889756      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:58.890081      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:13:59.890755      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 04/19/24 16:14:00.521
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 04/19/24 16:14:00.53
  STEP: Ensuring no more jobs are scheduled @ 04/19/24 16:14:00.546
  E0419 16:14:00.890830      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:01.891759      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:02.892369      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:03.893472      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:04.893872      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:05.894579      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:06.895468      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:07.894968      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:08.895377      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:09.896366      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:10.896769      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:11.898251      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:12.898532      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:13.898980      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:14.900956      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:15.900919      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:16.902134      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:17.903090      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:18.903201      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:19.903411      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:20.903692      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:21.904099      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:22.904649      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:23.905113      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:24.905877      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:25.906190      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:26.907092      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:27.908684      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:28.908311      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:29.908657      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:30.909347      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:31.909181      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:32.909561      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:33.910086      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:34.910492      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:35.910904      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:36.910937      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:37.911964      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:38.912180      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:39.912398      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:40.913223      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:41.914021      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:42.914953      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:43.916138      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:44.916380      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:45.917388      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:46.918243      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:47.918389      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:48.918756      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:49.918808      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:50.919074      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:51.919639      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:52.920509      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:53.921127      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:54.921779      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:55.922698      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:56.922766      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:57.922867      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:58.923553      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:14:59.924426      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:00.924550      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:01.925738      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:02.925994      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:03.926917      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:04.927121      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:05.927510      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:06.927829      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:07.928105      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:08.928262      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:09.931945      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:10.930044      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:11.930513      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:12.931414      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:13.931595      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:14.935291      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:15.934586      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:16.935689      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:17.936174      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:18.938368      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:19.938185      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:20.939809      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:21.939741      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:22.940356      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:23.940780      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:24.941751      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:25.941753      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:26.942668      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:27.943555      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:28.944310      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:29.944598      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:30.944425      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:31.947998      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:32.946003      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:33.946380      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:34.946755      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:35.947704      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:36.947968      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:37.949160      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:38.949698      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:39.949990      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:40.950238      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:41.950681      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:42.951270      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:43.952232      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:44.953198      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:45.953560      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:46.954611      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:47.954850      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:48.955150      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:49.955745      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:50.956442      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:51.956800      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:52.957448      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:53.957897      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:54.958575      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:55.959450      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:56.959779      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:57.960896      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:58.961113      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:15:59.961542      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:00.963023      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:01.962710      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:02.963163      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:03.963439      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:04.964190      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:05.964558      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:06.965720      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:07.966656      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:08.966963      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:09.967280      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:10.968805      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:11.968777      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:12.969721      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:13.969792      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:14.970795      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:15.979361      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:16.975953      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:17.977112      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:18.982096      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:19.980141      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:20.980467      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:21.980762      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:22.982526      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:23.981640      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:24.983570      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:25.982572      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:26.983997      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:27.983568      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:28.984787      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:29.985673      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:30.986687      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:31.986836      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:32.987903      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:33.988752      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:34.988579      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:35.989004      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:36.991322      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:37.990481      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:38.990902      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:39.991530      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:40.991534      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:41.991797      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:42.992627      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:43.993322      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:44.994423      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:45.994715      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:46.996008      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:47.997270      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:48.998477      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:49.998780      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:50.999036      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:51.999807      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:52.999603      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:53.999933      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:55.000174      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:56.001207      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:57.001528      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:58.001800      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:16:59.002996      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:00.002981      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:01.004209      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:02.004713      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:03.004800      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:04.005288      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:05.005639      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:06.005999      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:07.006449      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:08.007239      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:09.007654      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:10.008602      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:11.010110      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:12.010594      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:13.010928      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:14.011212      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:15.011865      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:16.012292      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:17.013158      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:18.014486      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:19.014397      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:20.014515      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:21.015223      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:22.016717      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:23.017156      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:24.017505      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:25.017551      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:26.018036      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:27.018868      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:28.019000      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:29.019274      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:30.019673      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:31.020211      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:32.019973      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:33.020897      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:34.025236      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:35.021947      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:36.022356      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:37.023305      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:38.024045      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:39.025062      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:40.025803      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:41.025808      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:42.026164      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:43.026741      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:44.026868      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:45.028139      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:46.028336      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:47.028581      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:48.028837      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:49.029580      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:50.029936      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:51.031000      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:52.031485      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:53.032064      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:54.032358      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:55.032536      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:56.033449      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:57.033680      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:58.034552      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:17:59.034837      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:00.035060      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:01.035389      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:02.035605      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:03.036691      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:04.036472      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:05.037175      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:06.037258      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:07.038017      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:08.038571      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:09.038947      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:10.039498      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:11.039766      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:12.040450      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:13.040706      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:14.041277      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:15.042137      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:16.042443      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:17.042777      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:18.043136      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:19.043430      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:20.043567      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:21.044358      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:22.044674      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:23.044974      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:24.045125      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:25.045427      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:26.045615      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:27.046210      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:28.046635      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:29.046787      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:30.047168      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:31.047319      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:32.047834      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:33.048841      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:34.049381      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:35.049494      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:36.049564      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:37.049872      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:38.050941      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:39.051191      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:40.051345      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:41.052336      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:42.052865      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:43.053764      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:44.056776      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:45.057569      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:46.058056      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:47.058703      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:48.059853      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:49.059892      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:50.060162      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:51.060556      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:52.061343      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:53.061561      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:54.061905      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:55.062619      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:56.063462      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:57.064447      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:58.065082      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:18:59.065271      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:00.078687      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing cronjob @ 04/19/24 16:19:00.567
  Apr 19 16:19:00.585: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-409" for this suite. @ 04/19/24 16:19:00.602
• [308.183 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:158
  STEP: Creating a kubernetes client @ 04/19/24 16:19:00.624
  Apr 19 16:19:00.624: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename runtimeclass @ 04/19/24 16:19:00.633
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:19:00.694
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:19:00.702
  STEP: Deleting RuntimeClass runtimeclass-4340-delete-me @ 04/19/24 16:19:00.719
  STEP: Waiting for the RuntimeClass to disappear @ 04/19/24 16:19:00.732
  Apr 19 16:19:00.757: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-4340" for this suite. @ 04/19/24 16:19:00.766
• [0.155 seconds]
------------------------------
SSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/certificates.go:200
  STEP: Creating a kubernetes client @ 04/19/24 16:19:00.78
  Apr 19 16:19:00.780: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename certificates @ 04/19/24 16:19:00.784
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:19:00.813
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:19:00.819
  E0419 16:19:01.072391      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:02.077665      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: getting /apis @ 04/19/24 16:19:02.328
  STEP: getting /apis/certificates.k8s.io @ 04/19/24 16:19:02.341
  STEP: getting /apis/certificates.k8s.io/v1 @ 04/19/24 16:19:02.345
  STEP: creating @ 04/19/24 16:19:02.35
  STEP: getting @ 04/19/24 16:19:02.398
  STEP: listing @ 04/19/24 16:19:02.404
  STEP: watching @ 04/19/24 16:19:02.413
  Apr 19 16:19:02.413: INFO: starting watch
  STEP: patching @ 04/19/24 16:19:02.416
  STEP: updating @ 04/19/24 16:19:02.432
  Apr 19 16:19:02.447: INFO: waiting for watch events with expected annotations
  Apr 19 16:19:02.448: INFO: saw patched and updated annotations
  STEP: getting /approval @ 04/19/24 16:19:02.449
  STEP: patching /approval @ 04/19/24 16:19:02.458
  STEP: updating /approval @ 04/19/24 16:19:02.472
  STEP: getting /status @ 04/19/24 16:19:02.484
  STEP: patching /status @ 04/19/24 16:19:02.495
  STEP: updating /status @ 04/19/24 16:19:02.525
  STEP: deleting @ 04/19/24 16:19:02.545
  STEP: deleting a collection @ 04/19/24 16:19:02.585
  Apr 19 16:19:02.617: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "certificates-9899" for this suite. @ 04/19/24 16:19:02.627
• [1.856 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:161
  STEP: Creating a kubernetes client @ 04/19/24 16:19:02.638
  Apr 19 16:19:02.638: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename cronjob @ 04/19/24 16:19:02.641
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:19:02.678
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:19:02.684
  STEP: Creating a ReplaceConcurrent cronjob @ 04/19/24 16:19:02.691
  STEP: Ensuring a job is scheduled @ 04/19/24 16:19:02.704
  E0419 16:19:03.073443      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:04.073773      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:05.074130      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:06.075021      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:07.074712      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:08.074744      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:09.075136      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:10.075426      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:11.076763      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:12.077481      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:13.078584      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:14.079054      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:15.079394      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:16.080272      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:17.080407      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:18.080718      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:19.081916      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:20.082571      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:21.083469      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:22.083711      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:23.084180      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:24.084389      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:25.085474      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:26.085636      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:27.085738      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:28.086014      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:29.086932      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:30.087296      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:31.088132      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:32.088167      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:33.088363      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:34.089207      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:35.089726      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:36.089942      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:37.090573      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:38.091225      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:39.092214      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:40.092566      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:41.093016      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:42.093905      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:43.093950      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:44.094889      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:45.096227      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:46.096787      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:47.097682      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:48.097942      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:49.099357      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:50.099506      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:51.099713      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:52.100169      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:53.101161      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:54.101740      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:55.102758      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:56.103641      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:57.105198      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:58.105876      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:19:59.107408      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:00.107244      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 04/19/24 16:20:00.713
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 04/19/24 16:20:00.721
  STEP: Ensuring the job is replaced with a new one @ 04/19/24 16:20:00.729
  E0419 16:20:01.108082      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:02.108365      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:03.109342      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:04.109027      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:05.109466      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:06.109747      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:07.110062      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:08.111090      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:09.111488      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:10.113495      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:11.113659      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:12.113429      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:13.113987      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:14.114572      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:15.114801      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:16.115417      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:17.115846      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:18.116272      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:19.116309      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:20.116506      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:21.117302      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:22.120512      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:23.120803      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:24.122132      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:25.122912      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:26.123926      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:27.125021      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:28.125190      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:29.125371      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:30.125763      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:31.126542      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:32.126723      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:33.126925      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:34.127907      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:35.128934      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:36.130024      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:37.130901      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:38.132195      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:39.133154      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:40.134070      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:41.134381      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:42.135244      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:43.135237      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:44.136104      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:45.136306      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:46.136616      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:47.137562      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:48.137663      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:49.137870      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:50.138881      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:51.139279      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:52.140021      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:53.140346      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:54.141482      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:55.142072      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:56.142661      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:57.142810      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:58.142956      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:20:59.143776      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:00.144301      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing cronjob @ 04/19/24 16:21:00.738
  Apr 19 16:21:00.751: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-2202" for this suite. @ 04/19/24 16:21:00.766
• [118.144 seconds]
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:385
  STEP: Creating a kubernetes client @ 04/19/24 16:21:00.782
  Apr 19 16:21:00.782: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename daemonsets @ 04/19/24 16:21:00.786
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:21:00.835
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:21:00.841
  Apr 19 16:21:00.892: INFO: Creating simple daemon set daemon-set
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/19/24 16:21:00.903
  Apr 19 16:21:00.920: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 16:21:00.920: INFO: Node co4fe9zoo9oc-1 is running 0 daemon pod, expected 1
  E0419 16:21:01.144610      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:21:01.927: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 16:21:01.928: INFO: Node co4fe9zoo9oc-1 is running 0 daemon pod, expected 1
  E0419 16:21:02.145760      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:21:02.919: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 19 16:21:02.919: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Update daemon pods image. @ 04/19/24 16:21:02.946
  STEP: Check that daemon pods images are updated. @ 04/19/24 16:21:02.971
  Apr 19 16:21:02.979: INFO: Wrong image for pod: daemon-set-57jdw. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 19 16:21:02.979: INFO: Wrong image for pod: daemon-set-t7zqh. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 19 16:21:02.979: INFO: Wrong image for pod: daemon-set-zlr54. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  E0419 16:21:03.146646      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:21:03.979: INFO: Wrong image for pod: daemon-set-57jdw. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 19 16:21:03.979: INFO: Pod daemon-set-ddkjs is not available
  Apr 19 16:21:03.979: INFO: Wrong image for pod: daemon-set-t7zqh. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  E0419 16:21:04.147623      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:21:04.985: INFO: Wrong image for pod: daemon-set-57jdw. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 19 16:21:04.985: INFO: Pod daemon-set-ddkjs is not available
  Apr 19 16:21:04.985: INFO: Wrong image for pod: daemon-set-t7zqh. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  E0419 16:21:05.148551      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:21:05.982: INFO: Wrong image for pod: daemon-set-t7zqh. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 19 16:21:05.983: INFO: Pod daemon-set-w2ppn is not available
  E0419 16:21:06.149675      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:21:06.981: INFO: Wrong image for pod: daemon-set-t7zqh. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 19 16:21:06.981: INFO: Pod daemon-set-w2ppn is not available
  E0419 16:21:07.151052      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:21:07.982: INFO: Pod daemon-set-9w9xq is not available
  STEP: Check that daemon pods are still running on every node of the cluster. @ 04/19/24 16:21:07.996
  Apr 19 16:21:08.018: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 19 16:21:08.018: INFO: Node co4fe9zoo9oc-3 is running 0 daemon pod, expected 1
  E0419 16:21:08.151343      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:21:09.017: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 19 16:21:09.017: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 04/19/24 16:21:09.075
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1826, will wait for the garbage collector to delete the pods @ 04/19/24 16:21:09.076
  E0419 16:21:09.152191      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:21:09.157: INFO: Deleting DaemonSet.extensions daemon-set took: 18.01164ms
  Apr 19 16:21:09.258: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.452706ms
  E0419 16:21:10.152693      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:21:10.266: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 16:21:10.266: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 19 16:21:10.273: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"16454"},"items":null}

  Apr 19 16:21:10.279: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"16454"},"items":null}

  Apr 19 16:21:10.306: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-1826" for this suite. @ 04/19/24 16:21:10.315
• [9.544 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:105
  STEP: Creating a kubernetes client @ 04/19/24 16:21:10.328
  Apr 19 16:21:10.328: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename subpath @ 04/19/24 16:21:10.331
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:21:10.358
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:21:10.366
  STEP: Setting up data @ 04/19/24 16:21:10.373
  STEP: Creating pod pod-subpath-test-projected-t2hl @ 04/19/24 16:21:10.398
  STEP: Creating a pod to test atomic-volume-subpath @ 04/19/24 16:21:10.398
  E0419 16:21:11.153013      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:12.153564      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:13.154619      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:14.155373      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:15.155574      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:16.155726      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:17.156492      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:18.157610      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:19.157788      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:20.158228      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:21.158697      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:22.158994      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:23.159734      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:24.159907      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:25.160209      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:26.160884      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:27.161093      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:28.161785      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:29.163725      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:30.162758      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:31.163823      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:32.165011      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:21:32.543
  Apr 19 16:21:32.553: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-subpath-test-projected-t2hl container test-container-subpath-projected-t2hl: <nil>
  STEP: delete the pod @ 04/19/24 16:21:32.6
  STEP: Deleting pod pod-subpath-test-projected-t2hl @ 04/19/24 16:21:32.632
  Apr 19 16:21:32.633: INFO: Deleting pod "pod-subpath-test-projected-t2hl" in namespace "subpath-4765"
  Apr 19 16:21:32.646: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-4765" for this suite. @ 04/19/24 16:21:32.66
• [22.348 seconds]
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:110
  STEP: Creating a kubernetes client @ 04/19/24 16:21:32.676
  Apr 19 16:21:32.676: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename configmap @ 04/19/24 16:21:32.681
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:21:32.725
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:21:32.736
  STEP: Creating configMap with name configmap-test-volume-map-3da3bfa0-e932-4a8a-a8fc-ed7a643e8fd2 @ 04/19/24 16:21:32.746
  STEP: Creating a pod to test consume configMaps @ 04/19/24 16:21:32.759
  E0419 16:21:33.165332      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:34.166606      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:35.166956      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:36.167189      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:21:36.807
  Apr 19 16:21:36.818: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-configmaps-43ee3d4e-eabe-4eb9-a6b9-34af803e43a0 container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/24 16:21:36.846
  Apr 19 16:21:36.891: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3677" for this suite. @ 04/19/24 16:21:36.902
• [4.242 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:61
  STEP: Creating a kubernetes client @ 04/19/24 16:21:36.923
  Apr 19 16:21:36.923: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename containers @ 04/19/24 16:21:36.929
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:21:36.971
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:21:36.979
  STEP: Creating a pod to test override arguments @ 04/19/24 16:21:36.992
  E0419 16:21:37.167433      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:38.168101      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:39.168821      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:40.169037      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:21:41.04
  Apr 19 16:21:41.050: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod client-containers-4a8c4489-0de5-418f-8b0f-af0ace1fdf7e container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/24 16:21:41.073
  Apr 19 16:21:41.112: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-3675" for this suite. @ 04/19/24 16:21:41.124
• [4.220 seconds]
------------------------------
SSS
------------------------------
[sig-node] Pods should delete a collection of pods [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:846
  STEP: Creating a kubernetes client @ 04/19/24 16:21:41.145
  Apr 19 16:21:41.145: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename pods @ 04/19/24 16:21:41.151
  E0419 16:21:41.170164      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:21:41.204
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:21:41.212
  STEP: Create set of pods @ 04/19/24 16:21:41.22
  Apr 19 16:21:41.247: INFO: created test-pod-1
  Apr 19 16:21:41.278: INFO: created test-pod-2
  Apr 19 16:21:41.299: INFO: created test-pod-3
  STEP: waiting for all 3 pods to be running @ 04/19/24 16:21:41.299
  E0419 16:21:42.170975      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:43.173024      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:44.173238      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:45.173840      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting for all pods to be deleted @ 04/19/24 16:21:45.517
  Apr 19 16:21:45.527: INFO: Pod quantity 3 is different from expected quantity 0
  E0419 16:21:46.175844      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:21:46.580: INFO: Pod quantity 3 is different from expected quantity 0
  E0419 16:21:47.175476      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:21:47.529: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-3081" for this suite. @ 04/19/24 16:21:47.543
• [6.418 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:90
  STEP: Creating a kubernetes client @ 04/19/24 16:21:47.568
  Apr 19 16:21:47.569: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename emptydir @ 04/19/24 16:21:47.574
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:21:47.624
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:21:47.634
  STEP: Creating a pod to test emptydir volume type on tmpfs @ 04/19/24 16:21:47.643
  E0419 16:21:48.176269      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:49.176855      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:50.178021      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:51.178376      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:21:51.726
  Apr 19 16:21:51.735: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-b220508c-5d16-4242-92e0-39d20678073e container test-container: <nil>
  STEP: delete the pod @ 04/19/24 16:21:51.762
  Apr 19 16:21:51.805: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7243" for this suite. @ 04/19/24 16:21:51.823
• [4.281 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:236
  STEP: Creating a kubernetes client @ 04/19/24 16:21:51.858
  Apr 19 16:21:51.859: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/19/24 16:21:51.865
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:21:51.906
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:21:51.915
  Apr 19 16:21:51.926: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  E0419 16:21:52.179164      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:53.179025      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 04/19/24 16:21:53.804
  Apr 19 16:21:53.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=crd-publish-openapi-2201 --namespace=crd-publish-openapi-2201 create -f -'
  Apr 19 16:21:54.088: INFO: stderr: ""
  Apr 19 16:21:54.088: INFO: stdout: "e2e-test-crd-publish-openapi-2241-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  Apr 19 16:21:54.088: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=crd-publish-openapi-2201 --namespace=crd-publish-openapi-2201 delete e2e-test-crd-publish-openapi-2241-crds test-cr'
  E0419 16:21:54.179894      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:21:54.268: INFO: stderr: ""
  Apr 19 16:21:54.268: INFO: stdout: "e2e-test-crd-publish-openapi-2241-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  Apr 19 16:21:54.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=crd-publish-openapi-2201 --namespace=crd-publish-openapi-2201 apply -f -'
  Apr 19 16:21:54.456: INFO: stderr: ""
  Apr 19 16:21:54.456: INFO: stdout: "e2e-test-crd-publish-openapi-2241-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  Apr 19 16:21:54.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=crd-publish-openapi-2201 --namespace=crd-publish-openapi-2201 delete e2e-test-crd-publish-openapi-2241-crds test-cr'
  Apr 19 16:21:54.749: INFO: stderr: ""
  Apr 19 16:21:54.749: INFO: stdout: "e2e-test-crd-publish-openapi-2241-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 04/19/24 16:21:54.749
  Apr 19 16:21:54.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=crd-publish-openapi-2201 explain e2e-test-crd-publish-openapi-2241-crds'
  Apr 19 16:21:54.907: INFO: stderr: ""
  Apr 19 16:21:54.907: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-in-nested.example.com\nKIND:       e2e-test-crd-publish-openapi-2241-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties in nested field for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E0419 16:21:55.180401      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:56.180261      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:21:56.478: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-2201" for this suite. @ 04/19/24 16:21:56.51
• [4.671 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:119
  STEP: Creating a kubernetes client @ 04/19/24 16:21:56.538
  Apr 19 16:21:56.538: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename webhook @ 04/19/24 16:21:56.542
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:21:56.578
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:21:56.586
  STEP: Setting up server cert @ 04/19/24 16:21:56.643
  E0419 16:21:57.180908      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 16:21:57.842
  STEP: Deploying the webhook pod @ 04/19/24 16:21:57.856
  STEP: Wait for the deployment to be ready @ 04/19/24 16:21:57.876
  Apr 19 16:21:57.894: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0419 16:21:58.181277      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:21:59.182476      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 16:21:59.914
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 16:21:59.936
  E0419 16:22:00.182609      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:22:00.936: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: fetching the /apis discovery document @ 04/19/24 16:22:00.955
  STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document @ 04/19/24 16:22:00.958
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document @ 04/19/24 16:22:00.959
  STEP: fetching the /apis/admissionregistration.k8s.io discovery document @ 04/19/24 16:22:00.96
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document @ 04/19/24 16:22:00.964
  STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document @ 04/19/24 16:22:00.964
  STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document @ 04/19/24 16:22:00.968
  Apr 19 16:22:01.069: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6749" for this suite. @ 04/19/24 16:22:01.077
  STEP: Destroying namespace "webhook-markers-6103" for this suite. @ 04/19/24 16:22:01.09
• [4.565 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:550
  STEP: Creating a kubernetes client @ 04/19/24 16:22:01.103
  Apr 19 16:22:01.103: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename container-probe @ 04/19/24 16:22:01.106
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:22:01.133
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:22:01.137
  STEP: Creating pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 in namespace container-probe-8226 @ 04/19/24 16:22:01.143
  E0419 16:22:01.183112      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:02.183440      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/19/24 16:22:03.175
  E0419 16:22:03.184827      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:22:03.185: INFO: Initial restart count of pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 is 0
  Apr 19 16:22:03.195: INFO: Get pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 in namespace container-probe-8226
  E0419 16:22:04.185115      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:05.185352      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:22:05.207: INFO: Get pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 in namespace container-probe-8226
  E0419 16:22:06.186002      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:07.186791      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:22:07.220: INFO: Get pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 in namespace container-probe-8226
  E0419 16:22:08.187160      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:09.187523      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:22:09.234: INFO: Get pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 in namespace container-probe-8226
  E0419 16:22:10.188104      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:11.188481      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:22:11.246: INFO: Get pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 in namespace container-probe-8226
  E0419 16:22:12.188767      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:13.189099      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:22:13.266: INFO: Get pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 in namespace container-probe-8226
  E0419 16:22:14.189413      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:15.189975      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:22:15.279: INFO: Get pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 in namespace container-probe-8226
  E0419 16:22:16.190258      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:17.191375      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:22:17.298: INFO: Get pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 in namespace container-probe-8226
  E0419 16:22:18.192648      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:19.193659      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:22:19.312: INFO: Get pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 in namespace container-probe-8226
  E0419 16:22:20.193952      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:21.194898      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:22:21.354: INFO: Get pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 in namespace container-probe-8226
  E0419 16:22:22.195193      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:23.196437      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:22:23.363: INFO: Get pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 in namespace container-probe-8226
  E0419 16:22:24.196986      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:25.198474      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:22:25.372: INFO: Get pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 in namespace container-probe-8226
  E0419 16:22:26.198734      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:27.198651      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:22:27.386: INFO: Get pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 in namespace container-probe-8226
  E0419 16:22:28.198862      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:29.199198      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:22:29.404: INFO: Get pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 in namespace container-probe-8226
  E0419 16:22:30.199706      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:31.200018      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:22:31.412: INFO: Get pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 in namespace container-probe-8226
  E0419 16:22:32.213178      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:33.207133      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:22:33.422: INFO: Get pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 in namespace container-probe-8226
  E0419 16:22:34.213285      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:35.209353      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:22:35.433: INFO: Get pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 in namespace container-probe-8226
  E0419 16:22:36.209490      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:37.209955      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:22:37.444: INFO: Get pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 in namespace container-probe-8226
  E0419 16:22:38.210074      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:39.210624      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:22:39.455: INFO: Get pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 in namespace container-probe-8226
  E0419 16:22:40.210948      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:41.211128      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:22:41.466: INFO: Get pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 in namespace container-probe-8226
  E0419 16:22:42.211478      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:43.211920      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:22:43.478: INFO: Get pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 in namespace container-probe-8226
  E0419 16:22:44.211882      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:45.213859      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:22:45.492: INFO: Get pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 in namespace container-probe-8226
  E0419 16:22:46.212654      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:47.212882      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:22:47.504: INFO: Get pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 in namespace container-probe-8226
  E0419 16:22:48.212924      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:49.213385      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:22:49.517: INFO: Get pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 in namespace container-probe-8226
  E0419 16:22:50.214474      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:51.215205      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:22:51.532: INFO: Get pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 in namespace container-probe-8226
  E0419 16:22:52.216251      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:53.217393      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:22:53.541: INFO: Get pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 in namespace container-probe-8226
  E0419 16:22:54.218242      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:55.218578      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:22:55.554: INFO: Get pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 in namespace container-probe-8226
  E0419 16:22:56.219744      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:57.220918      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:22:57.563: INFO: Get pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 in namespace container-probe-8226
  E0419 16:22:58.221839      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:22:59.222032      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:22:59.577: INFO: Get pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 in namespace container-probe-8226
  E0419 16:23:00.222430      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:01.222726      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:23:01.619: INFO: Get pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 in namespace container-probe-8226
  E0419 16:23:02.222901      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:03.223192      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:23:03.630: INFO: Get pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 in namespace container-probe-8226
  E0419 16:23:04.223479      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:05.223663      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:23:05.643: INFO: Get pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 in namespace container-probe-8226
  E0419 16:23:06.224874      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:07.225859      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:23:07.658: INFO: Get pod test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 in namespace container-probe-8226
  Apr 19 16:23:07.658: INFO: Restart count of pod container-probe-8226/test-grpc-e7753bbe-e427-4d78-a5ab-94740f927fc2 is now 1 (1m4.471877526s elapsed)
  STEP: deleting the pod @ 04/19/24 16:23:07.659
  Apr 19 16:23:07.690: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-8226" for this suite. @ 04/19/24 16:23:07.712
• [66.629 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:199
  STEP: Creating a kubernetes client @ 04/19/24 16:23:07.741
  Apr 19 16:23:07.741: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename webhook @ 04/19/24 16:23:07.747
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:23:07.784
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:23:07.792
  STEP: Setting up server cert @ 04/19/24 16:23:07.848
  E0419 16:23:08.226711      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 16:23:08.869
  STEP: Deploying the webhook pod @ 04/19/24 16:23:08.886
  STEP: Wait for the deployment to be ready @ 04/19/24 16:23:08.91
  Apr 19 16:23:08.955: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0419 16:23:09.227278      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:10.227311      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 16:23:10.989
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 16:23:11.029
  E0419 16:23:11.228871      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:23:12.030: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 04/19/24 16:23:12.053
  STEP: create a pod that should be denied by the webhook @ 04/19/24 16:23:12.113
  STEP: create a pod that causes the webhook to hang @ 04/19/24 16:23:12.14
  E0419 16:23:12.229418      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:13.230687      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:14.231458      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:15.231788      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:16.232484      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:17.232890      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:18.233381      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:19.233709      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:20.233908      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:21.233827      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create a configmap that should be denied by the webhook @ 04/19/24 16:23:22.154
  STEP: create a configmap that should be admitted by the webhook @ 04/19/24 16:23:22.225
  E0419 16:23:22.234639      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook @ 04/19/24 16:23:22.246
  STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook @ 04/19/24 16:23:22.268
  STEP: create a namespace that bypass the webhook @ 04/19/24 16:23:22.285
  STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace @ 04/19/24 16:23:22.331
  Apr 19 16:23:22.457: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8160" for this suite. @ 04/19/24 16:23:22.467
  STEP: Destroying namespace "webhook-markers-2796" for this suite. @ 04/19/24 16:23:22.489
  STEP: Destroying namespace "exempted-namespace-8119" for this suite. @ 04/19/24 16:23:22.543
• [14.844 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:350
  STEP: Creating a kubernetes client @ 04/19/24 16:23:22.587
  Apr 19 16:23:22.587: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename field-validation @ 04/19/24 16:23:22.592
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:23:22.626
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:23:22.631
  Apr 19 16:23:22.637: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  W0419 16:23:22.639696      13 field_validation.go:423] props: &JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{spec: {  <nil>  object   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[cronSpec:{  <nil>  string   nil <nil> false <nil> false <nil> <nil> ^(\d+|\*)(/\d+)?(\s+(\d+|\*)(/\d+)?){4}$ <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} foo:{  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} ports:{  <nil>  array   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] &JSONSchemaPropsOrArray{Schema:&JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[containerPort protocol],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{containerPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostIP: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},name: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},protocol: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},},JSONSchemas:[]JSONSchemaProps{},} [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [containerPort protocol] 0xc0019b9920 <nil> []}] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},}
  E0419 16:23:23.235296      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:24.238904      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:25.237236      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0419 16:23:25.368849      13 warnings.go:70] unknown field "alpha"
  W0419 16:23:25.369347      13 warnings.go:70] unknown field "beta"
  W0419 16:23:25.369707      13 warnings.go:70] unknown field "delta"
  W0419 16:23:25.370060      13 warnings.go:70] unknown field "epsilon"
  W0419 16:23:25.370463      13 warnings.go:70] unknown field "gamma"
  Apr 19 16:23:25.970: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-550" for this suite. @ 04/19/24 16:23:25.989
• [3.422 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:216
  STEP: Creating a kubernetes client @ 04/19/24 16:23:26.009
  Apr 19 16:23:26.009: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename container-runtime @ 04/19/24 16:23:26.014
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:23:26.059
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:23:26.065
  STEP: create the container @ 04/19/24 16:23:26.076
  W0419 16:23:26.099753      13 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Failed @ 04/19/24 16:23:26.1
  E0419 16:23:26.238310      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:27.239000      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:28.238720      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 04/19/24 16:23:29.142
  STEP: the container should be terminated @ 04/19/24 16:23:29.152
  STEP: the termination message should be set @ 04/19/24 16:23:29.152
  Apr 19 16:23:29.152: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 04/19/24 16:23:29.153
  Apr 19 16:23:29.185: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-1670" for this suite. @ 04/19/24 16:23:29.213
• [3.220 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:445
  STEP: Creating a kubernetes client @ 04/19/24 16:23:29.23
  Apr 19 16:23:29.230: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  E0419 16:23:29.238832      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Building a namespace api object, basename pods @ 04/19/24 16:23:29.242
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:23:29.301
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:23:29.305
  E0419 16:23:30.255128      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:31.244192      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:32.243966      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:33.244945      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:23:33.436
  Apr 19 16:23:33.443: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod client-envvars-dc16c313-bcc9-4d6f-b71c-314770485972 container env3cont: <nil>
  STEP: delete the pod @ 04/19/24 16:23:33.472
  Apr 19 16:23:33.512: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-3670" for this suite. @ 04/19/24 16:23:33.52
• [4.307 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:836
  STEP: Creating a kubernetes client @ 04/19/24 16:23:33.538
  Apr 19 16:23:33.538: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename daemonsets @ 04/19/24 16:23:33.553
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:23:33.621
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:23:33.627
  STEP: Creating simple DaemonSet "daemon-set" @ 04/19/24 16:23:33.679
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/19/24 16:23:33.692
  Apr 19 16:23:33.711: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 16:23:33.711: INFO: Node co4fe9zoo9oc-1 is running 0 daemon pod, expected 1
  E0419 16:23:34.245252      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:23:34.710: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 16:23:34.710: INFO: Node co4fe9zoo9oc-1 is running 0 daemon pod, expected 1
  E0419 16:23:35.246541      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:23:35.715: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 19 16:23:35.715: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: listing all DaemonSets @ 04/19/24 16:23:35.723
  STEP: DeleteCollection of the DaemonSets @ 04/19/24 16:23:35.735
  STEP: Verify that ReplicaSets have been deleted @ 04/19/24 16:23:35.752
  Apr 19 16:23:35.788: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"17216"},"items":null}

  Apr 19 16:23:35.815: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"17217"},"items":[{"metadata":{"name":"daemon-set-42tqx","generateName":"daemon-set-","namespace":"daemonsets-1580","uid":"7eee6f9b-2b57-4b5a-ad09-4d8bf6b0a7fa","resourceVersion":"17207","creationTimestamp":"2024-04-19T16:23:33Z","labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"49dea282-3443-4652-9396-a808fb02e8c1","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-04-19T16:23:33Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"49dea282-3443-4652-9396-a808fb02e8c1\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-04-19T16:23:34Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.115\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-bvqdz","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-bvqdz","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"co4fe9zoo9oc-2","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["co4fe9zoo9oc-2"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-19T16:23:34Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-19T16:23:33Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-19T16:23:34Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-19T16:23:34Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-19T16:23:33Z"}],"hostIP":"192.168.121.39","hostIPs":[{"ip":"192.168.121.39"}],"podIP":"10.233.65.115","podIPs":[{"ip":"10.233.65.115"}],"startTime":"2024-04-19T16:23:33Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-04-19T16:23:34Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"cri-o://19d0acf139be77dc7abc71426059b2b5064f611e9388d363b5a519545a9f3223","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-pfx2s","generateName":"daemon-set-","namespace":"daemonsets-1580","uid":"6007bda1-0acb-47df-b2cc-410f0da0e21d","resourceVersion":"17214","creationTimestamp":"2024-04-19T16:23:33Z","labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"49dea282-3443-4652-9396-a808fb02e8c1","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-04-19T16:23:33Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"49dea282-3443-4652-9396-a808fb02e8c1\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-04-19T16:23:35Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.215\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-rfq2n","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-rfq2n","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"co4fe9zoo9oc-3","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["co4fe9zoo9oc-3"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-19T16:23:35Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-19T16:23:33Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-19T16:23:35Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-19T16:23:35Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-19T16:23:33Z"}],"hostIP":"192.168.121.60","hostIPs":[{"ip":"192.168.121.60"}],"podIP":"10.233.66.215","podIPs":[{"ip":"10.233.66.215"}],"startTime":"2024-04-19T16:23:33Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-04-19T16:23:34Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"cri-o://b2d661dd16071b6a05d6657591dae1c2d804a45ad8804e53828a7e36276c6a4a","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-rwdc4","generateName":"daemon-set-","namespace":"daemonsets-1580","uid":"43031471-01d1-4113-9695-bca53f34aade","resourceVersion":"17217","creationTimestamp":"2024-04-19T16:23:33Z","deletionTimestamp":"2024-04-19T16:24:05Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"49dea282-3443-4652-9396-a808fb02e8c1","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-04-19T16:23:33Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"49dea282-3443-4652-9396-a808fb02e8c1\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-04-19T16:23:34Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.110\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-t2q9x","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-t2q9x","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"co4fe9zoo9oc-1","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["co4fe9zoo9oc-1"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-19T16:23:34Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-19T16:23:33Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-19T16:23:34Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-19T16:23:34Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-19T16:23:33Z"}],"hostIP":"192.168.121.127","hostIPs":[{"ip":"192.168.121.127"}],"podIP":"10.233.64.110","podIPs":[{"ip":"10.233.64.110"}],"startTime":"2024-04-19T16:23:33Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-04-19T16:23:34Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"cri-o://7c0f6092c61a518abdb10d6016147f3b150a8018ea712d1678c5ec62cf8dfc02","started":true}],"qosClass":"BestEffort"}}]}

  Apr 19 16:23:35.882: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-1580" for this suite. @ 04/19/24 16:23:35.89
• [2.369 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:191
  STEP: Creating a kubernetes client @ 04/19/24 16:23:35.907
  Apr 19 16:23:35.907: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename watch @ 04/19/24 16:23:35.91
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:23:35.949
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:23:35.957
  STEP: creating a watch on configmaps @ 04/19/24 16:23:35.962
  STEP: creating a new configmap @ 04/19/24 16:23:35.968
  STEP: modifying the configmap once @ 04/19/24 16:23:35.984
  STEP: closing the watch once it receives two notifications @ 04/19/24 16:23:36
  Apr 19 16:23:36.000: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1022  668cb146-3124-4ef3-9a8d-c8480fb5a489 17227 0 2024-04-19 16:23:35 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-04-19 16:23:35 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 19 16:23:36.000: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1022  668cb146-3124-4ef3-9a8d-c8480fb5a489 17228 0 2024-04-19 16:23:35 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-04-19 16:23:35 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time, while the watch is closed @ 04/19/24 16:23:36
  STEP: creating a new watch on configmaps from the last resource version observed by the first watch @ 04/19/24 16:23:36.028
  STEP: deleting the configmap @ 04/19/24 16:23:36.03
  STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed @ 04/19/24 16:23:36.042
  Apr 19 16:23:36.042: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1022  668cb146-3124-4ef3-9a8d-c8480fb5a489 17229 0 2024-04-19 16:23:35 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-04-19 16:23:36 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 19 16:23:36.043: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1022  668cb146-3124-4ef3-9a8d-c8480fb5a489 17230 0 2024-04-19 16:23:35 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-04-19 16:23:36 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 19 16:23:36.043: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-1022" for this suite. @ 04/19/24 16:23:36.053
• [0.171 seconds]
------------------------------
S
------------------------------
[sig-network] IngressClass API should support creating IngressClass API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/ingressclass.go:268
  STEP: Creating a kubernetes client @ 04/19/24 16:23:36.079
  Apr 19 16:23:36.079: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename ingressclass @ 04/19/24 16:23:36.083
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:23:36.126
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:23:36.132
  STEP: getting /apis @ 04/19/24 16:23:36.139
  STEP: getting /apis/networking.k8s.io @ 04/19/24 16:23:36.151
  STEP: getting /apis/networking.k8s.iov1 @ 04/19/24 16:23:36.153
  STEP: creating @ 04/19/24 16:23:36.155
  STEP: getting @ 04/19/24 16:23:36.204
  STEP: listing @ 04/19/24 16:23:36.209
  STEP: watching @ 04/19/24 16:23:36.216
  Apr 19 16:23:36.216: INFO: starting watch
  STEP: patching @ 04/19/24 16:23:36.218
  STEP: updating @ 04/19/24 16:23:36.231
  Apr 19 16:23:36.238: INFO: waiting for watch events with expected annotations
  Apr 19 16:23:36.239: INFO: saw patched and updated annotations
  STEP: deleting @ 04/19/24 16:23:36.239
  E0419 16:23:36.247255      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting a collection @ 04/19/24 16:23:36.271
  Apr 19 16:23:36.294: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingressclass-6538" for this suite. @ 04/19/24 16:23:36.307
• [0.246 seconds]
------------------------------
[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:205
  STEP: Creating a kubernetes client @ 04/19/24 16:23:36.326
  Apr 19 16:23:36.326: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename daemonsets @ 04/19/24 16:23:36.329
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:23:36.359
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:23:36.364
  Apr 19 16:23:36.406: INFO: Creating daemon "daemon-set" with a node selector
  STEP: Initially, daemon pods should not be running on any nodes. @ 04/19/24 16:23:36.42
  Apr 19 16:23:36.426: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 16:23:36.426: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Change node label to blue, check that daemon pod is launched. @ 04/19/24 16:23:36.426
  Apr 19 16:23:36.463: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 16:23:36.463: INFO: Node co4fe9zoo9oc-1 is running 0 daemon pod, expected 1
  E0419 16:23:37.247786      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:23:37.464: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 16:23:37.465: INFO: Node co4fe9zoo9oc-1 is running 0 daemon pod, expected 1
  E0419 16:23:38.249044      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:23:38.466: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 19 16:23:38.466: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Update the node label to green, and wait for daemons to be unscheduled @ 04/19/24 16:23:38.478
  Apr 19 16:23:38.528: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 19 16:23:38.529: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
  E0419 16:23:39.249983      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:23:39.526: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 16:23:39.527: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate @ 04/19/24 16:23:39.527
  Apr 19 16:23:39.555: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 16:23:39.555: INFO: Node co4fe9zoo9oc-1 is running 0 daemon pod, expected 1
  E0419 16:23:40.250695      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:23:40.553: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 16:23:40.553: INFO: Node co4fe9zoo9oc-1 is running 0 daemon pod, expected 1
  E0419 16:23:41.251080      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:23:41.562: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 19 16:23:41.562: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 04/19/24 16:23:41.588
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3938, will wait for the garbage collector to delete the pods @ 04/19/24 16:23:41.588
  Apr 19 16:23:41.664: INFO: Deleting DaemonSet.extensions daemon-set took: 17.723784ms
  Apr 19 16:23:41.764: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.825951ms
  E0419 16:23:42.252091      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:23:42.974: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 16:23:42.975: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 19 16:23:42.980: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"17370"},"items":null}

  Apr 19 16:23:42.991: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"17370"},"items":null}

  Apr 19 16:23:43.046: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-3938" for this suite. @ 04/19/24 16:23:43.054
• [6.741 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:611
  STEP: Creating a kubernetes client @ 04/19/24 16:23:43.067
  Apr 19 16:23:43.067: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename security-context-test @ 04/19/24 16:23:43.069
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:23:43.099
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:23:43.109
  E0419 16:23:43.252757      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:44.253448      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:45.254167      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:46.254600      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:47.255489      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:48.255826      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:23:49.193: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-5047" for this suite. @ 04/19/24 16:23:49.206
• [6.157 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:86
  STEP: Creating a kubernetes client @ 04/19/24 16:23:49.226
  Apr 19 16:23:49.226: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename downward-api @ 04/19/24 16:23:49.23
  E0419 16:23:49.256823      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:23:49.272
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:23:49.282
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 16:23:49.291
  E0419 16:23:50.256607      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:51.256760      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:52.257110      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:53.258134      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:23:53.337
  Apr 19 16:23:53.354: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod downwardapi-volume-97d4e2cb-061f-4c76-a0da-6d2e1e19d476 container client-container: <nil>
  STEP: delete the pod @ 04/19/24 16:23:53.371
  Apr 19 16:23:53.405: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4361" for this suite. @ 04/19/24 16:23:53.418
• [4.206 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicationController should adopt matching pods on creation [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:95
  STEP: Creating a kubernetes client @ 04/19/24 16:23:53.433
  Apr 19 16:23:53.433: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename replication-controller @ 04/19/24 16:23:53.437
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:23:53.485
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:23:53.489
  STEP: Given a Pod with a 'name' label pod-adoption is created @ 04/19/24 16:23:53.502
  E0419 16:23:54.258465      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:55.258590      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When a replication controller with a matching selector is created @ 04/19/24 16:23:55.561
  STEP: Then the orphan pod is adopted @ 04/19/24 16:23:55.577
  E0419 16:23:56.259605      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:23:56.593: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-2821" for this suite. @ 04/19/24 16:23:56.6
• [3.176 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Hostname [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:244
  STEP: Creating a kubernetes client @ 04/19/24 16:23:56.614
  Apr 19 16:23:56.614: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename dns @ 04/19/24 16:23:56.617
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:23:56.65
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:23:56.655
  STEP: Creating a test headless service @ 04/19/24 16:23:56.661
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7972.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-7972.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
   @ 04/19/24 16:23:56.67
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7972.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-7972.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
   @ 04/19/24 16:23:56.67
  STEP: creating a pod to probe DNS @ 04/19/24 16:23:56.67
  STEP: submitting the pod to kubernetes @ 04/19/24 16:23:56.671
  E0419 16:23:57.260585      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:23:58.260855      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/19/24 16:23:58.707
  STEP: looking for the results for each expected name from probers @ 04/19/24 16:23:58.717
  Apr 19 16:23:58.751: INFO: Unable to read jessie_hosts@dns-querier-2 from pod dns-7972/dns-test-6911f703-3b88-49a4-8f84-a1140f879e3d: the server could not find the requested resource (get pods dns-test-6911f703-3b88-49a4-8f84-a1140f879e3d)
  Apr 19 16:23:58.752: INFO: Lookups using dns-7972/dns-test-6911f703-3b88-49a4-8f84-a1140f879e3d failed for: [jessie_hosts@dns-querier-2]

  Apr 19 16:23:58.762: INFO: Pod client logs for webserver: 
  Apr 19 16:23:58.772: INFO: Pod client logs for querier: 
  Apr 19 16:23:58.784: INFO: Pod client logs for jessie-querier: 
  E0419 16:23:59.260938      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:00.261815      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:01.262619      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:02.262657      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:03.262771      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:24:03.766: INFO: Unable to read jessie_hosts@dns-querier-2 from pod dns-7972/dns-test-6911f703-3b88-49a4-8f84-a1140f879e3d: the server could not find the requested resource (get pods dns-test-6911f703-3b88-49a4-8f84-a1140f879e3d)
  Apr 19 16:24:03.767: INFO: Lookups using dns-7972/dns-test-6911f703-3b88-49a4-8f84-a1140f879e3d failed for: [jessie_hosts@dns-querier-2]

  Apr 19 16:24:03.781: INFO: Pod client logs for webserver: 
  Apr 19 16:24:03.802: INFO: Pod client logs for querier: 
  Apr 19 16:24:03.825: INFO: Pod client logs for jessie-querier: 
  E0419 16:24:04.263470      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:05.263532      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:06.264414      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:07.264222      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:08.265252      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:24:08.742: INFO: DNS probes using dns-7972/dns-test-6911f703-3b88-49a4-8f84-a1140f879e3d succeeded

  STEP: deleting the pod @ 04/19/24 16:24:08.742
  STEP: deleting the test headless service @ 04/19/24 16:24:08.788
  Apr 19 16:24:08.824: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-7972" for this suite. @ 04/19/24 16:24:08.831
• [12.230 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance] [sig-scheduling, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/limit_range.go:253
  STEP: Creating a kubernetes client @ 04/19/24 16:24:08.845
  Apr 19 16:24:08.845: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename limitrange @ 04/19/24 16:24:08.848
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:24:08.884
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:24:08.888
  STEP: Creating LimitRange "e2e-limitrange-gg4dg" in namespace "limitrange-2600" @ 04/19/24 16:24:08.893
  STEP: Creating another limitRange in another namespace @ 04/19/24 16:24:08.9
  Apr 19 16:24:08.925: INFO: Namespace "e2e-limitrange-gg4dg-2320" created
  Apr 19 16:24:08.926: INFO: Creating LimitRange "e2e-limitrange-gg4dg" in namespace "e2e-limitrange-gg4dg-2320"
  STEP: Listing all LimitRanges with label "e2e-test=e2e-limitrange-gg4dg" @ 04/19/24 16:24:08.933
  Apr 19 16:24:08.940: INFO: Found 2 limitRanges
  STEP: Patching LimitRange "e2e-limitrange-gg4dg" in "limitrange-2600" namespace @ 04/19/24 16:24:08.94
  Apr 19 16:24:08.953: INFO: LimitRange "e2e-limitrange-gg4dg" has been patched
  STEP: Delete LimitRange "e2e-limitrange-gg4dg" by Collection with labelSelector: "e2e-limitrange-gg4dg=patched" @ 04/19/24 16:24:08.953
  STEP: Confirm that the limitRange "e2e-limitrange-gg4dg" has been deleted @ 04/19/24 16:24:08.967
  Apr 19 16:24:08.967: INFO: Requesting list of LimitRange to confirm quantity
  Apr 19 16:24:08.972: INFO: Found 0 LimitRange with label "e2e-limitrange-gg4dg=patched"
  Apr 19 16:24:08.972: INFO: LimitRange "e2e-limitrange-gg4dg" has been deleted.
  STEP: Confirm that a single LimitRange still exists with label "e2e-test=e2e-limitrange-gg4dg" @ 04/19/24 16:24:08.973
  Apr 19 16:24:08.979: INFO: Found 1 limitRange
  Apr 19 16:24:08.979: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-2600" for this suite. @ 04/19/24 16:24:08.987
  STEP: Destroying namespace "e2e-limitrange-gg4dg-2320" for this suite. @ 04/19/24 16:24:08.998
• [0.163 seconds]
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:469
  STEP: Creating a kubernetes client @ 04/19/24 16:24:09.009
  Apr 19 16:24:09.009: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename sched-pred @ 04/19/24 16:24:09.013
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:24:09.041
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:24:09.046
  Apr 19 16:24:09.053: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Apr 19 16:24:09.073: INFO: Waiting for terminating namespaces to be deleted...
  Apr 19 16:24:09.081: INFO: 
  Logging pods the apiserver thinks is on node co4fe9zoo9oc-1 before test
  Apr 19 16:24:09.098: INFO: coredns-76f75df574-dnglm from kube-system started at 2024-04-19 15:34:35 +0000 UTC (1 container statuses recorded)
  Apr 19 16:24:09.099: INFO: 	Container coredns ready: true, restart count 1
  Apr 19 16:24:09.099: INFO: coredns-76f75df574-n4wlj from kube-system started at 2024-04-19 15:34:35 +0000 UTC (1 container statuses recorded)
  Apr 19 16:24:09.100: INFO: 	Container coredns ready: true, restart count 1
  Apr 19 16:24:09.101: INFO: kube-addon-manager-co4fe9zoo9oc-1 from kube-system started at 2024-04-19 15:40:36 +0000 UTC (1 container statuses recorded)
  Apr 19 16:24:09.101: INFO: 	Container kube-addon-manager ready: true, restart count 1
  Apr 19 16:24:09.102: INFO: kube-apiserver-co4fe9zoo9oc-1 from kube-system started at 2024-04-19 15:40:36 +0000 UTC (1 container statuses recorded)
  Apr 19 16:24:09.102: INFO: 	Container kube-apiserver ready: true, restart count 1
  Apr 19 16:24:09.104: INFO: kube-controller-manager-co4fe9zoo9oc-1 from kube-system started at 2024-04-19 15:40:36 +0000 UTC (1 container statuses recorded)
  Apr 19 16:24:09.105: INFO: 	Container kube-controller-manager ready: true, restart count 1
  Apr 19 16:24:09.105: INFO: kube-flannel-ds-9gpfv from kube-system started at 2024-04-19 15:34:17 +0000 UTC (1 container statuses recorded)
  Apr 19 16:24:09.106: INFO: 	Container kube-flannel ready: true, restart count 1
  Apr 19 16:24:09.106: INFO: kube-proxy-zzhn9 from kube-system started at 2024-04-19 15:27:31 +0000 UTC (1 container statuses recorded)
  Apr 19 16:24:09.107: INFO: 	Container kube-proxy ready: true, restart count 1
  Apr 19 16:24:09.107: INFO: kube-scheduler-co4fe9zoo9oc-1 from kube-system started at 2024-04-19 15:40:36 +0000 UTC (1 container statuses recorded)
  Apr 19 16:24:09.108: INFO: 	Container kube-scheduler ready: true, restart count 1
  Apr 19 16:24:09.108: INFO: sonobuoy-systemd-logs-daemon-set-f3d7cdfd30314b67-kskjf from sonobuoy started at 2024-04-19 15:41:34 +0000 UTC (2 container statuses recorded)
  Apr 19 16:24:09.109: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 19 16:24:09.109: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 19 16:24:09.110: INFO: 
  Logging pods the apiserver thinks is on node co4fe9zoo9oc-2 before test
  Apr 19 16:24:09.131: INFO: kube-addon-manager-co4fe9zoo9oc-2 from kube-system started at 2024-04-19 15:36:28 +0000 UTC (1 container statuses recorded)
  Apr 19 16:24:09.132: INFO: 	Container kube-addon-manager ready: true, restart count 1
  Apr 19 16:24:09.132: INFO: kube-apiserver-co4fe9zoo9oc-2 from kube-system started at 2024-04-19 15:36:28 +0000 UTC (1 container statuses recorded)
  Apr 19 16:24:09.133: INFO: 	Container kube-apiserver ready: true, restart count 1
  Apr 19 16:24:09.134: INFO: kube-controller-manager-co4fe9zoo9oc-2 from kube-system started at 2024-04-19 15:36:28 +0000 UTC (1 container statuses recorded)
  Apr 19 16:24:09.135: INFO: 	Container kube-controller-manager ready: true, restart count 1
  Apr 19 16:24:09.135: INFO: kube-flannel-ds-g2l7p from kube-system started at 2024-04-19 15:34:17 +0000 UTC (1 container statuses recorded)
  Apr 19 16:24:09.135: INFO: 	Container kube-flannel ready: true, restart count 1
  Apr 19 16:24:09.136: INFO: kube-proxy-6gjw7 from kube-system started at 2024-04-19 15:28:18 +0000 UTC (1 container statuses recorded)
  Apr 19 16:24:09.137: INFO: 	Container kube-proxy ready: true, restart count 1
  Apr 19 16:24:09.137: INFO: kube-scheduler-co4fe9zoo9oc-2 from kube-system started at 2024-04-19 15:36:28 +0000 UTC (1 container statuses recorded)
  Apr 19 16:24:09.137: INFO: 	Container kube-scheduler ready: true, restart count 1
  Apr 19 16:24:09.137: INFO: sonobuoy-systemd-logs-daemon-set-f3d7cdfd30314b67-l6thv from sonobuoy started at 2024-04-19 15:41:34 +0000 UTC (2 container statuses recorded)
  Apr 19 16:24:09.137: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 19 16:24:09.137: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 19 16:24:09.137: INFO: 
  Logging pods the apiserver thinks is on node co4fe9zoo9oc-3 before test
  Apr 19 16:24:09.153: INFO: kube-flannel-ds-8xgdk from kube-system started at 2024-04-19 15:47:35 +0000 UTC (1 container statuses recorded)
  Apr 19 16:24:09.154: INFO: 	Container kube-flannel ready: true, restart count 0
  Apr 19 16:24:09.155: INFO: kube-proxy-nxtbd from kube-system started at 2024-04-19 15:28:43 +0000 UTC (1 container statuses recorded)
  Apr 19 16:24:09.156: INFO: 	Container kube-proxy ready: true, restart count 1
  Apr 19 16:24:09.157: INFO: sonobuoy from sonobuoy started at 2024-04-19 15:41:27 +0000 UTC (1 container statuses recorded)
  Apr 19 16:24:09.157: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Apr 19 16:24:09.158: INFO: sonobuoy-e2e-job-8260c76ae18e4472 from sonobuoy started at 2024-04-19 15:41:34 +0000 UTC (2 container statuses recorded)
  Apr 19 16:24:09.159: INFO: 	Container e2e ready: true, restart count 0
  Apr 19 16:24:09.159: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 19 16:24:09.160: INFO: sonobuoy-systemd-logs-daemon-set-f3d7cdfd30314b67-2fw62 from sonobuoy started at 2024-04-19 15:41:34 +0000 UTC (2 container statuses recorded)
  Apr 19 16:24:09.161: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 19 16:24:09.162: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 04/19/24 16:24:09.163
  E0419 16:24:09.265935      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:10.266615      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 04/19/24 16:24:11.211
  STEP: Trying to apply a random label on the found node. @ 04/19/24 16:24:11.247
  E0419 16:24:11.266925      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the node has the label kubernetes.io/e2e-74a1d360-561e-4107-a1b5-6a780aad3007 42 @ 04/19/24 16:24:11.277
  STEP: Trying to relaunch the pod, now with labels. @ 04/19/24 16:24:11.285
  E0419 16:24:12.267994      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:13.268452      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-74a1d360-561e-4107-a1b5-6a780aad3007 off the node co4fe9zoo9oc-3 @ 04/19/24 16:24:13.36
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-74a1d360-561e-4107-a1b5-6a780aad3007 @ 04/19/24 16:24:13.396
  Apr 19 16:24:13.405: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-801" for this suite. @ 04/19/24 16:24:13.425
• [4.435 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] StorageClasses CSI Conformance should run through the lifecycle of a StorageClass [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/storageclass.go:53
  STEP: Creating a kubernetes client @ 04/19/24 16:24:13.45
  Apr 19 16:24:13.450: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename csi-storageclass @ 04/19/24 16:24:13.459
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:24:13.489
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:24:13.497
  STEP: Creating a StorageClass @ 04/19/24 16:24:13.511
  STEP: Get StorageClass "e2e-g9lgf" @ 04/19/24 16:24:13.525
  STEP: Patching the StorageClass "e2e-g9lgf" @ 04/19/24 16:24:13.535
  STEP: Delete StorageClass "e2e-g9lgf" @ 04/19/24 16:24:13.554
  STEP: Confirm deletion of StorageClass "e2e-g9lgf" @ 04/19/24 16:24:13.585
  STEP: Create a replacement StorageClass @ 04/19/24 16:24:13.595
  STEP: Updating StorageClass "e2e-v2-5nf6n" @ 04/19/24 16:24:13.634
  STEP: Listing all StorageClass with the labelSelector: "e2e-v2-5nf6n=updated" @ 04/19/24 16:24:13.674
  STEP: Deleting StorageClass "e2e-v2-5nf6n" via DeleteCollection @ 04/19/24 16:24:13.683
  STEP: Confirm deletion of StorageClass "e2e-v2-5nf6n" @ 04/19/24 16:24:13.698
  Apr 19 16:24:13.704: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csi-storageclass-9577" for this suite. @ 04/19/24 16:24:13.712
• [0.274 seconds]
------------------------------
SSS
------------------------------
[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:71
  STEP: Creating a kubernetes client @ 04/19/24 16:24:13.726
  Apr 19 16:24:13.727: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename container-probe @ 04/19/24 16:24:13.729
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:24:13.762
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:24:13.767
  E0419 16:24:14.268355      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:15.269287      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:16.269951      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:17.270366      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:18.271169      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:19.271751      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:20.272643      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:21.273064      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:22.274311      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:23.276925      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:24.275506      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:25.275923      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:26.277270      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:27.276947      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:28.277449      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:29.278352      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:30.278046      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:31.278157      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:32.278710      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:33.279338      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:34.280624      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:35.280557      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:24:35.971: INFO: Container started at 2024-04-19 16:24:14 +0000 UTC, pod became ready at 2024-04-19 16:24:34 +0000 UTC
  Apr 19 16:24:35.973: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-5426" for this suite. @ 04/19/24 16:24:35.988
• [22.280 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:69
  STEP: Creating a kubernetes client @ 04/19/24 16:24:36.008
  Apr 19 16:24:36.008: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename subpath @ 04/19/24 16:24:36.014
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:24:36.057
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:24:36.063
  STEP: Setting up data @ 04/19/24 16:24:36.072
  STEP: Creating pod pod-subpath-test-configmap-hjpv @ 04/19/24 16:24:36.093
  STEP: Creating a pod to test atomic-volume-subpath @ 04/19/24 16:24:36.093
  E0419 16:24:36.281101      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:37.287088      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:38.284392      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:39.284761      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:40.284659      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:41.285398      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:42.286122      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:43.286847      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:44.287393      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:45.287601      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:46.288410      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:47.288832      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:48.290203      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:49.289884      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:50.289984      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:51.290121      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:52.290825      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:53.291101      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:54.291308      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:55.291913      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:56.293444      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:57.293345      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:58.294341      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:24:59.295026      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:25:00.279
  Apr 19 16:25:00.289: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-subpath-test-configmap-hjpv container test-container-subpath-configmap-hjpv: <nil>
  E0419 16:25:00.295678      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod @ 04/19/24 16:25:00.309
  STEP: Deleting pod pod-subpath-test-configmap-hjpv @ 04/19/24 16:25:00.345
  Apr 19 16:25:00.345: INFO: Deleting pod "pod-subpath-test-configmap-hjpv" in namespace "subpath-3589"
  Apr 19 16:25:00.351: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-3589" for this suite. @ 04/19/24 16:25:00.361
• [24.366 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:41
  STEP: Creating a kubernetes client @ 04/19/24 16:25:00.391
  Apr 19 16:25:00.391: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename containers @ 04/19/24 16:25:00.394
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:25:00.427
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:25:00.432
  E0419 16:25:01.295918      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:02.296750      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:25:02.498: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-9549" for this suite. @ 04/19/24 16:25:02.51
• [2.134 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:76
  STEP: Creating a kubernetes client @ 04/19/24 16:25:02.527
  Apr 19 16:25:02.527: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename var-expansion @ 04/19/24 16:25:02.53
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:25:02.603
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:25:02.607
  STEP: Creating a pod to test substitution in container's command @ 04/19/24 16:25:02.612
  E0419 16:25:03.297256      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:04.297428      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:05.297795      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:06.298590      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:25:06.661
  Apr 19 16:25:06.667: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod var-expansion-03449851-5a30-4f2b-aca3-fc91387e3eaf container dapi-container: <nil>
  STEP: delete the pod @ 04/19/24 16:25:06.683
  Apr 19 16:25:06.714: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-7034" for this suite. @ 04/19/24 16:25:06.724
• [4.211 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:166
  STEP: Creating a kubernetes client @ 04/19/24 16:25:06.74
  Apr 19 16:25:06.740: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename replicaset @ 04/19/24 16:25:06.743
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:25:06.778
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:25:06.785
  STEP: Create a ReplicaSet @ 04/19/24 16:25:06.793
  STEP: Verify that the required pods have come up @ 04/19/24 16:25:06.807
  Apr 19 16:25:06.820: INFO: Pod name sample-pod: Found 0 pods out of 3
  E0419 16:25:07.298506      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:08.298810      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:09.298755      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:10.299078      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:11.299258      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:25:11.831: INFO: Pod name sample-pod: Found 3 pods out of 3
  STEP: ensuring each pod is running @ 04/19/24 16:25:11.831
  Apr 19 16:25:11.841: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
  STEP: Listing all ReplicaSets @ 04/19/24 16:25:11.841
  STEP: DeleteCollection of the ReplicaSets @ 04/19/24 16:25:11.851
  STEP: After DeleteCollection verify that ReplicaSets have been deleted @ 04/19/24 16:25:11.871
  Apr 19 16:25:11.882: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-9474" for this suite. @ 04/19/24 16:25:11.896
• [5.178 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:214
  STEP: Creating a kubernetes client @ 04/19/24 16:25:11.924
  Apr 19 16:25:11.924: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename container-probe @ 04/19/24 16:25:11.928
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:25:12.017
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:25:12.026
  STEP: Creating pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995 @ 04/19/24 16:25:12.032
  E0419 16:25:12.300272      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:13.310736      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/19/24 16:25:14.077
  Apr 19 16:25:14.091: INFO: Initial restart count of pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 is 0
  Apr 19 16:25:14.101: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:25:14.311684      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:15.312365      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:25:16.114: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:25:16.313073      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:17.313803      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:25:18.131: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:25:18.314477      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:19.314810      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:25:20.142: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:25:20.315992      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:21.316073      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:25:22.155: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:25:22.316827      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:23.320880      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:25:24.171: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:25:24.319396      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:25.319618      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:25:26.184: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:25:26.320612      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:27.321420      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:25:28.195: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:25:28.322327      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:29.322647      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:25:30.209: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:25:30.323432      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:31.324749      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:25:32.221: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:25:32.325331      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:33.326055      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:25:34.232: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:25:34.326921      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:35.327206      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:25:36.244: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:25:36.327439      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:37.328023      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:25:38.255: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:25:38.328983      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:39.329376      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:25:40.269: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:25:40.329912      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:41.330047      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:25:42.281: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:25:42.330939      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:43.331365      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:25:44.290: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:25:44.332012      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:45.332368      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:25:46.301: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:25:46.332981      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:47.333297      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:25:48.309: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:25:48.333552      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:49.334968      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:25:50.319: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:25:50.337512      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:51.338068      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:25:52.328: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:25:52.338932      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:53.339878      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:25:54.338: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:25:54.340580      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:55.341721      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:56.342704      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:25:56.352: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:25:57.343679      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:25:58.344852      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:25:58.361: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:25:59.345760      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:00.346248      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:26:00.371: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:26:01.346312      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:02.347034      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:26:02.385: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:26:03.347046      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:04.347380      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:26:04.395: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:26:05.347724      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:06.348089      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:26:06.406: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:26:07.348391      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:08.348650      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:26:08.414: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:26:09.349705      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:10.350397      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:26:10.425: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:26:11.350520      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:12.350908      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:26:12.433: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:26:13.351721      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:14.351986      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:26:14.443: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:26:15.352992      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:16.353791      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:26:16.451: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:26:17.354571      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:18.355610      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:26:18.463: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:26:19.356641      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:20.356823      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:26:20.471: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:26:21.357622      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:22.357948      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:26:22.484: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:26:23.358659      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:24.358746      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:26:24.493: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:26:25.358928      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:26.359262      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:26:26.503: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:26:27.359575      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:28.359870      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:26:28.510: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:26:29.360139      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:30.360477      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:26:30.518: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:26:31.361026      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:32.361909      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:26:32.531: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:26:33.362080      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:34.362672      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:26:34.542: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:26:35.363273      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:36.363419      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:26:36.552: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:26:37.363835      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:38.364009      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:26:38.562: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:26:39.364292      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:40.364410      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:26:40.570: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:26:41.365103      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:42.365347      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:26:42.579: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:26:43.365517      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:44.365658      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:26:44.588: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:26:45.365863      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:46.366264      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:26:46.597: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:26:47.366762      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:48.367477      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:26:48.610: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:26:49.368590      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:50.368748      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:26:50.619: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:26:51.368937      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:52.369328      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:26:52.627: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:26:53.369465      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:54.369767      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:26:54.635: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:26:55.369855      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:56.370097      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:26:56.646: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:26:57.370322      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:26:58.370461      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:26:58.658: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:26:59.371090      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:00.371309      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:27:00.667: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:27:01.371728      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:02.372161      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:27:02.677: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:27:03.372627      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:04.373235      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:27:04.687: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:27:05.374156      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:06.374806      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:27:06.698: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:27:07.375064      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:08.374935      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:27:08.708: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:27:09.376053      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:10.376276      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:27:10.720: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:27:11.377071      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:12.377300      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:27:12.731: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:27:13.377717      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:14.378385      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:27:14.755: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:27:15.379095      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:16.379428      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:27:16.768: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:27:17.379761      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:18.380104      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:27:18.782: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:27:19.380817      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:20.380827      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:27:20.791: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:27:21.381439      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:22.381295      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:27:22.807: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:27:23.381925      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:24.381942      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:27:24.821: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:27:25.383110      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:26.383494      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:27:26.838: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:27:27.383354      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:28.384107      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:27:28.849: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:27:29.384447      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:30.385154      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:27:30.859: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:27:31.386091      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:32.386823      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:27:32.871: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:27:33.387209      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:34.387419      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:27:34.883: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:27:35.387794      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:36.388094      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:27:36.899: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:27:37.388684      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:38.389036      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:27:38.910: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:27:39.389572      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:40.389863      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:27:40.921: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:27:41.392157      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:42.391338      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:27:42.934: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:27:43.392233      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:44.392657      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:27:44.945: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:27:45.392868      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:46.393445      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:27:46.956: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:27:47.393907      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:48.394184      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:27:48.965: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:27:49.395661      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:50.396156      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:27:50.975: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:27:51.396767      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:52.397814      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:27:52.987: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:27:53.398363      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:54.398824      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:27:54.998: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:27:55.398971      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:56.399379      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:27:57.009: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:27:57.400426      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:27:58.401624      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:27:59.027: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:27:59.401733      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:00.402012      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:28:01.037: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:28:01.402224      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:02.402706      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:28:03.046: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:28:03.402894      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:04.403019      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:28:05.060: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:28:05.403298      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:06.404453      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:28:07.070: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:28:07.404783      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:08.404759      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:28:09.080: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:28:09.405992      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:10.406945      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:28:11.089: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:28:11.407872      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:12.407983      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:28:13.100: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:28:13.409337      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:14.409512      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:28:15.109: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:28:15.409786      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:16.410191      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:28:17.128: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:28:17.410881      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:18.411267      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:28:19.136: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:28:19.411311      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:20.413021      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:28:21.147: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:28:21.413631      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:22.413838      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:28:23.157: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:28:23.414925      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:24.415213      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:28:25.167: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:28:25.416240      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:26.416726      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:28:27.177: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:28:27.416987      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:28.417142      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:28:29.186: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:28:29.418037      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:30.418792      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:28:31.194: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:28:31.418625      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:32.418792      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:28:33.206: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:28:33.419701      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:34.420557      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:28:35.214: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:28:35.420709      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:36.420980      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:28:37.225: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:28:37.421709      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:38.422149      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:28:39.234: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:28:39.422826      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:40.423182      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:28:41.246: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:28:41.424183      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:42.425048      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:28:43.258: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:28:43.426050      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:44.426867      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:28:45.267: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:28:45.427810      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:46.428723      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:28:47.279: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:28:47.429495      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:48.429549      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:28:49.287: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:28:49.430176      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:50.430720      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:28:51.299: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:28:51.431526      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:52.431699      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:28:53.308: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:28:53.432614      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:54.432921      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:28:55.320: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:28:55.433956      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:56.434940      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:28:57.331: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:28:57.435503      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:28:58.436494      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:28:59.344: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:28:59.436036      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:00.436272      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:29:01.352: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:29:01.436730      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:02.437204      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:29:03.363: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:29:03.437199      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:04.437396      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:29:05.370: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:29:05.437589      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:06.437991      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:29:07.385: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:29:07.439230      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:08.443549      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:29:09.399: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:29:09.444220      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:10.444210      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:29:11.413: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:29:11.444693      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:12.445008      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:29:13.422: INFO: Get pod test-webserver-f5daa679-baaf-4f08-b300-9f202c955fb8 in namespace container-probe-995
  E0419 16:29:13.446063      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:14.446250      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 04/19/24 16:29:15.423
  E0419 16:29:15.448639      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:29:15.458: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-995" for this suite. @ 04/19/24 16:29:15.474
• [243.587 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:248
  STEP: Creating a kubernetes client @ 04/19/24 16:29:15.511
  Apr 19 16:29:15.511: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename container-runtime @ 04/19/24 16:29:15.518
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:29:15.617
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:29:15.623
  STEP: create the container @ 04/19/24 16:29:15.633
  W0419 16:29:15.653806      13 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 04/19/24 16:29:15.654
  E0419 16:29:16.449679      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:17.450710      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:18.453167      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 04/19/24 16:29:18.696
  STEP: the container should be terminated @ 04/19/24 16:29:18.706
  STEP: the termination message should be set @ 04/19/24 16:29:18.706
  Apr 19 16:29:18.707: INFO: Expected: &{OK} to match Container's Termination Message: OK --
  STEP: delete the container @ 04/19/24 16:29:18.707
  Apr 19 16:29:18.747: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-7368" for this suite. @ 04/19/24 16:29:18.767
• [3.278 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1698
  STEP: Creating a kubernetes client @ 04/19/24 16:29:18.796
  Apr 19 16:29:18.796: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename kubectl @ 04/19/24 16:29:18.8
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:29:18.847
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:29:18.859
  STEP: creating Agnhost RC @ 04/19/24 16:29:18.867
  Apr 19 16:29:18.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-3599 create -f -'
  Apr 19 16:29:19.212: INFO: stderr: ""
  Apr 19 16:29:19.212: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 04/19/24 16:29:19.212
  E0419 16:29:19.454045      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:29:20.221: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 19 16:29:20.221: INFO: Found 1 / 1
  Apr 19 16:29:20.221: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  STEP: patching all pods @ 04/19/24 16:29:20.221
  Apr 19 16:29:20.226: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 19 16:29:20.226: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Apr 19 16:29:20.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-3599 patch pod agnhost-primary-4mt5t -p {"metadata":{"annotations":{"x":"y"}}}'
  Apr 19 16:29:20.415: INFO: stderr: ""
  Apr 19 16:29:20.415: INFO: stdout: "pod/agnhost-primary-4mt5t patched\n"
  STEP: checking annotations @ 04/19/24 16:29:20.415
  Apr 19 16:29:20.422: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 19 16:29:20.422: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Apr 19 16:29:20.422: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3599" for this suite. @ 04/19/24 16:29:20.432
• [1.651 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:220
  STEP: Creating a kubernetes client @ 04/19/24 16:29:20.449
  Apr 19 16:29:20.449: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename emptydir @ 04/19/24 16:29:20.454
  E0419 16:29:20.455382      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:29:20.487
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:29:20.492
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 04/19/24 16:29:20.497
  E0419 16:29:21.456034      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:22.456047      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:23.457174      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:24.457344      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:29:24.542
  Apr 19 16:29:24.549: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-fe801446-78ad-4a65-afde-e7cba379e101 container test-container: <nil>
  STEP: delete the pod @ 04/19/24 16:29:24.588
  Apr 19 16:29:24.622: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7583" for this suite. @ 04/19/24 16:29:24.631
• [4.201 seconds]
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:67
  STEP: Creating a kubernetes client @ 04/19/24 16:29:24.651
  Apr 19 16:29:24.651: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename projected @ 04/19/24 16:29:24.656
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:29:24.711
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:29:24.721
  STEP: Creating projection with secret that has name projected-secret-test-db5d1be9-97de-48f3-a157-ebe9ee2197bd @ 04/19/24 16:29:24.731
  STEP: Creating a pod to test consume secrets @ 04/19/24 16:29:24.742
  E0419 16:29:25.458031      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:26.459247      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:27.459536      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:28.459777      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:29:28.795
  Apr 19 16:29:28.803: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-projected-secrets-22f78cf2-529f-4b49-ba68-e243b5afc717 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/24 16:29:28.823
  Apr 19 16:29:28.847: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5399" for this suite. @ 04/19/24 16:29:28.856
• [4.220 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Ingress API should support creating Ingress API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/ingress.go:558
  STEP: Creating a kubernetes client @ 04/19/24 16:29:28.875
  Apr 19 16:29:28.875: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename ingress @ 04/19/24 16:29:28.878
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:29:28.94
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:29:28.946
  STEP: getting /apis @ 04/19/24 16:29:28.954
  STEP: getting /apis/networking.k8s.io @ 04/19/24 16:29:28.966
  STEP: getting /apis/networking.k8s.iov1 @ 04/19/24 16:29:28.969
  STEP: creating @ 04/19/24 16:29:28.973
  STEP: getting @ 04/19/24 16:29:29.008
  STEP: listing @ 04/19/24 16:29:29.017
  STEP: watching @ 04/19/24 16:29:29.031
  Apr 19 16:29:29.031: INFO: starting watch
  STEP: cluster-wide listing @ 04/19/24 16:29:29.035
  STEP: cluster-wide watching @ 04/19/24 16:29:29.044
  Apr 19 16:29:29.044: INFO: starting watch
  STEP: patching @ 04/19/24 16:29:29.047
  STEP: updating @ 04/19/24 16:29:29.063
  Apr 19 16:29:29.084: INFO: waiting for watch events with expected annotations
  Apr 19 16:29:29.084: INFO: saw patched and updated annotations
  STEP: patching /status @ 04/19/24 16:29:29.085
  STEP: updating /status @ 04/19/24 16:29:29.1
  STEP: get /status @ 04/19/24 16:29:29.124
  STEP: deleting @ 04/19/24 16:29:29.132
  STEP: deleting a collection @ 04/19/24 16:29:29.161
  Apr 19 16:29:29.202: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingress-6273" for this suite. @ 04/19/24 16:29:29.215
• [0.359 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:263
  STEP: Creating a kubernetes client @ 04/19/24 16:29:29.238
  Apr 19 16:29:29.239: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename downward-api @ 04/19/24 16:29:29.243
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:29:29.306
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:29:29.311
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 16:29:29.32
  E0419 16:29:29.460832      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:30.461382      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:31.461797      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:32.461779      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:29:33.397
  Apr 19 16:29:33.404: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod downwardapi-volume-04c3ec8f-858f-4606-b9ad-33c2a8730179 container client-container: <nil>
  STEP: delete the pod @ 04/19/24 16:29:33.421
  E0419 16:29:33.463636      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:29:33.472: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4813" for this suite. @ 04/19/24 16:29:33.483
• [4.259 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:209
  STEP: Creating a kubernetes client @ 04/19/24 16:29:33.5
  Apr 19 16:29:33.500: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename projected @ 04/19/24 16:29:33.504
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:29:33.545
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:29:33.556
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 16:29:33.568
  E0419 16:29:34.464032      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:35.465988      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:36.465808      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:37.466101      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:29:37.615
  Apr 19 16:29:37.634: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod downwardapi-volume-71af2469-0a6b-4dff-8cc3-80b0f5d31cee container client-container: <nil>
  STEP: delete the pod @ 04/19/24 16:29:37.65
  Apr 19 16:29:37.679: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8968" for this suite. @ 04/19/24 16:29:37.688
• [4.199 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Job should apply changes to a job status [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:784
  STEP: Creating a kubernetes client @ 04/19/24 16:29:37.701
  Apr 19 16:29:37.701: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename job @ 04/19/24 16:29:37.705
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:29:37.733
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:29:37.737
  STEP: Creating a job @ 04/19/24 16:29:37.745
  STEP: Ensure pods equal to parallelism count is attached to the job @ 04/19/24 16:29:37.757
  E0419 16:29:38.466253      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:39.467082      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching /status @ 04/19/24 16:29:39.772
  STEP: updating /status @ 04/19/24 16:29:39.794
  STEP: get /status @ 04/19/24 16:29:39.819
  Apr 19 16:29:39.828: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-4370" for this suite. @ 04/19/24 16:29:39.842
• [2.161 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:144
  STEP: Creating a kubernetes client @ 04/19/24 16:29:39.868
  Apr 19 16:29:39.869: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename replicaset @ 04/19/24 16:29:39.873
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:29:39.909
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:29:39.918
  STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota @ 04/19/24 16:29:39.928
  Apr 19 16:29:39.951: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0419 16:29:40.467815      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:41.468911      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:42.469995      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:43.471211      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:44.471931      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:29:44.962: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/19/24 16:29:44.964
  STEP: getting scale subresource @ 04/19/24 16:29:44.965
  STEP: updating a scale subresource @ 04/19/24 16:29:44.975
  STEP: verifying the replicaset Spec.Replicas was modified @ 04/19/24 16:29:44.988
  STEP: Patch a scale subresource @ 04/19/24 16:29:44.995
  Apr 19 16:29:45.022: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-2569" for this suite. @ 04/19/24 16:29:45.033
• [5.188 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/persistent_volumes.go:669
  STEP: Creating a kubernetes client @ 04/19/24 16:29:45.057
  Apr 19 16:29:45.057: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename pv @ 04/19/24 16:29:45.06
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:29:45.135
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:29:45.142
  STEP: Creating initial PV and PVC @ 04/19/24 16:29:45.148
  Apr 19 16:29:45.148: INFO: Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-9196" @ 04/19/24 16:29:45.169
  STEP: Listing PVCs in namespace "pv-9196" @ 04/19/24 16:29:45.175
  STEP: Reading "pvc-bbqhr" Status @ 04/19/24 16:29:45.183
  STEP: Reading "pv-9196-q2r9g" Status @ 04/19/24 16:29:45.196
  STEP: Patching "pvc-bbqhr" Status @ 04/19/24 16:29:45.206
  STEP: Patching "pv-9196-q2r9g" Status @ 04/19/24 16:29:45.213
  STEP: Updating "pvc-bbqhr" Status @ 04/19/24 16:29:45.23
  STEP: Updating "pv-9196-q2r9g" Status @ 04/19/24 16:29:45.245
  Apr 19 16:29:45.285: INFO: AfterEach: deleting 1 PVCs and 1 PVs...
  Apr 19 16:29:45.286: INFO: Deleting PersistentVolumeClaim "pvc-bbqhr"
  Apr 19 16:29:45.330: INFO: Deleting PersistentVolume "pv-9196-q2r9g"
  Apr 19 16:29:45.340: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-9196" for this suite. @ 04/19/24 16:29:45.349
• [0.303 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:134
  STEP: Creating a kubernetes client @ 04/19/24 16:29:45.367
  Apr 19 16:29:45.367: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename container-probe @ 04/19/24 16:29:45.369
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:29:45.402
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:29:45.407
  STEP: Creating pod busybox-19e7fc24-2d18-44fa-b006-2160cc978d7b in namespace container-probe-3378 @ 04/19/24 16:29:45.413
  E0419 16:29:45.472555      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:46.476631      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/19/24 16:29:47.456
  Apr 19 16:29:47.466: INFO: Initial restart count of pod busybox-19e7fc24-2d18-44fa-b006-2160cc978d7b is 0
  Apr 19 16:29:47.474: INFO: Get pod busybox-19e7fc24-2d18-44fa-b006-2160cc978d7b in namespace container-probe-3378
  E0419 16:29:47.475127      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:48.477105      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:49.477117      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:29:49.487: INFO: Get pod busybox-19e7fc24-2d18-44fa-b006-2160cc978d7b in namespace container-probe-3378
  E0419 16:29:50.478339      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:51.477868      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:29:51.496: INFO: Get pod busybox-19e7fc24-2d18-44fa-b006-2160cc978d7b in namespace container-probe-3378
  E0419 16:29:52.490759      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:53.483101      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:29:53.514: INFO: Get pod busybox-19e7fc24-2d18-44fa-b006-2160cc978d7b in namespace container-probe-3378
  E0419 16:29:54.480725      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:55.481055      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:29:55.536: INFO: Get pod busybox-19e7fc24-2d18-44fa-b006-2160cc978d7b in namespace container-probe-3378
  E0419 16:29:56.481379      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:57.481765      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:29:57.549: INFO: Get pod busybox-19e7fc24-2d18-44fa-b006-2160cc978d7b in namespace container-probe-3378
  E0419 16:29:58.482215      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:29:59.484498      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:29:59.564: INFO: Get pod busybox-19e7fc24-2d18-44fa-b006-2160cc978d7b in namespace container-probe-3378
  E0419 16:30:00.484468      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:01.485446      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:30:01.581: INFO: Get pod busybox-19e7fc24-2d18-44fa-b006-2160cc978d7b in namespace container-probe-3378
  E0419 16:30:02.485887      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:03.486830      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:30:03.591: INFO: Get pod busybox-19e7fc24-2d18-44fa-b006-2160cc978d7b in namespace container-probe-3378
  E0419 16:30:04.487645      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:05.487972      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:30:05.608: INFO: Get pod busybox-19e7fc24-2d18-44fa-b006-2160cc978d7b in namespace container-probe-3378
  E0419 16:30:06.488211      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:07.488930      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:30:07.617: INFO: Get pod busybox-19e7fc24-2d18-44fa-b006-2160cc978d7b in namespace container-probe-3378
  E0419 16:30:08.488538      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:09.488838      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:30:09.642: INFO: Get pod busybox-19e7fc24-2d18-44fa-b006-2160cc978d7b in namespace container-probe-3378
  E0419 16:30:10.489842      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:11.490703      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:30:11.652: INFO: Get pod busybox-19e7fc24-2d18-44fa-b006-2160cc978d7b in namespace container-probe-3378
  E0419 16:30:12.490703      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:13.491072      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:30:13.659: INFO: Get pod busybox-19e7fc24-2d18-44fa-b006-2160cc978d7b in namespace container-probe-3378
  E0419 16:30:14.491318      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:15.491830      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:30:15.674: INFO: Get pod busybox-19e7fc24-2d18-44fa-b006-2160cc978d7b in namespace container-probe-3378
  E0419 16:30:16.492108      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:17.493144      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:30:17.683: INFO: Get pod busybox-19e7fc24-2d18-44fa-b006-2160cc978d7b in namespace container-probe-3378
  E0419 16:30:18.493547      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:19.494016      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:30:19.696: INFO: Get pod busybox-19e7fc24-2d18-44fa-b006-2160cc978d7b in namespace container-probe-3378
  E0419 16:30:20.494978      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:21.496314      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:30:21.705: INFO: Get pod busybox-19e7fc24-2d18-44fa-b006-2160cc978d7b in namespace container-probe-3378
  E0419 16:30:22.496743      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:23.496932      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:30:23.717: INFO: Get pod busybox-19e7fc24-2d18-44fa-b006-2160cc978d7b in namespace container-probe-3378
  E0419 16:30:24.497198      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:25.497395      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:30:25.725: INFO: Get pod busybox-19e7fc24-2d18-44fa-b006-2160cc978d7b in namespace container-probe-3378
  E0419 16:30:26.497704      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:27.498636      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:30:27.736: INFO: Get pod busybox-19e7fc24-2d18-44fa-b006-2160cc978d7b in namespace container-probe-3378
  E0419 16:30:28.498740      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:29.498908      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:30:29.752: INFO: Get pod busybox-19e7fc24-2d18-44fa-b006-2160cc978d7b in namespace container-probe-3378
  E0419 16:30:30.499758      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:31.500618      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:30:31.760: INFO: Get pod busybox-19e7fc24-2d18-44fa-b006-2160cc978d7b in namespace container-probe-3378
  E0419 16:30:32.500857      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:33.501151      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:30:33.769: INFO: Get pod busybox-19e7fc24-2d18-44fa-b006-2160cc978d7b in namespace container-probe-3378
  E0419 16:30:34.501378      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:35.501708      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:30:35.781: INFO: Get pod busybox-19e7fc24-2d18-44fa-b006-2160cc978d7b in namespace container-probe-3378
  E0419 16:30:36.501945      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:37.502895      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:30:37.789: INFO: Get pod busybox-19e7fc24-2d18-44fa-b006-2160cc978d7b in namespace container-probe-3378
  Apr 19 16:30:37.789: INFO: Restart count of pod container-probe-3378/busybox-19e7fc24-2d18-44fa-b006-2160cc978d7b is now 1 (50.323424324s elapsed)
  STEP: deleting the pod @ 04/19/24 16:30:37.79
  Apr 19 16:30:37.812: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-3378" for this suite. @ 04/19/24 16:30:37.821
• [52.477 seconds]
------------------------------
[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2199
  STEP: Creating a kubernetes client @ 04/19/24 16:30:37.845
  Apr 19 16:30:37.845: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename services @ 04/19/24 16:30:37.851
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:30:37.89
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:30:37.896
  STEP: creating service in namespace services-8435 @ 04/19/24 16:30:37.901
  STEP: creating service affinity-clusterip-transition in namespace services-8435 @ 04/19/24 16:30:37.901
  STEP: creating replication controller affinity-clusterip-transition in namespace services-8435 @ 04/19/24 16:30:37.923
  I0419 16:30:37.942807      13 runners.go:197] Created replication controller with name: affinity-clusterip-transition, namespace: services-8435, replica count: 3
  E0419 16:30:38.503929      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:39.505554      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:40.505848      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:30:40.994810      13 runners.go:197] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 19 16:30:41.016: INFO: Creating new exec pod
  E0419 16:30:41.506433      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:42.507089      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:43.508333      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:30:44.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-8435 exec execpod-affinity77jwx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
  Apr 19 16:30:44.435: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
  Apr 19 16:30:44.436: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 16:30:44.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-8435 exec execpod-affinity77jwx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.49.184 80'
  E0419 16:30:44.508300      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:30:44.703: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.49.184 80\nConnection to 10.233.49.184 80 port [tcp/http] succeeded!\n"
  Apr 19 16:30:44.703: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 16:30:44.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-8435 exec execpod-affinity77jwx -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.49.184:80/ ; done'
  Apr 19 16:30:45.211: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.184:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.184:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.184:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.184:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.184:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.184:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.184:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.184:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.184:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.184:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.184:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.184:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.184:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.184:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.184:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.184:80/\n"
  Apr 19 16:30:45.211: INFO: stdout: "\naffinity-clusterip-transition-xxkj8\naffinity-clusterip-transition-zczhj\naffinity-clusterip-transition-kkv5t\naffinity-clusterip-transition-zczhj\naffinity-clusterip-transition-kkv5t\naffinity-clusterip-transition-kkv5t\naffinity-clusterip-transition-xxkj8\naffinity-clusterip-transition-kkv5t\naffinity-clusterip-transition-zczhj\naffinity-clusterip-transition-kkv5t\naffinity-clusterip-transition-xxkj8\naffinity-clusterip-transition-zczhj\naffinity-clusterip-transition-xxkj8\naffinity-clusterip-transition-kkv5t\naffinity-clusterip-transition-kkv5t\naffinity-clusterip-transition-kkv5t"
  Apr 19 16:30:45.212: INFO: Received response from host: affinity-clusterip-transition-xxkj8
  Apr 19 16:30:45.212: INFO: Received response from host: affinity-clusterip-transition-zczhj
  Apr 19 16:30:45.212: INFO: Received response from host: affinity-clusterip-transition-kkv5t
  Apr 19 16:30:45.212: INFO: Received response from host: affinity-clusterip-transition-zczhj
  Apr 19 16:30:45.212: INFO: Received response from host: affinity-clusterip-transition-kkv5t
  Apr 19 16:30:45.212: INFO: Received response from host: affinity-clusterip-transition-kkv5t
  Apr 19 16:30:45.212: INFO: Received response from host: affinity-clusterip-transition-xxkj8
  Apr 19 16:30:45.212: INFO: Received response from host: affinity-clusterip-transition-kkv5t
  Apr 19 16:30:45.212: INFO: Received response from host: affinity-clusterip-transition-zczhj
  Apr 19 16:30:45.212: INFO: Received response from host: affinity-clusterip-transition-kkv5t
  Apr 19 16:30:45.212: INFO: Received response from host: affinity-clusterip-transition-xxkj8
  Apr 19 16:30:45.212: INFO: Received response from host: affinity-clusterip-transition-zczhj
  Apr 19 16:30:45.212: INFO: Received response from host: affinity-clusterip-transition-xxkj8
  Apr 19 16:30:45.212: INFO: Received response from host: affinity-clusterip-transition-kkv5t
  Apr 19 16:30:45.212: INFO: Received response from host: affinity-clusterip-transition-kkv5t
  Apr 19 16:30:45.212: INFO: Received response from host: affinity-clusterip-transition-kkv5t
  Apr 19 16:30:45.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-8435 exec execpod-affinity77jwx -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.49.184:80/ ; done'
  E0419 16:30:45.508980      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:30:45.778: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.184:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.184:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.184:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.184:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.184:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.184:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.184:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.184:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.184:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.184:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.184:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.184:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.184:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.184:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.184:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.184:80/\n"
  Apr 19 16:30:45.778: INFO: stdout: "\naffinity-clusterip-transition-xxkj8\naffinity-clusterip-transition-xxkj8\naffinity-clusterip-transition-xxkj8\naffinity-clusterip-transition-xxkj8\naffinity-clusterip-transition-xxkj8\naffinity-clusterip-transition-xxkj8\naffinity-clusterip-transition-xxkj8\naffinity-clusterip-transition-xxkj8\naffinity-clusterip-transition-xxkj8\naffinity-clusterip-transition-xxkj8\naffinity-clusterip-transition-xxkj8\naffinity-clusterip-transition-xxkj8\naffinity-clusterip-transition-xxkj8\naffinity-clusterip-transition-xxkj8\naffinity-clusterip-transition-xxkj8\naffinity-clusterip-transition-xxkj8"
  Apr 19 16:30:45.778: INFO: Received response from host: affinity-clusterip-transition-xxkj8
  Apr 19 16:30:45.778: INFO: Received response from host: affinity-clusterip-transition-xxkj8
  Apr 19 16:30:45.778: INFO: Received response from host: affinity-clusterip-transition-xxkj8
  Apr 19 16:30:45.778: INFO: Received response from host: affinity-clusterip-transition-xxkj8
  Apr 19 16:30:45.778: INFO: Received response from host: affinity-clusterip-transition-xxkj8
  Apr 19 16:30:45.778: INFO: Received response from host: affinity-clusterip-transition-xxkj8
  Apr 19 16:30:45.778: INFO: Received response from host: affinity-clusterip-transition-xxkj8
  Apr 19 16:30:45.778: INFO: Received response from host: affinity-clusterip-transition-xxkj8
  Apr 19 16:30:45.778: INFO: Received response from host: affinity-clusterip-transition-xxkj8
  Apr 19 16:30:45.779: INFO: Received response from host: affinity-clusterip-transition-xxkj8
  Apr 19 16:30:45.779: INFO: Received response from host: affinity-clusterip-transition-xxkj8
  Apr 19 16:30:45.779: INFO: Received response from host: affinity-clusterip-transition-xxkj8
  Apr 19 16:30:45.779: INFO: Received response from host: affinity-clusterip-transition-xxkj8
  Apr 19 16:30:45.779: INFO: Received response from host: affinity-clusterip-transition-xxkj8
  Apr 19 16:30:45.779: INFO: Received response from host: affinity-clusterip-transition-xxkj8
  Apr 19 16:30:45.779: INFO: Received response from host: affinity-clusterip-transition-xxkj8
  Apr 19 16:30:45.779: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-8435, will wait for the garbage collector to delete the pods @ 04/19/24 16:30:45.804
  Apr 19 16:30:45.875: INFO: Deleting ReplicationController affinity-clusterip-transition took: 14.303445ms
  Apr 19 16:30:45.975: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.356588ms
  E0419 16:30:46.509391      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:47.509450      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:48.509632      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:30:48.817: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8435" for this suite. @ 04/19/24 16:30:48.826
• [10.994 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:126
  STEP: Creating a kubernetes client @ 04/19/24 16:30:48.856
  Apr 19 16:30:48.856: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename discovery @ 04/19/24 16:30:48.86
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:30:48.887
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:30:48.893
  STEP: Setting up server cert @ 04/19/24 16:30:48.901
  Apr 19 16:30:49.507: INFO: Checking APIGroup: apiregistration.k8s.io
  E0419 16:30:49.509613      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:30:49.510: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
  Apr 19 16:30:49.510: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
  Apr 19 16:30:49.510: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
  Apr 19 16:30:49.510: INFO: Checking APIGroup: apps
  Apr 19 16:30:49.512: INFO: PreferredVersion.GroupVersion: apps/v1
  Apr 19 16:30:49.512: INFO: Versions found [{apps/v1 v1}]
  Apr 19 16:30:49.512: INFO: apps/v1 matches apps/v1
  Apr 19 16:30:49.512: INFO: Checking APIGroup: events.k8s.io
  Apr 19 16:30:49.516: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
  Apr 19 16:30:49.517: INFO: Versions found [{events.k8s.io/v1 v1}]
  Apr 19 16:30:49.517: INFO: events.k8s.io/v1 matches events.k8s.io/v1
  Apr 19 16:30:49.517: INFO: Checking APIGroup: authentication.k8s.io
  Apr 19 16:30:49.521: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
  Apr 19 16:30:49.521: INFO: Versions found [{authentication.k8s.io/v1 v1}]
  Apr 19 16:30:49.521: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
  Apr 19 16:30:49.521: INFO: Checking APIGroup: authorization.k8s.io
  Apr 19 16:30:49.524: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
  Apr 19 16:30:49.524: INFO: Versions found [{authorization.k8s.io/v1 v1}]
  Apr 19 16:30:49.524: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
  Apr 19 16:30:49.524: INFO: Checking APIGroup: autoscaling
  Apr 19 16:30:49.527: INFO: PreferredVersion.GroupVersion: autoscaling/v2
  Apr 19 16:30:49.527: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1}]
  Apr 19 16:30:49.527: INFO: autoscaling/v2 matches autoscaling/v2
  Apr 19 16:30:49.527: INFO: Checking APIGroup: batch
  Apr 19 16:30:49.529: INFO: PreferredVersion.GroupVersion: batch/v1
  Apr 19 16:30:49.530: INFO: Versions found [{batch/v1 v1}]
  Apr 19 16:30:49.531: INFO: batch/v1 matches batch/v1
  Apr 19 16:30:49.531: INFO: Checking APIGroup: certificates.k8s.io
  Apr 19 16:30:49.534: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
  Apr 19 16:30:49.534: INFO: Versions found [{certificates.k8s.io/v1 v1}]
  Apr 19 16:30:49.534: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
  Apr 19 16:30:49.534: INFO: Checking APIGroup: networking.k8s.io
  Apr 19 16:30:49.537: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
  Apr 19 16:30:49.537: INFO: Versions found [{networking.k8s.io/v1 v1}]
  Apr 19 16:30:49.538: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
  Apr 19 16:30:49.538: INFO: Checking APIGroup: policy
  Apr 19 16:30:49.542: INFO: PreferredVersion.GroupVersion: policy/v1
  Apr 19 16:30:49.542: INFO: Versions found [{policy/v1 v1}]
  Apr 19 16:30:49.542: INFO: policy/v1 matches policy/v1
  Apr 19 16:30:49.542: INFO: Checking APIGroup: rbac.authorization.k8s.io
  Apr 19 16:30:49.545: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
  Apr 19 16:30:49.545: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
  Apr 19 16:30:49.545: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
  Apr 19 16:30:49.545: INFO: Checking APIGroup: storage.k8s.io
  Apr 19 16:30:49.547: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
  Apr 19 16:30:49.547: INFO: Versions found [{storage.k8s.io/v1 v1}]
  Apr 19 16:30:49.547: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
  Apr 19 16:30:49.547: INFO: Checking APIGroup: admissionregistration.k8s.io
  Apr 19 16:30:49.549: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
  Apr 19 16:30:49.549: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
  Apr 19 16:30:49.549: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
  Apr 19 16:30:49.549: INFO: Checking APIGroup: apiextensions.k8s.io
  Apr 19 16:30:49.551: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
  Apr 19 16:30:49.551: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
  Apr 19 16:30:49.551: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
  Apr 19 16:30:49.552: INFO: Checking APIGroup: scheduling.k8s.io
  Apr 19 16:30:49.554: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
  Apr 19 16:30:49.554: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
  Apr 19 16:30:49.554: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
  Apr 19 16:30:49.554: INFO: Checking APIGroup: coordination.k8s.io
  Apr 19 16:30:49.556: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
  Apr 19 16:30:49.556: INFO: Versions found [{coordination.k8s.io/v1 v1}]
  Apr 19 16:30:49.556: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
  Apr 19 16:30:49.557: INFO: Checking APIGroup: node.k8s.io
  Apr 19 16:30:49.559: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
  Apr 19 16:30:49.560: INFO: Versions found [{node.k8s.io/v1 v1}]
  Apr 19 16:30:49.560: INFO: node.k8s.io/v1 matches node.k8s.io/v1
  Apr 19 16:30:49.561: INFO: Checking APIGroup: discovery.k8s.io
  Apr 19 16:30:49.563: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
  Apr 19 16:30:49.563: INFO: Versions found [{discovery.k8s.io/v1 v1}]
  Apr 19 16:30:49.563: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
  Apr 19 16:30:49.563: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
  Apr 19 16:30:49.565: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1
  Apr 19 16:30:49.566: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1 v1} {flowcontrol.apiserver.k8s.io/v1beta3 v1beta3}]
  Apr 19 16:30:49.566: INFO: flowcontrol.apiserver.k8s.io/v1 matches flowcontrol.apiserver.k8s.io/v1
  Apr 19 16:30:49.567: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-5753" for this suite. @ 04/19/24 16:30:49.576
• [0.780 seconds]
------------------------------
[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:89
  STEP: Creating a kubernetes client @ 04/19/24 16:30:49.638
  Apr 19 16:30:49.638: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename containers @ 04/19/24 16:30:49.648
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:30:49.675
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:30:49.679
  STEP: Creating a pod to test override all @ 04/19/24 16:30:49.682
  E0419 16:30:50.510404      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:51.511526      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:52.512315      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:53.513155      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:30:53.73
  Apr 19 16:30:53.736: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod client-containers-7974ca7a-e39e-4b73-8553-f38fa614b0ed container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/24 16:30:53.749
  Apr 19 16:30:53.777: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-7783" for this suite. @ 04/19/24 16:30:53.785
• [4.160 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:100
  STEP: Creating a kubernetes client @ 04/19/24 16:30:53.8
  Apr 19 16:30:53.800: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename projected @ 04/19/24 16:30:53.802
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:30:53.861
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:30:53.865
  STEP: Creating configMap with name projected-configmap-test-volume-map-af819e4d-dc59-41a0-ae82-076320008f43 @ 04/19/24 16:30:53.869
  STEP: Creating a pod to test consume configMaps @ 04/19/24 16:30:53.879
  E0419 16:30:54.513535      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:55.514092      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:30:55.908
  Apr 19 16:30:55.912: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-projected-configmaps-c76aa57f-7a4c-4424-ae45-8f79d050b3c5 container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/24 16:30:55.925
  Apr 19 16:30:55.947: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5880" for this suite. @ 04/19/24 16:30:55.954
• [2.165 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:371
  STEP: Creating a kubernetes client @ 04/19/24 16:30:55.969
  Apr 19 16:30:55.970: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename webhook @ 04/19/24 16:30:55.973
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:30:55.997
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:30:56.002
  STEP: Setting up server cert @ 04/19/24 16:30:56.045
  E0419 16:30:56.514339      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 16:30:57.031
  STEP: Deploying the webhook pod @ 04/19/24 16:30:57.05
  STEP: Wait for the deployment to be ready @ 04/19/24 16:30:57.077
  Apr 19 16:30:57.099: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0419 16:30:57.514786      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:30:58.514977      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 16:30:59.117
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 16:30:59.139
  E0419 16:30:59.516297      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:31:00.139: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Setting timeout (1s) shorter than webhook latency (5s) @ 04/19/24 16:31:00.155
  STEP: Registering slow webhook via the AdmissionRegistration API @ 04/19/24 16:31:00.156
  STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) @ 04/19/24 16:31:00.208
  E0419 16:31:00.516751      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore @ 04/19/24 16:31:01.226
  STEP: Registering slow webhook via the AdmissionRegistration API @ 04/19/24 16:31:01.226
  E0419 16:31:01.517981      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is longer than webhook latency @ 04/19/24 16:31:02.302
  STEP: Registering slow webhook via the AdmissionRegistration API @ 04/19/24 16:31:02.302
  E0419 16:31:02.517888      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:03.517974      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:04.518651      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:05.518935      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:06.519731      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is empty (defaulted to 10s in v1) @ 04/19/24 16:31:07.394
  STEP: Registering slow webhook via the AdmissionRegistration API @ 04/19/24 16:31:07.394
  E0419 16:31:07.524948      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:08.524692      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:09.527928      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:10.526909      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:11.527729      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:12.529049      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:31:12.584: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3550" for this suite. @ 04/19/24 16:31:12.593
  STEP: Destroying namespace "webhook-markers-6025" for this suite. @ 04/19/24 16:31:12.612
• [16.654 seconds]
------------------------------
S
------------------------------
[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:424
  STEP: Creating a kubernetes client @ 04/19/24 16:31:12.624
  Apr 19 16:31:12.624: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename configmap @ 04/19/24 16:31:12.627
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:31:12.66
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:31:12.665
  STEP: Creating configMap with name configmap-test-volume-ac4c4515-28e4-4152-a467-af2a3432b721 @ 04/19/24 16:31:12.67
  STEP: Creating a pod to test consume configMaps @ 04/19/24 16:31:12.676
  E0419 16:31:13.529560      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:14.530089      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:15.530226      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:16.530467      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:31:16.716
  Apr 19 16:31:16.726: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-configmaps-dec4cd58-a7c7-4c90-a65a-926f4fd90171 container configmap-volume-test: <nil>
  STEP: delete the pod @ 04/19/24 16:31:16.822
  Apr 19 16:31:16.863: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8494" for this suite. @ 04/19/24 16:31:16.878
• [4.272 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:64
  STEP: Creating a kubernetes client @ 04/19/24 16:31:16.9
  Apr 19 16:31:16.900: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename field-validation @ 04/19/24 16:31:16.903
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:31:16.949
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:31:16.956
  STEP: apply creating a deployment @ 04/19/24 16:31:16.964
  Apr 19 16:31:16.998: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-2043" for this suite. @ 04/19/24 16:31:17.01
• [0.127 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_inline.go:50
  STEP: Creating a kubernetes client @ 04/19/24 16:31:17.035
  Apr 19 16:31:17.035: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename csiinlinevolumes @ 04/19/24 16:31:17.039
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:31:17.077
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:31:17.083
  STEP: creating @ 04/19/24 16:31:17.09
  STEP: getting @ 04/19/24 16:31:17.138
  STEP: listing in namespace @ 04/19/24 16:31:17.145
  STEP: patching @ 04/19/24 16:31:17.149
  STEP: deleting @ 04/19/24 16:31:17.161
  Apr 19 16:31:17.190: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-3114" for this suite. @ 04/19/24 16:31:17.202
• [0.184 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:453
  STEP: Creating a kubernetes client @ 04/19/24 16:31:17.225
  Apr 19 16:31:17.225: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename resourcequota @ 04/19/24 16:31:17.228
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:31:17.253
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:31:17.258
  STEP: Counting existing ResourceQuota @ 04/19/24 16:31:17.263
  E0419 16:31:17.531073      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:18.532289      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:19.532597      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:20.532705      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:21.533948      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 04/19/24 16:31:22.273
  STEP: Ensuring resource quota status is calculated @ 04/19/24 16:31:22.286
  E0419 16:31:22.534791      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:23.535982      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ReplicaSet @ 04/19/24 16:31:24.325
  STEP: Ensuring resource quota status captures replicaset creation @ 04/19/24 16:31:24.359
  E0419 16:31:24.536735      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:25.537045      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicaSet @ 04/19/24 16:31:26.374
  STEP: Ensuring resource quota status released usage @ 04/19/24 16:31:26.401
  E0419 16:31:26.537577      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:27.539399      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:31:28.413: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-890" for this suite. @ 04/19/24 16:31:28.425
• [11.217 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:446
  STEP: Creating a kubernetes client @ 04/19/24 16:31:28.456
  Apr 19 16:31:28.457: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename sched-pred @ 04/19/24 16:31:28.461
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:31:28.501
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:31:28.51
  Apr 19 16:31:28.519: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  E0419 16:31:28.539182      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:31:28.539: INFO: Waiting for terminating namespaces to be deleted...
  Apr 19 16:31:28.547: INFO: 
  Logging pods the apiserver thinks is on node co4fe9zoo9oc-1 before test
  Apr 19 16:31:28.564: INFO: coredns-76f75df574-dnglm from kube-system started at 2024-04-19 15:34:35 +0000 UTC (1 container statuses recorded)
  Apr 19 16:31:28.564: INFO: 	Container coredns ready: true, restart count 1
  Apr 19 16:31:28.564: INFO: coredns-76f75df574-n4wlj from kube-system started at 2024-04-19 15:34:35 +0000 UTC (1 container statuses recorded)
  Apr 19 16:31:28.564: INFO: 	Container coredns ready: true, restart count 1
  Apr 19 16:31:28.564: INFO: kube-addon-manager-co4fe9zoo9oc-1 from kube-system started at 2024-04-19 15:40:36 +0000 UTC (1 container statuses recorded)
  Apr 19 16:31:28.564: INFO: 	Container kube-addon-manager ready: true, restart count 1
  Apr 19 16:31:28.564: INFO: kube-apiserver-co4fe9zoo9oc-1 from kube-system started at 2024-04-19 15:40:36 +0000 UTC (1 container statuses recorded)
  Apr 19 16:31:28.564: INFO: 	Container kube-apiserver ready: true, restart count 1
  Apr 19 16:31:28.564: INFO: kube-controller-manager-co4fe9zoo9oc-1 from kube-system started at 2024-04-19 15:40:36 +0000 UTC (1 container statuses recorded)
  Apr 19 16:31:28.564: INFO: 	Container kube-controller-manager ready: true, restart count 1
  Apr 19 16:31:28.564: INFO: kube-flannel-ds-9gpfv from kube-system started at 2024-04-19 15:34:17 +0000 UTC (1 container statuses recorded)
  Apr 19 16:31:28.564: INFO: 	Container kube-flannel ready: true, restart count 1
  Apr 19 16:31:28.564: INFO: kube-proxy-zzhn9 from kube-system started at 2024-04-19 15:27:31 +0000 UTC (1 container statuses recorded)
  Apr 19 16:31:28.564: INFO: 	Container kube-proxy ready: true, restart count 1
  Apr 19 16:31:28.564: INFO: kube-scheduler-co4fe9zoo9oc-1 from kube-system started at 2024-04-19 15:40:36 +0000 UTC (1 container statuses recorded)
  Apr 19 16:31:28.564: INFO: 	Container kube-scheduler ready: true, restart count 1
  Apr 19 16:31:28.564: INFO: sonobuoy-systemd-logs-daemon-set-f3d7cdfd30314b67-kskjf from sonobuoy started at 2024-04-19 15:41:34 +0000 UTC (2 container statuses recorded)
  Apr 19 16:31:28.564: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 19 16:31:28.564: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 19 16:31:28.564: INFO: 
  Logging pods the apiserver thinks is on node co4fe9zoo9oc-2 before test
  Apr 19 16:31:28.576: INFO: kube-addon-manager-co4fe9zoo9oc-2 from kube-system started at 2024-04-19 15:36:28 +0000 UTC (1 container statuses recorded)
  Apr 19 16:31:28.576: INFO: 	Container kube-addon-manager ready: true, restart count 1
  Apr 19 16:31:28.576: INFO: kube-apiserver-co4fe9zoo9oc-2 from kube-system started at 2024-04-19 15:36:28 +0000 UTC (1 container statuses recorded)
  Apr 19 16:31:28.576: INFO: 	Container kube-apiserver ready: true, restart count 1
  Apr 19 16:31:28.576: INFO: kube-controller-manager-co4fe9zoo9oc-2 from kube-system started at 2024-04-19 15:36:28 +0000 UTC (1 container statuses recorded)
  Apr 19 16:31:28.576: INFO: 	Container kube-controller-manager ready: true, restart count 1
  Apr 19 16:31:28.576: INFO: kube-flannel-ds-g2l7p from kube-system started at 2024-04-19 15:34:17 +0000 UTC (1 container statuses recorded)
  Apr 19 16:31:28.577: INFO: 	Container kube-flannel ready: true, restart count 1
  Apr 19 16:31:28.577: INFO: kube-proxy-6gjw7 from kube-system started at 2024-04-19 15:28:18 +0000 UTC (1 container statuses recorded)
  Apr 19 16:31:28.577: INFO: 	Container kube-proxy ready: true, restart count 1
  Apr 19 16:31:28.577: INFO: kube-scheduler-co4fe9zoo9oc-2 from kube-system started at 2024-04-19 15:36:28 +0000 UTC (1 container statuses recorded)
  Apr 19 16:31:28.577: INFO: 	Container kube-scheduler ready: true, restart count 1
  Apr 19 16:31:28.577: INFO: sonobuoy-systemd-logs-daemon-set-f3d7cdfd30314b67-l6thv from sonobuoy started at 2024-04-19 15:41:34 +0000 UTC (2 container statuses recorded)
  Apr 19 16:31:28.577: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 19 16:31:28.577: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 19 16:31:28.577: INFO: 
  Logging pods the apiserver thinks is on node co4fe9zoo9oc-3 before test
  Apr 19 16:31:28.594: INFO: kube-flannel-ds-8xgdk from kube-system started at 2024-04-19 15:47:35 +0000 UTC (1 container statuses recorded)
  Apr 19 16:31:28.594: INFO: 	Container kube-flannel ready: true, restart count 0
  Apr 19 16:31:28.595: INFO: kube-proxy-nxtbd from kube-system started at 2024-04-19 15:28:43 +0000 UTC (1 container statuses recorded)
  Apr 19 16:31:28.595: INFO: 	Container kube-proxy ready: true, restart count 1
  Apr 19 16:31:28.596: INFO: sonobuoy from sonobuoy started at 2024-04-19 15:41:27 +0000 UTC (1 container statuses recorded)
  Apr 19 16:31:28.596: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Apr 19 16:31:28.597: INFO: sonobuoy-e2e-job-8260c76ae18e4472 from sonobuoy started at 2024-04-19 15:41:34 +0000 UTC (2 container statuses recorded)
  Apr 19 16:31:28.597: INFO: 	Container e2e ready: true, restart count 0
  Apr 19 16:31:28.598: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 19 16:31:28.598: INFO: sonobuoy-systemd-logs-daemon-set-f3d7cdfd30314b67-2fw62 from sonobuoy started at 2024-04-19 15:41:34 +0000 UTC (2 container statuses recorded)
  Apr 19 16:31:28.599: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 19 16:31:28.599: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to schedule Pod with nonempty NodeSelector. @ 04/19/24 16:31:28.599
  STEP: Considering event: 
  Type = [Warning], Name = [restricted-pod.17c7bb73a7105076], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.] @ 04/19/24 16:31:28.645
  E0419 16:31:29.540130      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:31:29.658: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-8667" for this suite. @ 04/19/24 16:31:29.677
• [1.239 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should manage the lifecycle of a job [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:855
  STEP: Creating a kubernetes client @ 04/19/24 16:31:29.7
  Apr 19 16:31:29.700: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename job @ 04/19/24 16:31:29.705
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:31:29.762
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:31:29.767
  STEP: Creating a suspended job @ 04/19/24 16:31:29.779
  STEP: Patching the Job @ 04/19/24 16:31:29.789
  STEP: Watching for Job to be patched @ 04/19/24 16:31:29.807
  Apr 19 16:31:29.812: INFO: Event ADDED observed for Job e2e-hjgjh in namespace job-4561 with labels: map[e2e-job-label:e2e-hjgjh] and annotations: map[]
  Apr 19 16:31:29.813: INFO: Event MODIFIED found for Job e2e-hjgjh in namespace job-4561 with labels: map[e2e-hjgjh:patched e2e-job-label:e2e-hjgjh] and annotations: map[]
  STEP: Updating the job @ 04/19/24 16:31:29.813
  STEP: Watching for Job to be updated @ 04/19/24 16:31:29.841
  Apr 19 16:31:29.844: INFO: Event MODIFIED found for Job e2e-hjgjh in namespace job-4561 with labels: map[e2e-hjgjh:patched e2e-job-label:e2e-hjgjh] and annotations: map[updated:true]
  Apr 19 16:31:29.845: INFO: Found Job annotations: map[string]string{"updated":"true"}
  STEP: Listing all Jobs with LabelSelector @ 04/19/24 16:31:29.845
  Apr 19 16:31:29.853: INFO: Job: e2e-hjgjh as labels: map[e2e-hjgjh:patched e2e-job-label:e2e-hjgjh]
  STEP: Waiting for job to complete @ 04/19/24 16:31:29.853
  E0419 16:31:30.549737      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:31.544250      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:32.543191      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:33.543611      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:34.543835      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:35.544654      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:36.544716      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:37.546863      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Delete a job collection with a labelselector @ 04/19/24 16:31:37.866
  STEP: Watching for Job to be deleted @ 04/19/24 16:31:37.888
  Apr 19 16:31:37.893: INFO: Event MODIFIED observed for Job e2e-hjgjh in namespace job-4561 with labels: map[e2e-hjgjh:patched e2e-job-label:e2e-hjgjh] and annotations: map[updated:true]
  Apr 19 16:31:37.893: INFO: Event MODIFIED observed for Job e2e-hjgjh in namespace job-4561 with labels: map[e2e-hjgjh:patched e2e-job-label:e2e-hjgjh] and annotations: map[updated:true]
  Apr 19 16:31:37.894: INFO: Event MODIFIED observed for Job e2e-hjgjh in namespace job-4561 with labels: map[e2e-hjgjh:patched e2e-job-label:e2e-hjgjh] and annotations: map[updated:true]
  Apr 19 16:31:37.894: INFO: Event MODIFIED observed for Job e2e-hjgjh in namespace job-4561 with labels: map[e2e-hjgjh:patched e2e-job-label:e2e-hjgjh] and annotations: map[updated:true]
  Apr 19 16:31:37.895: INFO: Event MODIFIED observed for Job e2e-hjgjh in namespace job-4561 with labels: map[e2e-hjgjh:patched e2e-job-label:e2e-hjgjh] and annotations: map[updated:true]
  Apr 19 16:31:37.895: INFO: Event DELETED found for Job e2e-hjgjh in namespace job-4561 with labels: map[e2e-hjgjh:patched e2e-job-label:e2e-hjgjh] and annotations: map[updated:true]
  STEP: Relist jobs to confirm deletion @ 04/19/24 16:31:37.897
  Apr 19 16:31:37.909: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-4561" for this suite. @ 04/19/24 16:31:37.921
• [8.235 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/core_events.go:176
  STEP: Creating a kubernetes client @ 04/19/24 16:31:37.938
  Apr 19 16:31:37.938: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename events @ 04/19/24 16:31:37.941
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:31:37.987
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:31:37.992
  STEP: Create set of events @ 04/19/24 16:31:37.997
  Apr 19 16:31:38.005: INFO: created test-event-1
  Apr 19 16:31:38.012: INFO: created test-event-2
  Apr 19 16:31:38.019: INFO: created test-event-3
  STEP: get a list of Events with a label in the current namespace @ 04/19/24 16:31:38.019
  STEP: delete collection of events @ 04/19/24 16:31:38.025
  Apr 19 16:31:38.025: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 04/19/24 16:31:38.078
  Apr 19 16:31:38.078: INFO: requesting list of events to confirm quantity
  Apr 19 16:31:38.083: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-4228" for this suite. @ 04/19/24 16:31:38.092
• [0.169 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose should create services for rc [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1538
  STEP: Creating a kubernetes client @ 04/19/24 16:31:38.11
  Apr 19 16:31:38.110: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename kubectl @ 04/19/24 16:31:38.113
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:31:38.14
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:31:38.146
  STEP: creating Agnhost RC @ 04/19/24 16:31:38.155
  Apr 19 16:31:38.155: INFO: namespace kubectl-4981
  Apr 19 16:31:38.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-4981 create -f -'
  E0419 16:31:38.545080      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:31:38.550: INFO: stderr: ""
  Apr 19 16:31:38.550: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 04/19/24 16:31:38.55
  E0419 16:31:39.545441      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:31:39.561: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 19 16:31:39.561: INFO: Found 0 / 1
  E0419 16:31:40.545692      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:31:40.560: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 19 16:31:40.560: INFO: Found 1 / 1
  Apr 19 16:31:40.560: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  Apr 19 16:31:40.567: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 19 16:31:40.568: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Apr 19 16:31:40.568: INFO: wait on agnhost-primary startup in kubectl-4981 
  Apr 19 16:31:40.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-4981 logs agnhost-primary-6cj92 agnhost-primary'
  Apr 19 16:31:40.749: INFO: stderr: ""
  Apr 19 16:31:40.749: INFO: stdout: "Paused\n"
  STEP: exposing RC @ 04/19/24 16:31:40.749
  Apr 19 16:31:40.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-4981 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
  Apr 19 16:31:40.982: INFO: stderr: ""
  Apr 19 16:31:40.982: INFO: stdout: "service/rm2 exposed\n"
  Apr 19 16:31:40.990: INFO: Service rm2 in namespace kubectl-4981 found.
  E0419 16:31:41.545758      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:42.546322      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: exposing service @ 04/19/24 16:31:43.038
  Apr 19 16:31:43.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-4981 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
  Apr 19 16:31:43.263: INFO: stderr: ""
  Apr 19 16:31:43.263: INFO: stdout: "service/rm3 exposed\n"
  Apr 19 16:31:43.272: INFO: Service rm3 in namespace kubectl-4981 found.
  E0419 16:31:43.547103      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:44.547485      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:31:45.290: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4981" for this suite. @ 04/19/24 16:31:45.301
• [7.214 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:57
  STEP: Creating a kubernetes client @ 04/19/24 16:31:45.333
  Apr 19 16:31:45.333: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename runtimeclass @ 04/19/24 16:31:45.34
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:31:45.374
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:31:45.379
  Apr 19 16:31:45.405: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-6309" for this suite. @ 04/19/24 16:31:45.419
• [0.102 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:459
  STEP: Creating a kubernetes client @ 04/19/24 16:31:45.443
  Apr 19 16:31:45.443: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename init-container @ 04/19/24 16:31:45.447
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:31:45.487
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:31:45.493
  STEP: creating the pod @ 04/19/24 16:31:45.5
  Apr 19 16:31:45.501: INFO: PodSpec: initContainers in spec.initContainers
  E0419 16:31:45.548140      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:46.549479      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:47.549820      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:48.551375      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:31:49.265: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-9192" for this suite. @ 04/19/24 16:31:49.285
• [3.863 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:91
  STEP: Creating a kubernetes client @ 04/19/24 16:31:49.31
  Apr 19 16:31:49.310: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename subpath @ 04/19/24 16:31:49.312
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:31:49.35
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:31:49.357
  STEP: Setting up data @ 04/19/24 16:31:49.362
  STEP: Creating pod pod-subpath-test-downwardapi-ll2r @ 04/19/24 16:31:49.381
  STEP: Creating a pod to test atomic-volume-subpath @ 04/19/24 16:31:49.381
  E0419 16:31:49.551885      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:50.552181      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:51.553610      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:52.553576      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:53.554045      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:54.554377      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:55.555664      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:56.556499      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:57.557282      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:58.558514      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:31:59.559501      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:00.560358      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:01.560385      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:02.560911      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:03.561542      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:04.561704      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:05.562148      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:06.562495      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:07.563322      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:08.564573      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:09.565354      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:10.566537      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:32:11.515
  Apr 19 16:32:11.521: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-subpath-test-downwardapi-ll2r container test-container-subpath-downwardapi-ll2r: <nil>
  STEP: delete the pod @ 04/19/24 16:32:11.535
  STEP: Deleting pod pod-subpath-test-downwardapi-ll2r @ 04/19/24 16:32:11.562
  Apr 19 16:32:11.562: INFO: Deleting pod "pod-subpath-test-downwardapi-ll2r" in namespace "subpath-7513"
  E0419 16:32:11.566900      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:32:11.568: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-7513" for this suite. @ 04/19/24 16:32:11.577
• [22.283 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:78
  STEP: Creating a kubernetes client @ 04/19/24 16:32:11.593
  Apr 19 16:32:11.593: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename projected @ 04/19/24 16:32:11.596
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:32:11.626
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:32:11.631
  STEP: Creating projection with secret that has name projected-secret-test-map-f07da4a2-d18a-42c4-9d3d-a1773297303a @ 04/19/24 16:32:11.637
  STEP: Creating a pod to test consume secrets @ 04/19/24 16:32:11.647
  E0419 16:32:12.568006      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:13.568208      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:14.569119      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:15.569447      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:32:15.7
  Apr 19 16:32:15.710: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-projected-secrets-3426ec4d-94f0-40c5-8b7b-28856d637655 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/24 16:32:15.734
  Apr 19 16:32:15.779: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9397" for this suite. @ 04/19/24 16:32:15.793
• [4.220 seconds]
------------------------------
S
------------------------------
[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:251
  STEP: Creating a kubernetes client @ 04/19/24 16:32:15.816
  Apr 19 16:32:15.816: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename downward-api @ 04/19/24 16:32:15.822
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:32:15.864
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:32:15.871
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 16:32:15.881
  E0419 16:32:16.570414      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:17.570703      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:18.571097      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:19.571321      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:32:19.943
  Apr 19 16:32:19.955: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod downwardapi-volume-ce46ff50-1b38-436b-b551-462eb552ba00 container client-container: <nil>
  STEP: delete the pod @ 04/19/24 16:32:19.975
  Apr 19 16:32:20.006: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1220" for this suite. @ 04/19/24 16:32:20.016
• [4.218 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:98
  STEP: Creating a kubernetes client @ 04/19/24 16:32:20.036
  Apr 19 16:32:20.036: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename aggregator @ 04/19/24 16:32:20.042
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:32:20.089
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:32:20.096
  Apr 19 16:32:20.105: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Registering the sample API server. @ 04/19/24 16:32:20.109
  E0419 16:32:20.571448      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:21.571870      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:32:21.831: INFO: Found ClusterRoles; assuming RBAC is enabled.
  Apr 19 16:32:21.889: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
  E0419 16:32:22.572506      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:23.572849      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:32:24.010: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 16:32:24.572994      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:25.573181      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:32:26.018: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 16:32:26.574058      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:27.574097      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:32:28.019: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 16:32:28.574582      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:29.574985      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:32:30.019: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 16:32:30.575048      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:31.575779      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:32:32.017: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 16:32:32.575999      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:33.576884      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:32:34.019: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 16:32:34.576909      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:35.577259      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:32:36.020: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 16:32:36.577017      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:37.577881      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:32:38.025: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 16:32:38.578059      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:39.578907      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:32:40.024: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 16:32:40.578718      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:41.579792      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:32:42.023: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 16:32:42.580042      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:43.581145      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:32:44.023: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 16:32:44.581332      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:45.581799      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:32:46.021: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 32, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 16:32:46.582775      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:47.582914      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:32:48.162: INFO: Waited 122.050921ms for the sample-apiserver to be ready to handle requests.
  STEP: Read Status for v1alpha1.wardle.example.com @ 04/19/24 16:32:48.237
  STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' @ 04/19/24 16:32:48.244
  STEP: List APIServices @ 04/19/24 16:32:48.259
  Apr 19 16:32:48.269: INFO: Found v1alpha1.wardle.example.com in APIServiceList
  STEP: Adding a label to the APIService @ 04/19/24 16:32:48.269
  Apr 19 16:32:48.298: INFO: APIService labels: map[e2e-apiservice:patched]
  STEP: Updating APIService Status @ 04/19/24 16:32:48.299
  Apr 19 16:32:48.325: INFO: updatedStatus.Conditions: []v1.APIServiceCondition{v1.APIServiceCondition{Type:"Available", Status:"True", LastTransitionTime:time.Date(2024, time.April, 19, 16, 32, 48, 0, time.Local), Reason:"Passed", Message:"all checks passed"}, v1.APIServiceCondition{Type:"StatusUpdated", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: Confirm that v1alpha1.wardle.example.com /status was updated @ 04/19/24 16:32:48.326
  Apr 19 16:32:48.335: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {Available True 2024-04-19 16:32:48 +0000 UTC Passed all checks passed}
  Apr 19 16:32:48.336: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 19 16:32:48.337: INFO: Found updated status condition for v1alpha1.wardle.example.com
  STEP: Replace APIService v1alpha1.wardle.example.com @ 04/19/24 16:32:48.337
  Apr 19 16:32:48.363: INFO: Found updated apiService label for "v1alpha1.wardle.example.com"
  STEP: Delete flunders resource "dynamic-flunder-1834180772" @ 04/19/24 16:32:48.363
  STEP: Recreating test-flunder before removing endpoint via deleteCollection @ 04/19/24 16:32:48.393
  STEP: Read v1alpha1.wardle.example.com /status before patching it @ 04/19/24 16:32:48.408
  STEP: Patch APIService Status @ 04/19/24 16:32:48.418
  STEP: Confirm that v1alpha1.wardle.example.com /status was patched @ 04/19/24 16:32:48.432
  Apr 19 16:32:48.441: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {Available True 2024-04-19 16:32:48 +0000 UTC Passed all checks passed}
  Apr 19 16:32:48.441: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 19 16:32:48.441: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC E2E Set by e2e test}
  Apr 19 16:32:48.441: INFO: Found patched status condition for v1alpha1.wardle.example.com
  STEP: APIService deleteCollection with labelSelector: "v1alpha1.wardle.example.com=updated" @ 04/19/24 16:32:48.441
  STEP: Confirm that the generated APIService has been deleted @ 04/19/24 16:32:48.462
  Apr 19 16:32:48.462: INFO: Requesting list of APIServices to confirm quantity
  Apr 19 16:32:48.473: INFO: Found 0 APIService with label "v1alpha1.wardle.example.com=updated"
  Apr 19 16:32:48.473: INFO: APIService v1alpha1.wardle.example.com has been deleted.
  E0419 16:32:48.583020      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:32:48.749: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregator-4476" for this suite. @ 04/19/24 16:32:48.759
• [28.735 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:309
  STEP: Creating a kubernetes client @ 04/19/24 16:32:48.775
  Apr 19 16:32:48.775: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/19/24 16:32:48.779
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:32:48.803
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:32:48.807
  STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation @ 04/19/24 16:32:48.813
  Apr 19 16:32:48.815: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  E0419 16:32:49.584271      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:50.585024      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:51.594692      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:52.606618      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:53.606888      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:54.608502      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:55.609048      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation @ 04/19/24 16:32:56.293
  Apr 19 16:32:56.295: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  E0419 16:32:56.610235      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:57.610642      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:32:58.256: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  E0419 16:32:58.610922      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:32:59.611667      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:00.611988      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:01.612326      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:02.613580      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:03.614221      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:04.614967      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:33:05.611: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0419 16:33:05.615990      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "crd-publish-openapi-7245" for this suite. @ 04/19/24 16:33:05.632
• [16.873 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/persistent_volumes.go:430
  STEP: Creating a kubernetes client @ 04/19/24 16:33:05.648
  Apr 19 16:33:05.648: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename pv @ 04/19/24 16:33:05.651
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:33:05.68
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:33:05.686
  STEP: Creating initial PV and PVC @ 04/19/24 16:33:05.693
  Apr 19 16:33:05.694: INFO: Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-8120" @ 04/19/24 16:33:05.719
  STEP: Listing PVCs in namespace "pv-8120" @ 04/19/24 16:33:05.727
  STEP: Patching the PV "pv-8120-7k4tx" @ 04/19/24 16:33:05.735
  STEP: Patching the PVC "pvc-dlwv8" @ 04/19/24 16:33:05.764
  STEP: Getting PV "pv-8120-7k4tx" @ 04/19/24 16:33:05.782
  STEP: Getting PVC "pvc-dlwv8" @ 04/19/24 16:33:05.788
  STEP: Deleting PVC "pvc-dlwv8" @ 04/19/24 16:33:05.797
  STEP: Confirm deletion of PVC "pvc-dlwv8" @ 04/19/24 16:33:05.81
  E0419 16:33:06.618239      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:07.617034      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting PV "pv-8120-7k4tx" @ 04/19/24 16:33:07.835
  STEP: Confirm deletion of PV "pv-8120-7k4tx" @ 04/19/24 16:33:07.854
  E0419 16:33:08.618397      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:09.618834      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating another PV & PVC @ 04/19/24 16:33:09.876
  Apr 19 16:33:09.877: INFO: Creating a PV followed by a PVC
  STEP: Updating the PV "pv-8120-gks5x" @ 04/19/24 16:33:09.928
  STEP: Updating the PVC "pvc-dr578" @ 04/19/24 16:33:09.962
  STEP: Listing PVCs in all namespaces with the labelSelector: "pvc-dr578=updated" @ 04/19/24 16:33:09.983
  STEP: Deleting PVC "pvc-dr578" via DeleteCollection @ 04/19/24 16:33:10
  STEP: Confirm deletion of PVC "pvc-dr578" @ 04/19/24 16:33:10.036
  E0419 16:33:10.621083      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:11.619976      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting PV "pv-8120-gks5x" via DeleteCollection @ 04/19/24 16:33:12.059
  STEP: Confirm deletion of PV "pv-8120-gks5x" @ 04/19/24 16:33:12.087
  E0419 16:33:12.620832      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:13.637569      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:33:14.113: INFO: AfterEach: deleting 1 PVCs and 1 PVs...
  Apr 19 16:33:14.113: INFO: Deleting PersistentVolumeClaim "pvc-dr578"
  Apr 19 16:33:14.125: INFO: Deleting PersistentVolume "pv-8120-gks5x"
  Apr 19 16:33:14.136: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-8120" for this suite. @ 04/19/24 16:33:14.151
• [8.526 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:237
  STEP: Creating a kubernetes client @ 04/19/24 16:33:14.177
  Apr 19 16:33:14.177: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename projected @ 04/19/24 16:33:14.185
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:33:14.216
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:33:14.222
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 16:33:14.23
  E0419 16:33:14.627923      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:15.635525      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:16.632116      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:17.633040      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:33:18.3
  Apr 19 16:33:18.310: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod downwardapi-volume-77939725-b7b0-4b01-9030-ad7934d1d866 container client-container: <nil>
  STEP: delete the pod @ 04/19/24 16:33:18.359
  Apr 19 16:33:18.397: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9019" for this suite. @ 04/19/24 16:33:18.416
• [4.260 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:59
  STEP: Creating a kubernetes client @ 04/19/24 16:33:18.437
  Apr 19 16:33:18.437: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/19/24 16:33:18.443
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:33:18.481
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:33:18.487
  Apr 19 16:33:18.503: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  E0419 16:33:18.633209      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:33:19.582: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-2161" for this suite. @ 04/19/24 16:33:19.594
• [1.168 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:357
  STEP: Creating a kubernetes client @ 04/19/24 16:33:19.608
  Apr 19 16:33:19.608: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/19/24 16:33:19.614
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:33:19.635
  E0419 16:33:19.636435      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:33:19.64
  STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation @ 04/19/24 16:33:19.646
  Apr 19 16:33:19.647: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  E0419 16:33:20.634147      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:33:21.570: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  E0419 16:33:21.635681      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:22.635587      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:23.635891      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:24.637114      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:25.637558      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:26.637318      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:27.638178      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:28.638702      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:33:28.945: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-4607" for this suite. @ 04/19/24 16:33:28.967
• [9.376 seconds]
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1053
  STEP: Creating a kubernetes client @ 04/19/24 16:33:28.983
  Apr 19 16:33:28.983: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename kubectl @ 04/19/24 16:33:28.987
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:33:29.023
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:33:29.028
  STEP: create deployment with httpd image @ 04/19/24 16:33:29.032
  Apr 19 16:33:29.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-2434 create -f -'
  Apr 19 16:33:29.376: INFO: stderr: ""
  Apr 19 16:33:29.376: INFO: stdout: "deployment.apps/httpd-deployment created\n"
  STEP: verify diff finds difference between live and declared image @ 04/19/24 16:33:29.376
  Apr 19 16:33:29.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-2434 diff -f -'
  E0419 16:33:29.639243      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:33:29.729: INFO: rc: 1
  Apr 19 16:33:29.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-2434 delete -f -'
  Apr 19 16:33:29.938: INFO: stderr: ""
  Apr 19 16:33:29.938: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
  Apr 19 16:33:29.938: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2434" for this suite. @ 04/19/24 16:33:29.947
• [0.978 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should support CronJob API operations [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:324
  STEP: Creating a kubernetes client @ 04/19/24 16:33:29.962
  Apr 19 16:33:29.962: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename cronjob @ 04/19/24 16:33:29.965
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:33:29.998
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:33:30.004
  STEP: Creating a cronjob @ 04/19/24 16:33:30.009
  STEP: creating @ 04/19/24 16:33:30.009
  STEP: getting @ 04/19/24 16:33:30.022
  STEP: listing @ 04/19/24 16:33:30.028
  STEP: watching @ 04/19/24 16:33:30.034
  Apr 19 16:33:30.034: INFO: starting watch
  STEP: cluster-wide listing @ 04/19/24 16:33:30.035
  STEP: cluster-wide watching @ 04/19/24 16:33:30.041
  Apr 19 16:33:30.041: INFO: starting watch
  STEP: patching @ 04/19/24 16:33:30.043
  STEP: updating @ 04/19/24 16:33:30.082
  Apr 19 16:33:30.096: INFO: waiting for watch events with expected annotations
  Apr 19 16:33:30.096: INFO: saw patched and updated annotations
  STEP: patching /status @ 04/19/24 16:33:30.097
  STEP: updating /status @ 04/19/24 16:33:30.114
  STEP: get /status @ 04/19/24 16:33:30.127
  STEP: deleting @ 04/19/24 16:33:30.137
  STEP: deleting a collection @ 04/19/24 16:33:30.165
  Apr 19 16:33:30.184: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-3437" for this suite. @ 04/19/24 16:33:30.193
• [0.245 seconds]
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1764
  STEP: Creating a kubernetes client @ 04/19/24 16:33:30.207
  Apr 19 16:33:30.208: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename kubectl @ 04/19/24 16:33:30.211
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:33:30.237
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:33:30.245
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 04/19/24 16:33:30.251
  Apr 19 16:33:30.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-5640 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4'
  Apr 19 16:33:30.450: INFO: stderr: ""
  Apr 19 16:33:30.450: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 04/19/24 16:33:30.45
  Apr 19 16:33:30.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-5640 delete pods e2e-test-httpd-pod'
  E0419 16:33:30.640313      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:31.641508      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:33:31.896: INFO: stderr: ""
  Apr 19 16:33:31.896: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Apr 19 16:33:31.896: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5640" for this suite. @ 04/19/24 16:33:31.904
• [1.713 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:443
  STEP: Creating a kubernetes client @ 04/19/24 16:33:31.921
  Apr 19 16:33:31.921: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename daemonsets @ 04/19/24 16:33:31.924
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:33:31.968
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:33:31.973
  Apr 19 16:33:32.029: INFO: Create a RollingUpdate DaemonSet
  Apr 19 16:33:32.043: INFO: Check that daemon pods launch on every node of the cluster
  Apr 19 16:33:32.058: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 16:33:32.059: INFO: Node co4fe9zoo9oc-1 is running 0 daemon pod, expected 1
  E0419 16:33:32.641635      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:33:33.056: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 19 16:33:33.057: INFO: Node co4fe9zoo9oc-1 is running 0 daemon pod, expected 1
  E0419 16:33:33.642716      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:33:34.079: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 19 16:33:34.080: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  Apr 19 16:33:34.080: INFO: Update the DaemonSet to trigger a rollout
  Apr 19 16:33:34.109: INFO: Updating DaemonSet daemon-set
  E0419 16:33:34.643744      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:33:35.140: INFO: Roll back the DaemonSet before rollout is complete
  Apr 19 16:33:35.159: INFO: Updating DaemonSet daemon-set
  Apr 19 16:33:35.159: INFO: Make sure DaemonSet rollback is complete
  Apr 19 16:33:35.166: INFO: Wrong image for pod: daemon-set-vjc42. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-4, got: foo:non-existent.
  Apr 19 16:33:35.166: INFO: Pod daemon-set-vjc42 is not available
  E0419 16:33:35.645320      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:36.645190      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:37.646658      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:38.647034      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:39.648255      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:40.649231      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:33:41.168: INFO: Pod daemon-set-6jsnc is not available
  STEP: Deleting DaemonSet "daemon-set" @ 04/19/24 16:33:41.191
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5349, will wait for the garbage collector to delete the pods @ 04/19/24 16:33:41.192
  Apr 19 16:33:41.275: INFO: Deleting DaemonSet.extensions daemon-set took: 24.019994ms
  Apr 19 16:33:41.377: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.502499ms
  E0419 16:33:41.651654      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:42.651935      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:33:43.089: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 16:33:43.090: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 19 16:33:43.101: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"20141"},"items":null}

  Apr 19 16:33:43.111: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"20141"},"items":null}

  Apr 19 16:33:43.155: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-5349" for this suite. @ 04/19/24 16:33:43.165
• [11.256 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support --unix-socket=/path [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1863
  STEP: Creating a kubernetes client @ 04/19/24 16:33:43.179
  Apr 19 16:33:43.179: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename kubectl @ 04/19/24 16:33:43.182
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:33:43.219
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:33:43.223
  STEP: Starting the proxy @ 04/19/24 16:33:43.228
  Apr 19 16:33:43.230: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-2587 proxy --unix-socket=/tmp/kubectl-proxy-unix3668274733/test'
  STEP: retrieving proxy /api/ output @ 04/19/24 16:33:43.34
  Apr 19 16:33:43.342: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2587" for this suite. @ 04/19/24 16:33:43.352
• [0.187 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application should create and stop a working application [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:399
  STEP: Creating a kubernetes client @ 04/19/24 16:33:43.366
  Apr 19 16:33:43.366: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename kubectl @ 04/19/24 16:33:43.368
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:33:43.409
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:33:43.414
  STEP: creating all guestbook components @ 04/19/24 16:33:43.418
  Apr 19 16:33:43.418: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-replica
    labels:
      app: agnhost
      role: replica
      tier: backend
  spec:
    ports:
    - port: 6379
    selector:
      app: agnhost
      role: replica
      tier: backend

  Apr 19 16:33:43.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-8711 create -f -'
  E0419 16:33:43.652713      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:33:43.779: INFO: stderr: ""
  Apr 19 16:33:43.779: INFO: stdout: "service/agnhost-replica created\n"
  Apr 19 16:33:43.779: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-primary
    labels:
      app: agnhost
      role: primary
      tier: backend
  spec:
    ports:
    - port: 6379
      targetPort: 6379
    selector:
      app: agnhost
      role: primary
      tier: backend

  Apr 19 16:33:43.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-8711 create -f -'
  Apr 19 16:33:44.095: INFO: stderr: ""
  Apr 19 16:33:44.095: INFO: stdout: "service/agnhost-primary created\n"
  Apr 19 16:33:44.095: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: frontend
    labels:
      app: guestbook
      tier: frontend
  spec:
    # if your cluster supports it, uncomment the following to automatically create
    # an external load-balanced IP for the frontend service.
    # type: LoadBalancer
    ports:
    - port: 80
    selector:
      app: guestbook
      tier: frontend

  Apr 19 16:33:44.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-8711 create -f -'
  Apr 19 16:33:44.443: INFO: stderr: ""
  Apr 19 16:33:44.443: INFO: stdout: "service/frontend created\n"
  Apr 19 16:33:44.443: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: frontend
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: guestbook
        tier: frontend
    template:
      metadata:
        labels:
          app: guestbook
          tier: frontend
      spec:
        containers:
        - name: guestbook-frontend
          image: registry.k8s.io/e2e-test-images/agnhost:2.47
          args: [ "guestbook", "--backend-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 80

  Apr 19 16:33:44.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-8711 create -f -'
  E0419 16:33:44.653568      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:33:44.709: INFO: stderr: ""
  Apr 19 16:33:44.709: INFO: stdout: "deployment.apps/frontend created\n"
  Apr 19 16:33:44.710: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-primary
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: agnhost
        role: primary
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: primary
          tier: backend
      spec:
        containers:
        - name: primary
          image: registry.k8s.io/e2e-test-images/agnhost:2.47
          args: [ "guestbook", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  Apr 19 16:33:44.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-8711 create -f -'
  Apr 19 16:33:44.961: INFO: stderr: ""
  Apr 19 16:33:44.961: INFO: stdout: "deployment.apps/agnhost-primary created\n"
  Apr 19 16:33:44.961: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-replica
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: agnhost
        role: replica
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: replica
          tier: backend
      spec:
        containers:
        - name: replica
          image: registry.k8s.io/e2e-test-images/agnhost:2.47
          args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  Apr 19 16:33:44.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-8711 create -f -'
  Apr 19 16:33:45.267: INFO: stderr: ""
  Apr 19 16:33:45.267: INFO: stdout: "deployment.apps/agnhost-replica created\n"
  STEP: validating guestbook app @ 04/19/24 16:33:45.267
  Apr 19 16:33:45.267: INFO: Waiting for all frontend pods to be Running.
  E0419 16:33:45.653659      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:46.653986      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:47.654179      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:48.654802      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:49.655906      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:33:50.319: INFO: Waiting for frontend to serve content.
  Apr 19 16:33:50.347: INFO: Trying to add a new entry to the guestbook.
  Apr 19 16:33:50.388: INFO: Verifying that added entry can be retrieved.
  STEP: using delete to clean up resources @ 04/19/24 16:33:50.404
  Apr 19 16:33:50.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-8711 delete --grace-period=0 --force -f -'
  Apr 19 16:33:50.610: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 19 16:33:50.610: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
  STEP: using delete to clean up resources @ 04/19/24 16:33:50.61
  Apr 19 16:33:50.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-8711 delete --grace-period=0 --force -f -'
  E0419 16:33:50.656838      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:33:50.809: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 19 16:33:50.809: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 04/19/24 16:33:50.809
  Apr 19 16:33:50.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-8711 delete --grace-period=0 --force -f -'
  Apr 19 16:33:50.983: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 19 16:33:50.983: INFO: stdout: "service \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 04/19/24 16:33:50.983
  Apr 19 16:33:50.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-8711 delete --grace-period=0 --force -f -'
  Apr 19 16:33:51.157: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 19 16:33:51.157: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 04/19/24 16:33:51.157
  Apr 19 16:33:51.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-8711 delete --grace-period=0 --force -f -'
  Apr 19 16:33:51.358: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 19 16:33:51.358: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 04/19/24 16:33:51.358
  Apr 19 16:33:51.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-8711 delete --grace-period=0 --force -f -'
  Apr 19 16:33:51.589: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 19 16:33:51.589: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
  Apr 19 16:33:51.589: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8711" for this suite. @ 04/19/24 16:33:51.598
• [8.256 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:70
  STEP: Creating a kubernetes client @ 04/19/24 16:33:51.623
  Apr 19 16:33:51.623: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  E0419 16:33:51.657467      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Building a namespace api object, basename downward-api @ 04/19/24 16:33:51.665
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:33:51.694
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:33:51.699
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 16:33:51.707
  E0419 16:33:52.658646      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:53.659612      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:54.659809      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:55.659957      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:33:55.755
  Apr 19 16:33:55.770: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod downwardapi-volume-5255e4fd-6ff2-4dc2-b0d8-cbc6c9ef6199 container client-container: <nil>
  STEP: delete the pod @ 04/19/24 16:33:55.799
  Apr 19 16:33:55.819: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5992" for this suite. @ 04/19/24 16:33:55.827
• [4.214 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/hostport.go:63
  STEP: Creating a kubernetes client @ 04/19/24 16:33:55.837
  Apr 19 16:33:55.837: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename hostport @ 04/19/24 16:33:55.839
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:33:55.862
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:33:55.865
  STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled @ 04/19/24 16:33:55.875
  E0419 16:33:56.660096      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:57.660223      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 192.168.121.39 on the node which pod1 resides and expect scheduled @ 04/19/24 16:33:57.906
  E0419 16:33:58.660593      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:33:59.661619      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 192.168.121.39 but use UDP protocol on the node which pod2 resides @ 04/19/24 16:33:59.943
  E0419 16:34:00.662674      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:01.662797      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:02.662873      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:03.663806      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 @ 04/19/24 16:34:04.011
  Apr 19 16:34:04.011: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 192.168.121.39 http://127.0.0.1:54323/hostname] Namespace:hostport-1400 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 16:34:04.011: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 16:34:04.013: INFO: ExecWithOptions: Clientset creation
  Apr 19 16:34:04.013: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-1400/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+192.168.121.39+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.121.39, port: 54323 @ 04/19/24 16:34:04.234
  Apr 19 16:34:04.234: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://192.168.121.39:54323/hostname] Namespace:hostport-1400 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 16:34:04.235: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 16:34:04.237: INFO: ExecWithOptions: Clientset creation
  Apr 19 16:34:04.237: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-1400/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F192.168.121.39%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.121.39, port: 54323 UDP @ 04/19/24 16:34:04.362
  Apr 19 16:34:04.362: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 192.168.121.39 54323] Namespace:hostport-1400 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 16:34:04.362: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 16:34:04.365: INFO: ExecWithOptions: Clientset creation
  Apr 19 16:34:04.366: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-1400/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+192.168.121.39+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  E0419 16:34:04.664935      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:05.665441      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:06.665494      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:07.666458      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:08.667184      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:34:09.471: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "hostport-1400" for this suite. @ 04/19/24 16:34:09.481
• [13.657 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:537
  STEP: Creating a kubernetes client @ 04/19/24 16:34:09.497
  Apr 19 16:34:09.497: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename pods @ 04/19/24 16:34:09.505
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:34:09.562
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:34:09.566
  Apr 19 16:34:09.572: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: creating the pod @ 04/19/24 16:34:09.574
  STEP: submitting the pod to kubernetes @ 04/19/24 16:34:09.574
  E0419 16:34:09.667674      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:10.668135      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:11.668973      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:34:11.808: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-4262" for this suite. @ 04/19/24 16:34:11.819
• [2.340 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:79
  STEP: Creating a kubernetes client @ 04/19/24 16:34:11.838
  Apr 19 16:34:11.838: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename secrets @ 04/19/24 16:34:11.841
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:34:11.881
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:34:11.886
  STEP: Creating secret with name secret-test-map-886d85bf-b9f8-4a3f-a9bf-0f51bb59b01e @ 04/19/24 16:34:11.892
  STEP: Creating a pod to test consume secrets @ 04/19/24 16:34:11.904
  E0419 16:34:12.669157      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:13.669365      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:14.670596      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:15.671322      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:34:15.956
  Apr 19 16:34:15.964: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-secrets-20a52b0e-49e8-4550-b2da-7edb534f91b7 container secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/24 16:34:15.977
  Apr 19 16:34:15.997: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6279" for this suite. @ 04/19/24 16:34:16.004
• [4.179 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:305
  STEP: Creating a kubernetes client @ 04/19/24 16:34:16.025
  Apr 19 16:34:16.025: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename daemonsets @ 04/19/24 16:34:16.027
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:34:16.05
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:34:16.055
  STEP: Creating a simple DaemonSet "daemon-set" @ 04/19/24 16:34:16.109
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/19/24 16:34:16.131
  Apr 19 16:34:16.150: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 16:34:16.150: INFO: Node co4fe9zoo9oc-1 is running 0 daemon pod, expected 1
  E0419 16:34:16.672366      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:34:17.157: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 16:34:17.157: INFO: Node co4fe9zoo9oc-1 is running 0 daemon pod, expected 1
  E0419 16:34:17.673094      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:34:18.157: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 19 16:34:18.157: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. @ 04/19/24 16:34:18.167
  Apr 19 16:34:18.225: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 19 16:34:18.225: INFO: Node co4fe9zoo9oc-2 is running 0 daemon pod, expected 1
  E0419 16:34:18.674073      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:34:19.225: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 19 16:34:19.226: INFO: Node co4fe9zoo9oc-2 is running 0 daemon pod, expected 1
  E0419 16:34:19.674215      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:34:20.213: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 19 16:34:20.213: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Wait for the failed daemon pod to be completely deleted. @ 04/19/24 16:34:20.213
  STEP: Deleting DaemonSet "daemon-set" @ 04/19/24 16:34:20.224
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4571, will wait for the garbage collector to delete the pods @ 04/19/24 16:34:20.224
  Apr 19 16:34:20.293: INFO: Deleting DaemonSet.extensions daemon-set took: 11.406623ms
  Apr 19 16:34:20.394: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.376381ms
  E0419 16:34:20.675083      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:21.675099      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:22.676226      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:34:23.001: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 16:34:23.001: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 19 16:34:23.006: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"20679"},"items":null}

  Apr 19 16:34:23.012: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"20679"},"items":null}

  Apr 19 16:34:23.039: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-4571" for this suite. @ 04/19/24 16:34:23.049
• [7.036 seconds]
------------------------------
SSS
------------------------------
[sig-node] Pods should patch a pod status [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:1084
  STEP: Creating a kubernetes client @ 04/19/24 16:34:23.061
  Apr 19 16:34:23.061: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename pods @ 04/19/24 16:34:23.066
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:34:23.096
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:34:23.102
  STEP: Create a pod @ 04/19/24 16:34:23.109
  E0419 16:34:23.676317      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:24.677437      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching /status @ 04/19/24 16:34:25.145
  Apr 19 16:34:25.168: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
  Apr 19 16:34:25.169: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2710" for this suite. @ 04/19/24 16:34:25.178
• [2.136 seconds]
------------------------------
S
------------------------------
[sig-node] Secrets should fail to create secret due to empty secret key [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:141
  STEP: Creating a kubernetes client @ 04/19/24 16:34:25.2
  Apr 19 16:34:25.200: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename secrets @ 04/19/24 16:34:25.205
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:34:25.259
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:34:25.267
  STEP: Creating projection with secret that has name secret-emptykey-test-1dda9db2-ef16-466c-bcae-c5d09162f282 @ 04/19/24 16:34:25.272
  Apr 19 16:34:25.276: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3807" for this suite. @ 04/19/24 16:34:25.286
• [0.102 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:168
  STEP: Creating a kubernetes client @ 04/19/24 16:34:25.304
  Apr 19 16:34:25.304: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename container-probe @ 04/19/24 16:34:25.307
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:34:25.353
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:34:25.357
  STEP: Creating pod liveness-b0c835e6-17fe-4adb-999a-07e35590542b in namespace container-probe-5231 @ 04/19/24 16:34:25.361
  E0419 16:34:25.677048      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:26.677820      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/19/24 16:34:27.393
  Apr 19 16:34:27.402: INFO: Initial restart count of pod liveness-b0c835e6-17fe-4adb-999a-07e35590542b is 0
  Apr 19 16:34:27.414: INFO: Get pod liveness-b0c835e6-17fe-4adb-999a-07e35590542b in namespace container-probe-5231
  E0419 16:34:27.677862      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:28.679033      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:34:29.425: INFO: Get pod liveness-b0c835e6-17fe-4adb-999a-07e35590542b in namespace container-probe-5231
  E0419 16:34:29.678591      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:30.680787      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:34:31.433: INFO: Get pod liveness-b0c835e6-17fe-4adb-999a-07e35590542b in namespace container-probe-5231
  E0419 16:34:31.681606      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:32.682016      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:34:33.443: INFO: Get pod liveness-b0c835e6-17fe-4adb-999a-07e35590542b in namespace container-probe-5231
  E0419 16:34:33.683206      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:34.684185      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:34:35.453: INFO: Get pod liveness-b0c835e6-17fe-4adb-999a-07e35590542b in namespace container-probe-5231
  E0419 16:34:35.684692      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:36.685777      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:34:37.462: INFO: Get pod liveness-b0c835e6-17fe-4adb-999a-07e35590542b in namespace container-probe-5231
  E0419 16:34:37.686477      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:38.687529      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:34:39.471: INFO: Get pod liveness-b0c835e6-17fe-4adb-999a-07e35590542b in namespace container-probe-5231
  E0419 16:34:39.688564      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:40.688851      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:34:41.480: INFO: Get pod liveness-b0c835e6-17fe-4adb-999a-07e35590542b in namespace container-probe-5231
  E0419 16:34:41.689147      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:42.689378      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:34:43.490: INFO: Get pod liveness-b0c835e6-17fe-4adb-999a-07e35590542b in namespace container-probe-5231
  E0419 16:34:43.690631      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:44.690741      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:34:45.500: INFO: Get pod liveness-b0c835e6-17fe-4adb-999a-07e35590542b in namespace container-probe-5231
  E0419 16:34:45.691942      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:46.692615      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:34:47.511: INFO: Get pod liveness-b0c835e6-17fe-4adb-999a-07e35590542b in namespace container-probe-5231
  Apr 19 16:34:47.512: INFO: Restart count of pod container-probe-5231/liveness-b0c835e6-17fe-4adb-999a-07e35590542b is now 1 (20.108459441s elapsed)
  STEP: deleting the pod @ 04/19/24 16:34:47.513
  Apr 19 16:34:47.544: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-5231" for this suite. @ 04/19/24 16:34:47.556
• [22.274 seconds]
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:707
  STEP: Creating a kubernetes client @ 04/19/24 16:34:47.578
  Apr 19 16:34:47.578: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename sched-pred @ 04/19/24 16:34:47.582
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:34:47.615
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:34:47.62
  Apr 19 16:34:47.625: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Apr 19 16:34:47.639: INFO: Waiting for terminating namespaces to be deleted...
  Apr 19 16:34:47.646: INFO: 
  Logging pods the apiserver thinks is on node co4fe9zoo9oc-1 before test
  Apr 19 16:34:47.659: INFO: coredns-76f75df574-dnglm from kube-system started at 2024-04-19 15:34:35 +0000 UTC (1 container statuses recorded)
  Apr 19 16:34:47.659: INFO: 	Container coredns ready: true, restart count 1
  Apr 19 16:34:47.659: INFO: coredns-76f75df574-n4wlj from kube-system started at 2024-04-19 15:34:35 +0000 UTC (1 container statuses recorded)
  Apr 19 16:34:47.659: INFO: 	Container coredns ready: true, restart count 1
  Apr 19 16:34:47.659: INFO: kube-addon-manager-co4fe9zoo9oc-1 from kube-system started at 2024-04-19 15:40:36 +0000 UTC (1 container statuses recorded)
  Apr 19 16:34:47.659: INFO: 	Container kube-addon-manager ready: true, restart count 1
  Apr 19 16:34:47.660: INFO: kube-apiserver-co4fe9zoo9oc-1 from kube-system started at 2024-04-19 15:40:36 +0000 UTC (1 container statuses recorded)
  Apr 19 16:34:47.660: INFO: 	Container kube-apiserver ready: true, restart count 1
  Apr 19 16:34:47.660: INFO: kube-controller-manager-co4fe9zoo9oc-1 from kube-system started at 2024-04-19 15:40:36 +0000 UTC (1 container statuses recorded)
  Apr 19 16:34:47.660: INFO: 	Container kube-controller-manager ready: true, restart count 1
  Apr 19 16:34:47.660: INFO: kube-flannel-ds-9gpfv from kube-system started at 2024-04-19 15:34:17 +0000 UTC (1 container statuses recorded)
  Apr 19 16:34:47.660: INFO: 	Container kube-flannel ready: true, restart count 1
  Apr 19 16:34:47.660: INFO: kube-proxy-zzhn9 from kube-system started at 2024-04-19 15:27:31 +0000 UTC (1 container statuses recorded)
  Apr 19 16:34:47.660: INFO: 	Container kube-proxy ready: true, restart count 1
  Apr 19 16:34:47.660: INFO: kube-scheduler-co4fe9zoo9oc-1 from kube-system started at 2024-04-19 15:40:36 +0000 UTC (1 container statuses recorded)
  Apr 19 16:34:47.660: INFO: 	Container kube-scheduler ready: true, restart count 1
  Apr 19 16:34:47.660: INFO: sonobuoy-systemd-logs-daemon-set-f3d7cdfd30314b67-kskjf from sonobuoy started at 2024-04-19 15:41:34 +0000 UTC (2 container statuses recorded)
  Apr 19 16:34:47.660: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 19 16:34:47.660: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 19 16:34:47.660: INFO: 
  Logging pods the apiserver thinks is on node co4fe9zoo9oc-2 before test
  Apr 19 16:34:47.675: INFO: kube-addon-manager-co4fe9zoo9oc-2 from kube-system started at 2024-04-19 15:36:28 +0000 UTC (1 container statuses recorded)
  Apr 19 16:34:47.675: INFO: 	Container kube-addon-manager ready: true, restart count 1
  Apr 19 16:34:47.675: INFO: kube-apiserver-co4fe9zoo9oc-2 from kube-system started at 2024-04-19 15:36:28 +0000 UTC (1 container statuses recorded)
  Apr 19 16:34:47.675: INFO: 	Container kube-apiserver ready: true, restart count 1
  Apr 19 16:34:47.675: INFO: kube-controller-manager-co4fe9zoo9oc-2 from kube-system started at 2024-04-19 15:36:28 +0000 UTC (1 container statuses recorded)
  Apr 19 16:34:47.675: INFO: 	Container kube-controller-manager ready: true, restart count 1
  Apr 19 16:34:47.675: INFO: kube-flannel-ds-g2l7p from kube-system started at 2024-04-19 15:34:17 +0000 UTC (1 container statuses recorded)
  Apr 19 16:34:47.675: INFO: 	Container kube-flannel ready: true, restart count 1
  Apr 19 16:34:47.675: INFO: kube-proxy-6gjw7 from kube-system started at 2024-04-19 15:28:18 +0000 UTC (1 container statuses recorded)
  Apr 19 16:34:47.675: INFO: 	Container kube-proxy ready: true, restart count 1
  Apr 19 16:34:47.675: INFO: kube-scheduler-co4fe9zoo9oc-2 from kube-system started at 2024-04-19 15:36:28 +0000 UTC (1 container statuses recorded)
  Apr 19 16:34:47.675: INFO: 	Container kube-scheduler ready: true, restart count 1
  Apr 19 16:34:47.675: INFO: sonobuoy-systemd-logs-daemon-set-f3d7cdfd30314b67-l6thv from sonobuoy started at 2024-04-19 15:41:34 +0000 UTC (2 container statuses recorded)
  Apr 19 16:34:47.675: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 19 16:34:47.675: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 19 16:34:47.675: INFO: 
  Logging pods the apiserver thinks is on node co4fe9zoo9oc-3 before test
  Apr 19 16:34:47.689: INFO: kube-flannel-ds-8xgdk from kube-system started at 2024-04-19 15:47:35 +0000 UTC (1 container statuses recorded)
  Apr 19 16:34:47.689: INFO: 	Container kube-flannel ready: true, restart count 0
  Apr 19 16:34:47.689: INFO: kube-proxy-nxtbd from kube-system started at 2024-04-19 15:28:43 +0000 UTC (1 container statuses recorded)
  Apr 19 16:34:47.689: INFO: 	Container kube-proxy ready: true, restart count 1
  Apr 19 16:34:47.689: INFO: pod-exec-websocket-9da975d9-2cb5-4d5e-a852-9707ec14db42 from pods-4262 started at 2024-04-19 16:34:09 +0000 UTC (1 container statuses recorded)
  Apr 19 16:34:47.689: INFO: 	Container main ready: false, restart count 0
  Apr 19 16:34:47.689: INFO: sonobuoy from sonobuoy started at 2024-04-19 15:41:27 +0000 UTC (1 container statuses recorded)
  Apr 19 16:34:47.689: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Apr 19 16:34:47.689: INFO: sonobuoy-e2e-job-8260c76ae18e4472 from sonobuoy started at 2024-04-19 15:41:34 +0000 UTC (2 container statuses recorded)
  Apr 19 16:34:47.689: INFO: 	Container e2e ready: true, restart count 0
  Apr 19 16:34:47.689: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 19 16:34:47.689: INFO: sonobuoy-systemd-logs-daemon-set-f3d7cdfd30314b67-2fw62 from sonobuoy started at 2024-04-19 15:41:34 +0000 UTC (2 container statuses recorded)
  Apr 19 16:34:47.689: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 19 16:34:47.689: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 04/19/24 16:34:47.69
  E0419 16:34:47.692272      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:48.692583      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:49.693157      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 04/19/24 16:34:49.728
  STEP: Trying to apply a random label on the found node. @ 04/19/24 16:34:49.777
  STEP: verifying the node has the label kubernetes.io/e2e-80330cce-1691-4071-bb8b-8f8714fd8a27 95 @ 04/19/24 16:34:49.798
  STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled @ 04/19/24 16:34:49.805
  E0419 16:34:50.693186      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:51.693568      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 192.168.121.60 on the node which pod4 resides and expect not scheduled @ 04/19/24 16:34:51.84
  E0419 16:34:52.693901      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:53.694952      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:54.695129      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:55.695886      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:56.696418      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:57.696713      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:58.696884      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:34:59.697181      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:00.697489      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:01.697565      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:02.697844      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:03.698403      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:04.698678      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:05.699763      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:06.700299      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:07.700528      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:08.700876      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:09.701849      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:10.702353      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:11.702787      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:12.704023      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:13.704250      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:14.704307      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:15.704993      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:16.705214      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:17.706445      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:18.706588      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:19.706733      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:20.707035      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:21.707401      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:22.707697      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:23.707937      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:24.708317      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:25.709390      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:26.709614      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:27.709945      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:28.710383      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:29.710621      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:30.710889      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:31.711140      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:32.711882      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:33.712096      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:34.712249      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:35.712752      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:36.712972      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:37.714229      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:38.714368      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:39.715316      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:40.716458      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:41.717404      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:42.718369      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:43.718749      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:44.718976      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:45.720192      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:46.720985      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:47.721412      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:48.721860      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:49.722702      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:50.722851      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:51.723460      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:52.724532      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:53.724846      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:54.724958      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:55.725305      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:56.725361      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:57.726257      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:58.726898      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:35:59.727364      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:00.727650      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:01.728708      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:02.728997      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:03.729170      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:04.730616      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:05.730712      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:06.731132      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:07.731994      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:08.732284      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:09.734064      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:10.733403      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:11.734081      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:12.734414      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:13.734593      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:14.735316      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:15.735703      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:16.736667      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:17.737678      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:18.738359      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:19.739528      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:20.739747      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:21.740672      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:22.741365      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:23.742595      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:24.742965      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:25.743644      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:26.744080      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:27.745181      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:28.745475      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:29.747275      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:30.746219      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:31.746805      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:32.747107      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:33.747422      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:34.747929      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:35.748604      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:36.748596      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:37.749237      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:38.749434      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:39.750873      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:40.751100      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:41.751709      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:42.751843      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:43.752190      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:44.752700      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:45.753092      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:46.754957      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:47.755348      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:48.756147      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:49.757080      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:50.757870      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:51.758468      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:52.758589      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:53.758863      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:54.758913      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:55.759402      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:56.759776      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:57.761116      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:58.762120      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:36:59.762702      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:00.763593      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:01.763898      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:02.764232      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:03.764639      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:04.764777      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:05.765710      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:06.766314      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:07.767048      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:08.768159      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:09.768561      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:10.769115      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:11.769296      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:12.770219      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:13.770636      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:14.771373      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:15.771642      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:16.771804      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:17.772258      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:18.772625      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:19.773239      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:20.773431      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:21.774422      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:22.774528      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:23.774952      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:24.776349      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:25.776550      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:26.777045      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:27.777837      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:28.779046      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:29.780065      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:30.781044      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:31.781328      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:32.782028      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:33.782850      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:34.783257      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:35.783597      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:36.783946      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:37.784890      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:38.785644      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:39.785969      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:40.786765      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:41.787816      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:42.788112      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:43.788584      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:44.789168      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:45.789557      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:46.789707      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:47.790207      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:48.790559      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:49.790847      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:50.791747      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:51.792304      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:52.792608      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:53.792939      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:54.793013      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:55.793354      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:56.794581      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:57.794909      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:58.795380      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:37:59.795634      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:00.796521      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:01.797424      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:02.797592      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:03.798070      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:04.798415      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:05.798588      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:06.799583      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:07.799948      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:08.800228      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:09.800662      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:10.801609      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:11.801915      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:12.802187      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:13.802527      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:14.803604      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:15.804080      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:16.805264      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:17.805938      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:18.806323      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:19.807017      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:20.807065      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:21.807377      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:22.807918      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:23.808120      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:24.809311      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:25.809493      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:26.809816      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:27.810137      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:28.810554      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:29.810688      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:30.811789      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:31.812048      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:32.812246      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:33.812568      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:34.812670      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:35.813122      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:36.813436      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:37.814443      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:38.814773      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:39.814847      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:40.815093      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:41.815488      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:42.815703      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:43.815995      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:44.816241      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:45.816587      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:46.816790      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:47.817943      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:48.818467      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:49.818661      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:50.819555      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:51.819955      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:52.820995      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:53.822952      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:54.822785      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:55.822924      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:56.823100      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:57.823639      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:58.824082      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:38:59.824812      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:00.825157      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:01.825864      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:02.826348      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:03.827102      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:04.828121      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:05.829173      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:06.829390      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:07.829607      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:08.832466      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:09.830709      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:10.831745      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:11.832057      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:12.832514      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:13.832603      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:14.833349      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:15.834502      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:16.835118      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:17.836255      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:18.837278      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:19.838179      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:20.838797      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:21.839471      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:22.839617      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:23.839890      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:24.840518      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:25.841088      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:26.841453      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:27.842016      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:28.842262      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:29.842829      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:30.843926      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:31.844020      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:32.844793      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:33.845121      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:34.846348      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:35.846542      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:36.846902      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:37.847628      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:38.847668      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:39.848335      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:40.848625      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:41.848746      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:42.849640      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:43.850591      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:44.850696      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:45.851581      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:46.851888      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:47.852734      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:48.853966      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:49.854782      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:50.855638      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:51.855879      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-80330cce-1691-4071-bb8b-8f8714fd8a27 off the node co4fe9zoo9oc-3 @ 04/19/24 16:39:51.867
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-80330cce-1691-4071-bb8b-8f8714fd8a27 @ 04/19/24 16:39:51.905
  Apr 19 16:39:51.913: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-2248" for this suite. @ 04/19/24 16:39:51.925
• [304.363 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:125
  STEP: Creating a kubernetes client @ 04/19/24 16:39:51.946
  Apr 19 16:39:51.947: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename projected @ 04/19/24 16:39:51.952
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:39:51.993
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:39:52.001
  STEP: Creating projection with configMap that has name projected-configmap-test-upd-2cf5e2d8-0b58-4dde-86b0-034537a2eee8 @ 04/19/24 16:39:52.021
  STEP: Creating the pod @ 04/19/24 16:39:52.029
  E0419 16:39:52.856418      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:53.856727      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating configmap projected-configmap-test-upd-2cf5e2d8-0b58-4dde-86b0-034537a2eee8 @ 04/19/24 16:39:54.145
  STEP: waiting to observe update in volume @ 04/19/24 16:39:54.163
  E0419 16:39:54.857203      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:55.857353      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:56.857888      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:57.857631      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:58.858892      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:39:59.858755      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:00.859979      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:01.860760      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:02.860912      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:03.861262      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:04.862621      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:05.862952      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:06.864725      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:07.865144      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:08.866125      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:09.867001      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:10.867169      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:11.867245      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:12.868448      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:13.894013      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:14.879986      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:15.880239      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:16.880432      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:17.881059      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:18.882875      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:19.883036      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:20.883738      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:21.884183      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:22.884271      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:23.890619      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:24.889061      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:25.889418      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:26.889733      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:27.890690      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:28.891193      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:29.891367      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:30.892252      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:31.892684      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:32.893064      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:33.893916      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:34.894732      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:35.895114      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:36.896103      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:37.896906      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:38.897070      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:39.898215      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:40.899129      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:41.899750      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:42.900463      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:43.901507      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:44.901747      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:45.903243      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:46.903636      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:47.904800      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:48.905254      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:49.905993      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:50.906388      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:51.907690      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:52.908796      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:53.908995      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:54.909335      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:55.909559      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:56.909966      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:57.910623      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:58.910931      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:40:59.910892      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:00.916981      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:01.913217      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:02.913676      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:03.913922      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:04.915046      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:05.915243      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:06.915426      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:41:07.130: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1068" for this suite. @ 04/19/24 16:41:07.155
• [75.233 seconds]
------------------------------
S
------------------------------
[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:209
  STEP: Creating a kubernetes client @ 04/19/24 16:41:07.182
  Apr 19 16:41:07.182: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename downward-api @ 04/19/24 16:41:07.19
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:41:07.239
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:41:07.246
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 16:41:07.253
  E0419 16:41:07.925081      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:08.916151      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:09.917782      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:10.918052      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:41:11.305
  Apr 19 16:41:11.319: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod downwardapi-volume-06f5e453-9c9d-4e8b-beb7-46e6cbb77b34 container client-container: <nil>
  STEP: delete the pod @ 04/19/24 16:41:11.339
  Apr 19 16:41:11.391: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4708" for this suite. @ 04/19/24 16:41:11.407
• [4.244 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:274
  STEP: Creating a kubernetes client @ 04/19/24 16:41:11.47
  Apr 19 16:41:11.470: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename namespaces @ 04/19/24 16:41:11.475
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:41:11.511
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:41:11.519
  STEP: creating a Namespace @ 04/19/24 16:41:11.526
  STEP: patching the Namespace @ 04/19/24 16:41:11.56
  STEP: get the Namespace and ensuring it has the label @ 04/19/24 16:41:11.573
  Apr 19 16:41:11.582: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-485" for this suite. @ 04/19/24 16:41:11.6
  STEP: Destroying namespace "nspatchtest-720adfe4-5da4-4b3a-bc8e-e369d6c4af00-1679" for this suite. @ 04/19/24 16:41:11.614
• [0.161 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve endpoints on same port and different protocols [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3649
  STEP: Creating a kubernetes client @ 04/19/24 16:41:11.651
  Apr 19 16:41:11.651: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename services @ 04/19/24 16:41:11.657
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:41:11.698
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:41:11.707
  STEP: creating service multiprotocol-test in namespace services-5938 @ 04/19/24 16:41:11.713
  STEP: creating pod pod1 in namespace services-5938 @ 04/19/24 16:41:11.734
  STEP: Creating pod pod1 in namespace services-5938 @ 04/19/24 16:41:11.734
  E0419 16:41:11.919137      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:12.919312      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multiprotocol-test in namespace services-5938 to expose endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]] @ 04/19/24 16:41:13.781
  Apr 19 16:41:13.814: INFO: successfully validated that service multiprotocol-test in namespace services-5938 exposes endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]]
  STEP: Checking if the Service forwards traffic to the TCP and UDP port @ 04/19/24 16:41:13.815
  Apr 19 16:41:13.816: INFO: Creating new exec pod
  E0419 16:41:13.919940      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:14.920700      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:41:15.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-5938 exec execpod5znt7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.35.190 80'
  E0419 16:41:15.921220      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:41:16.284: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.35.190 80\nConnection to 10.233.35.190 80 port [tcp/http] succeeded!\n"
  Apr 19 16:41:16.284: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 16:41:16.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-5938 exec execpod5znt7 -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.233.35.190 80'
  E0419 16:41:16.922049      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:17.923067      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:18.923977      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:19.924982      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:41:20.619: INFO: stderr: "+ echo hostName\n+ nc -v -u -w 2 10.233.35.190 80\nConnection to 10.233.35.190 80 port [udp/*] succeeded!\n"
  Apr 19 16:41:20.619: INFO: stdout: "pod1"
  STEP: Checking if the Service forwards traffic to TCP only @ 04/19/24 16:41:20.62
  Apr 19 16:41:20.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-5938 exec execpod5znt7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.35.190 80'
  E0419 16:41:20.925686      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:41:20.949: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.35.190 80\nConnection to 10.233.35.190 80 port [tcp/http] succeeded!\n"
  Apr 19 16:41:20.949: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 16:41:20.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-5938 exec execpod5znt7 -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.233.35.190 80'
  E0419 16:41:21.925929      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:22.926494      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:23.926684      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:24.926926      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:41:25.273: INFO: stderr: "+ echo hostName\n+ nc -v -u -w 2 10.233.35.190 80\nConnection to 10.233.35.190 80 port [udp/*] succeeded!\n"
  Apr 19 16:41:25.274: INFO: stdout: ""
  Apr 19 16:41:25.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-5938 exec execpod5znt7 -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.233.35.190 80'
  E0419 16:41:25.927838      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:26.928224      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:27.928474      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:28.928874      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:41:29.590: INFO: stderr: "+ echo hostName\n+ nc -v -u -w 2 10.233.35.190 80\nConnection to 10.233.35.190 80 port [udp/*] succeeded!\n"
  Apr 19 16:41:29.590: INFO: stdout: ""
  STEP: Checking if the Service forwards traffic to UDP only @ 04/19/24 16:41:29.59
  Apr 19 16:41:29.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-5938 exec execpod5znt7 -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.233.35.190 80'
  E0419 16:41:29.929904      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:30.930723      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:31.931701      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:32.932865      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:41:33.913: INFO: stderr: "+ echo hostName\n+ nc -v -u -w 2 10.233.35.190 80\nConnection to 10.233.35.190 80 port [udp/*] succeeded!\n"
  Apr 19 16:41:33.914: INFO: stdout: "pod1"
  Apr 19 16:41:33.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-5938 exec execpod5znt7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.35.190 80'
  E0419 16:41:33.933086      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:34.933436      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:35.934099      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:41:36.280: INFO: rc: 1
  Apr 19 16:41:36.280: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-5938 exec execpod5znt7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.35.190 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.233.35.190 80
  nc: connect to 10.233.35.190 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  Apr 19 16:41:36.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-5938 exec execpod5znt7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.35.190 80'
  E0419 16:41:36.934634      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:37.934675      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:41:38.604: INFO: rc: 1
  Apr 19 16:41:38.604: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-5938 exec execpod5znt7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.35.190 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.233.35.190 80
  nc: connect to 10.233.35.190 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  Apr 19 16:41:38.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-5938 exec execpod5znt7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.35.190 80'
  E0419 16:41:38.935527      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:39.936158      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:41:40.900: INFO: rc: 1
  Apr 19 16:41:40.901: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-5938 exec execpod5znt7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.35.190 80:
  Command stdout:

  stderr:
  + + ncecho -v hostName -t
   -w 2 10.233.35.190 80
  nc: connect to 10.233.35.190 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  Apr 19 16:41:40.901: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5938" for this suite. @ 04/19/24 16:41:40.915
• [29.284 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS  E0419 16:41:40.946966      13 retrywatcher.go:129] "Watch failed" err="context canceled"
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:345
  STEP: Creating a kubernetes client @ 04/19/24 16:41:40.95
  Apr 19 16:41:40.950: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename pods @ 04/19/24 16:41:40.957
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:41:41.003
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:41:41.008
  STEP: creating the pod @ 04/19/24 16:41:41.02
  STEP: submitting the pod to kubernetes @ 04/19/24 16:41:41.02
  E0419 16:41:41.947108      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:42.948234      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 04/19/24 16:41:43.08
  STEP: updating the pod @ 04/19/24 16:41:43.092
  Apr 19 16:41:43.628: INFO: Successfully updated pod "pod-update-210b6468-e897-408e-8051-1fce41fc9d92"
  STEP: verifying the updated pod is in kubernetes @ 04/19/24 16:41:43.639
  Apr 19 16:41:43.651: INFO: Pod update OK
  Apr 19 16:41:43.651: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2218" for this suite. @ 04/19/24 16:41:43.666
• [2.732 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:100
  STEP: Creating a kubernetes client @ 04/19/24 16:41:43.685
  Apr 19 16:41:43.686: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename emptydir @ 04/19/24 16:41:43.69
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:41:43.726
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:41:43.732
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 04/19/24 16:41:43.738
  E0419 16:41:43.949211      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:44.949992      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:45.950948      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:46.951699      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:41:47.789
  Apr 19 16:41:47.799: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-0ba9b436-f699-4c9f-b654-7fbc3e9620dc container test-container: <nil>
  STEP: delete the pod @ 04/19/24 16:41:47.821
  Apr 19 16:41:47.865: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7164" for this suite. @ 04/19/24 16:41:47.881
• [4.214 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:154
  STEP: Creating a kubernetes client @ 04/19/24 16:41:47.9
  Apr 19 16:41:47.901: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename tables @ 04/19/24 16:41:47.906
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:41:47.945
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:41:47.949
  E0419 16:41:47.952046      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:41:47.959: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "tables-9497" for this suite. @ 04/19/24 16:41:47.967
• [0.083 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:889
  STEP: Creating a kubernetes client @ 04/19/24 16:41:47.984
  Apr 19 16:41:47.984: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename resourcequota @ 04/19/24 16:41:47.988
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:41:48.021
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:41:48.026
  STEP: Creating a ResourceQuota @ 04/19/24 16:41:48.031
  STEP: Getting a ResourceQuota @ 04/19/24 16:41:48.04
  STEP: Updating a ResourceQuota @ 04/19/24 16:41:48.049
  STEP: Verifying a ResourceQuota was modified @ 04/19/24 16:41:48.066
  STEP: Deleting a ResourceQuota @ 04/19/24 16:41:48.077
  STEP: Verifying the deleted ResourceQuota @ 04/19/24 16:41:48.088
  Apr 19 16:41:48.095: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-7021" for this suite. @ 04/19/24 16:41:48.104
• [0.135 seconds]
------------------------------
[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:649
  STEP: Creating a kubernetes client @ 04/19/24 16:41:48.12
  Apr 19 16:41:48.121: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename svcaccounts @ 04/19/24 16:41:48.124
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:41:48.164
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:41:48.168
  STEP: creating a ServiceAccount @ 04/19/24 16:41:48.173
  STEP: watching for the ServiceAccount to be added @ 04/19/24 16:41:48.186
  STEP: patching the ServiceAccount @ 04/19/24 16:41:48.188
  STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) @ 04/19/24 16:41:48.197
  STEP: deleting the ServiceAccount @ 04/19/24 16:41:48.204
  Apr 19 16:41:48.231: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-7478" for this suite. @ 04/19/24 16:41:48.242
• [0.137 seconds]
------------------------------
SS
------------------------------
[sig-apps] ReplicationController should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:70
  STEP: Creating a kubernetes client @ 04/19/24 16:41:48.259
  Apr 19 16:41:48.259: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename replication-controller @ 04/19/24 16:41:48.263
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:41:48.298
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:41:48.303
  STEP: Creating replication controller my-hostname-basic-91a3b004-fd91-4aff-8625-2bbdc1a70c4e @ 04/19/24 16:41:48.308
  Apr 19 16:41:48.321: INFO: Pod name my-hostname-basic-91a3b004-fd91-4aff-8625-2bbdc1a70c4e: Found 0 pods out of 1
  E0419 16:41:48.952597      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:49.953903      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:50.954509      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:51.954785      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:52.956472      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:41:53.333: INFO: Pod name my-hostname-basic-91a3b004-fd91-4aff-8625-2bbdc1a70c4e: Found 1 pods out of 1
  Apr 19 16:41:53.333: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-91a3b004-fd91-4aff-8625-2bbdc1a70c4e" are running
  Apr 19 16:41:53.339: INFO: Pod "my-hostname-basic-91a3b004-fd91-4aff-8625-2bbdc1a70c4e-6jn56" is running and ready(conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-19 16:41:49 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-19 16:41:48 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-19 16:41:49 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-19 16:41:49 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-19 16:41:48 +0000 UTC Reason: Message:}])
  Apr 19 16:41:53.340: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 04/19/24 16:41:53.34
  Apr 19 16:41:53.362: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-9154" for this suite. @ 04/19/24 16:41:53.374
• [5.128 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:96
  STEP: Creating a kubernetes client @ 04/19/24 16:41:53.389
  Apr 19 16:41:53.389: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename pod-network-test @ 04/19/24 16:41:53.395
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:41:53.432
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:41:53.437
  STEP: Performing setup for networking test in namespace pod-network-test-6779 @ 04/19/24 16:41:53.443
  STEP: creating a selector @ 04/19/24 16:41:53.444
  STEP: Creating the service pods in kubernetes @ 04/19/24 16:41:53.444
  Apr 19 16:41:53.444: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0419 16:41:53.956845      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:54.957486      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:55.958501      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:56.958941      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:57.960044      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:58.960799      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:41:59.960862      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:00.961763      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:01.962399      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:02.962714      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:03.962966      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:04.963238      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:05.963323      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:06.964203      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:07.964608      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:08.964841      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:09.965856      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:10.966196      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:11.967026      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:12.966641      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:13.966943      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:14.967580      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 04/19/24 16:42:15.748
  E0419 16:42:15.969085      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:16.969578      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:42:17.801: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Apr 19 16:42:17.802: INFO: Breadth first check of 10.233.64.118 on host 192.168.121.127...
  Apr 19 16:42:17.809: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.27:9080/dial?request=hostname&protocol=udp&host=10.233.64.118&port=8081&tries=1'] Namespace:pod-network-test-6779 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 16:42:17.810: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 16:42:17.814: INFO: ExecWithOptions: Clientset creation
  Apr 19 16:42:17.814: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-6779/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.27%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.64.118%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  E0419 16:42:17.969814      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:42:18.014: INFO: Waiting for responses: map[]
  Apr 19 16:42:18.014: INFO: reached 10.233.64.118 after 0/1 tries
  Apr 19 16:42:18.014: INFO: Breadth first check of 10.233.65.126 on host 192.168.121.39...
  Apr 19 16:42:18.024: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.27:9080/dial?request=hostname&protocol=udp&host=10.233.65.126&port=8081&tries=1'] Namespace:pod-network-test-6779 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 16:42:18.024: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 16:42:18.026: INFO: ExecWithOptions: Clientset creation
  Apr 19 16:42:18.026: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-6779/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.27%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.65.126%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Apr 19 16:42:18.182: INFO: Waiting for responses: map[]
  Apr 19 16:42:18.183: INFO: reached 10.233.65.126 after 0/1 tries
  Apr 19 16:42:18.183: INFO: Breadth first check of 10.233.66.26 on host 192.168.121.60...
  Apr 19 16:42:18.191: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.27:9080/dial?request=hostname&protocol=udp&host=10.233.66.26&port=8081&tries=1'] Namespace:pod-network-test-6779 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 16:42:18.191: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 16:42:18.194: INFO: ExecWithOptions: Clientset creation
  Apr 19 16:42:18.194: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-6779/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.27%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.66.26%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Apr 19 16:42:18.342: INFO: Waiting for responses: map[]
  Apr 19 16:42:18.343: INFO: reached 10.233.66.26 after 0/1 tries
  Apr 19 16:42:18.343: INFO: Going to retry 0 out of 3 pods....
  Apr 19 16:42:18.343: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-6779" for this suite. @ 04/19/24 16:42:18.353
• [24.980 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:177
  STEP: Creating a kubernetes client @ 04/19/24 16:42:18.373
  Apr 19 16:42:18.373: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename daemonsets @ 04/19/24 16:42:18.377
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:42:18.414
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:42:18.419
  STEP: Creating simple DaemonSet "daemon-set" @ 04/19/24 16:42:18.467
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/19/24 16:42:18.481
  Apr 19 16:42:18.522: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 16:42:18.522: INFO: Node co4fe9zoo9oc-1 is running 0 daemon pod, expected 1
  E0419 16:42:18.970773      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:42:19.498: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 16:42:19.498: INFO: Node co4fe9zoo9oc-1 is running 0 daemon pod, expected 1
  E0419 16:42:19.971162      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:42:20.501: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 19 16:42:20.501: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Stop a daemon pod, check that the daemon pod is revived. @ 04/19/24 16:42:20.508
  Apr 19 16:42:20.571: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 19 16:42:20.571: INFO: Node co4fe9zoo9oc-2 is running 0 daemon pod, expected 1
  E0419 16:42:20.971592      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:42:21.560: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 19 16:42:21.560: INFO: Node co4fe9zoo9oc-2 is running 0 daemon pod, expected 1
  E0419 16:42:21.973108      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:42:22.561: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 19 16:42:22.561: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 04/19/24 16:42:22.601
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3731, will wait for the garbage collector to delete the pods @ 04/19/24 16:42:22.601
  Apr 19 16:42:22.675: INFO: Deleting DaemonSet.extensions daemon-set took: 14.142625ms
  Apr 19 16:42:22.776: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.851649ms
  E0419 16:42:22.973247      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:23.973585      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:42:24.184: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 16:42:24.184: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 19 16:42:24.195: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"22036"},"items":null}

  Apr 19 16:42:24.201: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"22036"},"items":null}

  Apr 19 16:42:24.231: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-3731" for this suite. @ 04/19/24 16:42:24.242
• [5.900 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:897
  STEP: Creating a kubernetes client @ 04/19/24 16:42:24.277
  Apr 19 16:42:24.277: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename pods @ 04/19/24 16:42:24.28
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:42:24.334
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:42:24.339
  STEP: creating a Pod with a static label @ 04/19/24 16:42:24.376
  STEP: watching for Pod to be ready @ 04/19/24 16:42:24.392
  Apr 19 16:42:24.395: INFO: observed Pod pod-test in namespace pods-8231 in phase Pending with labels: map[test-pod-static:true] & conditions []
  Apr 19 16:42:24.403: INFO: observed Pod pod-test in namespace pods-8231 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:42:24 +0000 UTC  }]
  Apr 19 16:42:24.444: INFO: observed Pod pod-test in namespace pods-8231 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:42:24 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:42:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:42:24 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:42:24 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:42:24 +0000 UTC  }]
  E0419 16:42:24.974451      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:42:25.819: INFO: Found Pod pod-test in namespace pods-8231 in phase Running with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:42:25 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:42:24 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:42:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:42:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 16:42:24 +0000 UTC  }]
  STEP: patching the Pod with a new Label and updated data @ 04/19/24 16:42:25.83
  STEP: getting the Pod and ensuring that it's patched @ 04/19/24 16:42:25.862
  STEP: replacing the Pod's status Ready condition to False @ 04/19/24 16:42:25.871
  STEP: check the Pod again to ensure its Ready conditions are False @ 04/19/24 16:42:25.893
  STEP: deleting the Pod via a Collection with a LabelSelector @ 04/19/24 16:42:25.894
  STEP: watching for the Pod to be deleted @ 04/19/24 16:42:25.919
  Apr 19 16:42:25.923: INFO: observed event type MODIFIED
  E0419 16:42:25.975554      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:26.976395      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:42:27.846: INFO: observed event type MODIFIED
  E0419 16:42:27.976445      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:42:27.997: INFO: observed event type MODIFIED
  Apr 19 16:42:28.864: INFO: observed event type MODIFIED
  Apr 19 16:42:28.894: INFO: observed event type MODIFIED
  Apr 19 16:42:28.904: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8231" for this suite. @ 04/19/24 16:42:28.931
• [4.667 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:146
  STEP: Creating a kubernetes client @ 04/19/24 16:42:28.948
  Apr 19 16:42:28.948: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/19/24 16:42:28.956
  E0419 16:42:28.976436      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:42:28.994
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:42:29
  Apr 19 16:42:29.006: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 16:42:29.584: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-9549" for this suite. @ 04/19/24 16:42:29.599
• [0.708 seconds]
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts should allow opting out of API token automount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:163
  STEP: Creating a kubernetes client @ 04/19/24 16:42:29.657
  Apr 19 16:42:29.657: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename svcaccounts @ 04/19/24 16:42:29.66
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:42:29.686
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:42:29.69
  Apr 19 16:42:29.722: INFO: created pod pod-service-account-defaultsa
  Apr 19 16:42:29.722: INFO: pod pod-service-account-defaultsa service account token volume mount: true
  Apr 19 16:42:29.729: INFO: created pod pod-service-account-mountsa
  Apr 19 16:42:29.730: INFO: pod pod-service-account-mountsa service account token volume mount: true
  Apr 19 16:42:29.746: INFO: created pod pod-service-account-nomountsa
  Apr 19 16:42:29.747: INFO: pod pod-service-account-nomountsa service account token volume mount: false
  Apr 19 16:42:29.753: INFO: created pod pod-service-account-defaultsa-mountspec
  Apr 19 16:42:29.753: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
  Apr 19 16:42:29.775: INFO: created pod pod-service-account-mountsa-mountspec
  Apr 19 16:42:29.776: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
  Apr 19 16:42:29.784: INFO: created pod pod-service-account-nomountsa-mountspec
  Apr 19 16:42:29.784: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
  Apr 19 16:42:29.795: INFO: created pod pod-service-account-defaultsa-nomountspec
  Apr 19 16:42:29.795: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
  Apr 19 16:42:29.802: INFO: created pod pod-service-account-mountsa-nomountspec
  Apr 19 16:42:29.803: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
  Apr 19 16:42:29.817: INFO: created pod pod-service-account-nomountsa-nomountspec
  Apr 19 16:42:29.818: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
  Apr 19 16:42:29.818: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-7742" for this suite. @ 04/19/24 16:42:29.828
• [0.198 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replace and Patch tests [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:155
  STEP: Creating a kubernetes client @ 04/19/24 16:42:29.858
  Apr 19 16:42:29.858: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename replicaset @ 04/19/24 16:42:29.872
  E0419 16:42:29.977040      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:42:29.988
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:42:29.993
  Apr 19 16:42:30.047: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0419 16:42:30.977950      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:31.978342      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:32.978938      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:33.979071      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:34.979356      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:42:35.054: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/19/24 16:42:35.055
  STEP: Scaling up "test-rs" replicaset @ 04/19/24 16:42:35.055
  Apr 19 16:42:35.071: INFO: Updating replica set "test-rs"
  STEP: patching the ReplicaSet @ 04/19/24 16:42:35.071
  Apr 19 16:42:35.095: INFO: observed ReplicaSet test-rs in namespace replicaset-926 with ReadyReplicas 1, AvailableReplicas 1
  Apr 19 16:42:35.137: INFO: observed ReplicaSet test-rs in namespace replicaset-926 with ReadyReplicas 1, AvailableReplicas 1
  Apr 19 16:42:35.164: INFO: observed ReplicaSet test-rs in namespace replicaset-926 with ReadyReplicas 1, AvailableReplicas 1
  Apr 19 16:42:35.203: INFO: observed ReplicaSet test-rs in namespace replicaset-926 with ReadyReplicas 1, AvailableReplicas 1
  E0419 16:42:35.980203      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:42:36.029: INFO: observed ReplicaSet test-rs in namespace replicaset-926 with ReadyReplicas 2, AvailableReplicas 2
  E0419 16:42:36.980489      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:42:37.222: INFO: observed Replicaset test-rs in namespace replicaset-926 with ReadyReplicas 3 found true
  Apr 19 16:42:37.222: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-926" for this suite. @ 04/19/24 16:42:37.232
• [7.387 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/ephemeral_containers.go:51
  STEP: Creating a kubernetes client @ 04/19/24 16:42:37.246
  Apr 19 16:42:37.246: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 04/19/24 16:42:37.248
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:42:37.322
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:42:37.348
  STEP: creating a target pod @ 04/19/24 16:42:37.355
  E0419 16:42:37.981297      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:38.981926      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 04/19/24 16:42:39.394
  E0419 16:42:39.983395      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:40.983185      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:41.983945      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:42.984589      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 04/19/24 16:42:43.459
  Apr 19 16:42:43.459: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-8444 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 16:42:43.459: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 16:42:43.463: INFO: ExecWithOptions: Clientset creation
  Apr 19 16:42:43.464: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/ephemeral-containers-test-8444/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  Apr 19 16:42:43.634: INFO: Exec stderr: ""
  Apr 19 16:42:43.651: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-8444" for this suite. @ 04/19/24 16:42:43.666
• [6.446 seconds]
------------------------------
[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:195
  STEP: Creating a kubernetes client @ 04/19/24 16:42:43.692
  Apr 19 16:42:43.692: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename downward-api @ 04/19/24 16:42:43.695
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:42:43.743
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:42:43.747
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 16:42:43.753
  E0419 16:42:43.985734      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:44.986731      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:45.986808      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:46.987601      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:42:47.807
  Apr 19 16:42:47.818: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod downwardapi-volume-153c1bbc-98fe-445b-921f-a48a0c03ef22 container client-container: <nil>
  STEP: delete the pod @ 04/19/24 16:42:47.841
  Apr 19 16:42:47.890: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8703" for this suite. @ 04/19/24 16:42:47.9
• [4.222 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:505
  STEP: Creating a kubernetes client @ 04/19/24 16:42:47.915
  Apr 19 16:42:47.916: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename configmap @ 04/19/24 16:42:47.918
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:42:47.952
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:42:47.957
  E0419 16:42:47.987033      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:42:48.053: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8456" for this suite. @ 04/19/24 16:42:48.063
• [0.167 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:86
  STEP: Creating a kubernetes client @ 04/19/24 16:42:48.088
  Apr 19 16:42:48.088: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/19/24 16:42:48.09
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:42:48.115
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:42:48.12
  Apr 19 16:42:48.127: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  E0419 16:42:48.988098      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:49.988649      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:50.989430      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:51.989915      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:52.990103      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:53.990583      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:42:54.629: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-4066" for this suite. @ 04/19/24 16:42:54.64
• [6.563 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:141
  STEP: Creating a kubernetes client @ 04/19/24 16:42:54.656
  Apr 19 16:42:54.656: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename disruption @ 04/19/24 16:42:54.662
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:42:54.69
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:42:54.695
  STEP: Waiting for the pdb to be processed @ 04/19/24 16:42:54.707
  E0419 16:42:54.990878      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:55.991831      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 04/19/24 16:42:56.787
  Apr 19 16:42:56.805: INFO: running pods: 0 < 3
  E0419 16:42:56.992745      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:57.993834      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:42:58.807: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-6523" for this suite. @ 04/19/24 16:42:58.818
• [4.181 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:117
  STEP: Creating a kubernetes client @ 04/19/24 16:42:58.84
  Apr 19 16:42:58.841: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename dns @ 04/19/24 16:42:58.843
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:42:58.876
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:42:58.88
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-7428.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-7428.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
   @ 04/19/24 16:42:58.884
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-7428.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-7428.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
   @ 04/19/24 16:42:58.885
  STEP: creating a pod to probe /etc/hosts @ 04/19/24 16:42:58.885
  STEP: submitting the pod to kubernetes @ 04/19/24 16:42:58.885
  E0419 16:42:58.994476      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:42:59.994793      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/19/24 16:43:00.94
  STEP: looking for the results for each expected name from probers @ 04/19/24 16:43:00.947
  E0419 16:43:00.994726      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:43:01.006: INFO: Unable to read jessie_hosts@dns-querier-1 from pod dns-7428/dns-test-6a3c1845-0126-474e-9500-ae0deeb21f85: the server could not find the requested resource (get pods dns-test-6a3c1845-0126-474e-9500-ae0deeb21f85)
  Apr 19 16:43:01.006: INFO: Lookups using dns-7428/dns-test-6a3c1845-0126-474e-9500-ae0deeb21f85 failed for: [jessie_hosts@dns-querier-1]

  Apr 19 16:43:01.072: INFO: Pod client logs for webserver: 
  Apr 19 16:43:01.098: INFO: Pod client logs for querier: 
  Apr 19 16:43:01.125: INFO: Pod client logs for jessie-querier: 
  E0419 16:43:01.995942      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:02.996904      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:03.997029      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:04.997329      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:43:05.991: INFO: Unable to read jessie_hosts@dns-querier-1 from pod dns-7428/dns-test-6a3c1845-0126-474e-9500-ae0deeb21f85: the server could not find the requested resource (get pods dns-test-6a3c1845-0126-474e-9500-ae0deeb21f85)
  Apr 19 16:43:05.991: INFO: Lookups using dns-7428/dns-test-6a3c1845-0126-474e-9500-ae0deeb21f85 failed for: [jessie_hosts@dns-querier-1]

  E0419 16:43:05.997702      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:43:06.012: INFO: Pod client logs for webserver: 
  Apr 19 16:43:06.029: INFO: Pod client logs for querier: 
  Apr 19 16:43:06.047: INFO: Pod client logs for jessie-querier: 
  E0419 16:43:06.998112      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:07.998803      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:08.999105      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:09.999316      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:43:10.982: INFO: DNS probes using dns-7428/dns-test-6a3c1845-0126-474e-9500-ae0deeb21f85 succeeded

  STEP: deleting the pod @ 04/19/24 16:43:10.982
  E0419 16:43:10.999962      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:43:11.001: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-7428" for this suite. @ 04/19/24 16:43:11.023
• [12.194 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:125
  STEP: Creating a kubernetes client @ 04/19/24 16:43:11.037
  Apr 19 16:43:11.037: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename pod-network-test @ 04/19/24 16:43:11.04
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:43:11.076
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:43:11.08
  STEP: Performing setup for networking test in namespace pod-network-test-454 @ 04/19/24 16:43:11.085
  STEP: creating a selector @ 04/19/24 16:43:11.085
  STEP: Creating the service pods in kubernetes @ 04/19/24 16:43:11.085
  Apr 19 16:43:11.085: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0419 16:43:12.000293      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:13.001101      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:14.001236      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:15.001589      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:16.002723      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:17.003864      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:18.004661      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:19.005280      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:20.005677      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:21.006812      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:22.007281      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:23.007928      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 04/19/24 16:43:23.284
  E0419 16:43:24.008670      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:25.009579      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:43:25.397: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Apr 19 16:43:25.398: INFO: Going to poll 10.233.64.121 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  Apr 19 16:43:25.405: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.64.121 8081 | grep -v '^\s*$'] Namespace:pod-network-test-454 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 16:43:25.405: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 16:43:25.407: INFO: ExecWithOptions: Clientset creation
  Apr 19 16:43:25.408: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-454/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.64.121+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0419 16:43:26.010340      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:43:26.553: INFO: Found all 1 expected endpoints: [netserver-0]
  Apr 19 16:43:26.553: INFO: Going to poll 10.233.65.133 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  Apr 19 16:43:26.559: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.65.133 8081 | grep -v '^\s*$'] Namespace:pod-network-test-454 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 16:43:26.559: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 16:43:26.561: INFO: ExecWithOptions: Clientset creation
  Apr 19 16:43:26.561: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-454/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.65.133+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0419 16:43:27.011284      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:43:27.672: INFO: Found all 1 expected endpoints: [netserver-1]
  Apr 19 16:43:27.673: INFO: Going to poll 10.233.66.38 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  Apr 19 16:43:27.683: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.66.38 8081 | grep -v '^\s*$'] Namespace:pod-network-test-454 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 16:43:27.683: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 16:43:27.686: INFO: ExecWithOptions: Clientset creation
  Apr 19 16:43:27.686: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-454/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.66.38+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0419 16:43:28.012011      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:43:28.839: INFO: Found all 1 expected endpoints: [netserver-2]
  Apr 19 16:43:28.839: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-454" for this suite. @ 04/19/24 16:43:28.853
• [17.831 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:655
  STEP: Creating a kubernetes client @ 04/19/24 16:43:28.869
  Apr 19 16:43:28.869: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename job @ 04/19/24 16:43:28.876
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:43:28.924
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:43:28.932
  STEP: Creating a job @ 04/19/24 16:43:28.941
  STEP: Ensuring active pods == parallelism @ 04/19/24 16:43:28.963
  E0419 16:43:29.013048      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:30.013755      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Orphaning one of the Job's Pods @ 04/19/24 16:43:30.975
  E0419 16:43:31.014093      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:43:31.514: INFO: Successfully updated pod "adopt-release-6jw6v"
  STEP: Checking that the Job readopts the Pod @ 04/19/24 16:43:31.514
  E0419 16:43:32.014571      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:33.014736      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing the labels from the Job's Pod @ 04/19/24 16:43:33.527
  E0419 16:43:34.015049      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:43:34.091: INFO: Successfully updated pod "adopt-release-6jw6v"
  STEP: Checking that the Job releases the Pod @ 04/19/24 16:43:34.091
  E0419 16:43:35.015223      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:36.015467      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:43:36.124: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-9146" for this suite. @ 04/19/24 16:43:36.132
• [7.271 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:51
  STEP: Creating a kubernetes client @ 04/19/24 16:43:36.144
  Apr 19 16:43:36.144: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename crd-watch @ 04/19/24 16:43:36.147
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:43:36.183
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:43:36.189
  Apr 19 16:43:36.193: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  E0419 16:43:37.016697      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:38.016788      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating first CR  @ 04/19/24 16:43:38.863
  Apr 19 16:43:38.872: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-19T16:43:38Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-19T16:43:38Z]] name:name1 resourceVersion:22820 uid:b6953198-dbf1-44ef-97bb-0495641ff2ee] num:map[num1:9223372036854775807 num2:1000000]]}
  E0419 16:43:39.017623      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:40.018852      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:41.020104      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:42.020135      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:43.020838      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:44.021551      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:45.021882      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:46.022546      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:47.022627      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:48.023586      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating second CR @ 04/19/24 16:43:48.873
  Apr 19 16:43:48.887: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-19T16:43:48Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-19T16:43:48Z]] name:name2 resourceVersion:22879 uid:59044454-6aa0-46ad-b8c7-8a85ebf8c393] num:map[num1:9223372036854775807 num2:1000000]]}
  E0419 16:43:49.024515      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:50.024926      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:51.025249      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:52.025660      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:53.026089      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:54.041210      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:55.031813      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:56.032286      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:57.032813      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:43:58.033868      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Modifying first CR @ 04/19/24 16:43:58.889
  Apr 19 16:43:58.909: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-19T16:43:38Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-19T16:43:58Z]] name:name1 resourceVersion:22898 uid:b6953198-dbf1-44ef-97bb-0495641ff2ee] num:map[num1:9223372036854775807 num2:1000000]]}
  E0419 16:43:59.034639      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:00.035016      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:01.035427      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:02.035613      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:03.035568      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:04.035934      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:05.036345      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:06.037103      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:07.037203      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:08.038186      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Modifying second CR @ 04/19/24 16:44:08.911
  Apr 19 16:44:08.931: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-19T16:43:48Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-19T16:44:08Z]] name:name2 resourceVersion:22916 uid:59044454-6aa0-46ad-b8c7-8a85ebf8c393] num:map[num1:9223372036854775807 num2:1000000]]}
  E0419 16:44:09.038802      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:10.039556      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:11.040441      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:12.041252      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:13.042264      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:14.053733      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:15.045895      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:16.046412      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:17.046949      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:18.048412      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting first CR @ 04/19/24 16:44:18.933
  Apr 19 16:44:18.958: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-19T16:43:38Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-19T16:43:58Z]] name:name1 resourceVersion:22933 uid:b6953198-dbf1-44ef-97bb-0495641ff2ee] num:map[num1:9223372036854775807 num2:1000000]]}
  E0419 16:44:19.048473      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:20.048952      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:21.049495      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:22.049364      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:23.049925      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:24.050589      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:25.051312      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:26.052219      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:27.052666      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:28.053586      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting second CR @ 04/19/24 16:44:28.959
  Apr 19 16:44:28.979: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-19T16:43:48Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-19T16:44:08Z]] name:name2 resourceVersion:22951 uid:59044454-6aa0-46ad-b8c7-8a85ebf8c393] num:map[num1:9223372036854775807 num2:1000000]]}
  E0419 16:44:29.054028      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:30.055290      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:31.055104      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:32.055956      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:33.056116      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:34.056617      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:35.057456      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:36.057875      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:37.058888      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:38.059581      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:39.060230      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:44:39.515: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-watch-4003" for this suite. @ 04/19/24 16:44:39.535
• [63.409 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:107
  STEP: Creating a kubernetes client @ 04/19/24 16:44:39.556
  Apr 19 16:44:39.557: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename container-probe @ 04/19/24 16:44:39.561
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:44:39.609
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:44:39.619
  E0419 16:44:40.060631      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:41.061120      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:42.061962      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:43.062226      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:44.063122      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:45.065139      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:46.064224      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:47.064287      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:48.065219      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:49.066347      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:50.067574      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:51.067996      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:52.068798      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:53.069649      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:54.070250      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:55.070870      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:56.071677      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:57.072559      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:58.072564      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:44:59.073656      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:00.074754      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:01.075798      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:02.076499      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:03.076879      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:04.077332      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:05.077908      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:06.079366      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:07.079809      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:08.082420      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:09.082208      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:10.082229      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:11.082848      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:12.083199      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:13.083819      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:14.085927      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:15.085848      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:16.086877      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:17.088058      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:18.088775      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:19.089395      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:20.089702      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:21.091016      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:22.091333      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:23.091718      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:24.092469      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:25.092524      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:26.093500      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:27.093647      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:28.093971      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:29.094483      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:30.094504      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:31.094877      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:32.095224      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:33.095977      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:34.096169      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:35.096410      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:36.096612      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:37.096828      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:38.096978      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:39.097991      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:45:39.672: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-8429" for this suite. @ 04/19/24 16:45:39.69
• [60.153 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:89
  STEP: Creating a kubernetes client @ 04/19/24 16:45:39.715
  Apr 19 16:45:39.715: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename secrets @ 04/19/24 16:45:39.721
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:45:39.773
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:45:39.78
  STEP: Creating secret with name secret-test-map-e535656c-ebda-4874-967f-806d81e58fbc @ 04/19/24 16:45:39.794
  STEP: Creating a pod to test consume secrets @ 04/19/24 16:45:39.809
  E0419 16:45:40.098114      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:41.099804      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:42.099967      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:43.100801      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:45:43.859
  Apr 19 16:45:43.868: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-secrets-ae8e0475-6b44-4e00-af57-775dbd51684a container secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/24 16:45:43.927
  Apr 19 16:45:43.970: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-731" for this suite. @ 04/19/24 16:45:43.982
• [4.286 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:139
  STEP: Creating a kubernetes client @ 04/19/24 16:45:44.002
  Apr 19 16:45:44.003: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename configmap @ 04/19/24 16:45:44.007
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:45:44.052
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:45:44.059
  STEP: Creating configMap that has name configmap-test-emptyKey-8cb0785a-f430-4586-952d-70b003cc0b1e @ 04/19/24 16:45:44.067
  Apr 19 16:45:44.074: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9706" for this suite. @ 04/19/24 16:45:44.093
  E0419 16:45:44.101907      13 retrywatcher.go:129] "Watch failed" err="context canceled"
• [0.104 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:100
  STEP: Creating a kubernetes client @ 04/19/24 16:45:44.108
  Apr 19 16:45:44.109: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename configmap @ 04/19/24 16:45:44.112
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:45:44.154
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:45:44.161
  STEP: Creating configMap with name configmap-test-volume-map-ea501ca4-cae4-4863-b6fe-0a01e3b018f1 @ 04/19/24 16:45:44.168
  STEP: Creating a pod to test consume configMaps @ 04/19/24 16:45:44.177
  E0419 16:45:45.102035      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:46.103028      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:47.103164      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:48.104458      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:45:48.233
  Apr 19 16:45:48.242: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-configmaps-5d238e92-82c8-4977-8d4a-13582a77f55b container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/24 16:45:48.26
  Apr 19 16:45:48.305: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8979" for this suite. @ 04/19/24 16:45:48.317
• [4.223 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:356
  STEP: Creating a kubernetes client @ 04/19/24 16:45:48.333
  Apr 19 16:45:48.333: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename endpointslice @ 04/19/24 16:45:48.336
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:45:48.375
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:45:48.381
  STEP: getting /apis @ 04/19/24 16:45:48.387
  STEP: getting /apis/discovery.k8s.io @ 04/19/24 16:45:48.395
  STEP: getting /apis/discovery.k8s.iov1 @ 04/19/24 16:45:48.397
  STEP: creating @ 04/19/24 16:45:48.399
  STEP: getting @ 04/19/24 16:45:48.427
  STEP: listing @ 04/19/24 16:45:48.439
  STEP: watching @ 04/19/24 16:45:48.447
  Apr 19 16:45:48.447: INFO: starting watch
  STEP: cluster-wide listing @ 04/19/24 16:45:48.45
  STEP: cluster-wide watching @ 04/19/24 16:45:48.457
  Apr 19 16:45:48.457: INFO: starting watch
  STEP: patching @ 04/19/24 16:45:48.458
  STEP: updating @ 04/19/24 16:45:48.471
  Apr 19 16:45:48.490: INFO: waiting for watch events with expected annotations
  Apr 19 16:45:48.491: INFO: saw patched and updated annotations
  STEP: deleting @ 04/19/24 16:45:48.491
  STEP: deleting a collection @ 04/19/24 16:45:48.519
  Apr 19 16:45:48.558: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-2351" for this suite. @ 04/19/24 16:45:48.566
• [0.243 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:372
  STEP: Creating a kubernetes client @ 04/19/24 16:45:48.59
  Apr 19 16:45:48.590: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename namespaces @ 04/19/24 16:45:48.593
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:45:48.631
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:45:48.636
  STEP: Updating Namespace "namespaces-432" @ 04/19/24 16:45:48.64
  Apr 19 16:45:48.655: INFO: Namespace "namespaces-432" now has labels, map[string]string{"e2e-framework":"namespaces", "e2e-run":"12150ae6-21c8-4ad4-878b-2f85707d31fb", "kubernetes.io/metadata.name":"namespaces-432", "namespaces-432":"updated", "pod-security.kubernetes.io/audit":"baseline", "pod-security.kubernetes.io/enforce":"baseline", "pod-security.kubernetes.io/warn":"baseline"}
  Apr 19 16:45:48.657: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-432" for this suite. @ 04/19/24 16:45:48.665
• [0.088 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should provide secure master service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:775
  STEP: Creating a kubernetes client @ 04/19/24 16:45:48.682
  Apr 19 16:45:48.682: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename services @ 04/19/24 16:45:48.686
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:45:48.722
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:45:48.729
  Apr 19 16:45:48.745: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-841" for this suite. @ 04/19/24 16:45:48.756
• [0.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:130
  STEP: Creating a kubernetes client @ 04/19/24 16:45:48.777
  Apr 19 16:45:48.778: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename sched-preemption @ 04/19/24 16:45:48.782
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:45:48.82
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:45:48.828
  Apr 19 16:45:48.874: INFO: Waiting up to 1m0s for all nodes to be ready
  E0419 16:45:49.105334      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:50.105722      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:51.105920      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:52.106169      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:53.107098      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:54.107224      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:55.108281      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:56.108608      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:57.109163      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:58.109520      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:45:59.110104      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:00.110973      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:01.111860      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:02.112175      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:03.112462      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:04.113563      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:05.114682      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:06.115579      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:07.116067      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:08.116768      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:09.116918      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:10.117189      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:11.117406      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:12.117713      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:13.117801      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:14.118355      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:15.118933      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:16.119298      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:17.119822      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:18.121063      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:19.121876      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:20.121957      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:21.122583      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:22.122934      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:23.123106      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:24.123417      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:25.124463      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:26.124831      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:27.124997      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:28.125846      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:29.126502      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:30.127353      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:31.128266      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:32.128506      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:33.128868      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:34.129524      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:35.130022      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:36.130198      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:37.131027      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:38.131521      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:39.132039      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:40.132548      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:41.132873      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:42.133995      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:43.134223      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:44.134440      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:45.135205      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:46.135704      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:47.136348      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:48.137160      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:46:48.889: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 04/19/24 16:46:48.898
  Apr 19 16:46:48.956: INFO: Created pod: pod0-0-sched-preemption-low-priority
  Apr 19 16:46:48.971: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  Apr 19 16:46:49.020: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  Apr 19 16:46:49.032: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  Apr 19 16:46:49.084: INFO: Created pod: pod2-0-sched-preemption-medium-priority
  Apr 19 16:46:49.098: INFO: Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 04/19/24 16:46:49.098
  E0419 16:46:49.137968      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:50.138777      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:51.138353      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Run a high priority pod that has same requirements as that of lower priority pod @ 04/19/24 16:46:51.151
  E0419 16:46:52.139260      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:53.140281      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:54.140701      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:55.140828      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:56.141454      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:57.142341      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:46:57.411: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-5684" for this suite. @ 04/19/24 16:46:57.423
• [68.663 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1455
  STEP: Creating a kubernetes client @ 04/19/24 16:46:57.447
  Apr 19 16:46:57.447: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename services @ 04/19/24 16:46:57.451
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:46:57.495
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:46:57.501
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-9429 @ 04/19/24 16:46:57.508
  STEP: changing the ExternalName service to type=NodePort @ 04/19/24 16:46:57.519
  STEP: creating replication controller externalname-service in namespace services-9429 @ 04/19/24 16:46:57.568
  I0419 16:46:57.606891      13 runners.go:197] Created replication controller with name: externalname-service, namespace: services-9429, replica count: 2
  E0419 16:46:58.144420      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:46:59.144216      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:00.144263      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:47:00.658133      13 runners.go:197] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 19 16:47:00.658: INFO: Creating new exec pod
  E0419 16:47:01.144564      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:02.145150      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:03.145397      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:47:03.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-9429 exec execpodh2wvr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Apr 19 16:47:04.090: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Apr 19 16:47:04.090: INFO: stdout: ""
  E0419 16:47:04.145799      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:47:04.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-9429 exec execpodh2wvr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Apr 19 16:47:05.014: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Apr 19 16:47:05.014: INFO: stdout: ""
  E0419 16:47:05.146539      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:47:05.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-9429 exec execpodh2wvr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Apr 19 16:47:06.096: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Apr 19 16:47:06.096: INFO: stdout: "externalname-service-2pdvs"
  Apr 19 16:47:06.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-9429 exec execpodh2wvr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.9.227 80'
  E0419 16:47:06.146964      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:47:06.390: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.9.227 80\nConnection to 10.233.9.227 80 port [tcp/http] succeeded!\n"
  Apr 19 16:47:06.390: INFO: stdout: "externalname-service-2pdvs"
  Apr 19 16:47:06.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-9429 exec execpodh2wvr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.60 30642'
  Apr 19 16:47:06.638: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.60 30642\nConnection to 192.168.121.60 30642 port [tcp/*] succeeded!\n"
  Apr 19 16:47:06.638: INFO: stdout: "externalname-service-vz2dk"
  Apr 19 16:47:06.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-9429 exec execpodh2wvr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.39 30642'
  Apr 19 16:47:06.958: INFO: stderr: "+ nc -v -t -w 2 192.168.121.39 30642\n+ echo hostName\nConnection to 192.168.121.39 30642 port [tcp/*] succeeded!\n"
  Apr 19 16:47:06.958: INFO: stdout: ""
  E0419 16:47:07.147834      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:47:07.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-9429 exec execpodh2wvr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.39 30642'
  Apr 19 16:47:07.997: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.39 30642\nConnection to 192.168.121.39 30642 port [tcp/*] succeeded!\n"
  Apr 19 16:47:07.997: INFO: stdout: "externalname-service-2pdvs"
  Apr 19 16:47:07.997: INFO: Cleaning up the ExternalName to NodePort test service
  Apr 19 16:47:08.040: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9429" for this suite. @ 04/19/24 16:47:08.053
• [10.623 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:210
  STEP: Creating a kubernetes client @ 04/19/24 16:47:08.07
  Apr 19 16:47:08.070: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename webhook @ 04/19/24 16:47:08.077
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:47:08.104
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:47:08.109
  E0419 16:47:08.148621      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Setting up server cert @ 04/19/24 16:47:08.149
  E0419 16:47:09.149244      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 16:47:09.858
  STEP: Deploying the webhook pod @ 04/19/24 16:47:09.877
  STEP: Wait for the deployment to be ready @ 04/19/24 16:47:09.906
  Apr 19 16:47:09.936: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0419 16:47:10.150381      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:11.151376      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 16:47:11.965
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 16:47:11.997
  E0419 16:47:12.152752      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:47:12.998: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 04/19/24 16:47:13.018
  STEP: create a pod @ 04/19/24 16:47:13.073
  E0419 16:47:13.152924      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:14.153345      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: 'kubectl attach' the pod, should be denied by the webhook @ 04/19/24 16:47:15.129
  Apr 19 16:47:15.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=webhook-8187 attach --namespace=webhook-8187 to-be-attached-pod -i -c=container1'
  E0419 16:47:15.154230      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:47:15.384: INFO: rc: 1
  Apr 19 16:47:15.531: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8187" for this suite. @ 04/19/24 16:47:15.541
  STEP: Destroying namespace "webhook-markers-3049" for this suite. @ 04/19/24 16:47:15.562
• [7.508 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:119
  STEP: Creating a kubernetes client @ 04/19/24 16:47:15.579
  Apr 19 16:47:15.579: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename projected @ 04/19/24 16:47:15.583
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:47:15.617
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:47:15.622
  STEP: Creating secret with name projected-secret-test-78e67fe9-052b-4cf4-bc52-7ffbf9fdb2b9 @ 04/19/24 16:47:15.635
  STEP: Creating a pod to test consume secrets @ 04/19/24 16:47:15.652
  E0419 16:47:16.155234      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:17.156478      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:18.156471      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:19.156786      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:47:19.702
  Apr 19 16:47:19.712: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-projected-secrets-5e4569d7-bb3d-4352-834a-0b0bec0f05a3 container secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/24 16:47:19.747
  Apr 19 16:47:19.776: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1504" for this suite. @ 04/19/24 16:47:19.804
• [4.243 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:189
  STEP: Creating a kubernetes client @ 04/19/24 16:47:19.836
  Apr 19 16:47:19.836: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename var-expansion @ 04/19/24 16:47:19.84
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:47:19.873
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:47:19.878
  E0419 16:47:20.157330      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:21.157668      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:47:21.922: INFO: Deleting pod "var-expansion-ce10600f-242f-4c4d-8c1c-6739cede0134" in namespace "var-expansion-3414"
  Apr 19 16:47:21.953: INFO: Wait up to 5m0s for pod "var-expansion-ce10600f-242f-4c4d-8c1c-6739cede0134" to be fully deleted
  E0419 16:47:22.157970      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:23.158564      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:47:23.976: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-3414" for this suite. @ 04/19/24 16:47:23.989
• [4.180 seconds]
------------------------------
SS
------------------------------
[sig-instrumentation] Events should manage the lifecycle of an event [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/core_events.go:58
  STEP: Creating a kubernetes client @ 04/19/24 16:47:24.015
  Apr 19 16:47:24.016: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename events @ 04/19/24 16:47:24.021
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:47:24.066
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:47:24.075
  STEP: creating a test event @ 04/19/24 16:47:24.085
  STEP: listing all events in all namespaces @ 04/19/24 16:47:24.097
  STEP: patching the test event @ 04/19/24 16:47:24.108
  STEP: fetching the test event @ 04/19/24 16:47:24.124
  STEP: updating the test event @ 04/19/24 16:47:24.13
  E0419 16:47:24.158259      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: getting the test event @ 04/19/24 16:47:24.161
  STEP: deleting the test event @ 04/19/24 16:47:24.172
  STEP: listing all events in all namespaces @ 04/19/24 16:47:24.193
  Apr 19 16:47:24.203: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-6389" for this suite. @ 04/19/24 16:47:24.215
• [0.217 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:75
  STEP: Creating a kubernetes client @ 04/19/24 16:47:24.234
  Apr 19 16:47:24.234: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename projected @ 04/19/24 16:47:24.237
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:47:24.278
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:47:24.284
  STEP: Creating configMap with name projected-configmap-test-volume-14f2afcd-b750-4f12-9692-4bf6d3d1416c @ 04/19/24 16:47:24.293
  STEP: Creating a pod to test consume configMaps @ 04/19/24 16:47:24.307
  E0419 16:47:25.158637      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:26.158921      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:27.160542      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:28.160935      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:47:28.358
  Apr 19 16:47:28.369: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-projected-configmaps-cea5db1b-1d3e-43ce-ae3e-1aae5e27d0e5 container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/24 16:47:28.387
  Apr 19 16:47:28.422: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5430" for this suite. @ 04/19/24 16:47:28.436
• [4.218 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:136
  STEP: Creating a kubernetes client @ 04/19/24 16:47:28.471
  Apr 19 16:47:28.471: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 04/19/24 16:47:28.477
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:47:28.522
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:47:28.529
  STEP: create the container to handle the HTTPGet hook request. @ 04/19/24 16:47:28.549
  E0419 16:47:29.161770      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:30.162218      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 04/19/24 16:47:30.595
  E0419 16:47:31.163250      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:32.163588      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 04/19/24 16:47:32.651
  STEP: delete the pod with lifecycle hook @ 04/19/24 16:47:32.673
  E0419 16:47:33.165006      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:34.165046      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:47:34.713: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-9406" for this suite. @ 04/19/24 16:47:34.727
• [6.276 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS should support configurable pod DNS nameservers [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:407
  STEP: Creating a kubernetes client @ 04/19/24 16:47:34.749
  Apr 19 16:47:34.749: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename dns @ 04/19/24 16:47:34.755
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:47:34.796
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:47:34.805
  STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... @ 04/19/24 16:47:34.814
  Apr 19 16:47:34.839: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-7227  0a02cc7b-2a4a-45e9-b172-575f23416c26 23838 0 2024-04-19 16:47:34 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2024-04-19 16:47:34 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hssb7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,ClusterTrustBundle:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.47,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hssb7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,ResourceClaimStatuses:[]PodResourceClaimStatus{},HostIPs:[]HostIP{},},}
  E0419 16:47:35.166467      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:36.166898      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying customized DNS suffix list is configured on pod... @ 04/19/24 16:47:36.859
  Apr 19 16:47:36.859: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-7227 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 16:47:36.860: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 16:47:36.862: INFO: ExecWithOptions: Clientset creation
  Apr 19 16:47:36.862: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/dns-7227/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  STEP: Verifying customized DNS server is configured on pod... @ 04/19/24 16:47:37.02
  Apr 19 16:47:37.020: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-7227 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 16:47:37.020: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 16:47:37.022: INFO: ExecWithOptions: Clientset creation
  Apr 19 16:47:37.023: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/dns-7227/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Apr 19 16:47:37.146: INFO: Deleting pod test-dns-nameservers...
  E0419 16:47:37.167153      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:47:37.167: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-7227" for this suite. @ 04/19/24 16:47:37.176
• [2.437 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
  STEP: Creating a kubernetes client @ 04/19/24 16:47:37.19
  Apr 19 16:47:37.190: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename kubectl @ 04/19/24 16:47:37.195
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:47:37.231
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:47:37.235
  Apr 19 16:47:37.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-2082 create -f -'
  Apr 19 16:47:37.635: INFO: stderr: ""
  Apr 19 16:47:37.635: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  Apr 19 16:47:37.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-2082 create -f -'
  Apr 19 16:47:38.010: INFO: stderr: ""
  Apr 19 16:47:38.010: INFO: stdout: "service/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 04/19/24 16:47:38.01
  E0419 16:47:38.167823      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:47:39.021: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 19 16:47:39.021: INFO: Found 1 / 1
  Apr 19 16:47:39.021: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  Apr 19 16:47:39.037: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 19 16:47:39.038: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Apr 19 16:47:39.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-2082 describe pod agnhost-primary-5jfwf'
  E0419 16:47:39.168649      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:47:39.255: INFO: stderr: ""
  Apr 19 16:47:39.255: INFO: stdout: "Name:             agnhost-primary-5jfwf\nNamespace:        kubectl-2082\nPriority:         0\nService Account:  default\nNode:             co4fe9zoo9oc-3/192.168.121.60\nStart Time:       Fri, 19 Apr 2024 16:47:37 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               10.233.66.58\nIPs:\n  IP:           10.233.66.58\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   cri-o://a6bdcdad81f2ece2053a27a482f1b3c92b677952b7aebcda1988d111c564d91c\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.47\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:c9997bf8d2e223d7d2a0078dcfb11a653e9b16cf09418829ec03e1d57ca9628a\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 19 Apr 2024 16:47:38 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-69m6h (ro)\nConditions:\n  Type                        Status\n  PodReadyToStartContainers   True \n  Initialized                 True \n  Ready                       True \n  ContainersReady             True \n  PodScheduled                True \nVolumes:\n  kube-api-access-69m6h:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  1s    default-scheduler  Successfully assigned kubectl-2082/agnhost-primary-5jfwf to co4fe9zoo9oc-3\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.47\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
  Apr 19 16:47:39.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-2082 describe rc agnhost-primary'
  Apr 19 16:47:39.460: INFO: stderr: ""
  Apr 19 16:47:39.460: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-2082\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.47\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-5jfwf\n"
  Apr 19 16:47:39.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-2082 describe service agnhost-primary'
  Apr 19 16:47:39.638: INFO: stderr: ""
  Apr 19 16:47:39.638: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-2082\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.233.55.17\nIPs:               10.233.55.17\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.233.66.58:6379\nSession Affinity:  None\nEvents:            <none>\n"
  Apr 19 16:47:39.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-2082 describe node co4fe9zoo9oc-1'
  Apr 19 16:47:39.910: INFO: stderr: ""
  Apr 19 16:47:39.910: INFO: stdout: "Name:               co4fe9zoo9oc-1\nRoles:              control-plane\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=co4fe9zoo9oc-1\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/control-plane=\n                    node.kubernetes.io/exclude-from-external-load-balancers=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VNI\":1,\"VtepMAC\":\"82:db:93:3b:ec:75\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 192.168.121.127\n                    kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/crio/crio.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 19 Apr 2024 15:27:13 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  co4fe9zoo9oc-1\n  AcquireTime:     <unset>\n  RenewTime:       Fri, 19 Apr 2024 16:47:35 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Fri, 19 Apr 2024 15:41:24 +0000   Fri, 19 Apr 2024 15:41:24 +0000   FlannelIsUp                  Flannel is running on this node\n  MemoryPressure       False   Fri, 19 Apr 2024 16:43:40 +0000   Fri, 19 Apr 2024 15:27:05 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Fri, 19 Apr 2024 16:43:40 +0000   Fri, 19 Apr 2024 15:27:05 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Fri, 19 Apr 2024 16:43:40 +0000   Fri, 19 Apr 2024 15:27:05 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Fri, 19 Apr 2024 16:43:40 +0000   Fri, 19 Apr 2024 15:34:34 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  192.168.121.127\n  Hostname:    co4fe9zoo9oc-1\nCapacity:\n  cpu:                    2\n  ephemeral-storage:      115008636Ki\n  hugepages-1Gi:          0\n  hugepages-2Mi:          0\n  memory:                 8123560Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  5\nAllocatable:\n  cpu:                    1600m\n  ephemeral-storage:      111880401014\n  hugepages-1Gi:          0\n  hugepages-2Mi:          0\n  memory:                 3273896Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  5\nSystem Info:\n  Machine ID:                 082f59c174364db18893b5656ce3d4b9\n  System UUID:                082f59c1-7436-4db1-8893-b5656ce3d4b9\n  Boot ID:                    777b6dfc-914b-478d-abde-c882c3dfce68\n  Kernel Version:             6.5.0-28-generic\n  OS Image:                   Ubuntu 22.04.4 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  cri-o://1.29.2\n  Kubelet Version:            v1.29.4\n  Kube-Proxy Version:         v1.29.4\nPodCIDR:                      10.233.64.0/24\nPodCIDRs:                     10.233.64.0/24\nNon-terminated Pods:          (9 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 coredns-76f75df574-dnglm                                   100m (6%)     0 (0%)      70Mi (2%)        170Mi (5%)     80m\n  kube-system                 coredns-76f75df574-n4wlj                                   100m (6%)     0 (0%)      70Mi (2%)        170Mi (5%)     80m\n  kube-system                 kube-addon-manager-co4fe9zoo9oc-1                          5m (0%)       0 (0%)      50Mi (1%)        0 (0%)         73m\n  kube-system                 kube-apiserver-co4fe9zoo9oc-1                              250m (15%)    0 (0%)      0 (0%)           0 (0%)         80m\n  kube-system                 kube-controller-manager-co4fe9zoo9oc-1                     200m (12%)    0 (0%)      0 (0%)           0 (0%)         80m\n  kube-system                 kube-flannel-ds-9gpfv                                      100m (6%)     0 (0%)      50Mi (1%)        0 (0%)         73m\n  kube-system                 kube-proxy-zzhn9                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         80m\n  kube-system                 kube-scheduler-co4fe9zoo9oc-1                              100m (6%)     0 (0%)      0 (0%)           0 (0%)         80m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-f3d7cdfd30314b67-kskjf    0 (0%)        0 (0%)      0 (0%)           0 (0%)         66m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource               Requests    Limits\n  --------               --------    ------\n  cpu                    855m (53%)  0 (0%)\n  memory                 240Mi (7%)  340Mi (10%)\n  ephemeral-storage      0 (0%)      0 (0%)\n  hugepages-1Gi          0 (0%)      0 (0%)\n  hugepages-2Mi          0 (0%)      0 (0%)\n  scheduling.k8s.io/foo  0           0\nEvents:                  <none>\n"
  Apr 19 16:47:39.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-2082 describe namespace kubectl-2082'
  Apr 19 16:47:40.167: INFO: stderr: ""
  Apr 19 16:47:40.167: INFO: stdout: "Name:         kubectl-2082\nLabels:       e2e-framework=kubectl\n              e2e-run=12150ae6-21c8-4ad4-878b-2f85707d31fb\n              kubernetes.io/metadata.name=kubectl-2082\n              pod-security.kubernetes.io/audit=baseline\n              pod-security.kubernetes.io/enforce=baseline\n              pod-security.kubernetes.io/warn=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
  Apr 19 16:47:40.168: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0419 16:47:40.168684      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "kubectl-2082" for this suite. @ 04/19/24 16:47:40.178
• [3.000 seconds]
------------------------------
SS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:335
  STEP: Creating a kubernetes client @ 04/19/24 16:47:40.191
  Apr 19 16:47:40.191: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename init-container @ 04/19/24 16:47:40.202
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:47:40.237
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:47:40.241
  STEP: creating the pod @ 04/19/24 16:47:40.246
  Apr 19 16:47:40.246: INFO: PodSpec: initContainers in spec.initContainers
  E0419 16:47:41.170246      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:42.170358      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:43.170920      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:44.171519      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:45.171843      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:46.172367      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:47.172561      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:48.173132      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:49.173134      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:50.173312      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:51.174346      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:52.174478      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:53.174472      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:54.177495      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:55.175558      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:56.175847      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:57.177405      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:58.177037      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:47:59.177193      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:00.177517      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:01.177816      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:02.178004      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:03.178378      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:04.178915      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:05.179086      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:06.179784      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:07.180494      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:08.180807      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:09.181752      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:10.181862      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:11.183181      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:12.183506      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:13.183721      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:14.184800      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:15.185280      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:16.185820      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:17.186212      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:18.186610      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:19.186995      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:20.187373      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:48:20.251: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-80729be5-68e7-4c51-b3bb-244895395f7d", GenerateName:"", Namespace:"init-container-4399", SelfLink:"", UID:"e35801be-df94-4575-b2e1-62693ff9df3e", ResourceVersion:"24024", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 47, 40, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"246586086"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 47, 40, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc006ab1500), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 48, 20, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc006ab1530), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-xv6qc", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc000e72980), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-xv6qc", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-xv6qc", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.9", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-xv6qc", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002f67600), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"co4fe9zoo9oc-3", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00061a230), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002f67690)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002f676b0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002f676b8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002f676bc), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc0070ec760), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil), SchedulingGates:[]v1.PodSchedulingGate(nil), ResourceClaims:[]v1.PodResourceClaim(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"PodReadyToStartContainers", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.April, 19, 16, 47, 41, 0, time.Local), Reason:"", Message:""}, v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.April, 19, 16, 47, 40, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.April, 19, 16, 47, 40, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.April, 19, 16, 47, 40, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.April, 19, 16, 47, 40, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.121.60", HostIPs:[]v1.HostIP{v1.HostIP{IP:"192.168.121.60"}}, PodIP:"10.233.66.59", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.233.66.59"}}, StartTime:time.Date(2024, time.April, 19, 16, 47, 40, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00061a3f0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00061a460)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9", ContainerID:"cri-o://60761d0a13dcb96ce373d032198417aad5f6eaa1bbab0ea1b2110754e4ed88e3", Started:(*bool)(0xc002f6777a), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000e72a00), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"", ContainerID:"", Started:(*bool)(0xc002f6778f), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000e729e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.9", ImageID:"", ContainerID:"", Started:(*bool)(0xc002f6775f), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil), Resize:"", ResourceClaimStatuses:[]v1.PodResourceClaimStatus(nil)}}
  Apr 19 16:48:20.257: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-4399" for this suite. @ 04/19/24 16:48:20.276
• [40.100 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Service endpoints latency should not be very high [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service_latency.go:59
  STEP: Creating a kubernetes client @ 04/19/24 16:48:20.292
  Apr 19 16:48:20.292: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename svc-latency @ 04/19/24 16:48:20.297
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:48:20.336
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:48:20.342
  Apr 19 16:48:20.348: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: creating replication controller svc-latency-rc in namespace svc-latency-9781 @ 04/19/24 16:48:20.351
  I0419 16:48:20.363979      13 runners.go:197] Created replication controller with name: svc-latency-rc, namespace: svc-latency-9781, replica count: 1
  E0419 16:48:21.187914      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 16:48:21.416475      13 runners.go:197] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 19 16:48:21.547: INFO: Created: latency-svc-zf9j6
  Apr 19 16:48:21.568: INFO: Got endpoints: latency-svc-zf9j6 [49.857931ms]
  Apr 19 16:48:21.596: INFO: Created: latency-svc-6v5rv
  Apr 19 16:48:21.633: INFO: Got endpoints: latency-svc-6v5rv [63.340465ms]
  Apr 19 16:48:21.660: INFO: Created: latency-svc-sp848
  Apr 19 16:48:21.672: INFO: Got endpoints: latency-svc-sp848 [102.565608ms]
  Apr 19 16:48:21.684: INFO: Created: latency-svc-dlr45
  Apr 19 16:48:21.689: INFO: Got endpoints: latency-svc-dlr45 [119.006134ms]
  Apr 19 16:48:21.697: INFO: Created: latency-svc-tjqr4
  Apr 19 16:48:21.706: INFO: Got endpoints: latency-svc-tjqr4 [135.849637ms]
  Apr 19 16:48:21.710: INFO: Created: latency-svc-6t7gp
  Apr 19 16:48:21.719: INFO: Got endpoints: latency-svc-6t7gp [147.773797ms]
  Apr 19 16:48:21.729: INFO: Created: latency-svc-qhq6l
  Apr 19 16:48:21.739: INFO: Got endpoints: latency-svc-qhq6l [167.823719ms]
  Apr 19 16:48:21.741: INFO: Created: latency-svc-c696f
  Apr 19 16:48:21.754: INFO: Created: latency-svc-nzbm7
  Apr 19 16:48:21.763: INFO: Got endpoints: latency-svc-c696f [191.086615ms]
  Apr 19 16:48:21.767: INFO: Got endpoints: latency-svc-nzbm7 [194.190082ms]
  Apr 19 16:48:21.775: INFO: Created: latency-svc-jx976
  Apr 19 16:48:21.785: INFO: Created: latency-svc-9kl5t
  Apr 19 16:48:21.786: INFO: Got endpoints: latency-svc-jx976 [214.768786ms]
  Apr 19 16:48:21.795: INFO: Got endpoints: latency-svc-9kl5t [221.853241ms]
  Apr 19 16:48:21.801: INFO: Created: latency-svc-f86bg
  Apr 19 16:48:21.807: INFO: Got endpoints: latency-svc-f86bg [234.763632ms]
  Apr 19 16:48:21.816: INFO: Created: latency-svc-g57qp
  Apr 19 16:48:21.823: INFO: Created: latency-svc-wvgnz
  Apr 19 16:48:21.826: INFO: Got endpoints: latency-svc-g57qp [252.898104ms]
  Apr 19 16:48:21.833: INFO: Got endpoints: latency-svc-wvgnz [263.306578ms]
  Apr 19 16:48:21.838: INFO: Created: latency-svc-9g54x
  Apr 19 16:48:21.846: INFO: Got endpoints: latency-svc-9g54x [271.333447ms]
  Apr 19 16:48:21.846: INFO: Created: latency-svc-2lwkw
  Apr 19 16:48:21.861: INFO: Got endpoints: latency-svc-2lwkw [286.943776ms]
  Apr 19 16:48:21.964: INFO: Created: latency-svc-zhpbt
  Apr 19 16:48:21.972: INFO: Created: latency-svc-7q8j9
  Apr 19 16:48:21.976: INFO: Created: latency-svc-n7kws
  Apr 19 16:48:21.980: INFO: Created: latency-svc-hvrkn
  Apr 19 16:48:21.984: INFO: Created: latency-svc-8vfmq
  Apr 19 16:48:21.985: INFO: Created: latency-svc-tzxlp
  Apr 19 16:48:21.986: INFO: Created: latency-svc-94pj9
  Apr 19 16:48:21.986: INFO: Created: latency-svc-v26gr
  Apr 19 16:48:21.987: INFO: Created: latency-svc-vm5bt
  Apr 19 16:48:21.987: INFO: Created: latency-svc-765xf
  Apr 19 16:48:21.987: INFO: Created: latency-svc-r6pfk
  Apr 19 16:48:21.987: INFO: Created: latency-svc-sqxjx
  Apr 19 16:48:21.985: INFO: Created: latency-svc-dgp6k
  Apr 19 16:48:21.988: INFO: Created: latency-svc-zggvv
  Apr 19 16:48:22.002: INFO: Created: latency-svc-4llz9
  Apr 19 16:48:22.006: INFO: Got endpoints: latency-svc-zhpbt [243.005572ms]
  Apr 19 16:48:22.007: INFO: Got endpoints: latency-svc-vm5bt [199.132825ms]
  Apr 19 16:48:22.007: INFO: Got endpoints: latency-svc-94pj9 [237.995554ms]
  Apr 19 16:48:22.017: INFO: Got endpoints: latency-svc-zggvv [230.52504ms]
  Apr 19 16:48:22.017: INFO: Got endpoints: latency-svc-dgp6k [327.118145ms]
  Apr 19 16:48:22.025: INFO: Got endpoints: latency-svc-sqxjx [318.06967ms]
  Apr 19 16:48:22.037: INFO: Created: latency-svc-9f96k
  Apr 19 16:48:22.043: INFO: Got endpoints: latency-svc-r6pfk [303.286586ms]
  Apr 19 16:48:22.044: INFO: Got endpoints: latency-svc-765xf [410.937279ms]
  Apr 19 16:48:22.045: INFO: Got endpoints: latency-svc-v26gr [372.377761ms]
  Apr 19 16:48:22.046: INFO: Got endpoints: latency-svc-8vfmq [184.746093ms]
  Apr 19 16:48:22.052: INFO: Got endpoints: latency-svc-tzxlp [219.295163ms]
  Apr 19 16:48:22.069: INFO: Created: latency-svc-29fbj
  Apr 19 16:48:22.083: INFO: Got endpoints: latency-svc-n7kws [287.658307ms]
  Apr 19 16:48:22.084: INFO: Created: latency-svc-w6p8s
  Apr 19 16:48:22.085: INFO: Got endpoints: latency-svc-7q8j9 [365.789426ms]
  Apr 19 16:48:22.093: INFO: Created: latency-svc-pshlm
  Apr 19 16:48:22.100: INFO: Got endpoints: latency-svc-hvrkn [253.909782ms]
  Apr 19 16:48:22.100: INFO: Got endpoints: latency-svc-4llz9 [273.481887ms]
  Apr 19 16:48:22.102: INFO: Got endpoints: latency-svc-9f96k [94.713133ms]
  Apr 19 16:48:22.107: INFO: Created: latency-svc-hv4nx
  Apr 19 16:48:22.131: INFO: Got endpoints: latency-svc-pshlm [114.275634ms]
  Apr 19 16:48:22.133: INFO: Got endpoints: latency-svc-w6p8s [126.874173ms]
  Apr 19 16:48:22.141: INFO: Got endpoints: latency-svc-29fbj [133.751869ms]
  Apr 19 16:48:22.149: INFO: Got endpoints: latency-svc-hv4nx [131.592534ms]
  Apr 19 16:48:22.156: INFO: Created: latency-svc-grrxk
  Apr 19 16:48:22.178: INFO: Got endpoints: latency-svc-grrxk [153.488838ms]
  Apr 19 16:48:22.184: INFO: Created: latency-svc-x68zn
  E0419 16:48:22.188879      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:48:22.190: INFO: Got endpoints: latency-svc-x68zn [146.716216ms]
  Apr 19 16:48:22.204: INFO: Created: latency-svc-vnhs8
  Apr 19 16:48:22.210: INFO: Got endpoints: latency-svc-vnhs8 [165.149271ms]
  Apr 19 16:48:22.223: INFO: Created: latency-svc-lp5h9
  Apr 19 16:48:22.226: INFO: Got endpoints: latency-svc-lp5h9 [183.224688ms]
  Apr 19 16:48:22.232: INFO: Created: latency-svc-6fmmd
  Apr 19 16:48:22.239: INFO: Got endpoints: latency-svc-6fmmd [186.633037ms]
  Apr 19 16:48:22.248: INFO: Created: latency-svc-ttcdd
  Apr 19 16:48:22.259: INFO: Created: latency-svc-mjpx7
  Apr 19 16:48:22.259: INFO: Got endpoints: latency-svc-ttcdd [212.898128ms]
  Apr 19 16:48:22.270: INFO: Got endpoints: latency-svc-mjpx7 [187.576814ms]
  Apr 19 16:48:22.276: INFO: Created: latency-svc-njbrs
  Apr 19 16:48:22.286: INFO: Got endpoints: latency-svc-njbrs [201.228831ms]
  Apr 19 16:48:22.291: INFO: Created: latency-svc-5fwdg
  Apr 19 16:48:22.297: INFO: Created: latency-svc-pdkw8
  Apr 19 16:48:22.306: INFO: Created: latency-svc-22pps
  Apr 19 16:48:22.318: INFO: Created: latency-svc-tn5z7
  Apr 19 16:48:22.321: INFO: Got endpoints: latency-svc-5fwdg [221.712993ms]
  Apr 19 16:48:22.334: INFO: Created: latency-svc-6tj7d
  Apr 19 16:48:22.337: INFO: Created: latency-svc-8ttmw
  Apr 19 16:48:22.348: INFO: Created: latency-svc-9qzvz
  Apr 19 16:48:22.355: INFO: Created: latency-svc-khshk
  Apr 19 16:48:22.368: INFO: Got endpoints: latency-svc-pdkw8 [266.755151ms]
  Apr 19 16:48:22.377: INFO: Created: latency-svc-dmwhf
  Apr 19 16:48:22.382: INFO: Created: latency-svc-cp247
  Apr 19 16:48:22.393: INFO: Created: latency-svc-rlgxm
  Apr 19 16:48:22.403: INFO: Created: latency-svc-gslpp
  Apr 19 16:48:22.421: INFO: Created: latency-svc-5f6ss
  Apr 19 16:48:22.422: INFO: Got endpoints: latency-svc-22pps [322.163764ms]
  Apr 19 16:48:22.432: INFO: Created: latency-svc-8l579
  Apr 19 16:48:22.446: INFO: Created: latency-svc-nnlg4
  Apr 19 16:48:22.450: INFO: Created: latency-svc-rdlf9
  Apr 19 16:48:22.463: INFO: Created: latency-svc-mpqf6
  Apr 19 16:48:22.468: INFO: Got endpoints: latency-svc-tn5z7 [336.293001ms]
  Apr 19 16:48:22.478: INFO: Created: latency-svc-l2z87
  Apr 19 16:48:22.494: INFO: Created: latency-svc-672f2
  Apr 19 16:48:22.524: INFO: Got endpoints: latency-svc-6tj7d [389.997953ms]
  Apr 19 16:48:22.561: INFO: Created: latency-svc-6gbg8
  Apr 19 16:48:22.574: INFO: Got endpoints: latency-svc-8ttmw [433.477226ms]
  Apr 19 16:48:22.594: INFO: Created: latency-svc-d2ld8
  Apr 19 16:48:22.618: INFO: Got endpoints: latency-svc-9qzvz [469.479605ms]
  Apr 19 16:48:22.635: INFO: Created: latency-svc-pwt9j
  Apr 19 16:48:22.667: INFO: Got endpoints: latency-svc-khshk [488.368388ms]
  Apr 19 16:48:22.685: INFO: Created: latency-svc-d6nt9
  Apr 19 16:48:22.718: INFO: Got endpoints: latency-svc-dmwhf [527.796877ms]
  Apr 19 16:48:22.738: INFO: Created: latency-svc-lj6k5
  Apr 19 16:48:22.766: INFO: Got endpoints: latency-svc-cp247 [555.715343ms]
  Apr 19 16:48:22.793: INFO: Created: latency-svc-n2nr5
  Apr 19 16:48:22.819: INFO: Got endpoints: latency-svc-rlgxm [592.536976ms]
  Apr 19 16:48:22.842: INFO: Created: latency-svc-rwpbn
  Apr 19 16:48:22.869: INFO: Got endpoints: latency-svc-gslpp [629.596154ms]
  Apr 19 16:48:22.887: INFO: Created: latency-svc-pvzp6
  Apr 19 16:48:22.918: INFO: Got endpoints: latency-svc-5f6ss [658.973062ms]
  Apr 19 16:48:22.940: INFO: Created: latency-svc-8pqfk
  Apr 19 16:48:22.970: INFO: Got endpoints: latency-svc-8l579 [699.01745ms]
  Apr 19 16:48:22.990: INFO: Created: latency-svc-lll2k
  Apr 19 16:48:23.017: INFO: Got endpoints: latency-svc-nnlg4 [730.56417ms]
  Apr 19 16:48:23.031: INFO: Created: latency-svc-g8p7d
  Apr 19 16:48:23.067: INFO: Got endpoints: latency-svc-rdlf9 [744.91437ms]
  Apr 19 16:48:23.083: INFO: Created: latency-svc-q2jvk
  Apr 19 16:48:23.117: INFO: Got endpoints: latency-svc-mpqf6 [748.417727ms]
  Apr 19 16:48:23.134: INFO: Created: latency-svc-8cnn8
  Apr 19 16:48:23.166: INFO: Got endpoints: latency-svc-l2z87 [743.263109ms]
  Apr 19 16:48:23.185: INFO: Created: latency-svc-k4lfk
  E0419 16:48:23.190206      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:48:23.217: INFO: Got endpoints: latency-svc-672f2 [749.204008ms]
  Apr 19 16:48:23.251: INFO: Created: latency-svc-dhcs8
  Apr 19 16:48:23.271: INFO: Got endpoints: latency-svc-6gbg8 [746.824883ms]
  Apr 19 16:48:23.296: INFO: Created: latency-svc-jfd8f
  Apr 19 16:48:23.318: INFO: Got endpoints: latency-svc-d2ld8 [742.754097ms]
  Apr 19 16:48:23.332: INFO: Created: latency-svc-c9pk7
  Apr 19 16:48:23.376: INFO: Got endpoints: latency-svc-pwt9j [757.054692ms]
  Apr 19 16:48:23.400: INFO: Created: latency-svc-wv898
  Apr 19 16:48:23.418: INFO: Got endpoints: latency-svc-d6nt9 [750.868283ms]
  Apr 19 16:48:23.437: INFO: Created: latency-svc-w5st7
  Apr 19 16:48:23.465: INFO: Got endpoints: latency-svc-lj6k5 [745.910694ms]
  Apr 19 16:48:23.483: INFO: Created: latency-svc-knql5
  Apr 19 16:48:23.518: INFO: Got endpoints: latency-svc-n2nr5 [749.860091ms]
  Apr 19 16:48:23.548: INFO: Created: latency-svc-5qn2q
  Apr 19 16:48:23.571: INFO: Got endpoints: latency-svc-rwpbn [751.795737ms]
  Apr 19 16:48:23.585: INFO: Created: latency-svc-n7vxc
  Apr 19 16:48:23.620: INFO: Got endpoints: latency-svc-pvzp6 [750.549185ms]
  Apr 19 16:48:23.639: INFO: Created: latency-svc-tfjxj
  Apr 19 16:48:23.668: INFO: Got endpoints: latency-svc-8pqfk [749.225744ms]
  Apr 19 16:48:23.688: INFO: Created: latency-svc-nktvz
  Apr 19 16:48:23.719: INFO: Got endpoints: latency-svc-lll2k [748.477784ms]
  Apr 19 16:48:23.736: INFO: Created: latency-svc-qppmj
  Apr 19 16:48:23.769: INFO: Got endpoints: latency-svc-g8p7d [751.16685ms]
  Apr 19 16:48:23.784: INFO: Created: latency-svc-mnwjh
  Apr 19 16:48:23.824: INFO: Got endpoints: latency-svc-q2jvk [757.31234ms]
  Apr 19 16:48:23.844: INFO: Created: latency-svc-drpnv
  Apr 19 16:48:23.868: INFO: Got endpoints: latency-svc-8cnn8 [750.659968ms]
  Apr 19 16:48:23.885: INFO: Created: latency-svc-fff7x
  Apr 19 16:48:23.917: INFO: Got endpoints: latency-svc-k4lfk [750.029085ms]
  Apr 19 16:48:23.935: INFO: Created: latency-svc-xq6xl
  Apr 19 16:48:23.965: INFO: Got endpoints: latency-svc-dhcs8 [747.015795ms]
  Apr 19 16:48:23.982: INFO: Created: latency-svc-rgsz4
  Apr 19 16:48:24.019: INFO: Got endpoints: latency-svc-jfd8f [748.122061ms]
  Apr 19 16:48:24.039: INFO: Created: latency-svc-4jnmf
  Apr 19 16:48:24.074: INFO: Got endpoints: latency-svc-c9pk7 [756.243781ms]
  Apr 19 16:48:24.099: INFO: Created: latency-svc-dl4gx
  Apr 19 16:48:24.118: INFO: Got endpoints: latency-svc-wv898 [740.989906ms]
  Apr 19 16:48:24.141: INFO: Created: latency-svc-vtwrr
  Apr 19 16:48:24.166: INFO: Got endpoints: latency-svc-w5st7 [746.958921ms]
  Apr 19 16:48:24.186: INFO: Created: latency-svc-8m6nn
  E0419 16:48:24.190825      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:48:24.219: INFO: Got endpoints: latency-svc-knql5 [752.633596ms]
  Apr 19 16:48:24.242: INFO: Created: latency-svc-h8wzj
  Apr 19 16:48:24.267: INFO: Got endpoints: latency-svc-5qn2q [747.317907ms]
  Apr 19 16:48:24.285: INFO: Created: latency-svc-jjsvl
  Apr 19 16:48:24.319: INFO: Got endpoints: latency-svc-n7vxc [747.549117ms]
  Apr 19 16:48:24.341: INFO: Created: latency-svc-58vfk
  Apr 19 16:48:24.370: INFO: Got endpoints: latency-svc-tfjxj [749.615083ms]
  Apr 19 16:48:24.391: INFO: Created: latency-svc-k9772
  Apr 19 16:48:24.418: INFO: Got endpoints: latency-svc-nktvz [749.408704ms]
  Apr 19 16:48:24.441: INFO: Created: latency-svc-rm9n4
  Apr 19 16:48:24.473: INFO: Got endpoints: latency-svc-qppmj [753.96402ms]
  Apr 19 16:48:24.499: INFO: Created: latency-svc-pb8dg
  Apr 19 16:48:24.523: INFO: Got endpoints: latency-svc-mnwjh [754.194388ms]
  Apr 19 16:48:24.546: INFO: Created: latency-svc-wjbwm
  Apr 19 16:48:24.569: INFO: Got endpoints: latency-svc-drpnv [741.109398ms]
  Apr 19 16:48:24.594: INFO: Created: latency-svc-5v9gt
  Apr 19 16:48:24.618: INFO: Got endpoints: latency-svc-fff7x [749.743767ms]
  Apr 19 16:48:24.635: INFO: Created: latency-svc-7zgqw
  Apr 19 16:48:24.669: INFO: Got endpoints: latency-svc-xq6xl [752.154941ms]
  Apr 19 16:48:24.685: INFO: Created: latency-svc-znhdx
  Apr 19 16:48:24.716: INFO: Got endpoints: latency-svc-rgsz4 [750.189742ms]
  Apr 19 16:48:24.737: INFO: Created: latency-svc-mkl27
  Apr 19 16:48:24.765: INFO: Got endpoints: latency-svc-4jnmf [745.676093ms]
  Apr 19 16:48:24.785: INFO: Created: latency-svc-9h6xv
  Apr 19 16:48:24.817: INFO: Got endpoints: latency-svc-dl4gx [742.612032ms]
  Apr 19 16:48:24.836: INFO: Created: latency-svc-ftc4n
  Apr 19 16:48:24.870: INFO: Got endpoints: latency-svc-vtwrr [752.019105ms]
  Apr 19 16:48:24.889: INFO: Created: latency-svc-n9bfc
  Apr 19 16:48:24.918: INFO: Got endpoints: latency-svc-8m6nn [751.291258ms]
  Apr 19 16:48:24.943: INFO: Created: latency-svc-ttvb9
  Apr 19 16:48:24.967: INFO: Got endpoints: latency-svc-h8wzj [748.286171ms]
  Apr 19 16:48:24.983: INFO: Created: latency-svc-xj6s7
  Apr 19 16:48:25.018: INFO: Got endpoints: latency-svc-jjsvl [751.304769ms]
  Apr 19 16:48:25.039: INFO: Created: latency-svc-lvg65
  Apr 19 16:48:25.071: INFO: Got endpoints: latency-svc-58vfk [752.405298ms]
  Apr 19 16:48:25.089: INFO: Created: latency-svc-zntjw
  Apr 19 16:48:25.121: INFO: Got endpoints: latency-svc-k9772 [749.909145ms]
  Apr 19 16:48:25.138: INFO: Created: latency-svc-ft7rb
  Apr 19 16:48:25.170: INFO: Got endpoints: latency-svc-rm9n4 [751.433972ms]
  Apr 19 16:48:25.188: INFO: Created: latency-svc-22x7t
  E0419 16:48:25.191250      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:48:25.218: INFO: Got endpoints: latency-svc-pb8dg [744.272729ms]
  Apr 19 16:48:25.235: INFO: Created: latency-svc-24zsl
  Apr 19 16:48:25.267: INFO: Got endpoints: latency-svc-wjbwm [743.764122ms]
  Apr 19 16:48:25.291: INFO: Created: latency-svc-7gjt7
  Apr 19 16:48:25.326: INFO: Got endpoints: latency-svc-5v9gt [755.694383ms]
  Apr 19 16:48:25.350: INFO: Created: latency-svc-9zkzf
  Apr 19 16:48:25.366: INFO: Got endpoints: latency-svc-7zgqw [748.48909ms]
  Apr 19 16:48:25.395: INFO: Created: latency-svc-fgbph
  Apr 19 16:48:25.416: INFO: Got endpoints: latency-svc-znhdx [745.969465ms]
  Apr 19 16:48:25.434: INFO: Created: latency-svc-8bxjc
  Apr 19 16:48:25.469: INFO: Got endpoints: latency-svc-mkl27 [752.166063ms]
  Apr 19 16:48:25.489: INFO: Created: latency-svc-ccj5n
  Apr 19 16:48:25.523: INFO: Got endpoints: latency-svc-9h6xv [758.17461ms]
  Apr 19 16:48:25.542: INFO: Created: latency-svc-7lk5r
  Apr 19 16:48:25.571: INFO: Got endpoints: latency-svc-ftc4n [753.098071ms]
  Apr 19 16:48:25.637: INFO: Created: latency-svc-kqhtv
  Apr 19 16:48:25.647: INFO: Got endpoints: latency-svc-n9bfc [773.97751ms]
  Apr 19 16:48:25.665: INFO: Created: latency-svc-tbx4z
  Apr 19 16:48:25.672: INFO: Got endpoints: latency-svc-ttvb9 [753.016013ms]
  Apr 19 16:48:25.691: INFO: Created: latency-svc-zmd57
  Apr 19 16:48:25.717: INFO: Got endpoints: latency-svc-xj6s7 [749.695997ms]
  Apr 19 16:48:25.731: INFO: Created: latency-svc-ldpqt
  Apr 19 16:48:25.770: INFO: Got endpoints: latency-svc-lvg65 [750.96657ms]
  Apr 19 16:48:25.788: INFO: Created: latency-svc-mqdsn
  Apr 19 16:48:25.815: INFO: Got endpoints: latency-svc-zntjw [743.070955ms]
  Apr 19 16:48:25.836: INFO: Created: latency-svc-tw4h8
  Apr 19 16:48:25.870: INFO: Got endpoints: latency-svc-ft7rb [748.021177ms]
  Apr 19 16:48:25.887: INFO: Created: latency-svc-grxmh
  Apr 19 16:48:25.915: INFO: Got endpoints: latency-svc-22x7t [744.620425ms]
  Apr 19 16:48:25.941: INFO: Created: latency-svc-xqmkg
  Apr 19 16:48:25.967: INFO: Got endpoints: latency-svc-24zsl [749.035449ms]
  Apr 19 16:48:25.984: INFO: Created: latency-svc-szkfn
  Apr 19 16:48:26.020: INFO: Got endpoints: latency-svc-7gjt7 [753.759109ms]
  Apr 19 16:48:26.039: INFO: Created: latency-svc-47vvk
  Apr 19 16:48:26.069: INFO: Got endpoints: latency-svc-9zkzf [743.207728ms]
  Apr 19 16:48:26.093: INFO: Created: latency-svc-t2qtk
  Apr 19 16:48:26.123: INFO: Got endpoints: latency-svc-fgbph [757.180057ms]
  Apr 19 16:48:26.148: INFO: Created: latency-svc-vjgfs
  Apr 19 16:48:26.170: INFO: Got endpoints: latency-svc-8bxjc [753.665845ms]
  Apr 19 16:48:26.190: INFO: Created: latency-svc-67k7k
  E0419 16:48:26.191977      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:48:26.217: INFO: Got endpoints: latency-svc-ccj5n [747.906084ms]
  Apr 19 16:48:26.237: INFO: Created: latency-svc-q89pv
  Apr 19 16:48:26.277: INFO: Got endpoints: latency-svc-7lk5r [753.088476ms]
  Apr 19 16:48:26.327: INFO: Created: latency-svc-vwr9v
  Apr 19 16:48:26.328: INFO: Got endpoints: latency-svc-kqhtv [756.068465ms]
  Apr 19 16:48:26.343: INFO: Created: latency-svc-nmcvm
  Apr 19 16:48:26.369: INFO: Got endpoints: latency-svc-tbx4z [721.515919ms]
  Apr 19 16:48:26.388: INFO: Created: latency-svc-cqk7f
  Apr 19 16:48:26.417: INFO: Got endpoints: latency-svc-zmd57 [745.374706ms]
  Apr 19 16:48:26.438: INFO: Created: latency-svc-fh8xz
  Apr 19 16:48:26.470: INFO: Got endpoints: latency-svc-ldpqt [752.642947ms]
  Apr 19 16:48:26.490: INFO: Created: latency-svc-4xhxs
  Apr 19 16:48:26.516: INFO: Got endpoints: latency-svc-mqdsn [745.895272ms]
  Apr 19 16:48:26.569: INFO: Got endpoints: latency-svc-tw4h8 [754.036634ms]
  Apr 19 16:48:26.585: INFO: Created: latency-svc-jslwp
  Apr 19 16:48:26.606: INFO: Created: latency-svc-rldk4
  Apr 19 16:48:26.616: INFO: Got endpoints: latency-svc-grxmh [746.722439ms]
  Apr 19 16:48:26.639: INFO: Created: latency-svc-gbf5k
  Apr 19 16:48:26.668: INFO: Got endpoints: latency-svc-xqmkg [753.109939ms]
  Apr 19 16:48:26.687: INFO: Created: latency-svc-zxjfv
  Apr 19 16:48:26.714: INFO: Got endpoints: latency-svc-szkfn [747.207048ms]
  Apr 19 16:48:26.731: INFO: Created: latency-svc-b6v9s
  Apr 19 16:48:26.771: INFO: Got endpoints: latency-svc-47vvk [750.017188ms]
  Apr 19 16:48:26.785: INFO: Created: latency-svc-bd5w6
  Apr 19 16:48:26.815: INFO: Got endpoints: latency-svc-t2qtk [745.697035ms]
  Apr 19 16:48:26.834: INFO: Created: latency-svc-xps2p
  Apr 19 16:48:26.866: INFO: Got endpoints: latency-svc-vjgfs [742.127337ms]
  Apr 19 16:48:26.885: INFO: Created: latency-svc-scdqs
  Apr 19 16:48:26.916: INFO: Got endpoints: latency-svc-67k7k [745.537361ms]
  Apr 19 16:48:26.934: INFO: Created: latency-svc-l88zc
  Apr 19 16:48:26.965: INFO: Got endpoints: latency-svc-q89pv [748.092845ms]
  Apr 19 16:48:26.990: INFO: Created: latency-svc-b6zrn
  Apr 19 16:48:27.018: INFO: Got endpoints: latency-svc-vwr9v [740.93837ms]
  Apr 19 16:48:27.036: INFO: Created: latency-svc-8sqqv
  Apr 19 16:48:27.067: INFO: Got endpoints: latency-svc-nmcvm [739.428402ms]
  Apr 19 16:48:27.082: INFO: Created: latency-svc-fjnnx
  Apr 19 16:48:27.119: INFO: Got endpoints: latency-svc-cqk7f [749.44432ms]
  Apr 19 16:48:27.143: INFO: Created: latency-svc-ncxbp
  Apr 19 16:48:27.171: INFO: Got endpoints: latency-svc-fh8xz [753.71547ms]
  E0419 16:48:27.192928      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:48:27.198: INFO: Created: latency-svc-9zrb6
  Apr 19 16:48:27.222: INFO: Got endpoints: latency-svc-4xhxs [751.710356ms]
  Apr 19 16:48:27.245: INFO: Created: latency-svc-6pd49
  Apr 19 16:48:27.270: INFO: Got endpoints: latency-svc-jslwp [754.238306ms]
  Apr 19 16:48:27.299: INFO: Created: latency-svc-rdw2z
  Apr 19 16:48:27.321: INFO: Got endpoints: latency-svc-rldk4 [751.942241ms]
  Apr 19 16:48:27.347: INFO: Created: latency-svc-xkvd8
  Apr 19 16:48:27.375: INFO: Got endpoints: latency-svc-gbf5k [758.835991ms]
  Apr 19 16:48:27.398: INFO: Created: latency-svc-6r6w5
  Apr 19 16:48:27.416: INFO: Got endpoints: latency-svc-zxjfv [747.340803ms]
  Apr 19 16:48:27.439: INFO: Created: latency-svc-g5866
  Apr 19 16:48:27.468: INFO: Got endpoints: latency-svc-b6v9s [753.670712ms]
  Apr 19 16:48:27.490: INFO: Created: latency-svc-r4pzq
  Apr 19 16:48:27.520: INFO: Got endpoints: latency-svc-bd5w6 [748.780692ms]
  Apr 19 16:48:27.540: INFO: Created: latency-svc-nsc27
  Apr 19 16:48:27.566: INFO: Got endpoints: latency-svc-xps2p [749.861743ms]
  Apr 19 16:48:27.602: INFO: Created: latency-svc-6qjmh
  Apr 19 16:48:27.625: INFO: Got endpoints: latency-svc-scdqs [759.046194ms]
  Apr 19 16:48:27.646: INFO: Created: latency-svc-whjjl
  Apr 19 16:48:27.670: INFO: Got endpoints: latency-svc-l88zc [753.600128ms]
  Apr 19 16:48:27.687: INFO: Created: latency-svc-gfxtq
  Apr 19 16:48:27.717: INFO: Got endpoints: latency-svc-b6zrn [750.759932ms]
  Apr 19 16:48:27.738: INFO: Created: latency-svc-z9qc2
  Apr 19 16:48:27.770: INFO: Got endpoints: latency-svc-8sqqv [751.984434ms]
  Apr 19 16:48:27.790: INFO: Created: latency-svc-8mdf2
  Apr 19 16:48:27.815: INFO: Got endpoints: latency-svc-fjnnx [747.755861ms]
  Apr 19 16:48:27.830: INFO: Created: latency-svc-5cp4m
  Apr 19 16:48:27.866: INFO: Got endpoints: latency-svc-ncxbp [747.074263ms]
  Apr 19 16:48:27.885: INFO: Created: latency-svc-j5h2x
  Apr 19 16:48:27.919: INFO: Got endpoints: latency-svc-9zrb6 [747.327893ms]
  Apr 19 16:48:27.943: INFO: Created: latency-svc-6mgtg
  Apr 19 16:48:27.975: INFO: Got endpoints: latency-svc-6pd49 [751.974366ms]
  Apr 19 16:48:27.993: INFO: Created: latency-svc-tbtsc
  Apr 19 16:48:28.017: INFO: Got endpoints: latency-svc-rdw2z [745.899431ms]
  Apr 19 16:48:28.046: INFO: Created: latency-svc-499mm
  Apr 19 16:48:28.070: INFO: Got endpoints: latency-svc-xkvd8 [748.634247ms]
  Apr 19 16:48:28.095: INFO: Created: latency-svc-x4vvt
  Apr 19 16:48:28.122: INFO: Got endpoints: latency-svc-6r6w5 [745.84353ms]
  Apr 19 16:48:28.139: INFO: Created: latency-svc-xvl2d
  Apr 19 16:48:28.167: INFO: Got endpoints: latency-svc-g5866 [750.646132ms]
  Apr 19 16:48:28.184: INFO: Created: latency-svc-mgsw7
  E0419 16:48:28.193049      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:48:28.216: INFO: Got endpoints: latency-svc-r4pzq [747.233235ms]
  Apr 19 16:48:28.231: INFO: Created: latency-svc-5lshv
  Apr 19 16:48:28.271: INFO: Got endpoints: latency-svc-nsc27 [750.392932ms]
  Apr 19 16:48:28.286: INFO: Created: latency-svc-6vtdk
  Apr 19 16:48:28.316: INFO: Got endpoints: latency-svc-6qjmh [749.80603ms]
  Apr 19 16:48:28.342: INFO: Created: latency-svc-qjmz2
  Apr 19 16:48:28.371: INFO: Got endpoints: latency-svc-whjjl [745.399152ms]
  Apr 19 16:48:28.395: INFO: Created: latency-svc-6vz72
  Apr 19 16:48:28.422: INFO: Got endpoints: latency-svc-gfxtq [751.984394ms]
  Apr 19 16:48:28.447: INFO: Created: latency-svc-6jk5f
  Apr 19 16:48:28.470: INFO: Got endpoints: latency-svc-z9qc2 [753.670591ms]
  Apr 19 16:48:28.507: INFO: Created: latency-svc-j2z2r
  Apr 19 16:48:28.526: INFO: Got endpoints: latency-svc-8mdf2 [754.834957ms]
  Apr 19 16:48:28.553: INFO: Created: latency-svc-lkmgp
  Apr 19 16:48:28.575: INFO: Got endpoints: latency-svc-5cp4m [760.159071ms]
  Apr 19 16:48:28.598: INFO: Created: latency-svc-sq4hj
  Apr 19 16:48:28.618: INFO: Got endpoints: latency-svc-j5h2x [751.342383ms]
  Apr 19 16:48:28.635: INFO: Created: latency-svc-6btmc
  Apr 19 16:48:28.667: INFO: Got endpoints: latency-svc-6mgtg [747.966765ms]
  Apr 19 16:48:28.684: INFO: Created: latency-svc-4j2jb
  Apr 19 16:48:28.716: INFO: Got endpoints: latency-svc-tbtsc [740.833915ms]
  Apr 19 16:48:28.733: INFO: Created: latency-svc-7br96
  Apr 19 16:48:28.768: INFO: Got endpoints: latency-svc-499mm [750.719715ms]
  Apr 19 16:48:28.789: INFO: Created: latency-svc-t6qvs
  Apr 19 16:48:28.818: INFO: Got endpoints: latency-svc-x4vvt [747.810814ms]
  Apr 19 16:48:28.837: INFO: Created: latency-svc-n9qkv
  Apr 19 16:48:28.866: INFO: Got endpoints: latency-svc-xvl2d [744.337299ms]
  Apr 19 16:48:28.887: INFO: Created: latency-svc-lr9m7
  Apr 19 16:48:28.918: INFO: Got endpoints: latency-svc-mgsw7 [751.021158ms]
  Apr 19 16:48:28.957: INFO: Created: latency-svc-2vgbm
  Apr 19 16:48:28.972: INFO: Got endpoints: latency-svc-5lshv [755.542407ms]
  Apr 19 16:48:28.991: INFO: Created: latency-svc-7vft4
  Apr 19 16:48:29.018: INFO: Got endpoints: latency-svc-6vtdk [747.336625ms]
  Apr 19 16:48:29.042: INFO: Created: latency-svc-nwssk
  Apr 19 16:48:29.070: INFO: Got endpoints: latency-svc-qjmz2 [752.655438ms]
  Apr 19 16:48:29.100: INFO: Created: latency-svc-p52rq
  Apr 19 16:48:29.117: INFO: Got endpoints: latency-svc-6vz72 [745.54162ms]
  Apr 19 16:48:29.137: INFO: Created: latency-svc-s7txz
  Apr 19 16:48:29.170: INFO: Got endpoints: latency-svc-6jk5f [747.317833ms]
  Apr 19 16:48:29.190: INFO: Created: latency-svc-w982c
  E0419 16:48:29.193717      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:48:29.219: INFO: Got endpoints: latency-svc-j2z2r [747.388093ms]
  Apr 19 16:48:29.243: INFO: Created: latency-svc-j4xp5
  Apr 19 16:48:29.267: INFO: Got endpoints: latency-svc-lkmgp [740.951086ms]
  Apr 19 16:48:29.299: INFO: Created: latency-svc-w6r9j
  Apr 19 16:48:29.318: INFO: Got endpoints: latency-svc-sq4hj [741.733048ms]
  Apr 19 16:48:29.335: INFO: Created: latency-svc-ddnfr
  Apr 19 16:48:29.366: INFO: Got endpoints: latency-svc-6btmc [748.305126ms]
  Apr 19 16:48:29.385: INFO: Created: latency-svc-24t6v
  Apr 19 16:48:29.418: INFO: Got endpoints: latency-svc-4j2jb [750.828526ms]
  Apr 19 16:48:29.469: INFO: Got endpoints: latency-svc-7br96 [752.702966ms]
  Apr 19 16:48:29.516: INFO: Got endpoints: latency-svc-t6qvs [747.492966ms]
  Apr 19 16:48:29.566: INFO: Got endpoints: latency-svc-n9qkv [746.993734ms]
  Apr 19 16:48:29.634: INFO: Got endpoints: latency-svc-lr9m7 [767.167672ms]
  Apr 19 16:48:29.665: INFO: Got endpoints: latency-svc-2vgbm [746.428143ms]
  Apr 19 16:48:29.717: INFO: Got endpoints: latency-svc-7vft4 [744.786618ms]
  Apr 19 16:48:29.770: INFO: Got endpoints: latency-svc-nwssk [751.892315ms]
  Apr 19 16:48:29.817: INFO: Got endpoints: latency-svc-p52rq [747.548274ms]
  Apr 19 16:48:29.873: INFO: Got endpoints: latency-svc-s7txz [755.751512ms]
  Apr 19 16:48:29.921: INFO: Got endpoints: latency-svc-w982c [751.298126ms]
  Apr 19 16:48:29.969: INFO: Got endpoints: latency-svc-j4xp5 [749.752835ms]
  Apr 19 16:48:30.022: INFO: Got endpoints: latency-svc-w6r9j [754.48398ms]
  Apr 19 16:48:30.082: INFO: Got endpoints: latency-svc-ddnfr [763.844633ms]
  Apr 19 16:48:30.122: INFO: Got endpoints: latency-svc-24t6v [755.750895ms]
  Apr 19 16:48:30.122: INFO: Latencies: [63.340465ms 94.713133ms 102.565608ms 114.275634ms 119.006134ms 126.874173ms 131.592534ms 133.751869ms 135.849637ms 146.716216ms 147.773797ms 153.488838ms 165.149271ms 167.823719ms 183.224688ms 184.746093ms 186.633037ms 187.576814ms 191.086615ms 194.190082ms 199.132825ms 201.228831ms 212.898128ms 214.768786ms 219.295163ms 221.712993ms 221.853241ms 230.52504ms 234.763632ms 237.995554ms 243.005572ms 252.898104ms 253.909782ms 263.306578ms 266.755151ms 271.333447ms 273.481887ms 286.943776ms 287.658307ms 303.286586ms 318.06967ms 322.163764ms 327.118145ms 336.293001ms 365.789426ms 372.377761ms 389.997953ms 410.937279ms 433.477226ms 469.479605ms 488.368388ms 527.796877ms 555.715343ms 592.536976ms 629.596154ms 658.973062ms 699.01745ms 721.515919ms 730.56417ms 739.428402ms 740.833915ms 740.93837ms 740.951086ms 740.989906ms 741.109398ms 741.733048ms 742.127337ms 742.612032ms 742.754097ms 743.070955ms 743.207728ms 743.263109ms 743.764122ms 744.272729ms 744.337299ms 744.620425ms 744.786618ms 744.91437ms 745.374706ms 745.399152ms 745.537361ms 745.54162ms 745.676093ms 745.697035ms 745.84353ms 745.895272ms 745.899431ms 745.910694ms 745.969465ms 746.428143ms 746.722439ms 746.824883ms 746.958921ms 746.993734ms 747.015795ms 747.074263ms 747.207048ms 747.233235ms 747.317833ms 747.317907ms 747.327893ms 747.336625ms 747.340803ms 747.388093ms 747.492966ms 747.548274ms 747.549117ms 747.755861ms 747.810814ms 747.906084ms 747.966765ms 748.021177ms 748.092845ms 748.122061ms 748.286171ms 748.305126ms 748.417727ms 748.477784ms 748.48909ms 748.634247ms 748.780692ms 749.035449ms 749.204008ms 749.225744ms 749.408704ms 749.44432ms 749.615083ms 749.695997ms 749.743767ms 749.752835ms 749.80603ms 749.860091ms 749.861743ms 749.909145ms 750.017188ms 750.029085ms 750.189742ms 750.392932ms 750.549185ms 750.646132ms 750.659968ms 750.719715ms 750.759932ms 750.828526ms 750.868283ms 750.96657ms 751.021158ms 751.16685ms 751.291258ms 751.298126ms 751.304769ms 751.342383ms 751.433972ms 751.710356ms 751.795737ms 751.892315ms 751.942241ms 751.974366ms 751.984394ms 751.984434ms 752.019105ms 752.154941ms 752.166063ms 752.405298ms 752.633596ms 752.642947ms 752.655438ms 752.702966ms 753.016013ms 753.088476ms 753.098071ms 753.109939ms 753.600128ms 753.665845ms 753.670591ms 753.670712ms 753.71547ms 753.759109ms 753.96402ms 754.036634ms 754.194388ms 754.238306ms 754.48398ms 754.834957ms 755.542407ms 755.694383ms 755.750895ms 755.751512ms 756.068465ms 756.243781ms 757.054692ms 757.180057ms 757.31234ms 758.17461ms 758.835991ms 759.046194ms 760.159071ms 763.844633ms 767.167672ms 773.97751ms]
  Apr 19 16:48:30.123: INFO: 50 %ile: 747.327893ms
  Apr 19 16:48:30.123: INFO: 90 %ile: 754.194388ms
  Apr 19 16:48:30.123: INFO: 99 %ile: 767.167672ms
  Apr 19 16:48:30.123: INFO: Total sample count: 200
  Apr 19 16:48:30.123: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svc-latency-9781" for this suite. @ 04/19/24 16:48:30.147
• [9.875 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:527
  STEP: Creating a kubernetes client @ 04/19/24 16:48:30.171
  Apr 19 16:48:30.171: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename container-probe @ 04/19/24 16:48:30.176
  E0419 16:48:30.194409      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:48:30.218
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:48:30.227
  STEP: Creating pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538 @ 04/19/24 16:48:30.236
  E0419 16:48:31.195685      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:32.195951      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/19/24 16:48:32.294
  Apr 19 16:48:32.304: INFO: Initial restart count of pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 is 0
  Apr 19 16:48:32.315: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:48:33.196606      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:34.197083      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:48:34.329: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:48:35.197714      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:36.197436      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:48:36.338: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:48:37.198652      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:38.200921      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:48:38.350: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:48:39.200276      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:40.200269      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:48:40.359: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:48:41.202099      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:42.201933      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:48:42.369: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:48:43.201991      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:44.203215      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:48:44.377: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:48:45.202647      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:46.202841      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:48:46.387: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:48:47.203220      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:48.204689      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:48:48.396: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:48:49.205454      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:50.205758      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:48:50.406: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:48:51.205636      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:52.206472      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:48:52.416: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:48:53.206944      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:54.207641      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:48:54.427: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:48:55.207784      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:56.208235      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:48:56.438: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:48:57.208464      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:48:58.208878      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:48:58.449: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:48:59.208726      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:00.209273      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:49:00.457: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:49:01.210554      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:02.210410      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:49:02.469: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:49:03.210623      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:04.211155      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:49:04.477: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:49:05.211243      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:06.211483      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:49:06.499: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:49:07.211898      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:08.212572      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:49:08.510: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:49:09.212717      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:10.213638      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:49:10.522: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:49:11.214726      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:12.215288      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:49:12.534: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:49:13.215503      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:14.215882      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:49:14.548: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:49:15.216031      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:16.216442      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:49:16.557: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:49:17.216687      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:18.217025      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:49:18.568: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:49:19.217965      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:20.218755      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:49:20.578: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:49:21.218911      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:22.219250      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:49:22.591: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:49:23.219716      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:24.220346      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:49:24.601: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:49:25.220360      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:26.220723      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:49:26.612: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:49:27.221039      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:28.222358      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:49:28.623: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:49:29.223182      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:30.228584      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:49:30.633: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:49:31.228046      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:32.228583      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:49:32.644: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:49:33.230731      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:34.231144      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:49:34.655: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:49:35.231301      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:36.231580      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:49:36.667: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:49:37.231824      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:38.232200      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:49:38.679: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:49:39.232747      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:40.234194      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:49:40.692: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:49:41.234051      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:42.234200      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:49:42.707: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:49:43.234761      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:44.235963      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:49:44.719: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:49:45.235890      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:46.236129      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:49:46.732: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:49:47.236533      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:48.237227      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:49:48.743: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:49:49.237484      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:50.237879      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:49:50.755: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:49:51.239000      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:52.239968      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:49:52.770: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:49:53.240715      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:54.241657      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:49:54.782: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:49:55.242611      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:56.242838      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:49:56.792: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:49:57.243179      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:49:58.243203      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:49:58.807: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:49:59.244327      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:00.244876      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:50:00.818: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:50:01.245723      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:02.246673      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:50:02.829: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:50:03.247787      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:04.248254      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:50:04.842: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:50:05.248453      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:06.249729      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:50:06.853: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:50:07.249843      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:08.250868      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:50:08.866: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:50:09.251297      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:10.251626      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:50:10.883: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:50:11.251939      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:12.252339      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:50:12.894: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:50:13.252603      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:14.252950      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:50:14.905: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:50:15.253004      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:16.253419      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:50:16.913: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:50:17.253942      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:18.254106      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:50:18.924: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:50:19.255251      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:20.255725      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:50:20.933: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:50:21.256768      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:22.256896      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:50:22.943: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:50:23.257931      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:24.258189      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:50:24.949: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:50:25.258836      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:26.258925      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:50:26.962: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:50:27.259712      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:28.260133      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:50:28.969: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:50:29.261011      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:30.261188      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:50:30.982: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:50:31.262459      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:32.263168      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:50:32.991: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:50:33.263509      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:34.263948      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:50:35.001: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:50:35.264894      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:36.265158      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:50:37.008: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:50:37.266389      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:38.266726      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:50:39.023: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:50:39.267118      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:40.268264      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:50:41.031: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:50:41.268787      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:42.269637      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:50:43.048: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:50:43.270042      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:44.270824      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:50:45.058: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:50:45.271305      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:46.271512      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:50:47.077: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:50:47.271803      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:48.272949      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:50:49.087: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:50:49.274206      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:50.274663      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:50:51.097: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:50:51.275820      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:52.276047      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:50:53.109: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:50:53.276707      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:54.276844      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:50:55.129: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:50:55.277165      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:56.277792      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:50:57.139: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:50:57.278429      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:50:58.279175      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:50:59.151: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:50:59.280021      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:00.281540      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:51:01.165: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:51:01.281548      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:02.281973      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:51:03.175: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:51:03.282968      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:04.283467      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:51:05.188: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:51:05.284674      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:06.285610      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:51:07.200: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:51:07.285740      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:08.286147      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:51:09.210: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:51:09.292213      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:10.288632      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:51:11.222: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:51:11.289265      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:12.290036      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:51:13.232: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:51:13.290900      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:14.291184      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:51:15.243: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:51:15.291943      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:16.292325      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:51:17.253: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:51:17.292470      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:18.292713      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:51:19.268: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:51:19.294865      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:20.297920      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:51:21.283: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:51:21.298874      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:22.298901      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:51:23.298: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:51:23.299517      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:24.299939      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:25.300429      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:51:25.307: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:51:26.300603      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:27.301153      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:51:27.318: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:51:28.301377      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:29.302039      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:51:29.328: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:51:30.301730      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:31.302084      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:51:31.336: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:51:32.302951      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:33.303229      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:51:33.347: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:51:34.303470      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:35.304229      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:51:35.355: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:51:36.304626      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:37.305326      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:51:37.367: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:51:38.305562      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:39.305867      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:51:39.375: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:51:40.306943      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:41.307387      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:51:41.387: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:51:42.307465      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:43.308490      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:51:43.400: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:51:44.308808      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:45.309435      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:51:45.409: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:51:46.309477      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:47.309865      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:51:47.418: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:51:48.309985      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:49.310664      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:51:49.428: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:51:50.310843      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:51.311848      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:51:51.439: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:51:52.312192      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:53.312961      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:51:53.451: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:51:54.313096      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:55.314066      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:51:55.459: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:51:56.314644      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:57.315758      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:51:57.469: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:51:58.316822      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:51:59.317142      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:51:59.478: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:52:00.317851      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:01.318051      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:52:01.487: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:52:02.318318      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:03.318547      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:52:03.495: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:52:04.318797      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:05.319849      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:52:05.506: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:52:06.319896      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:07.320241      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:52:07.513: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:52:08.320639      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:09.320872      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:52:09.525: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:52:10.320976      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:11.321720      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:52:11.534: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:52:12.322150      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:13.321910      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:52:13.545: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:52:14.322320      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:15.322896      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:52:15.553: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:52:16.323836      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:17.324717      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:52:17.564: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:52:18.325442      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:19.326508      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:52:19.572: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:52:20.326518      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:21.327298      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:52:21.583: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:52:22.328642      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:23.328821      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:52:23.594: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:52:24.329010      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:25.329946      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:52:25.643: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:52:26.331926      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:27.333173      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:52:27.653: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:52:28.331873      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:29.332126      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:52:29.662: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:52:30.335247      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:31.335009      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:52:31.673: INFO: Get pod test-grpc-ae9319f8-4d62-42d6-99af-baae019bea84 in namespace container-probe-6538
  E0419 16:52:32.336033      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:33.336314      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 04/19/24 16:52:33.674
  Apr 19 16:52:33.702: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-6538" for this suite. @ 04/19/24 16:52:33.717
• [243.580 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:793
  STEP: Creating a kubernetes client @ 04/19/24 16:52:33.754
  Apr 19 16:52:33.758: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename statefulset @ 04/19/24 16:52:33.769
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:52:33.819
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:52:33.826
  STEP: Creating service test in namespace statefulset-7548 @ 04/19/24 16:52:33.834
  STEP: Looking for a node to schedule stateful set and pod @ 04/19/24 16:52:33.845
  STEP: Creating pod with conflicting port in namespace statefulset-7548 @ 04/19/24 16:52:33.882
  STEP: Waiting until pod test-pod will start running in namespace statefulset-7548 @ 04/19/24 16:52:33.901
  E0419 16:52:34.337180      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:35.338586      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating statefulset with conflicting port in namespace statefulset-7548 @ 04/19/24 16:52:35.919
  STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-7548 @ 04/19/24 16:52:35.933
  Apr 19 16:52:36.018: INFO: Observed stateful pod in namespace: statefulset-7548, name: ss-0, uid: 5050d2c2-7a74-4d2d-af66-f14512df1d71, status phase: Pending. Waiting for statefulset controller to delete.
  Apr 19 16:52:36.056: INFO: Observed stateful pod in namespace: statefulset-7548, name: ss-0, uid: 5050d2c2-7a74-4d2d-af66-f14512df1d71, status phase: Failed. Waiting for statefulset controller to delete.
  Apr 19 16:52:36.109: INFO: Observed stateful pod in namespace: statefulset-7548, name: ss-0, uid: 5050d2c2-7a74-4d2d-af66-f14512df1d71, status phase: Failed. Waiting for statefulset controller to delete.
  Apr 19 16:52:36.115: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-7548
  STEP: Removing pod with conflicting port in namespace statefulset-7548 @ 04/19/24 16:52:36.115
  STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-7548 and will be in running state @ 04/19/24 16:52:36.135
  E0419 16:52:36.339494      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:37.340284      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:38.340006      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:39.340845      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:40.341445      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:41.342524      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:42.343671      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:43.345020      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:44.345891      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:45.346673      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:46.347187      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:47.347981      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:48.347931      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:49.348194      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:50.349052      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:51.350249      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:52.351194      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:53.352493      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:52:54.255: INFO: Deleting all statefulset in ns statefulset-7548
  Apr 19 16:52:54.261: INFO: Scaling statefulset ss to 0
  E0419 16:52:54.352732      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:55.353691      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:56.354256      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:57.354620      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:58.354756      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:52:59.355606      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:00.355908      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:01.356298      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:02.357413      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:03.358055      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:53:04.287: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 19 16:53:04.295: INFO: Deleting statefulset ss
  Apr 19 16:53:04.324: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-7548" for this suite. @ 04/19/24 16:53:04.335
• [30.599 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:103
  STEP: Creating a kubernetes client @ 04/19/24 16:53:04.359
  Apr 19 16:53:04.359: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  E0419 16:53:04.359767      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Building a namespace api object, basename resourcequota @ 04/19/24 16:53:04.363
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:53:04.403
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:53:04.412
  STEP: Counting existing ResourceQuota @ 04/19/24 16:53:04.42
  E0419 16:53:05.360084      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:06.360723      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:07.360957      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:08.362670      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:09.362601      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 04/19/24 16:53:09.428
  STEP: Ensuring resource quota status is calculated @ 04/19/24 16:53:09.441
  E0419 16:53:10.363461      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:11.365084      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Service @ 04/19/24 16:53:11.451
  STEP: Creating a NodePort Service @ 04/19/24 16:53:11.488
  STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota @ 04/19/24 16:53:11.542
  STEP: Ensuring resource quota status captures service creation @ 04/19/24 16:53:11.577
  E0419 16:53:12.365699      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:13.365659      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting Services @ 04/19/24 16:53:13.586
  STEP: Ensuring resource quota status released usage @ 04/19/24 16:53:13.716
  E0419 16:53:14.365847      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:15.367385      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:53:15.725: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-8267" for this suite. @ 04/19/24 16:53:15.735
• [11.397 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:163
  STEP: Creating a kubernetes client @ 04/19/24 16:53:15.756
  Apr 19 16:53:15.756: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename resourcequota @ 04/19/24 16:53:15.762
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:53:15.81
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:53:15.818
  STEP: Discovering how many secrets are in namespace by default @ 04/19/24 16:53:15.825
  E0419 16:53:16.367366      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:17.367707      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:18.367952      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:19.369059      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:20.369377      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 04/19/24 16:53:20.846
  E0419 16:53:21.370104      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:22.370533      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:23.371278      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:24.372536      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:25.372496      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 04/19/24 16:53:25.865
  STEP: Ensuring resource quota status is calculated @ 04/19/24 16:53:25.88
  E0419 16:53:26.372611      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:27.375011      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Secret @ 04/19/24 16:53:27.889
  STEP: Ensuring resource quota status captures secret creation @ 04/19/24 16:53:27.919
  E0419 16:53:28.374815      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:29.374654      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a secret @ 04/19/24 16:53:29.936
  STEP: Ensuring resource quota status released usage @ 04/19/24 16:53:29.955
  E0419 16:53:30.375176      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:31.377042      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:53:31.971: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6490" for this suite. @ 04/19/24 16:53:31.99
• [16.257 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:812
  STEP: Creating a kubernetes client @ 04/19/24 16:53:32.035
  Apr 19 16:53:32.035: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename sched-preemption @ 04/19/24 16:53:32.04
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:53:32.087
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:53:32.093
  Apr 19 16:53:32.134: INFO: Waiting up to 1m0s for all nodes to be ready
  E0419 16:53:32.377358      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:33.377848      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:34.378199      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:35.379452      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:36.379423      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:37.379561      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:38.380244      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:39.381057      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:40.381441      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:41.382773      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:42.383379      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:43.383799      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:44.384826      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:45.385673      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:46.386409      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:47.386689      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:48.387372      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:49.387253      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:50.387550      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:51.388482      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:52.388758      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:53.389075      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:54.390022      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:55.390442      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:56.391273      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:57.392138      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:58.392599      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:53:59.392813      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:00.393951      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:01.394192      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:02.394429      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:03.395564      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:04.396376      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:05.397465      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:06.398202      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:07.398507      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:08.399328      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:09.400194      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:10.400499      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:11.400820      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:12.401646      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:13.401835      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:14.402719      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:15.402962      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:16.404181      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:17.404952      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:18.405975      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:19.406233      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:20.406768      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:21.408452      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:22.408598      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:23.409022      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:24.410076      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:25.410409      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:26.411321      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:27.411732      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:28.412468      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:29.412925      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:30.413594      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:31.413948      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:54:32.181: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 04/19/24 16:54:32.191
  Apr 19 16:54:32.191: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename sched-preemption-path @ 04/19/24 16:54:32.195
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:54:32.233
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:54:32.241
  Apr 19 16:54:32.290: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
  Apr 19 16:54:32.301: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
  E0419 16:54:32.414959      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:54:32.491: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-6216" for this suite. @ 04/19/24 16:54:32.503
  Apr 19 16:54:32.519: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-5495" for this suite. @ 04/19/24 16:54:32.528
• [60.507 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:180
  STEP: Creating a kubernetes client @ 04/19/24 16:54:32.547
  Apr 19 16:54:32.547: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename emptydir @ 04/19/24 16:54:32.551
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:54:32.579
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:54:32.586
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 04/19/24 16:54:32.592
  E0419 16:54:33.416104      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:34.416759      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:35.417007      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:36.418157      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:54:36.639
  Apr 19 16:54:36.646: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-11411cfe-c7f8-4335-8399-0f5dd85a3f44 container test-container: <nil>
  STEP: delete the pod @ 04/19/24 16:54:36.693
  Apr 19 16:54:36.725: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1687" for this suite. @ 04/19/24 16:54:36.736
• [4.209 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:87
  STEP: Creating a kubernetes client @ 04/19/24 16:54:36.759
  Apr 19 16:54:36.759: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename disruption @ 04/19/24 16:54:36.762
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:54:36.796
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:54:36.801
  STEP: Creating a kubernetes client @ 04/19/24 16:54:36.808
  Apr 19 16:54:36.808: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename disruption-2 @ 04/19/24 16:54:36.812
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:54:36.839
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:54:36.846
  STEP: Waiting for the pdb to be processed @ 04/19/24 16:54:36.859
  E0419 16:54:37.419250      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:38.419447      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 04/19/24 16:54:38.886
  E0419 16:54:39.420677      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:40.421393      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 04/19/24 16:54:40.905
  E0419 16:54:41.421108      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:42.421267      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: listing a collection of PDBs across all namespaces @ 04/19/24 16:54:42.916
  STEP: listing a collection of PDBs in namespace disruption-9103 @ 04/19/24 16:54:42.93
  STEP: deleting a collection of PDBs @ 04/19/24 16:54:42.94
  STEP: Waiting for the PDB collection to be deleted @ 04/19/24 16:54:42.983
  Apr 19 16:54:42.992: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2-5627" for this suite. @ 04/19/24 16:54:43.006
  Apr 19 16:54:43.032: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-9103" for this suite. @ 04/19/24 16:54:43.045
• [6.309 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:808
  STEP: Creating a kubernetes client @ 04/19/24 16:54:43.073
  Apr 19 16:54:43.074: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename resourcequota @ 04/19/24 16:54:43.079
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:54:43.123
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:54:43.133
  STEP: Creating a ResourceQuota with best effort scope @ 04/19/24 16:54:43.141
  STEP: Ensuring ResourceQuota status is calculated @ 04/19/24 16:54:43.155
  E0419 16:54:43.421952      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:44.421990      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not best effort scope @ 04/19/24 16:54:45.165
  STEP: Ensuring ResourceQuota status is calculated @ 04/19/24 16:54:45.176
  E0419 16:54:45.422256      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:46.423093      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a best-effort pod @ 04/19/24 16:54:47.189
  STEP: Ensuring resource quota with best effort scope captures the pod usage @ 04/19/24 16:54:47.225
  E0419 16:54:47.423804      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:48.424934      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not best effort ignored the pod usage @ 04/19/24 16:54:49.234
  E0419 16:54:49.426088      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:50.426405      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 04/19/24 16:54:51.246
  STEP: Ensuring resource quota status released the pod usage @ 04/19/24 16:54:51.277
  E0419 16:54:51.427480      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:52.428172      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a not best-effort pod @ 04/19/24 16:54:53.292
  STEP: Ensuring resource quota with not best effort scope captures the pod usage @ 04/19/24 16:54:53.327
  E0419 16:54:53.428818      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:54.428939      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with best effort scope ignored the pod usage @ 04/19/24 16:54:55.341
  E0419 16:54:55.430070      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:56.430805      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 04/19/24 16:54:57.351
  STEP: Ensuring resource quota status released the pod usage @ 04/19/24 16:54:57.369
  E0419 16:54:57.431677      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:54:58.431915      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:54:59.383: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-8257" for this suite. @ 04/19/24 16:54:59.398
• [16.344 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount an API token into pods [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:80
  STEP: Creating a kubernetes client @ 04/19/24 16:54:59.418
  Apr 19 16:54:59.418: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename svcaccounts @ 04/19/24 16:54:59.427
  E0419 16:54:59.435219      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:54:59.472
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:54:59.479
  E0419 16:55:00.433794      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:01.434765      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: reading a file in the container @ 04/19/24 16:55:01.53
  Apr 19 16:55:01.531: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2056 pod-service-account-bf60857b-01b1-4b51-9d2e-55cd31028502 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
  STEP: reading a file in the container @ 04/19/24 16:55:01.882
  Apr 19 16:55:01.883: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2056 pod-service-account-bf60857b-01b1-4b51-9d2e-55cd31028502 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
  STEP: reading a file in the container @ 04/19/24 16:55:02.17
  Apr 19 16:55:02.171: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2056 pod-service-account-bf60857b-01b1-4b51-9d2e-55cd31028502 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
  E0419 16:55:02.435109      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:55:02.454: INFO: Got root ca configmap in namespace "svcaccounts-2056"
  Apr 19 16:55:02.461: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-2056" for this suite. @ 04/19/24 16:55:02.469
• [3.061 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:131
  STEP: Creating a kubernetes client @ 04/19/24 16:55:02.484
  Apr 19 16:55:02.484: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename runtimeclass @ 04/19/24 16:55:02.487
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:55:02.518
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:55:02.538
  E0419 16:55:03.435258      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:04.435954      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:55:04.607: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-9590" for this suite. @ 04/19/24 16:55:04.621
• [2.152 seconds]
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:474
  STEP: Creating a kubernetes client @ 04/19/24 16:55:04.637
  Apr 19 16:55:04.638: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename field-validation @ 04/19/24 16:55:04.64
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:55:04.671
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:55:04.679
  Apr 19 16:55:04.688: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  E0419 16:55:05.436493      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:06.436487      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:07.437201      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0419 16:55:07.551698      13 warnings.go:70] unknown field "alpha"
  W0419 16:55:07.551794      13 warnings.go:70] unknown field "beta"
  W0419 16:55:07.551900      13 warnings.go:70] unknown field "delta"
  W0419 16:55:07.551922      13 warnings.go:70] unknown field "epsilon"
  W0419 16:55:07.552034      13 warnings.go:70] unknown field "gamma"
  Apr 19 16:55:08.160: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-2038" for this suite. @ 04/19/24 16:55:08.17
• [3.548 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:286
  STEP: Creating a kubernetes client @ 04/19/24 16:55:08.191
  Apr 19 16:55:08.191: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename proxy @ 04/19/24 16:55:08.195
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:55:08.235
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:55:08.243
  Apr 19 16:55:08.255: INFO: Creating pod...
  E0419 16:55:08.437671      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:09.438155      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:55:10.293: INFO: Creating service...
  Apr 19 16:55:10.316: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-688/pods/agnhost/proxy/some/path/with/DELETE
  E0419 16:55:10.439251      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:11.440150      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:12.440759      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:13.441632      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:14.442331      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:15.442612      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:16.443357      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:17.443738      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:18.444121      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:19.444350      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:20.444699      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:21.444961      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:55:21.518: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Apr 19 16:55:21.520: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-688/pods/agnhost/proxy/some/path/with/GET
  Apr 19 16:55:21.533: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  Apr 19 16:55:21.534: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-688/pods/agnhost/proxy/some/path/with/HEAD
  Apr 19 16:55:21.547: INFO: http.Client request:HEAD | StatusCode:200
  Apr 19 16:55:21.547: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-688/pods/agnhost/proxy/some/path/with/OPTIONS
  Apr 19 16:55:21.559: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Apr 19 16:55:21.559: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-688/pods/agnhost/proxy/some/path/with/PATCH
  Apr 19 16:55:21.568: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Apr 19 16:55:21.568: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-688/pods/agnhost/proxy/some/path/with/POST
  Apr 19 16:55:21.578: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Apr 19 16:55:21.578: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-688/pods/agnhost/proxy/some/path/with/PUT
  Apr 19 16:55:21.588: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Apr 19 16:55:21.589: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-688/services/test-service/proxy/some/path/with/DELETE
  Apr 19 16:55:21.642: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Apr 19 16:55:21.644: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-688/services/test-service/proxy/some/path/with/GET
  Apr 19 16:55:21.661: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  Apr 19 16:55:21.661: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-688/services/test-service/proxy/some/path/with/HEAD
  Apr 19 16:55:21.675: INFO: http.Client request:HEAD | StatusCode:200
  Apr 19 16:55:21.676: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-688/services/test-service/proxy/some/path/with/OPTIONS
  Apr 19 16:55:21.690: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Apr 19 16:55:21.690: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-688/services/test-service/proxy/some/path/with/PATCH
  Apr 19 16:55:21.704: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Apr 19 16:55:21.704: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-688/services/test-service/proxy/some/path/with/POST
  Apr 19 16:55:21.719: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Apr 19 16:55:21.719: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-688/services/test-service/proxy/some/path/with/PUT
  Apr 19 16:55:21.733: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Apr 19 16:55:21.734: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-688" for this suite. @ 04/19/24 16:55:21.753
• [13.583 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:210
  STEP: Creating a kubernetes client @ 04/19/24 16:55:21.78
  Apr 19 16:55:21.780: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename emptydir @ 04/19/24 16:55:21.784
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:55:21.827
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:55:21.834
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 04/19/24 16:55:21.843
  E0419 16:55:22.445998      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:23.446584      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:24.447394      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:25.447753      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:55:25.899
  Apr 19 16:55:25.908: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-29f84507-21b6-4102-a28e-de361e4d4e29 container test-container: <nil>
  STEP: delete the pod @ 04/19/24 16:55:25.937
  Apr 19 16:55:25.998: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5229" for this suite. @ 04/19/24 16:55:26.017
• [4.262 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/security_context.go:135
  STEP: Creating a kubernetes client @ 04/19/24 16:55:26.048
  Apr 19 16:55:26.048: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename security-context @ 04/19/24 16:55:26.052
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:55:26.097
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:55:26.101
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 04/19/24 16:55:26.109
  E0419 16:55:26.448982      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:27.449929      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:28.450055      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:29.450647      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 16:55:30.155
  Apr 19 16:55:30.166: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod security-context-5dbd2f69-79e0-4985-a51f-e7913419a359 container test-container: <nil>
  STEP: delete the pod @ 04/19/24 16:55:30.185
  Apr 19 16:55:30.218: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-8719" for this suite. @ 04/19/24 16:55:30.225
• [4.192 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:818
  STEP: Creating a kubernetes client @ 04/19/24 16:55:30.246
  Apr 19 16:55:30.247: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename gc @ 04/19/24 16:55:30.251
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:55:30.283
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:55:30.287
  Apr 19 16:55:30.378: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"41eb1ece-8460-43aa-ad3d-d75f5ee9fd4e", Controller:(*bool)(0xc0068ecf56), BlockOwnerDeletion:(*bool)(0xc0068ecf57)}}
  Apr 19 16:55:30.389: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"e1dc09f1-4134-40a2-8372-3e0e2a89c811", Controller:(*bool)(0xc0068ed1fe), BlockOwnerDeletion:(*bool)(0xc0068ed1ff)}}
  Apr 19 16:55:30.402: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"c44b5e2c-6027-4fa6-8055-8b5cde365400", Controller:(*bool)(0xc0068ed426), BlockOwnerDeletion:(*bool)(0xc0068ed427)}}
  E0419 16:55:30.451607      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:31.452016      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:32.452327      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:33.452845      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:34.453440      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:55:35.424: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-7038" for this suite. @ 04/19/24 16:55:35.435
• [5.200 seconds]
------------------------------
SS
------------------------------
[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:164
  STEP: Creating a kubernetes client @ 04/19/24 16:55:35.45
  Apr 19 16:55:35.450: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  E0419 16:55:35.453502      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Building a namespace api object, basename downward-api @ 04/19/24 16:55:35.453
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:55:35.487
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:55:35.493
  STEP: Creating the pod @ 04/19/24 16:55:35.5
  E0419 16:55:36.454717      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:37.456608      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:55:38.106: INFO: Successfully updated pod "annotationupdateb6d401a0-931f-4af6-a107-a5751c94dff8"
  E0419 16:55:38.456322      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:39.456542      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:40.457622      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:41.457732      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:55:42.166: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7884" for this suite. @ 04/19/24 16:55:42.177
• [6.742 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:214
  STEP: Creating a kubernetes client @ 04/19/24 16:55:42.193
  Apr 19 16:55:42.193: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 04/19/24 16:55:42.197
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:55:42.233
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:55:42.24
  STEP: create the container to handle the HTTPGet hook request. @ 04/19/24 16:55:42.251
  E0419 16:55:42.458358      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:43.460556      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 04/19/24 16:55:44.29
  E0419 16:55:44.459143      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:45.459103      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 04/19/24 16:55:46.33
  E0419 16:55:46.460026      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:47.459780      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 04/19/24 16:55:48.362
  Apr 19 16:55:48.382: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-1458" for this suite. @ 04/19/24 16:55:48.393
• [6.216 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:108
  STEP: Creating a kubernetes client @ 04/19/24 16:55:48.423
  Apr 19 16:55:48.424: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename disruption @ 04/19/24 16:55:48.427
  E0419 16:55:48.460866      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:55:48.469
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:55:48.477
  STEP: creating the pdb @ 04/19/24 16:55:48.486
  STEP: Waiting for the pdb to be processed @ 04/19/24 16:55:48.498
  STEP: updating the pdb @ 04/19/24 16:55:48.512
  STEP: Waiting for the pdb to be processed @ 04/19/24 16:55:48.561
  STEP: patching the pdb @ 04/19/24 16:55:48.568
  STEP: Waiting for the pdb to be processed @ 04/19/24 16:55:48.605
  STEP: Waiting for the pdb to be deleted @ 04/19/24 16:55:48.63
  Apr 19 16:55:48.641: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2941" for this suite. @ 04/19/24 16:55:48.651
• [0.241 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:117
  STEP: Creating a kubernetes client @ 04/19/24 16:55:48.666
  Apr 19 16:55:48.666: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename field-validation @ 04/19/24 16:55:48.668
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:55:48.695
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:55:48.699
  STEP: apply creating a deployment @ 04/19/24 16:55:48.704
  Apr 19 16:55:48.727: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-16" for this suite. @ 04/19/24 16:55:48.734
• [0.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:261
  STEP: Creating a kubernetes client @ 04/19/24 16:55:48.75
  Apr 19 16:55:48.750: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename webhook @ 04/19/24 16:55:48.752
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:55:48.779
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:55:48.784
  STEP: Setting up server cert @ 04/19/24 16:55:48.819
  E0419 16:55:49.461313      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 16:55:49.888
  STEP: Deploying the webhook pod @ 04/19/24 16:55:49.911
  STEP: Wait for the deployment to be ready @ 04/19/24 16:55:49.938
  Apr 19 16:55:49.978: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0419 16:55:50.462500      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:51.463383      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:55:52.015: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 16, 55, 50, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 55, 50, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 55, 50, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 55, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7c55c7d74c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 16:55:52.464909      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:53.465491      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:55:54.021: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 16, 55, 50, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 55, 50, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 55, 50, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 55, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7c55c7d74c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 16:55:54.466064      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:55.466265      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:55:56.029: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 16, 55, 50, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 55, 50, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 55, 50, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 55, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7c55c7d74c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 16:55:56.466943      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:57.466921      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:55:58.024: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 16, 55, 50, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 55, 50, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 55, 50, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 55, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7c55c7d74c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 16:55:58.467189      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:55:59.467612      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:56:00.029: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 16, 55, 50, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 55, 50, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 16, 55, 50, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 16, 55, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7c55c7d74c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 16:56:00.468323      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:01.468145      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 16:56:02.027
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 16:56:02.078
  E0419 16:56:02.468748      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:56:03.079: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating pod webhook via the AdmissionRegistration API @ 04/19/24 16:56:03.096
  STEP: create a pod that should be updated by the webhook @ 04/19/24 16:56:03.14
  Apr 19 16:56:03.278: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9144" for this suite. @ 04/19/24 16:56:03.285
  STEP: Destroying namespace "webhook-markers-7885" for this suite. @ 04/19/24 16:56:03.302
• [14.575 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:887
  STEP: Creating a kubernetes client @ 04/19/24 16:56:03.326
  Apr 19 16:56:03.326: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename kubectl @ 04/19/24 16:56:03.332
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:56:03.36
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:56:03.365
  STEP: validating api versions @ 04/19/24 16:56:03.371
  Apr 19 16:56:03.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-8574 api-versions'
  E0419 16:56:03.468734      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:56:03.578: INFO: stderr: ""
  Apr 19 16:56:03.578: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta3\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nv1\n"
  Apr 19 16:56:03.578: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8574" for this suite. @ 04/19/24 16:56:03.587
• [0.273 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:1015
  STEP: Creating a kubernetes client @ 04/19/24 16:56:03.599
  Apr 19 16:56:03.599: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename resourcequota @ 04/19/24 16:56:03.606
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 16:56:03.642
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 16:56:03.646
  STEP: Creating resourceQuota "e2e-rq-status-p6kdr" @ 04/19/24 16:56:03.657
  Apr 19 16:56:03.678: INFO: Resource quota "e2e-rq-status-p6kdr" reports spec: hard cpu limit of 500m
  Apr 19 16:56:03.678: INFO: Resource quota "e2e-rq-status-p6kdr" reports spec: hard memory limit of 500Mi
  STEP: Updating resourceQuota "e2e-rq-status-p6kdr" /status @ 04/19/24 16:56:03.678
  STEP: Confirm /status for "e2e-rq-status-p6kdr" resourceQuota via watch @ 04/19/24 16:56:03.691
  Apr 19 16:56:03.694: INFO: observed resourceQuota "e2e-rq-status-p6kdr" in namespace "resourcequota-9674" with hard status: v1.ResourceList(nil)
  Apr 19 16:56:03.694: INFO: Found resourceQuota "e2e-rq-status-p6kdr" in namespace "resourcequota-9674" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  Apr 19 16:56:03.695: INFO: ResourceQuota "e2e-rq-status-p6kdr" /status was updated
  STEP: Patching hard spec values for cpu & memory @ 04/19/24 16:56:03.703
  Apr 19 16:56:03.715: INFO: Resource quota "e2e-rq-status-p6kdr" reports spec: hard cpu limit of 1
  Apr 19 16:56:03.716: INFO: Resource quota "e2e-rq-status-p6kdr" reports spec: hard memory limit of 1Gi
  STEP: Patching "e2e-rq-status-p6kdr" /status @ 04/19/24 16:56:03.716
  STEP: Confirm /status for "e2e-rq-status-p6kdr" resourceQuota via watch @ 04/19/24 16:56:03.726
  Apr 19 16:56:03.730: INFO: observed resourceQuota "e2e-rq-status-p6kdr" in namespace "resourcequota-9674" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  Apr 19 16:56:03.731: INFO: Found resourceQuota "e2e-rq-status-p6kdr" in namespace "resourcequota-9674" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
  Apr 19 16:56:03.732: INFO: ResourceQuota "e2e-rq-status-p6kdr" /status was patched
  STEP: Get "e2e-rq-status-p6kdr" /status @ 04/19/24 16:56:03.732
  Apr 19 16:56:03.750: INFO: Resourcequota "e2e-rq-status-p6kdr" reports status: hard cpu of 1
  Apr 19 16:56:03.750: INFO: Resourcequota "e2e-rq-status-p6kdr" reports status: hard memory of 1Gi
  STEP: Repatching "e2e-rq-status-p6kdr" /status before checking Spec is unchanged @ 04/19/24 16:56:03.759
  Apr 19 16:56:03.774: INFO: Resourcequota "e2e-rq-status-p6kdr" reports status: hard cpu of 2
  Apr 19 16:56:03.774: INFO: Resourcequota "e2e-rq-status-p6kdr" reports status: hard memory of 2Gi
  Apr 19 16:56:03.777: INFO: observed resourceQuota "e2e-rq-status-p6kdr" in namespace "resourcequota-9674" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
  Apr 19 16:56:03.777: INFO: Found resourceQuota "e2e-rq-status-p6kdr" in namespace "resourcequota-9674" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}
  Apr 19 16:56:03.783: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480c4e0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480c540), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480c588), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:56:04.469185      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:05.469733      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:06.470492      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:07.470840      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:08.471792      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:56:08.783: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480c7c8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480c810), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480c870), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:56:09.472080      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:10.473302      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:11.473431      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:12.473747      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:13.474046      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:56:13.788: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc005335de8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc005335e30), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc005335e78), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:56:14.474251      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:15.474554      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:16.475053      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:17.475450      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:18.476069      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:56:18.789: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480cde0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480ce58), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480cea0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:56:19.476644      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:20.477333      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:21.477462      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:22.478063      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:23.478383      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:56:23.785: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2c570), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2c5b8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2c690), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:56:24.478869      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:25.479243      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:26.483238      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:27.481429      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:28.483068      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:56:28.787: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2c9c0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2ca38), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2ca68), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:56:29.483256      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:30.483773      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:31.484717      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:32.486779      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:33.487094      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:56:33.791: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480c0f0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480c120), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480c150), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:56:34.490619      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:35.489531      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:36.489910      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:37.490651      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:38.491758      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:56:38.787: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2c468), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2c4b0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2c4f8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:56:39.492596      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:40.493707      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:41.494205      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:42.495129      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:43.496174      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:56:43.788: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2c9c0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2ca38), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2ca68), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:56:44.496706      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:45.496949      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:46.497695      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:47.497810      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:48.498412      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:56:48.784: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480c750), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480c798), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480c7c8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:56:49.498726      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:50.498829      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:51.499004      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:52.499296      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:53.499812      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:56:53.789: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2cf78), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2cfa8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2d008), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:56:54.500331      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:55.500499      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:56.501059      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:57.501353      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:56:58.502468      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:56:58.790: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2d470), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2d4d0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2d548), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:56:59.503251      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:00.503831      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:01.504773      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:02.505049      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:03.505187      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:57:03.788: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480cd38), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480cd98), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480cde0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:57:04.505717      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:05.506010      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:06.506510      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:07.506687      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:08.507472      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:57:08.785: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2da70), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2dab8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2db00), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:57:09.508420      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:10.508991      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:11.509005      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:12.510237      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:13.509692      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:57:13.793: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480d3e0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480d428), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480d4a0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:57:14.510098      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:15.510537      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:16.511079      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:17.511441      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:18.511306      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:57:18.786: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004218060), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004218090), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0042180c0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:57:19.511457      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:20.512180      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:21.513074      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:22.513179      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:23.513490      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:57:23.790: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480dab8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480db00), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480db60), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:57:24.514228      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:25.514691      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:26.515226      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:27.515247      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:28.515448      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:57:28.784: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480ddd0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480de00), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480de30), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:57:29.515585      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:30.516127      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:31.516550      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:32.517226      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:33.518045      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:57:33.786: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004218708), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004218750), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004218798), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:57:34.518599      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:35.518921      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:36.519476      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:37.519332      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:38.519557      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:57:38.789: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004218a68), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004218a98), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004218ae0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:57:39.519723      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:40.520697      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:41.520874      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:42.520928      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:43.521857      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:57:43.788: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004218de0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004218e40), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004218e88), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:57:44.523138      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:45.523548      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:46.523797      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:47.524153      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:48.526430      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:57:48.786: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004219158), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0042191b8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0042191e8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:57:49.525395      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:50.525951      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:51.526130      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:52.526795      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:53.526720      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:57:53.788: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004219530), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004219560), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0042195a8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:57:54.526928      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:55.527778      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:56.528412      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:57.528754      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:57:58.529247      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:57:58.788: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0042197d0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004219800), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004219848), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:57:59.530408      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:00.532122      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:01.531252      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:02.531741      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:03.531816      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:58:03.787: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004290a50), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004290f78), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004290fa8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:58:04.532401      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:05.532981      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:06.532882      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:07.532949      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:08.534077      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:58:08.786: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0042912a8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0042912f0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004291338), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:58:09.535156      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:10.535986      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:11.536823      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:12.537305      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:13.537684      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:58:13.791: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004219de8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004219e30), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004219e60), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:58:14.538131      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:15.538906      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:16.538798      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:17.539543      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:18.539798      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:58:18.788: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0042917e8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004291818), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004291860), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:58:19.540012      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:20.540716      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:21.541519      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:22.541716      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:23.542730      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:58:23.786: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0039d6378), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0039d63c0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0039d6408), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:58:24.542991      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:25.545316      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:26.545105      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:27.545295      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:28.545485      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:58:28.790: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0039d6780), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0039d67e0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0039d6840), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:58:29.546013      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:30.546866      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:31.547756      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:32.547994      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:33.548337      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:58:33.788: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004290108), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004290168), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004290198), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:58:34.548783      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:35.549264      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:36.550258      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:37.551348      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:38.552596      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:58:38.788: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0039d6378), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0039d63c0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0039d6408), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:58:39.552771      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:40.553046      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:41.553187      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:42.553682      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:43.553913      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:58:43.790: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004290678), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0042906d8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004290708), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:58:44.554762      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:45.555104      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:46.556134      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:47.556836      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:48.556781      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:58:48.785: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0039d6930), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0039d6990), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0039d69f0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:58:49.562645      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:50.563675      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:51.564482      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:52.565256      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:53.566535      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:58:53.786: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004291008), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004291038), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004291080), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:58:54.566670      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:55.567890      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:56.568072      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:57.568834      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:58:58.568968      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:58:58.793: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004291410), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004291470), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0042914b8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:58:59.569815      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:00.569480      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:01.571441      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:02.571036      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:03.572161      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:59:03.787: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004291848), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004291878), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0042918d8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:59:04.572733      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:05.573062      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:06.573153      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:07.573557      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:08.573529      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:59:08.784: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0039d7068), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0039d70b0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0039d70f8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:59:09.574192      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:10.574356      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:11.575604      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:12.575670      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:13.576227      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:59:13.787: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0039d7560), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0039d75c0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0039d75f0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:59:14.577437      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:15.578044      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:16.578579      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:17.578461      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:18.579385      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:59:18.789: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004291e30), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004291e78), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004291ea8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:59:19.579593      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:20.581466      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:21.581394      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:22.581624      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:23.582073      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:59:23.789: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0039d7c08), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0039d7c50), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0039d7cb0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:59:24.582693      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:25.582569      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:26.582791      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:27.583461      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:28.583403      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:59:28.785: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2c408), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2c468), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2c4b0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:59:29.583946      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:30.584690      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:31.585538      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:32.585417      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:33.585634      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:59:33.788: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2c960), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2c9c0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2ca38), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:59:34.585998      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:35.586348      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:36.586729      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:37.587688      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:38.588830      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:59:38.788: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2cd38), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2cd98), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2cdf8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:59:39.589088      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:40.589247      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:41.590264      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:42.590693      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:43.591114      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:59:43.789: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480c438), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480c480), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480c4e0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:59:44.591393      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:45.592088      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:46.592950      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:47.593080      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:48.594113      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:59:48.789: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2d4d0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2d548), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2d5a8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:59:49.594952      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:50.595234      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:51.595402      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:52.595651      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:53.595842      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:59:53.786: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2d908), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2d950), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2d9b0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:59:54.596025      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:55.598833      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:56.598964      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:57.599373      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 16:59:58.599714      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 16:59:58.790: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2dc98), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2dcc8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b2dd10), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 16:59:59.600880      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:00.600958      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:01.601867      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:02.602757      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:03.602972      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:00:03.794: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480cac8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480cb10), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480cb58), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 17:00:04.603361      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:05.604027      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:06.604918      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:07.605161      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:08.605191      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:00:08.786: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004218468), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004218498), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0042184e0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 17:00:09.605920      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:10.606353      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:11.607195      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:12.606982      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:13.607270      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:00:13.789: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0042187f8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004218840), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004218870), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 17:00:14.607670      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:15.608290      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:16.608267      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:17.608596      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:18.608926      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:00:18.785: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480d1b8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480d200), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480d230), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 17:00:19.610660      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:20.611045      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:21.611131      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:22.611877      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:23.612441      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:00:23.786: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480d650), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480d698), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480d6f8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 17:00:24.612565      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:25.613469      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:26.613780      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:27.614987      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:28.615078      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:00:28.788: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004218d80), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004218e10), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004218e70), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 17:00:29.615383      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:30.616239      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:31.616522      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:32.616914      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:33.617270      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:00:33.785: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480c138), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480c168), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00480c1c8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 17:00:34.618204      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:35.619199      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:36.619398      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:37.619878      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:38.621025      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:00:38.786: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-p6kdr", GenerateName:"", Namespace:"resourcequota-9674", SelfLink:"", UID:"6e06d393-9022-4955-994d-cedb55920359", ResourceVersion:"27170", Generation:0, CreationTimestamp:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-p6kdr"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004218138), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004218168), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 19, 16, 56, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0042181e0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0419 17:00:39.621258      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:40.621725      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:41.622808      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:42.623801      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:43.624089      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:00:43.789: INFO: ResourceQuota "e2e-rq-status-p6kdr" Spec was unchanged and /status reset
  Apr 19 17:00:43.789: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-9674" for this suite. @ 04/19/24 17:00:43.807
• [280.226 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:289
  STEP: Creating a kubernetes client @ 04/19/24 17:00:43.827
  Apr 19 17:00:43.827: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename field-validation @ 04/19/24 17:00:43.833
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:00:43.882
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:00:43.887
  Apr 19 17:00:43.892: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  E0419 17:00:44.624575      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:45.625012      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:46.624905      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:00:47.300: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-7655" for this suite. @ 04/19/24 17:00:47.31
• [3.496 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:742
  STEP: Creating a kubernetes client @ 04/19/24 17:00:47.325
  Apr 19 17:00:47.325: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename svcaccounts @ 04/19/24 17:00:47.328
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:00:47.359
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:00:47.367
  Apr 19 17:00:47.379: INFO: Got root ca configmap in namespace "svcaccounts-4081"
  Apr 19 17:00:47.400: INFO: Deleted root ca configmap in namespace "svcaccounts-4081"
  E0419 17:00:47.625964      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting for a new root ca configmap created @ 04/19/24 17:00:47.901
  Apr 19 17:00:47.911: INFO: Recreated root ca configmap in namespace "svcaccounts-4081"
  Apr 19 17:00:47.926: INFO: Updated root ca configmap in namespace "svcaccounts-4081"
  STEP: waiting for the root ca configmap reconciled @ 04/19/24 17:00:48.428
  Apr 19 17:00:48.438: INFO: Reconciled root ca configmap in namespace "svcaccounts-4081"
  Apr 19 17:00:48.438: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-4081" for this suite. @ 04/19/24 17:00:48.451
• [1.140 seconds]
------------------------------
S
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:256
  STEP: Creating a kubernetes client @ 04/19/24 17:00:48.469
  Apr 19 17:00:48.470: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename init-container @ 04/19/24 17:00:48.476
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:00:48.527
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:00:48.534
  STEP: creating the pod @ 04/19/24 17:00:48.543
  Apr 19 17:00:48.544: INFO: PodSpec: initContainers in spec.initContainers
  E0419 17:00:48.626887      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:49.627982      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:50.628344      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:51.628250      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:00:51.853: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-5393" for this suite. @ 04/19/24 17:00:51.867
• [3.416 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:172
  STEP: Creating a kubernetes client @ 04/19/24 17:00:51.888
  Apr 19 17:00:51.888: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename discovery @ 04/19/24 17:00:51.893
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:00:51.953
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:00:51.96
  STEP: Setting up server cert @ 04/19/24 17:00:51.972
  E0419 17:00:52.628982      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Requesting APIResourceList from "/api/v1" @ 04/19/24 17:00:52.953
  STEP: Requesting APIResourceList from "/apis/admissionregistration.k8s.io/v1" @ 04/19/24 17:00:52.958
  STEP: Requesting APIResourceList from "/apis/apiextensions.k8s.io/v1" @ 04/19/24 17:00:52.961
  STEP: Requesting APIResourceList from "/apis/apiregistration.k8s.io/v1" @ 04/19/24 17:00:52.964
  STEP: Requesting APIResourceList from "/apis/apps/v1" @ 04/19/24 17:00:52.967
  STEP: Requesting APIResourceList from "/apis/authentication.k8s.io/v1" @ 04/19/24 17:00:52.97
  STEP: Requesting APIResourceList from "/apis/authorization.k8s.io/v1" @ 04/19/24 17:00:52.974
  STEP: Requesting APIResourceList from "/apis/autoscaling/v1" @ 04/19/24 17:00:52.978
  STEP: Requesting APIResourceList from "/apis/autoscaling/v2" @ 04/19/24 17:00:52.982
  STEP: Requesting APIResourceList from "/apis/batch/v1" @ 04/19/24 17:00:52.986
  STEP: Requesting APIResourceList from "/apis/certificates.k8s.io/v1" @ 04/19/24 17:00:52.989
  STEP: Requesting APIResourceList from "/apis/coordination.k8s.io/v1" @ 04/19/24 17:00:52.993
  STEP: Requesting APIResourceList from "/apis/discovery.k8s.io/v1" @ 04/19/24 17:00:52.996
  STEP: Requesting APIResourceList from "/apis/events.k8s.io/v1" @ 04/19/24 17:00:53.001
  STEP: Requesting APIResourceList from "/apis/networking.k8s.io/v1" @ 04/19/24 17:00:53.004
  STEP: Requesting APIResourceList from "/apis/node.k8s.io/v1" @ 04/19/24 17:00:53.007
  STEP: Requesting APIResourceList from "/apis/policy/v1" @ 04/19/24 17:00:53.01
  STEP: Requesting APIResourceList from "/apis/scheduling.k8s.io/v1" @ 04/19/24 17:00:53.014
  STEP: Requesting APIResourceList from "/apis/storage.k8s.io/v1" @ 04/19/24 17:00:53.017
  Apr 19 17:00:53.021: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-8401" for this suite. @ 04/19/24 17:00:53.038
• [1.170 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pods.go:163
  STEP: Creating a kubernetes client @ 04/19/24 17:00:53.058
  Apr 19 17:00:53.058: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename pods @ 04/19/24 17:00:53.061
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:00:53.105
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:00:53.109
  STEP: creating the pod @ 04/19/24 17:00:53.119
  STEP: submitting the pod to kubernetes @ 04/19/24 17:00:53.12
  STEP: verifying QOS class is set on the pod @ 04/19/24 17:00:53.133
  Apr 19 17:00:53.141: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8146" for this suite. @ 04/19/24 17:00:53.165
• [0.129 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:400
  STEP: Creating a kubernetes client @ 04/19/24 17:00:53.188
  Apr 19 17:00:53.188: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename namespaces @ 04/19/24 17:00:53.191
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:00:53.22
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:00:53.224
  STEP: Creating namespace "e2e-ns-w62qx" @ 04/19/24 17:00:53.231
  Apr 19 17:00:53.257: INFO: Namespace "e2e-ns-w62qx-9051" has []v1.FinalizerName{"kubernetes"}
  STEP: Adding e2e finalizer to namespace "e2e-ns-w62qx-9051" @ 04/19/24 17:00:53.258
  Apr 19 17:00:53.275: INFO: Namespace "e2e-ns-w62qx-9051" has []v1.FinalizerName{"kubernetes", "e2e.example.com/fakeFinalizer"}
  STEP: Removing e2e finalizer from namespace "e2e-ns-w62qx-9051" @ 04/19/24 17:00:53.275
  Apr 19 17:00:53.292: INFO: Namespace "e2e-ns-w62qx-9051" has []v1.FinalizerName{"kubernetes"}
  Apr 19 17:00:53.293: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-6567" for this suite. @ 04/19/24 17:00:53.302
  STEP: Destroying namespace "e2e-ns-w62qx-9051" for this suite. @ 04/19/24 17:00:53.318
• [0.152 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:105
  STEP: Creating a kubernetes client @ 04/19/24 17:00:53.342
  Apr 19 17:00:53.343: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename deployment @ 04/19/24 17:00:53.345
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:00:53.375
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:00:53.379
  Apr 19 17:00:53.384: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
  Apr 19 17:00:53.400: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0419 17:00:53.629298      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:54.629935      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:55.630200      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:56.630385      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:57.630557      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:00:58.407: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/19/24 17:00:58.408
  Apr 19 17:00:58.408: INFO: Creating deployment "test-rolling-update-deployment"
  Apr 19 17:00:58.417: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
  Apr 19 17:00:58.430: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
  E0419 17:00:58.631101      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:00:59.631819      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:01:00.449: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
  Apr 19 17:01:00.458: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
  Apr 19 17:01:00.488: INFO: Deployment "test-rolling-update-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6740",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "624f39e8-99b3-4758-8e7c-6ec94e685f10",
      ResourceVersion: (string) (len=5) "27863",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849142858,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=10) "sample-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=10) "sample-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=10) "sample-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=83) "ReplicaSet \"test-rolling-update-deployment-7ddb77f68b\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Apr 19 17:01:00.513: INFO: New ReplicaSet "test-rolling-update-deployment-7ddb77f68b" of Deployment "test-rolling-update-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rolling-update-deployment-7ddb77f68b",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6740",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c2472e19-a9f7-4e43-b53a-546a71ffa30c",
      ResourceVersion: (string) (len=5) "27850",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849142858,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7ddb77f68b"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "624f39e8-99b3-4758-8e7c-6ec94e685f10",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 36 32 34 66 33 39  65 38 2d 39 39 62 33 2d  |\"624f39e8-99b3-|
              00000120  34 37 35 38 2d 38 65 37  63 2d 36 65 63 39 34 65  |4758-8e7c-6ec94e|
              00000130  36 38 35 66 31 30 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |685f10\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "7ddb77f68b",
          (string) (len=4) "name": (string) (len=10) "sample-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "7ddb77f68b"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 19 17:01:00.516: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
  Apr 19 17:01:00.516: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6740",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "fc9fae42-12e2-4c22-9d39-b7b1495f93c9",
      ResourceVersion: (string) (len=5) "27862",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849142853,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305832"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "624f39e8-99b3-4758-8e7c-6ec94e685f10",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142853,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=533) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  2c 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |,"f:labels":{"."|
              00000060  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000070  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              00000080  73 70 65 63 22 3a 7b 22  66 3a 73 65 6c 65 63 74  |spec":{"f:select|
              00000090  6f 72 22 3a 7b 7d 2c 22  66 3a 74 65 6d 70 6c 61  |or":{},"f:templa|
              000000a0  74 65 22 3a 7b 22 66 3a  6d 65 74 61 64 61 74 61  |te":{"f:metadata|
              000000b0  22 3a 7b 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |":{"f:labels":{"|
              000000c0  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              000000d0  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 7d 2c 22  |},"f:pod":{}}},"|
              000000e0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000f0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              00000100  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              00000110  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000120  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000130  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000140  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000150  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 74 65  |ources":{},"f:te|
              00000160  72 6d 69 6e 61 74 69 6f  6e 4d 65 73 73 61 67 65  |rminationMessage|
              00000170  50 61 74 68 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |Path":{},"f:term|
              00000180  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 6f  |inationMessagePo|
              00000190  6c 69 63 79 22 3a 7b 7d  7d 7d 2c 22 66 3a 64 6e  |licy":{}}},"f:dn|
              000001a0  73 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 72  |sPolicy":{},"f:r|
              000001b0  65 73 74 61 72 74 50 6f  6c 69 63 79 22 3a 7b 7d  |estartPolicy":{}|
              000001c0  2c 22 66 3a 73 63 68 65  64 75 6c 65 72 4e 61 6d  |,"f:schedulerNam|
              000001d0  65 22 3a 7b 7d 2c 22 66  3a 73 65 63 75 72 69 74  |e":{},"f:securit|
              000001e0  79 43 6f 6e 74 65 78 74  22 3a 7b 7d 2c 22 66 3a  |yContext":{},"f:|
              000001f0  74 65 72 6d 69 6e 61 74  69 6f 6e 47 72 61 63 65  |terminationGrace|
              00000200  50 65 72 69 6f 64 53 65  63 6f 6e 64 73 22 3a 7b  |PeriodSeconds":{|
              00000210  7d 7d 7d 7d 7d                                    |}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=242) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 64 65 70 6c 6f  79 6d 65 6e 74 2e 6b 75  |"f:deployment.ku|
              00000030  62 65 72 6e 65 74 65 73  2e 69 6f 2f 64 65 73 69  |bernetes.io/desi|
              00000040  72 65 64 2d 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |red-replicas":{}|
              00000050  2c 22 66 3a 64 65 70 6c  6f 79 6d 65 6e 74 2e 6b  |,"f:deployment.k|
              00000060  75 62 65 72 6e 65 74 65  73 2e 69 6f 2f 6d 61 78  |ubernetes.io/max|
              00000070  2d 72 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 2c 22  |-replicas":{}},"|
              00000080  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000090  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              000000a0  22 75 69 64 5c 22 3a 5c  22 36 32 34 66 33 39 65  |"uid\":\"624f39e|
              000000b0  38 2d 39 39 62 33 2d 34  37 35 38 2d 38 65 37 63  |8-99b3-4758-8e7c|
              000000c0  2d 36 65 63 39 34 65 36  38 35 66 31 30 5c 22 7d  |-6ec94e685f10\"}|
              000000d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000000e0  7b 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |{"f:replicas":{}|
              000000f0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 19 17:01:00.535: INFO: Pod "test-rolling-update-deployment-7ddb77f68b-pnbfw" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=47) "test-rolling-update-deployment-7ddb77f68b-pnbfw",
      GenerateName: (string) (len=42) "test-rolling-update-deployment-7ddb77f68b-",
      Namespace: (string) (len=15) "deployment-6740",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7a7b7cba-460d-4deb-9984-aed5f7acfc4c",
      ResourceVersion: (string) (len=5) "27849",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849142858,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7ddb77f68b"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=41) "test-rolling-update-deployment-7ddb77f68b",
          UID: (types.UID) (len=36) "c2472e19-a9f7-4e43-b53a-546a71ffa30c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 32  34 37 32 65 31 39 2d 61  |d\":\"c2472e19-a|
              00000090  39 66 37 2d 34 65 34 33  2d 62 35 33 61 2d 35 34  |9f7-4e43-b53a-54|
              000000a0  36 61 37 31 66 66 61 33  30 63 5c 22 7d 22 3a 7b  |6a71ffa30c\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 36 2e  37 36 5c 22 7d 22 3a 7b  |.233.66.76\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-5qnnt",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-5qnnt",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "co4fe9zoo9oc-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.60",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.60"
        }
      },
      PodIP: (string) (len=12) "10.233.66.76",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.66.76"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849142858,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63849142859,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:c9997bf8d2e223d7d2a0078dcfb11a653e9b16cf09418829ec03e1d57ca9628a",
          ContainerID: (string) (len=72) "cri-o://1e35d2f0c4085830d60f3add8912d313059ca5d5f6463383b7da7cce7b4ab86d",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 19 17:01:00.568: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-6740" for this suite. @ 04/19/24 17:01:00.577
• [7.248 seconds]
------------------------------
SSS
------------------------------
[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:227
  STEP: Creating a kubernetes client @ 04/19/24 17:01:00.591
  Apr 19 17:01:00.591: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename pods @ 04/19/24 17:01:00.595
  E0419 17:01:00.632365      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:01:00.636
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:01:00.64
  STEP: creating the pod @ 04/19/24 17:01:00.646
  STEP: setting up watch @ 04/19/24 17:01:00.646
  STEP: submitting the pod to kubernetes @ 04/19/24 17:01:00.753
  STEP: verifying the pod is in kubernetes @ 04/19/24 17:01:00.766
  STEP: verifying pod creation was observed @ 04/19/24 17:01:00.772
  E0419 17:01:01.633675      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:02.634202      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 04/19/24 17:01:02.803
  STEP: verifying pod deletion was observed @ 04/19/24 17:01:02.823
  E0419 17:01:03.635245      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:01:04.050: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8718" for this suite. @ 04/19/24 17:01:04.061
• [3.488 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1373
  STEP: Creating a kubernetes client @ 04/19/24 17:01:04.081
  Apr 19 17:01:04.081: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename kubectl @ 04/19/24 17:01:04.085
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:01:04.118
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:01:04.123
  STEP: validating cluster-info @ 04/19/24 17:01:04.13
  Apr 19 17:01:04.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-3111 cluster-info'
  Apr 19 17:01:04.308: INFO: stderr: ""
  Apr 19 17:01:04.308: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.233.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
  Apr 19 17:01:04.309: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3111" for this suite. @ 04/19/24 17:01:04.315
• [0.243 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_inline.go:157
  STEP: Creating a kubernetes client @ 04/19/24 17:01:04.324
  Apr 19 17:01:04.324: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename csiinlinevolumes @ 04/19/24 17:01:04.327
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:01:04.356
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:01:04.36
  STEP: Creating two CSIDrivers @ 04/19/24 17:01:04.365
  STEP: Getting "inline-driver-0795b975-f5d5-493c-be24-589d9a457bd8" & "inline-driver-d975d808-7d92-436b-9a65-e3b2f65ba54c" @ 04/19/24 17:01:04.39
  STEP: Patching the CSIDriver "inline-driver-d975d808-7d92-436b-9a65-e3b2f65ba54c" @ 04/19/24 17:01:04.401
  STEP: Updating the CSIDriver "inline-driver-d975d808-7d92-436b-9a65-e3b2f65ba54c" @ 04/19/24 17:01:04.418
  STEP: Listing all CSIDrivers with the labelSelector: "e2e-test=csiinlinevolumes-8214" @ 04/19/24 17:01:04.429
  STEP: Deleting CSIDriver "inline-driver-0795b975-f5d5-493c-be24-589d9a457bd8" @ 04/19/24 17:01:04.434
  STEP: Confirm deletion of CSIDriver "inline-driver-0795b975-f5d5-493c-be24-589d9a457bd8" @ 04/19/24 17:01:04.443
  STEP: Deleting CSIDriver "inline-driver-d975d808-7d92-436b-9a65-e3b2f65ba54c" via DeleteCollection @ 04/19/24 17:01:04.447
  STEP: Confirm deletion of CSIDriver "inline-driver-d975d808-7d92-436b-9a65-e3b2f65ba54c" @ 04/19/24 17:01:04.46
  Apr 19 17:01:04.465: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-8214" for this suite. @ 04/19/24 17:01:04.474
• [0.159 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:349
  STEP: Creating a kubernetes client @ 04/19/24 17:01:04.492
  Apr 19 17:01:04.492: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename disruption @ 04/19/24 17:01:04.495
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:01:04.524
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:01:04.532
  STEP: Creating a pdb that targets all three pods in a test replica set @ 04/19/24 17:01:04.539
  STEP: Waiting for the pdb to be processed @ 04/19/24 17:01:04.553
  STEP: First trying to evict a pod which shouldn't be evictable @ 04/19/24 17:01:04.573
  STEP: Waiting for all pods to be running @ 04/19/24 17:01:04.573
  Apr 19 17:01:04.585: INFO: pods: 0 < 3
  E0419 17:01:04.634811      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:05.635615      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 04/19/24 17:01:06.583
  STEP: Updating the pdb to allow a pod to be evicted @ 04/19/24 17:01:06.607
  STEP: Waiting for the pdb to be processed @ 04/19/24 17:01:06.629
  E0419 17:01:06.636665      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:07.637039      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:08.637467      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 04/19/24 17:01:08.639
  STEP: Waiting for all pods to be running @ 04/19/24 17:01:08.64
  STEP: Waiting for the pdb to observed all healthy pods @ 04/19/24 17:01:08.647
  STEP: Patching the pdb to disallow a pod to be evicted @ 04/19/24 17:01:08.711
  STEP: Waiting for the pdb to be processed @ 04/19/24 17:01:08.744
  E0419 17:01:09.638525      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:10.639288      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 04/19/24 17:01:10.753
  STEP: locating a running pod @ 04/19/24 17:01:10.763
  STEP: Deleting the pdb to allow a pod to be evicted @ 04/19/24 17:01:10.793
  STEP: Waiting for the pdb to be deleted @ 04/19/24 17:01:10.81
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 04/19/24 17:01:10.82
  STEP: Waiting for all pods to be running @ 04/19/24 17:01:10.82
  Apr 19 17:01:10.867: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-807" for this suite. @ 04/19/24 17:01:10.88
• [6.422 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/flowcontrol.go:514
  STEP: Creating a kubernetes client @ 04/19/24 17:01:10.914
  Apr 19 17:01:10.914: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename apf @ 04/19/24 17:01:10.916
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:01:10.945
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:01:10.95
  STEP: getting /apis @ 04/19/24 17:01:10.99
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 04/19/24 17:01:11.002
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 04/19/24 17:01:11.006
  STEP: creating @ 04/19/24 17:01:11.009
  STEP: getting @ 04/19/24 17:01:11.045
  STEP: listing @ 04/19/24 17:01:11.052
  STEP: watching @ 04/19/24 17:01:11.058
  Apr 19 17:01:11.059: INFO: starting watch
  STEP: patching @ 04/19/24 17:01:11.062
  STEP: updating @ 04/19/24 17:01:11.074
  Apr 19 17:01:11.089: INFO: waiting for watch events with expected annotations
  STEP: getting /status @ 04/19/24 17:01:11.089
  STEP: patching /status @ 04/19/24 17:01:11.097
  STEP: updating /status @ 04/19/24 17:01:11.108
  STEP: deleting @ 04/19/24 17:01:11.122
  STEP: deleting a collection @ 04/19/24 17:01:11.146
  Apr 19 17:01:11.185: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-5504" for this suite. @ 04/19/24 17:01:11.194
• [0.293 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:215
  STEP: Creating a kubernetes client @ 04/19/24 17:01:11.211
  Apr 19 17:01:11.212: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename projected @ 04/19/24 17:01:11.216
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:01:11.25
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:01:11.254
  STEP: Creating secret with name s-test-opt-del-1dea194f-ff75-4d39-a34c-889f02f2b645 @ 04/19/24 17:01:11.268
  STEP: Creating secret with name s-test-opt-upd-ec347fff-ecb9-456e-8cc8-219b33e14b42 @ 04/19/24 17:01:11.28
  STEP: Creating the pod @ 04/19/24 17:01:11.287
  E0419 17:01:11.639931      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:12.640266      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-1dea194f-ff75-4d39-a34c-889f02f2b645 @ 04/19/24 17:01:13.427
  STEP: Updating secret s-test-opt-upd-ec347fff-ecb9-456e-8cc8-219b33e14b42 @ 04/19/24 17:01:13.45
  STEP: Creating secret with name s-test-opt-create-48b9d24e-45d7-4060-aa4e-46df37d73cfd @ 04/19/24 17:01:13.476
  STEP: waiting to observe update in volume @ 04/19/24 17:01:13.488
  E0419 17:01:13.641233      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:14.641660      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:15.644181      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:16.643142      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:01:17.568: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1048" for this suite. @ 04/19/24 17:01:17.578
• [6.431 seconds]
  E0419 17:01:17.643173      13 retrywatcher.go:129] "Watch failed" err="context canceled"
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:399
  STEP: Creating a kubernetes client @ 04/19/24 17:01:17.65
  Apr 19 17:01:17.650: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename pods @ 04/19/24 17:01:17.655
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:01:17.681
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:01:17.685
  STEP: creating the pod @ 04/19/24 17:01:17.691
  STEP: submitting the pod to kubernetes @ 04/19/24 17:01:17.692
  W0419 17:01:17.706629      13 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  E0419 17:01:18.643521      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:19.643711      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 04/19/24 17:01:19.739
  STEP: updating the pod @ 04/19/24 17:01:19.749
  Apr 19 17:01:20.277: INFO: Successfully updated pod "pod-update-activedeadlineseconds-accaea24-788d-4fe5-a47c-f845ccd28ded"
  E0419 17:01:20.644723      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:21.644888      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:22.645624      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:23.646410      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:01:24.303: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-4157" for this suite. @ 04/19/24 17:01:24.313
• [6.674 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:269
  STEP: Creating a kubernetes client @ 04/19/24 17:01:24.334
  Apr 19 17:01:24.334: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename downward-api @ 04/19/24 17:01:24.337
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:01:24.369
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:01:24.374
  STEP: Creating a pod to test downward api env vars @ 04/19/24 17:01:24.382
  E0419 17:01:24.647242      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:25.653715      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:01:26.416
  Apr 19 17:01:26.422: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod downward-api-b993e43b-6298-405e-88c9-6158561dc496 container dapi-container: <nil>
  STEP: delete the pod @ 04/19/24 17:01:26.446
  Apr 19 17:01:26.481: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5463" for this suite. @ 04/19/24 17:01:26.491
• [2.177 seconds]
------------------------------
S
------------------------------
[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:101
  STEP: Creating a kubernetes client @ 04/19/24 17:01:26.513
  Apr 19 17:01:26.513: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename proxy @ 04/19/24 17:01:26.518
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:01:26.545
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:01:26.549
  STEP: starting an echo server on multiple ports @ 04/19/24 17:01:26.578
  STEP: creating replication controller proxy-service-wb44x in namespace proxy-3103 @ 04/19/24 17:01:26.579
  I0419 17:01:26.591717      13 runners.go:197] Created replication controller with name: proxy-service-wb44x, namespace: proxy-3103, replica count: 1
  E0419 17:01:26.653801      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:01:27.645053      13 runners.go:197] proxy-service-wb44x Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E0419 17:01:27.654524      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:01:28.646173      13 runners.go:197] proxy-service-wb44x Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E0419 17:01:28.655443      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:01:28.661: INFO: setup took 2.106805804s, starting test cases
  STEP: running 16 cases, 20 attempts per case, 320 total attempts @ 04/19/24 17:01:28.661
  Apr 19 17:01:28.684: INFO: (0) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/rewriteme">test</a> (200; 21.868463ms)
  Apr 19 17:01:28.699: INFO: (0) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/rewriteme">... (200; 34.561153ms)
  Apr 19 17:01:28.699: INFO: (0) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname1/proxy/: foo (200; 35.92437ms)
  Apr 19 17:01:28.699: INFO: (0) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/rewriteme">test<... (200; 34.988123ms)
  Apr 19 17:01:28.702: INFO: (0) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:160/proxy/: foo (200; 37.430631ms)
  Apr 19 17:01:28.699: INFO: (0) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:160/proxy/: foo (200; 36.622263ms)
  Apr 19 17:01:28.710: INFO: (0) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname1/proxy/: tls baz (200; 46.065331ms)
  Apr 19 17:01:28.712: INFO: (0) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:460/proxy/: tls baz (200; 48.690822ms)
  Apr 19 17:01:28.713: INFO: (0) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname2/proxy/: tls qux (200; 49.07219ms)
  Apr 19 17:01:28.713: INFO: (0) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:462/proxy/: tls qux (200; 50.396522ms)
  Apr 19 17:01:28.714: INFO: (0) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:162/proxy/: bar (200; 49.624575ms)
  Apr 19 17:01:28.715: INFO: (0) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname2/proxy/: bar (200; 52.263282ms)
  Apr 19 17:01:28.715: INFO: (0) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:162/proxy/: bar (200; 52.427748ms)
  Apr 19 17:01:28.715: INFO: (0) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname1/proxy/: foo (200; 51.174059ms)
  Apr 19 17:01:28.715: INFO: (0) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname2/proxy/: bar (200; 51.57312ms)
  Apr 19 17:01:28.718: INFO: (0) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/tlsrewritem... (200; 55.215966ms)
  Apr 19 17:01:28.732: INFO: (1) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:162/proxy/: bar (200; 13.042383ms)
  Apr 19 17:01:28.734: INFO: (1) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/rewriteme">... (200; 15.671731ms)
  Apr 19 17:01:28.735: INFO: (1) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/rewriteme">test<... (200; 16.283197ms)
  Apr 19 17:01:28.735: INFO: (1) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:160/proxy/: foo (200; 16.862711ms)
  Apr 19 17:01:28.736: INFO: (1) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/rewriteme">test</a> (200; 17.504524ms)
  Apr 19 17:01:28.737: INFO: (1) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:462/proxy/: tls qux (200; 17.810371ms)
  Apr 19 17:01:28.737: INFO: (1) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname2/proxy/: tls qux (200; 18.104474ms)
  Apr 19 17:01:28.739: INFO: (1) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/tlsrewritem... (200; 19.791575ms)
  Apr 19 17:01:28.739: INFO: (1) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:460/proxy/: tls baz (200; 20.006319ms)
  Apr 19 17:01:28.740: INFO: (1) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:160/proxy/: foo (200; 21.216933ms)
  Apr 19 17:01:28.740: INFO: (1) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname1/proxy/: foo (200; 21.531152ms)
  Apr 19 17:01:28.740: INFO: (1) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:162/proxy/: bar (200; 21.229573ms)
  Apr 19 17:01:28.741: INFO: (1) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname1/proxy/: tls baz (200; 21.618612ms)
  Apr 19 17:01:28.741: INFO: (1) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname2/proxy/: bar (200; 21.704627ms)
  Apr 19 17:01:28.741: INFO: (1) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname1/proxy/: foo (200; 22.274619ms)
  Apr 19 17:01:28.741: INFO: (1) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname2/proxy/: bar (200; 23.445056ms)
  Apr 19 17:01:28.758: INFO: (2) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:162/proxy/: bar (200; 15.913351ms)
  Apr 19 17:01:28.759: INFO: (2) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:460/proxy/: tls baz (200; 17.33803ms)
  Apr 19 17:01:28.763: INFO: (2) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname1/proxy/: foo (200; 21.156312ms)
  Apr 19 17:01:28.764: INFO: (2) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/rewriteme">test</a> (200; 21.320192ms)
  Apr 19 17:01:28.765: INFO: (2) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:160/proxy/: foo (200; 22.409091ms)
  Apr 19 17:01:28.766: INFO: (2) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/rewriteme">test<... (200; 23.393881ms)
  Apr 19 17:01:28.766: INFO: (2) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:160/proxy/: foo (200; 23.421638ms)
  Apr 19 17:01:28.766: INFO: (2) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname1/proxy/: tls baz (200; 23.87038ms)
  Apr 19 17:01:28.766: INFO: (2) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/rewriteme">... (200; 23.269048ms)
  Apr 19 17:01:28.767: INFO: (2) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname1/proxy/: foo (200; 24.446261ms)
  Apr 19 17:01:28.767: INFO: (2) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname2/proxy/: bar (200; 24.859284ms)
  Apr 19 17:01:28.768: INFO: (2) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:462/proxy/: tls qux (200; 24.753572ms)
  Apr 19 17:01:28.768: INFO: (2) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:162/proxy/: bar (200; 24.992405ms)
  Apr 19 17:01:28.768: INFO: (2) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/tlsrewritem... (200; 24.898852ms)
  Apr 19 17:01:28.768: INFO: (2) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname2/proxy/: tls qux (200; 25.663595ms)
  Apr 19 17:01:28.768: INFO: (2) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname2/proxy/: bar (200; 25.28558ms)
  Apr 19 17:01:28.786: INFO: (3) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:162/proxy/: bar (200; 12.893952ms)
  Apr 19 17:01:28.787: INFO: (3) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:160/proxy/: foo (200; 13.434426ms)
  Apr 19 17:01:28.786: INFO: (3) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/rewriteme">test</a> (200; 14.019741ms)
  Apr 19 17:01:28.789: INFO: (3) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:162/proxy/: bar (200; 14.918545ms)
  Apr 19 17:01:28.790: INFO: (3) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:160/proxy/: foo (200; 16.37651ms)
  Apr 19 17:01:28.791: INFO: (3) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname2/proxy/: bar (200; 18.70714ms)
  Apr 19 17:01:28.793: INFO: (3) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/rewriteme">... (200; 18.495977ms)
  Apr 19 17:01:28.793: INFO: (3) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:460/proxy/: tls baz (200; 18.786269ms)
  Apr 19 17:01:28.793: INFO: (3) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname2/proxy/: bar (200; 19.127758ms)
  Apr 19 17:01:28.793: INFO: (3) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/tlsrewritem... (200; 18.648793ms)
  Apr 19 17:01:28.796: INFO: (3) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname2/proxy/: tls qux (200; 22.987463ms)
  Apr 19 17:01:28.796: INFO: (3) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/rewriteme">test<... (200; 23.215417ms)
  Apr 19 17:01:28.797: INFO: (3) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname1/proxy/: foo (200; 23.351687ms)
  Apr 19 17:01:28.797: INFO: (3) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:462/proxy/: tls qux (200; 24.727565ms)
  Apr 19 17:01:28.797: INFO: (3) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname1/proxy/: tls baz (200; 24.328267ms)
  Apr 19 17:01:28.799: INFO: (3) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname1/proxy/: foo (200; 24.897129ms)
  Apr 19 17:01:28.807: INFO: (4) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/rewriteme">test<... (200; 7.36901ms)
  Apr 19 17:01:28.808: INFO: (4) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/rewriteme">test</a> (200; 8.3279ms)
  Apr 19 17:01:28.814: INFO: (4) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/tlsrewritem... (200; 14.878783ms)
  Apr 19 17:01:28.815: INFO: (4) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname2/proxy/: bar (200; 15.114812ms)
  Apr 19 17:01:28.815: INFO: (4) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:160/proxy/: foo (200; 14.398818ms)
  Apr 19 17:01:28.815: INFO: (4) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:462/proxy/: tls qux (200; 15.833987ms)
  Apr 19 17:01:28.816: INFO: (4) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:460/proxy/: tls baz (200; 15.574188ms)
  Apr 19 17:01:28.822: INFO: (4) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:162/proxy/: bar (200; 21.720598ms)
  Apr 19 17:01:28.822: INFO: (4) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:162/proxy/: bar (200; 22.136834ms)
  Apr 19 17:01:28.822: INFO: (4) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:160/proxy/: foo (200; 22.015919ms)
  Apr 19 17:01:28.822: INFO: (4) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname1/proxy/: foo (200; 22.591857ms)
  Apr 19 17:01:28.822: INFO: (4) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname2/proxy/: bar (200; 21.932037ms)
  Apr 19 17:01:28.822: INFO: (4) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/rewriteme">... (200; 22.500007ms)
  Apr 19 17:01:28.822: INFO: (4) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname2/proxy/: tls qux (200; 22.487392ms)
  Apr 19 17:01:28.822: INFO: (4) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname1/proxy/: foo (200; 22.011763ms)
  Apr 19 17:01:28.829: INFO: (4) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname1/proxy/: tls baz (200; 29.019848ms)
  Apr 19 17:01:28.844: INFO: (5) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:162/proxy/: bar (200; 13.713561ms)
  Apr 19 17:01:28.845: INFO: (5) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:162/proxy/: bar (200; 14.601477ms)
  Apr 19 17:01:28.845: INFO: (5) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/rewriteme">... (200; 15.053036ms)
  Apr 19 17:01:28.845: INFO: (5) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/rewriteme">test</a> (200; 14.351464ms)
  Apr 19 17:01:28.845: INFO: (5) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:460/proxy/: tls baz (200; 16.330455ms)
  Apr 19 17:01:28.850: INFO: (5) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:160/proxy/: foo (200; 19.217876ms)
  Apr 19 17:01:28.851: INFO: (5) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname1/proxy/: foo (200; 21.812148ms)
  Apr 19 17:01:28.852: INFO: (5) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/rewriteme">test<... (200; 21.348069ms)
  Apr 19 17:01:28.852: INFO: (5) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname1/proxy/: tls baz (200; 22.975387ms)
  Apr 19 17:01:28.852: INFO: (5) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:462/proxy/: tls qux (200; 21.153167ms)
  Apr 19 17:01:28.853: INFO: (5) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:160/proxy/: foo (200; 22.63529ms)
  Apr 19 17:01:28.854: INFO: (5) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname1/proxy/: foo (200; 23.339247ms)
  Apr 19 17:01:28.855: INFO: (5) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname2/proxy/: bar (200; 23.557972ms)
  Apr 19 17:01:28.855: INFO: (5) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname2/proxy/: bar (200; 25.196836ms)
  Apr 19 17:01:28.855: INFO: (5) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/tlsrewritem... (200; 24.714811ms)
  Apr 19 17:01:28.856: INFO: (5) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname2/proxy/: tls qux (200; 25.266168ms)
  Apr 19 17:01:28.879: INFO: (6) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:462/proxy/: tls qux (200; 19.831788ms)
  Apr 19 17:01:28.881: INFO: (6) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/rewriteme">... (200; 21.235611ms)
  Apr 19 17:01:28.881: INFO: (6) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/tlsrewritem... (200; 22.028612ms)
  Apr 19 17:01:28.881: INFO: (6) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname2/proxy/: bar (200; 22.672477ms)
  Apr 19 17:01:28.882: INFO: (6) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:162/proxy/: bar (200; 22.584117ms)
  Apr 19 17:01:28.882: INFO: (6) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/rewriteme">test</a> (200; 23.184377ms)
  Apr 19 17:01:28.882: INFO: (6) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:460/proxy/: tls baz (200; 21.216624ms)
  Apr 19 17:01:28.882: INFO: (6) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:160/proxy/: foo (200; 21.362959ms)
  Apr 19 17:01:28.882: INFO: (6) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname1/proxy/: foo (200; 23.942449ms)
  Apr 19 17:01:28.884: INFO: (6) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname1/proxy/: foo (200; 22.757637ms)
  Apr 19 17:01:28.885: INFO: (6) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname1/proxy/: tls baz (200; 24.575296ms)
  Apr 19 17:01:28.886: INFO: (6) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/rewriteme">test<... (200; 25.573133ms)
  Apr 19 17:01:28.888: INFO: (6) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:162/proxy/: bar (200; 26.508995ms)
  Apr 19 17:01:28.889: INFO: (6) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:160/proxy/: foo (200; 28.096452ms)
  Apr 19 17:01:28.891: INFO: (6) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname2/proxy/: bar (200; 30.420007ms)
  Apr 19 17:01:28.892: INFO: (6) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname2/proxy/: tls qux (200; 31.420839ms)
  Apr 19 17:01:28.901: INFO: (7) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:162/proxy/: bar (200; 8.226653ms)
  Apr 19 17:01:28.912: INFO: (7) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:460/proxy/: tls baz (200; 18.905393ms)
  Apr 19 17:01:28.912: INFO: (7) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/rewriteme">test</a> (200; 18.532921ms)
  Apr 19 17:01:28.912: INFO: (7) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname1/proxy/: foo (200; 19.45541ms)
  Apr 19 17:01:28.913: INFO: (7) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:160/proxy/: foo (200; 20.055037ms)
  Apr 19 17:01:28.914: INFO: (7) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/rewriteme">... (200; 21.161984ms)
  Apr 19 17:01:28.915: INFO: (7) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/rewriteme">test<... (200; 22.040238ms)
  Apr 19 17:01:28.916: INFO: (7) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:160/proxy/: foo (200; 22.060387ms)
  Apr 19 17:01:28.919: INFO: (7) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname1/proxy/: tls baz (200; 25.952078ms)
  Apr 19 17:01:28.919: INFO: (7) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/tlsrewritem... (200; 26.003445ms)
  Apr 19 17:01:28.922: INFO: (7) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname1/proxy/: foo (200; 29.0292ms)
  Apr 19 17:01:28.923: INFO: (7) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:162/proxy/: bar (200; 29.333469ms)
  Apr 19 17:01:28.923: INFO: (7) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname2/proxy/: bar (200; 29.57137ms)
  Apr 19 17:01:28.924: INFO: (7) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:462/proxy/: tls qux (200; 30.98517ms)
  Apr 19 17:01:28.924: INFO: (7) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname2/proxy/: bar (200; 31.392605ms)
  Apr 19 17:01:28.924: INFO: (7) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname2/proxy/: tls qux (200; 31.124771ms)
  Apr 19 17:01:28.993: INFO: (8) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:462/proxy/: tls qux (200; 68.112997ms)
  Apr 19 17:01:29.001: INFO: (8) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/rewriteme">test</a> (200; 75.874876ms)
  Apr 19 17:01:29.002: INFO: (8) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/rewriteme">test<... (200; 75.012185ms)
  Apr 19 17:01:29.003: INFO: (8) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:162/proxy/: bar (200; 76.748362ms)
  Apr 19 17:01:29.007: INFO: (8) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/tlsrewritem... (200; 80.490732ms)
  Apr 19 17:01:29.016: INFO: (8) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:160/proxy/: foo (200; 90.248498ms)
  Apr 19 17:01:29.016: INFO: (8) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/rewriteme">... (200; 89.908408ms)
  Apr 19 17:01:29.026: INFO: (8) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:162/proxy/: bar (200; 98.823429ms)
  Apr 19 17:01:29.027: INFO: (8) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:460/proxy/: tls baz (200; 100.562987ms)
  Apr 19 17:01:29.027: INFO: (8) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:160/proxy/: foo (200; 99.887917ms)
  Apr 19 17:01:29.029: INFO: (8) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname2/proxy/: bar (200; 102.888144ms)
  Apr 19 17:01:29.029: INFO: (8) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname1/proxy/: foo (200; 103.040254ms)
  Apr 19 17:01:29.029: INFO: (8) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname2/proxy/: bar (200; 103.027433ms)
  Apr 19 17:01:29.029: INFO: (8) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname1/proxy/: tls baz (200; 102.864881ms)
  Apr 19 17:01:29.030: INFO: (8) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname2/proxy/: tls qux (200; 103.34718ms)
  Apr 19 17:01:29.032: INFO: (8) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname1/proxy/: foo (200; 104.741303ms)
  Apr 19 17:01:29.060: INFO: (9) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:162/proxy/: bar (200; 26.982052ms)
  Apr 19 17:01:29.075: INFO: (9) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname1/proxy/: foo (200; 41.679735ms)
  Apr 19 17:01:29.093: INFO: (9) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/rewriteme">... (200; 58.132597ms)
  Apr 19 17:01:29.094: INFO: (9) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:162/proxy/: bar (200; 57.927858ms)
  Apr 19 17:01:29.094: INFO: (9) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/rewriteme">test<... (200; 57.669128ms)
  Apr 19 17:01:29.094: INFO: (9) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/rewriteme">test</a> (200; 60.355388ms)
  Apr 19 17:01:29.094: INFO: (9) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:160/proxy/: foo (200; 60.174832ms)
  Apr 19 17:01:29.094: INFO: (9) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:462/proxy/: tls qux (200; 58.47117ms)
  Apr 19 17:01:29.096: INFO: (9) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname1/proxy/: foo (200; 61.820078ms)
  Apr 19 17:01:29.097: INFO: (9) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname2/proxy/: bar (200; 61.998779ms)
  Apr 19 17:01:29.099: INFO: (9) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:160/proxy/: foo (200; 65.983895ms)
  Apr 19 17:01:29.100: INFO: (9) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname2/proxy/: tls qux (200; 64.229345ms)
  Apr 19 17:01:29.101: INFO: (9) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname2/proxy/: bar (200; 66.391751ms)
  Apr 19 17:01:29.103: INFO: (9) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname1/proxy/: tls baz (200; 67.200466ms)
  Apr 19 17:01:29.103: INFO: (9) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:460/proxy/: tls baz (200; 69.158638ms)
  Apr 19 17:01:29.104: INFO: (9) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/tlsrewritem... (200; 68.701685ms)
  Apr 19 17:01:29.156: INFO: (10) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/rewriteme">test<... (200; 51.349151ms)
  Apr 19 17:01:29.156: INFO: (10) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:160/proxy/: foo (200; 51.337776ms)
  Apr 19 17:01:29.158: INFO: (10) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:162/proxy/: bar (200; 53.24966ms)
  Apr 19 17:01:29.159: INFO: (10) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:462/proxy/: tls qux (200; 53.114159ms)
  Apr 19 17:01:29.159: INFO: (10) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname2/proxy/: tls qux (200; 54.706164ms)
  Apr 19 17:01:29.168: INFO: (10) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname2/proxy/: bar (200; 62.286233ms)
  Apr 19 17:01:29.169: INFO: (10) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:162/proxy/: bar (200; 63.677294ms)
  Apr 19 17:01:29.169: INFO: (10) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/rewriteme">test</a> (200; 64.251828ms)
  Apr 19 17:01:29.169: INFO: (10) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:160/proxy/: foo (200; 63.924765ms)
  Apr 19 17:01:29.172: INFO: (10) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname1/proxy/: foo (200; 66.377008ms)
  Apr 19 17:01:29.172: INFO: (10) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname2/proxy/: bar (200; 66.735104ms)
  Apr 19 17:01:29.172: INFO: (10) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname1/proxy/: tls baz (200; 66.719836ms)
  Apr 19 17:01:29.172: INFO: (10) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:460/proxy/: tls baz (200; 67.660299ms)
  Apr 19 17:01:29.172: INFO: (10) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/rewriteme">... (200; 67.851025ms)
  Apr 19 17:01:29.172: INFO: (10) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/tlsrewritem... (200; 67.227257ms)
  Apr 19 17:01:29.173: INFO: (10) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname1/proxy/: foo (200; 68.716986ms)
  Apr 19 17:01:29.191: INFO: (11) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:162/proxy/: bar (200; 16.227264ms)
  Apr 19 17:01:29.191: INFO: (11) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/rewriteme">... (200; 16.37608ms)
  Apr 19 17:01:29.198: INFO: (11) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/tlsrewritem... (200; 23.89585ms)
  Apr 19 17:01:29.199: INFO: (11) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname2/proxy/: bar (200; 24.623248ms)
  Apr 19 17:01:29.202: INFO: (11) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:462/proxy/: tls qux (200; 27.342157ms)
  Apr 19 17:01:29.203: INFO: (11) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:160/proxy/: foo (200; 28.560405ms)
  Apr 19 17:01:29.204: INFO: (11) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:160/proxy/: foo (200; 28.956392ms)
  Apr 19 17:01:29.205: INFO: (11) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname2/proxy/: tls qux (200; 30.466303ms)
  Apr 19 17:01:29.206: INFO: (11) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/rewriteme">test<... (200; 31.519835ms)
  Apr 19 17:01:29.206: INFO: (11) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname1/proxy/: tls baz (200; 32.288487ms)
  Apr 19 17:01:29.206: INFO: (11) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/rewriteme">test</a> (200; 31.468691ms)
  Apr 19 17:01:29.206: INFO: (11) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:162/proxy/: bar (200; 31.75391ms)
  Apr 19 17:01:29.206: INFO: (11) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:460/proxy/: tls baz (200; 31.649904ms)
  Apr 19 17:01:29.207: INFO: (11) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname1/proxy/: foo (200; 32.570744ms)
  Apr 19 17:01:29.209: INFO: (11) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname2/proxy/: bar (200; 34.206871ms)
  Apr 19 17:01:29.210: INFO: (11) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname1/proxy/: foo (200; 34.705367ms)
  Apr 19 17:01:29.232: INFO: (12) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/rewriteme">test<... (200; 21.223665ms)
  Apr 19 17:01:29.239: INFO: (12) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/rewriteme">... (200; 28.337923ms)
  Apr 19 17:01:29.239: INFO: (12) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:160/proxy/: foo (200; 27.626959ms)
  Apr 19 17:01:29.239: INFO: (12) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/tlsrewritem... (200; 28.845373ms)
  Apr 19 17:01:29.243: INFO: (12) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/rewriteme">test</a> (200; 32.030267ms)
  Apr 19 17:01:29.244: INFO: (12) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:160/proxy/: foo (200; 32.271062ms)
  Apr 19 17:01:29.244: INFO: (12) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:162/proxy/: bar (200; 33.795503ms)
  Apr 19 17:01:29.244: INFO: (12) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname2/proxy/: bar (200; 33.18959ms)
  Apr 19 17:01:29.244: INFO: (12) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname1/proxy/: foo (200; 32.899932ms)
  Apr 19 17:01:29.244: INFO: (12) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname2/proxy/: bar (200; 34.340433ms)
  Apr 19 17:01:29.244: INFO: (12) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:462/proxy/: tls qux (200; 33.433451ms)
  Apr 19 17:01:29.244: INFO: (12) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname1/proxy/: foo (200; 32.888385ms)
  Apr 19 17:01:29.244: INFO: (12) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname1/proxy/: tls baz (200; 33.377561ms)
  Apr 19 17:01:29.244: INFO: (12) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:460/proxy/: tls baz (200; 33.097273ms)
  Apr 19 17:01:29.245: INFO: (12) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:162/proxy/: bar (200; 33.972169ms)
  Apr 19 17:01:29.245: INFO: (12) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname2/proxy/: tls qux (200; 34.906263ms)
  Apr 19 17:01:29.256: INFO: (13) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/rewriteme">... (200; 11.125793ms)
  Apr 19 17:01:29.260: INFO: (13) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/rewriteme">test<... (200; 13.845033ms)
  Apr 19 17:01:29.266: INFO: (13) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/rewriteme">test</a> (200; 19.527745ms)
  Apr 19 17:01:29.266: INFO: (13) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:162/proxy/: bar (200; 20.430209ms)
  Apr 19 17:01:29.268: INFO: (13) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname2/proxy/: bar (200; 22.748477ms)
  Apr 19 17:01:29.270: INFO: (13) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:160/proxy/: foo (200; 23.882219ms)
  Apr 19 17:01:29.272: INFO: (13) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/tlsrewritem... (200; 26.05199ms)
  Apr 19 17:01:29.272: INFO: (13) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname2/proxy/: bar (200; 25.917515ms)
  Apr 19 17:01:29.274: INFO: (13) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname1/proxy/: tls baz (200; 28.385585ms)
  Apr 19 17:01:29.275: INFO: (13) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:460/proxy/: tls baz (200; 29.448079ms)
  Apr 19 17:01:29.278: INFO: (13) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:160/proxy/: foo (200; 31.770066ms)
  Apr 19 17:01:29.278: INFO: (13) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:462/proxy/: tls qux (200; 32.680926ms)
  Apr 19 17:01:29.278: INFO: (13) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:162/proxy/: bar (200; 32.287155ms)
  Apr 19 17:01:29.284: INFO: (13) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname1/proxy/: foo (200; 38.490887ms)
  Apr 19 17:01:29.284: INFO: (13) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname2/proxy/: tls qux (200; 38.070684ms)
  Apr 19 17:01:29.285: INFO: (13) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname1/proxy/: foo (200; 38.519296ms)
  Apr 19 17:01:29.310: INFO: (14) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:460/proxy/: tls baz (200; 24.617516ms)
  Apr 19 17:01:29.318: INFO: (14) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname1/proxy/: foo (200; 32.359879ms)
  Apr 19 17:01:29.318: INFO: (14) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:162/proxy/: bar (200; 32.244258ms)
  Apr 19 17:01:29.319: INFO: (14) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:160/proxy/: foo (200; 33.291728ms)
  Apr 19 17:01:29.319: INFO: (14) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:162/proxy/: bar (200; 33.28288ms)
  Apr 19 17:01:29.319: INFO: (14) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:462/proxy/: tls qux (200; 32.977961ms)
  Apr 19 17:01:29.319: INFO: (14) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname2/proxy/: tls qux (200; 33.76508ms)
  Apr 19 17:01:29.319: INFO: (14) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/tlsrewritem... (200; 33.999954ms)
  Apr 19 17:01:29.319: INFO: (14) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/rewriteme">test<... (200; 33.70815ms)
  Apr 19 17:01:29.320: INFO: (14) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/rewriteme">... (200; 34.754585ms)
  Apr 19 17:01:29.321: INFO: (14) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/rewriteme">test</a> (200; 35.221888ms)
  Apr 19 17:01:29.323: INFO: (14) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname2/proxy/: bar (200; 37.237293ms)
  Apr 19 17:01:29.323: INFO: (14) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:160/proxy/: foo (200; 37.246086ms)
  Apr 19 17:01:29.325: INFO: (14) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname1/proxy/: tls baz (200; 39.979417ms)
  Apr 19 17:01:29.333: INFO: (14) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname1/proxy/: foo (200; 47.112439ms)
  Apr 19 17:01:29.333: INFO: (14) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname2/proxy/: bar (200; 47.699058ms)
  Apr 19 17:01:29.343: INFO: (15) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:162/proxy/: bar (200; 9.166913ms)
  Apr 19 17:01:29.344: INFO: (15) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:160/proxy/: foo (200; 10.014327ms)
  Apr 19 17:01:29.353: INFO: (15) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:160/proxy/: foo (200; 18.298034ms)
  Apr 19 17:01:29.353: INFO: (15) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/rewriteme">test</a> (200; 18.26644ms)
  Apr 19 17:01:29.354: INFO: (15) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/tlsrewritem... (200; 18.577442ms)
  Apr 19 17:01:29.362: INFO: (15) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname2/proxy/: tls qux (200; 28.159294ms)
  Apr 19 17:01:29.363: INFO: (15) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname2/proxy/: bar (200; 27.561526ms)
  Apr 19 17:01:29.365: INFO: (15) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname1/proxy/: foo (200; 29.578568ms)
  Apr 19 17:01:29.365: INFO: (15) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/rewriteme">... (200; 29.49854ms)
  Apr 19 17:01:29.396: INFO: (15) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/rewriteme">test<... (200; 62.143121ms)
  Apr 19 17:01:29.396: INFO: (15) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:162/proxy/: bar (200; 62.504405ms)
  Apr 19 17:01:29.398: INFO: (15) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname1/proxy/: tls baz (200; 64.048207ms)
  Apr 19 17:01:29.399: INFO: (15) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:460/proxy/: tls baz (200; 64.221278ms)
  Apr 19 17:01:29.399: INFO: (15) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:462/proxy/: tls qux (200; 63.485899ms)
  Apr 19 17:01:29.405: INFO: (15) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname1/proxy/: foo (200; 70.064776ms)
  Apr 19 17:01:29.409: INFO: (15) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname2/proxy/: bar (200; 74.448543ms)
  Apr 19 17:01:29.422: INFO: (16) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:460/proxy/: tls baz (200; 12.920795ms)
  Apr 19 17:01:29.433: INFO: (16) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/tlsrewritem... (200; 22.66414ms)
  Apr 19 17:01:29.433: INFO: (16) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname1/proxy/: foo (200; 23.484365ms)
  Apr 19 17:01:29.433: INFO: (16) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/rewriteme">... (200; 23.361879ms)
  Apr 19 17:01:29.433: INFO: (16) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:162/proxy/: bar (200; 23.020365ms)
  Apr 19 17:01:29.433: INFO: (16) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:162/proxy/: bar (200; 22.631532ms)
  Apr 19 17:01:29.433: INFO: (16) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:462/proxy/: tls qux (200; 23.014544ms)
  Apr 19 17:01:29.433: INFO: (16) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/rewriteme">test<... (200; 22.663059ms)
  Apr 19 17:01:29.433: INFO: (16) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/rewriteme">test</a> (200; 22.543699ms)
  Apr 19 17:01:29.437: INFO: (16) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname2/proxy/: bar (200; 26.497162ms)
  Apr 19 17:01:29.437: INFO: (16) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:160/proxy/: foo (200; 26.554046ms)
  Apr 19 17:01:29.438: INFO: (16) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname2/proxy/: tls qux (200; 28.469058ms)
  Apr 19 17:01:29.438: INFO: (16) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname2/proxy/: bar (200; 28.948439ms)
  Apr 19 17:01:29.438: INFO: (16) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname1/proxy/: foo (200; 27.620907ms)
  Apr 19 17:01:29.439: INFO: (16) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname1/proxy/: tls baz (200; 30.563973ms)
  Apr 19 17:01:29.439: INFO: (16) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:160/proxy/: foo (200; 29.009839ms)
  Apr 19 17:01:29.449: INFO: (17) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/rewriteme">... (200; 8.759378ms)
  Apr 19 17:01:29.452: INFO: (17) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:160/proxy/: foo (200; 10.902605ms)
  Apr 19 17:01:29.452: INFO: (17) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/rewriteme">test</a> (200; 10.826151ms)
  Apr 19 17:01:29.454: INFO: (17) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:162/proxy/: bar (200; 12.713578ms)
  Apr 19 17:01:29.454: INFO: (17) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:160/proxy/: foo (200; 12.382186ms)
  Apr 19 17:01:29.454: INFO: (17) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:162/proxy/: bar (200; 13.790066ms)
  Apr 19 17:01:29.456: INFO: (17) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:462/proxy/: tls qux (200; 15.330766ms)
  Apr 19 17:01:29.456: INFO: (17) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname2/proxy/: bar (200; 15.784814ms)
  Apr 19 17:01:29.460: INFO: (17) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/rewriteme">test<... (200; 18.413304ms)
  Apr 19 17:01:29.460: INFO: (17) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:460/proxy/: tls baz (200; 18.137472ms)
  Apr 19 17:01:29.460: INFO: (17) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/tlsrewritem... (200; 18.931516ms)
  Apr 19 17:01:29.460: INFO: (17) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname2/proxy/: bar (200; 19.557797ms)
  Apr 19 17:01:29.464: INFO: (17) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname1/proxy/: foo (200; 22.530116ms)
  Apr 19 17:01:29.466: INFO: (17) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname1/proxy/: foo (200; 24.747883ms)
  Apr 19 17:01:29.467: INFO: (17) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname1/proxy/: tls baz (200; 25.83529ms)
  Apr 19 17:01:29.471: INFO: (17) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname2/proxy/: tls qux (200; 30.210715ms)
  Apr 19 17:01:29.485: INFO: (18) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:460/proxy/: tls baz (200; 12.42657ms)
  Apr 19 17:01:29.485: INFO: (18) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/rewriteme">test<... (200; 12.039555ms)
  Apr 19 17:01:29.488: INFO: (18) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:162/proxy/: bar (200; 15.403911ms)
  Apr 19 17:01:29.489: INFO: (18) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/tlsrewritem... (200; 16.454566ms)
  Apr 19 17:01:29.490: INFO: (18) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:160/proxy/: foo (200; 17.377032ms)
  Apr 19 17:01:29.492: INFO: (18) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname1/proxy/: tls baz (200; 20.435303ms)
  Apr 19 17:01:29.492: INFO: (18) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname1/proxy/: foo (200; 19.807647ms)
  Apr 19 17:01:29.492: INFO: (18) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/rewriteme">... (200; 19.398041ms)
  Apr 19 17:01:29.492: INFO: (18) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:162/proxy/: bar (200; 19.202956ms)
  Apr 19 17:01:29.497: INFO: (18) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:160/proxy/: foo (200; 23.370787ms)
  Apr 19 17:01:29.498: INFO: (18) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:462/proxy/: tls qux (200; 24.495358ms)
  Apr 19 17:01:29.500: INFO: (18) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname2/proxy/: bar (200; 26.609458ms)
  Apr 19 17:01:29.500: INFO: (18) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/rewriteme">test</a> (200; 26.557674ms)
  Apr 19 17:01:29.501: INFO: (18) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname1/proxy/: foo (200; 27.902749ms)
  Apr 19 17:01:29.502: INFO: (18) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname2/proxy/: tls qux (200; 29.165597ms)
  Apr 19 17:01:29.504: INFO: (18) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname2/proxy/: bar (200; 30.84029ms)
  Apr 19 17:01:29.522: INFO: (19) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname2/proxy/: bar (200; 18.42865ms)
  Apr 19 17:01:29.523: INFO: (19) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:1080/proxy/rewriteme">test<... (200; 18.166955ms)
  Apr 19 17:01:29.524: INFO: (19) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:1080/proxy/rewriteme">... (200; 19.469776ms)
  Apr 19 17:01:29.524: INFO: (19) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:162/proxy/: bar (200; 19.345022ms)
  Apr 19 17:01:29.524: INFO: (19) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:443/proxy/tlsrewritem... (200; 19.296628ms)
  Apr 19 17:01:29.524: INFO: (19) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/: <a href="/api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh/proxy/rewriteme">test</a> (200; 18.720751ms)
  Apr 19 17:01:29.525: INFO: (19) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname1/proxy/: tls baz (200; 20.929481ms)
  Apr 19 17:01:29.525: INFO: (19) /api/v1/namespaces/proxy-3103/pods/proxy-service-wb44x-69sbh:160/proxy/: foo (200; 20.652014ms)
  Apr 19 17:01:29.525: INFO: (19) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:162/proxy/: bar (200; 20.786842ms)
  Apr 19 17:01:29.526: INFO: (19) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:462/proxy/: tls qux (200; 21.72165ms)
  Apr 19 17:01:29.529: INFO: (19) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname2/proxy/: bar (200; 25.230489ms)
  Apr 19 17:01:29.530: INFO: (19) /api/v1/namespaces/proxy-3103/services/proxy-service-wb44x:portname1/proxy/: foo (200; 24.423472ms)
  Apr 19 17:01:29.530: INFO: (19) /api/v1/namespaces/proxy-3103/services/https:proxy-service-wb44x:tlsportname2/proxy/: tls qux (200; 24.680214ms)
  Apr 19 17:01:29.530: INFO: (19) /api/v1/namespaces/proxy-3103/pods/https:proxy-service-wb44x-69sbh:460/proxy/: tls baz (200; 24.600627ms)
  Apr 19 17:01:29.534: INFO: (19) /api/v1/namespaces/proxy-3103/pods/http:proxy-service-wb44x-69sbh:160/proxy/: foo (200; 28.531686ms)
  Apr 19 17:01:29.535: INFO: (19) /api/v1/namespaces/proxy-3103/services/http:proxy-service-wb44x:portname1/proxy/: foo (200; 30.404926ms)
  STEP: deleting ReplicationController proxy-service-wb44x in namespace proxy-3103, will wait for the garbage collector to delete the pods @ 04/19/24 17:01:29.536
  Apr 19 17:01:29.655: INFO: Deleting ReplicationController proxy-service-wb44x took: 61.842725ms
  E0419 17:01:29.656408      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:01:29.755: INFO: Terminating ReplicationController proxy-service-wb44x pods took: 100.560292ms
  E0419 17:01:30.656496      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:31.656611      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:01:32.357: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-3103" for this suite. @ 04/19/24 17:01:32.375
• [5.883 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/events.go:98
  STEP: Creating a kubernetes client @ 04/19/24 17:01:32.401
  Apr 19 17:01:32.401: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename events @ 04/19/24 17:01:32.406
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:01:32.45
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:01:32.457
  STEP: creating a test event @ 04/19/24 17:01:32.464
  STEP: listing events in all namespaces @ 04/19/24 17:01:32.483
  STEP: listing events in test namespace @ 04/19/24 17:01:32.492
  STEP: listing events with field selection filtering on source @ 04/19/24 17:01:32.501
  STEP: listing events with field selection filtering on reportingController @ 04/19/24 17:01:32.511
  STEP: getting the test event @ 04/19/24 17:01:32.522
  STEP: patching the test event @ 04/19/24 17:01:32.533
  STEP: getting the test event @ 04/19/24 17:01:32.554
  STEP: updating the test event @ 04/19/24 17:01:32.573
  STEP: getting the test event @ 04/19/24 17:01:32.584
  STEP: deleting the test event @ 04/19/24 17:01:32.589
  STEP: listing events in all namespaces @ 04/19/24 17:01:32.602
  STEP: listing events in test namespace @ 04/19/24 17:01:32.609
  Apr 19 17:01:32.615: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-7950" for this suite. @ 04/19/24 17:01:32.624
• [0.236 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:168
  STEP: Creating a kubernetes client @ 04/19/24 17:01:32.638
  Apr 19 17:01:32.638: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename downward-api @ 04/19/24 17:01:32.64
  E0419 17:01:32.656791      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:01:32.686
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:01:32.693
  STEP: Creating a pod to test downward api env vars @ 04/19/24 17:01:32.701
  E0419 17:01:33.657082      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:34.657272      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:35.657548      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:36.658775      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:01:36.755
  Apr 19 17:01:36.763: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod downward-api-976f72d1-44d0-4e18-ae92-76134535aa3a container dapi-container: <nil>
  STEP: delete the pod @ 04/19/24 17:01:36.785
  Apr 19 17:01:36.822: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4841" for this suite. @ 04/19/24 17:01:36.833
• [4.211 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment Deployment should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:150
  STEP: Creating a kubernetes client @ 04/19/24 17:01:36.853
  Apr 19 17:01:36.853: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename deployment @ 04/19/24 17:01:36.857
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:01:36.899
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:01:36.908
  Apr 19 17:01:36.914: INFO: Creating simple deployment test-new-deployment
  Apr 19 17:01:36.953: INFO: deployment "test-new-deployment" doesn't have the required revision set
  E0419 17:01:37.659704      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:38.660368      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: getting scale subresource @ 04/19/24 17:01:38.982
  STEP: updating a scale subresource @ 04/19/24 17:01:38.99
  STEP: verifying the deployment Spec.Replicas was modified @ 04/19/24 17:01:39.003
  STEP: Patch a scale subresource @ 04/19/24 17:01:39.011
  Apr 19 17:01:39.056: INFO: Deployment "test-new-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=19) "test-new-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-8338",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ec69cba1-0a98-44c8-8c93-8b2c76e4d3e4",
      ResourceVersion: (string) (len=5) "28362",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849142896,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)(<nil>),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=28) {
              00000000  7b 22 66 3a 73 70 65 63  22 3a 7b 22 66 3a 72 65  |{"f:spec":{"f:re|
              00000010  70 6c 69 63 61 73 22 3a  7b 7d 7d 7d              |plicas":{}}}|
            }
          }),
          Subresource: (string) (len=5) "scale"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142896,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=619) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |onds":{},"f:revi|
              00000060  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000070  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              00000090  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000a0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000b0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000c0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000d0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000e0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              000000f0  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000100  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000110  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000120  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000130  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000140  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000150  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000160  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000170  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000180  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000190  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001a0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001b0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001c0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001d0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001e0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000001f0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000200  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000210  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000220  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000230  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000240  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000250  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000260  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142898,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(4),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142898,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142898,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142898,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142896,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=72) "ReplicaSet \"test-new-deployment-557759b7c7\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Apr 19 17:01:39.085: INFO: New ReplicaSet "test-new-deployment-557759b7c7" of Deployment "test-new-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-new-deployment-557759b7c7",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-8338",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5c6fcf4e-9524-410d-8adf-0941748b6192",
      ResourceVersion: (string) (len=5) "28368",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849142896,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "4",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "5"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=19) "test-new-deployment",
          UID: (types.UID) (len=36) "ec69cba1-0a98-44c8-8c93-8b2c76e4d3e4",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142899,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 65 63 36 39 63 62  61 31 2d 30 61 39 38 2d  |\"ec69cba1-0a98-|
              00000120  34 34 63 38 2d 38 63 39  33 2d 38 62 32 63 37 36  |44c8-8c93-8b2c76|
              00000130  65 34 64 33 65 34 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |e4d3e4\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142899,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(4),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 19 17:01:39.098: INFO: Pod "test-new-deployment-557759b7c7-6rj5c" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-557759b7c7-6rj5c",
      GenerateName: (string) (len=31) "test-new-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-8338",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f2f735bb-54a2-45e9-b35f-170ae82b1c08",
      ResourceVersion: (string) (len=5) "28370",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849142899,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-557759b7c7",
          UID: (types.UID) (len=36) "5c6fcf4e-9524-410d-8adf-0941748b6192",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142899,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 63  36 66 63 66 34 65 2d 39  |d\":\"5c6fcf4e-9|
              00000090  35 32 34 2d 34 31 30 64  2d 38 61 64 66 2d 30 39  |524-410d-8adf-09|
              000000a0  34 31 37 34 38 62 36 31  39 32 5c 22 7d 22 3a 7b  |41748b6192\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142899,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-qr2h8",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-qr2h8",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "co4fe9zoo9oc-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142899,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142899,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142899,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142899,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142899,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.39",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.39"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849142899,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 19 17:01:39.104: INFO: Pod "test-new-deployment-557759b7c7-prk9p" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-557759b7c7-prk9p",
      GenerateName: (string) (len=31) "test-new-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-8338",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "216c3c4b-8d65-4207-8bf1-2ec4c25348a9",
      ResourceVersion: (string) (len=5) "28356",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849142896,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-557759b7c7",
          UID: (types.UID) (len=36) "5c6fcf4e-9524-410d-8adf-0941748b6192",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142896,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 63  36 66 63 66 34 65 2d 39  |d\":\"5c6fcf4e-9|
              00000090  35 32 34 2d 34 31 30 64  2d 38 61 64 66 2d 30 39  |524-410d-8adf-09|
              000000a0  34 31 37 34 38 62 36 31  39 32 5c 22 7d 22 3a 7b  |41748b6192\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142898,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 36 2e  38 34 5c 22 7d 22 3a 7b  |.233.66.84\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-mgfxh",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-mgfxh",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "co4fe9zoo9oc-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142898,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142896,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142898,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142898,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849142896,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.60",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.60"
        }
      },
      PodIP: (string) (len=12) "10.233.66.84",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.66.84"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849142896,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63849142897,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://88198502a971cb73c61d7742c408b4807600c9f96275ae439cfbf4d5baab94d3",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 19 17:01:39.107: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-8338" for this suite. @ 04/19/24 17:01:39.116
• [2.275 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS should provide DNS for the cluster [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:50
  STEP: Creating a kubernetes client @ 04/19/24 17:01:39.128
  Apr 19 17:01:39.129: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename dns @ 04/19/24 17:01:39.132
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:01:39.167
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:01:39.174
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 04/19/24 17:01:39.18
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 04/19/24 17:01:39.181
  STEP: creating a pod to probe DNS @ 04/19/24 17:01:39.181
  STEP: submitting the pod to kubernetes @ 04/19/24 17:01:39.182
  E0419 17:01:39.660982      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:40.661523      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/19/24 17:01:41.218
  STEP: looking for the results for each expected name from probers @ 04/19/24 17:01:41.232
  Apr 19 17:01:41.284: INFO: DNS probes using dns-639/dns-test-0044a611-d851-4087-bff3-f9ad275c5102 succeeded

  STEP: deleting the pod @ 04/19/24 17:01:41.285
  Apr 19 17:01:41.318: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-639" for this suite. @ 04/19/24 17:01:41.358
• [2.244 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:875
  STEP: Creating a kubernetes client @ 04/19/24 17:01:41.376
  Apr 19 17:01:41.376: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename daemonsets @ 04/19/24 17:01:41.386
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:01:41.447
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:01:41.451
  STEP: Creating simple DaemonSet "daemon-set" @ 04/19/24 17:01:41.495
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/19/24 17:01:41.505
  Apr 19 17:01:41.521: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 17:01:41.521: INFO: Node co4fe9zoo9oc-1 is running 0 daemon pod, expected 1
  E0419 17:01:41.662177      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:01:42.523: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 19 17:01:42.523: INFO: Node co4fe9zoo9oc-1 is running 0 daemon pod, expected 1
  E0419 17:01:42.662896      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:01:43.525: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 19 17:01:43.525: INFO: Node co4fe9zoo9oc-2 is running 0 daemon pod, expected 1
  E0419 17:01:43.663594      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:01:44.525: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 19 17:01:44.525: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Getting /status @ 04/19/24 17:01:44.532
  Apr 19 17:01:44.547: INFO: Daemon Set daemon-set has Conditions: []
  STEP: updating the DaemonSet Status @ 04/19/24 17:01:44.547
  Apr 19 17:01:44.571: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the daemon set status to be updated @ 04/19/24 17:01:44.571
  Apr 19 17:01:44.574: INFO: Observed &DaemonSet event: ADDED
  Apr 19 17:01:44.574: INFO: Observed &DaemonSet event: MODIFIED
  Apr 19 17:01:44.575: INFO: Observed &DaemonSet event: MODIFIED
  Apr 19 17:01:44.576: INFO: Observed &DaemonSet event: MODIFIED
  Apr 19 17:01:44.576: INFO: Observed &DaemonSet event: MODIFIED
  Apr 19 17:01:44.576: INFO: Observed &DaemonSet event: MODIFIED
  Apr 19 17:01:44.577: INFO: Found daemon set daemon-set in namespace daemonsets-3947 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Apr 19 17:01:44.577: INFO: Daemon set daemon-set has an updated status
  STEP: patching the DaemonSet Status @ 04/19/24 17:01:44.577
  STEP: watching for the daemon set status to be patched @ 04/19/24 17:01:44.588
  Apr 19 17:01:44.594: INFO: Observed &DaemonSet event: ADDED
  Apr 19 17:01:44.594: INFO: Observed &DaemonSet event: MODIFIED
  Apr 19 17:01:44.595: INFO: Observed &DaemonSet event: MODIFIED
  Apr 19 17:01:44.596: INFO: Observed &DaemonSet event: MODIFIED
  Apr 19 17:01:44.596: INFO: Observed &DaemonSet event: MODIFIED
  Apr 19 17:01:44.597: INFO: Observed &DaemonSet event: MODIFIED
  Apr 19 17:01:44.597: INFO: Observed daemon set daemon-set in namespace daemonsets-3947 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Apr 19 17:01:44.597: INFO: Observed &DaemonSet event: MODIFIED
  Apr 19 17:01:44.598: INFO: Found daemon set daemon-set in namespace daemonsets-3947 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
  Apr 19 17:01:44.598: INFO: Daemon set daemon-set has a patched status
  STEP: Deleting DaemonSet "daemon-set" @ 04/19/24 17:01:44.609
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3947, will wait for the garbage collector to delete the pods @ 04/19/24 17:01:44.609
  E0419 17:01:44.663805      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:01:44.675: INFO: Deleting DaemonSet.extensions daemon-set took: 10.235055ms
  Apr 19 17:01:44.776: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.334332ms
  E0419 17:01:45.664439      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:46.664680      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:01:47.383: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 17:01:47.384: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 19 17:01:47.392: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"28526"},"items":null}

  Apr 19 17:01:47.400: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"28526"},"items":null}

  Apr 19 17:01:47.440: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-3947" for this suite. @ 04/19/24 17:01:47.45
• [6.091 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:58
  STEP: Creating a kubernetes client @ 04/19/24 17:01:47.469
  Apr 19 17:01:47.469: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename projected @ 04/19/24 17:01:47.473
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:01:47.506
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:01:47.51
  STEP: Creating configMap with name projected-configmap-test-volume-73cd37e5-27c0-4ff3-bd55-57caaee73d5b @ 04/19/24 17:01:47.517
  STEP: Creating a pod to test consume configMaps @ 04/19/24 17:01:47.527
  E0419 17:01:47.665692      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:48.665966      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:01:49.565
  Apr 19 17:01:49.571: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-projected-configmaps-446e220a-6108-47c5-a0a9-8df4ab4a51e0 container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/24 17:01:49.585
  Apr 19 17:01:49.644: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1017" for this suite. @ 04/19/24 17:01:49.653
  E0419 17:01:49.666433      13 retrywatcher.go:129] "Watch failed" err="context canceled"
• [2.198 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:183
  STEP: Creating a kubernetes client @ 04/19/24 17:01:49.669
  Apr 19 17:01:49.670: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename container-probe @ 04/19/24 17:01:49.673
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:01:49.699
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:01:49.707
  STEP: Creating pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886 @ 04/19/24 17:01:49.712
  E0419 17:01:50.666834      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:51.667257      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/19/24 17:01:51.746
  Apr 19 17:01:51.757: INFO: Initial restart count of pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae is 0
  Apr 19 17:01:51.765: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:01:52.667796      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:53.667897      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:01:53.778: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:01:54.668056      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:55.668795      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:01:55.787: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:01:56.669641      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:57.670517      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:01:57.800: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:01:58.671332      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:01:59.671177      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:01:59.811: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:02:00.672074      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:01.671856      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:02:01.823: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:02:02.672234      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:03.673211      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:02:03.837: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:02:04.673165      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:05.673417      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:02:05.850: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:02:06.673759      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:07.674460      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:02:07.862: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:02:08.675827      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:09.675805      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:02:09.873: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:02:10.675669      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:11.677307      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:02:11.885: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:02:12.677782      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:13.678461      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:02:13.895: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:02:14.679191      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:15.679515      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:02:15.905: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:02:16.679879      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:17.679790      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:02:17.916: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:02:18.679920      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:19.680894      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:02:19.924: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:02:20.681457      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:21.682565      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:02:21.934: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:02:22.682651      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:23.683522      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:02:23.947: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:02:24.685850      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:25.684899      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:02:25.956: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:02:26.685175      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:27.685748      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:02:27.967: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:02:28.686169      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:29.686801      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:02:29.983: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:02:30.686659      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:31.686792      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:02:31.991: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:02:32.687673      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:33.688058      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:02:34.003: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:02:34.688104      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:35.688379      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:02:36.011: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:02:36.689268      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:37.689844      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:02:38.021: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:02:38.689776      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:39.690370      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:02:40.032: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:02:40.690627      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:41.691734      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:02:42.043: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:02:42.692216      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:43.692701      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:02:44.051: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:02:44.693324      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:45.694206      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:02:46.064: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:02:46.694152      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:47.694705      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:02:48.073: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:02:48.694871      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:49.695645      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:02:50.083: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:02:50.695595      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:51.696332      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:02:52.093: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:02:52.696700      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:53.696438      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:02:54.103: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:02:54.696730      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:55.697690      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:02:56.110: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:02:56.699106      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:57.699932      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:02:58.135: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:02:58.699610      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:02:59.700202      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:03:00.143: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:03:00.700373      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:01.700748      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:03:02.154: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:03:02.701512      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:03.701669      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:03:04.164: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:03:04.701884      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:05.702601      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:03:06.174: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:03:06.702676      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:07.703174      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:03:08.182: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:03:08.703233      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:09.703929      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:03:10.192: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:03:10.703920      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:11.704360      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:03:12.200: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:03:12.704716      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:13.705360      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:03:14.210: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:03:14.705625      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:15.706524      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:03:16.218: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:03:16.706906      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:17.707106      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:03:18.230: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:03:18.707682      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:19.708110      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:03:20.240: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:03:20.708343      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:21.708959      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:03:22.249: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:03:22.709003      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:23.709599      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:03:24.260: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:03:24.709848      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:25.710722      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:03:26.272: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:03:26.711421      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:27.712181      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:03:28.284: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:03:28.712481      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:29.713438      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:03:30.299: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:03:30.713800      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:31.714041      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:03:32.309: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:03:32.715153      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:33.716058      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:03:34.323: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:03:34.717186      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:35.717803      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:03:36.335: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:03:36.718135      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:37.718927      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:03:38.347: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:03:38.719363      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:39.719671      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:03:40.358: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:03:40.720605      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:41.720922      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:03:42.372: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:03:42.721445      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:43.722063      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:03:44.384: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:03:44.722792      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:45.722903      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:03:46.395: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:03:46.723763      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:47.725460      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:03:48.413: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:03:48.725419      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:49.727104      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:03:50.426: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:03:50.725643      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:51.736895      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:03:52.439: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:03:52.731482      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:53.746912      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:03:54.458: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:03:54.742166      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:55.742359      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:03:56.468: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:03:56.743282      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:57.744239      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:03:58.486: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:03:58.744214      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:03:59.744718      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:04:00.497: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:04:00.745422      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:01.748183      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:04:02.511: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:04:02.747102      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:03.747241      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:04:04.520: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:04:04.748062      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:05.748540      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:04:06.533: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:04:06.749188      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:07.749648      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:04:08.547: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:04:08.750509      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:09.751138      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:04:10.556: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:04:10.751716      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:11.752141      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:04:12.567: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:04:12.753148      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:13.753550      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:04:14.577: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:04:14.754115      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:15.754791      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:04:16.585: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:04:16.754923      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:17.755324      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:04:18.596: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:04:18.755396      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:19.755747      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:04:20.609: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:04:20.757140      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:21.757206      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:04:22.617: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:04:22.757994      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:23.758631      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:04:24.631: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:04:24.759249      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:25.760033      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:04:26.643: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:04:26.760816      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:27.761754      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:04:28.654: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:04:28.762199      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:29.762906      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:04:30.666: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:04:30.763233      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:31.763736      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:04:32.674: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:04:32.763884      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:33.764328      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:04:34.692: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:04:34.765085      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:35.765089      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:04:36.711: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:04:36.766397      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:37.766651      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:04:38.729: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:04:38.767482      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:39.768435      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:04:40.743: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:04:40.768969      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:41.769604      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:04:42.751: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:04:42.770789      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:43.770868      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:04:44.762: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:04:44.772035      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:45.771999      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:46.772570      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:04:46.782: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:04:47.773624      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:48.773216      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:04:48.795: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:04:49.773796      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:50.774724      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:04:50.807: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:04:51.775241      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:52.775445      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:04:52.821: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:04:53.780398      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:54.777645      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:04:54.836: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:04:55.777994      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:56.778499      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:04:56.845: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:04:57.779164      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:04:58.779540      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:04:58.855: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:04:59.779685      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:00.780107      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:05:00.868: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:05:01.781140      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:02.782478      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:05:02.882: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:05:03.782933      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:04.783306      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:05:04.893: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:05:05.784318      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:06.784754      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:05:06.902: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:05:07.784970      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:08.785208      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:05:08.917: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:05:09.786187      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:10.786571      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:05:10.931: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:05:11.787685      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:12.788698      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:05:12.942: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:05:13.789270      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:14.789316      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:05:14.951: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:05:15.790572      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:16.791223      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:05:16.962: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:05:17.792061      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:18.791961      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:05:18.975: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:05:19.793064      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:20.793844      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:05:20.988: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:05:21.794473      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:22.794763      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:05:23.002: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:05:23.795094      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:24.797831      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:05:25.013: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:05:25.797901      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:26.798211      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:05:27.020: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:05:27.798856      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:28.799611      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:05:29.034: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:05:29.799895      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:30.800169      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:05:31.042: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:05:31.801239      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:32.801547      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:05:33.052: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:05:33.802093      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:34.803011      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:05:35.062: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:05:35.803225      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:36.803821      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:05:37.071: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:05:37.804730      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:38.805072      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:05:39.080: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:05:39.805721      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:40.806458      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:05:41.092: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:05:41.806610      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:42.807064      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:05:43.101: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:05:43.808270      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:44.808485      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:05:45.112: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:05:45.808740      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:46.809434      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:05:47.123: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:05:47.809825      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:48.810341      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:05:49.136: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:05:49.810586      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:50.810990      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:05:51.144: INFO: Get pod liveness-bbe1f65b-2cbf-4d05-8d47-11279137dfae in namespace container-probe-4886
  E0419 17:05:51.812078      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:52.812470      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 04/19/24 17:05:53.145
  Apr 19 17:05:53.175: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-4886" for this suite. @ 04/19/24 17:05:53.203
• [243.575 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:315
  STEP: Creating a kubernetes client @ 04/19/24 17:05:53.248
  Apr 19 17:05:53.249: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename webhook @ 04/19/24 17:05:53.255
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:05:53.31
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:05:53.315
  STEP: Setting up server cert @ 04/19/24 17:05:53.408
  E0419 17:05:53.812546      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:54.812951      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 17:05:55.196
  STEP: Deploying the webhook pod @ 04/19/24 17:05:55.213
  STEP: Wait for the deployment to be ready @ 04/19/24 17:05:55.231
  Apr 19 17:05:55.245: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0419 17:05:55.813264      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:56.813662      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:05:57.291: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 17, 5, 55, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 5, 55, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 5, 55, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 5, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7c55c7d74c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 17:05:57.813698      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:05:58.814094      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:05:59.306: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 17, 5, 55, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 5, 55, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 5, 55, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 5, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7c55c7d74c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 17:05:59.814494      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:00.815584      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:06:01.303: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 17, 5, 55, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 5, 55, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 5, 55, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 5, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7c55c7d74c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 17:06:01.815751      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:02.816265      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:06:03.303: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 17, 5, 55, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 5, 55, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 5, 55, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 5, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7c55c7d74c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 17:06:03.816612      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:04.819625      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:06:05.303: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 17, 5, 55, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 5, 55, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 5, 55, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 5, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7c55c7d74c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 17:06:05.818715      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:06.819058      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 17:06:07.306
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 17:06:07.344
  E0419 17:06:07.820219      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:06:08.346: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 19 17:06:08.362: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  E0419 17:06:08.820435      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5692-crds.webhook.example.com via the AdmissionRegistration API @ 04/19/24 17:06:08.9
  STEP: Creating a custom resource while v1 is storage version @ 04/19/24 17:06:08.951
  E0419 17:06:09.821504      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:10.822002      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Patching Custom Resource Definition to set v2 as storage @ 04/19/24 17:06:11.182
  STEP: Patching the custom resource while v2 is storage version @ 04/19/24 17:06:11.216
  E0419 17:06:11.822224      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:06:11.903: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7429" for this suite. @ 04/19/24 17:06:11.92
  STEP: Destroying namespace "webhook-markers-834" for this suite. @ 04/19/24 17:06:11.94
• [18.711 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:85
  STEP: Creating a kubernetes client @ 04/19/24 17:06:11.967
  Apr 19 17:06:11.967: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename pod-network-test @ 04/19/24 17:06:11.972
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:06:12.022
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:06:12.031
  STEP: Performing setup for networking test in namespace pod-network-test-3740 @ 04/19/24 17:06:12.038
  STEP: creating a selector @ 04/19/24 17:06:12.038
  STEP: Creating the service pods in kubernetes @ 04/19/24 17:06:12.039
  Apr 19 17:06:12.039: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0419 17:06:12.822326      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:13.823101      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:14.823985      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:15.824818      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:16.825023      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:17.833362      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:18.828822      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:19.829596      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:20.829557      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:21.830895      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:22.831121      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:23.832088      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:24.832003      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:25.832936      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:26.834363      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:27.834436      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:28.835483      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:29.836122      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:30.836311      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:31.837166      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:32.838088      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:33.838459      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 04/19/24 17:06:34.346
  E0419 17:06:34.840595      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:35.839340      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:06:36.397: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Apr 19 17:06:36.397: INFO: Breadth first check of 10.233.64.128 on host 192.168.121.127...
  Apr 19 17:06:36.408: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.91:9080/dial?request=hostname&protocol=http&host=10.233.64.128&port=8083&tries=1'] Namespace:pod-network-test-3740 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 17:06:36.408: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 17:06:36.412: INFO: ExecWithOptions: Clientset creation
  Apr 19 17:06:36.413: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-3740/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.91%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.64.128%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Apr 19 17:06:36.660: INFO: Waiting for responses: map[]
  Apr 19 17:06:36.660: INFO: reached 10.233.64.128 after 0/1 tries
  Apr 19 17:06:36.660: INFO: Breadth first check of 10.233.65.139 on host 192.168.121.39...
  Apr 19 17:06:36.671: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.91:9080/dial?request=hostname&protocol=http&host=10.233.65.139&port=8083&tries=1'] Namespace:pod-network-test-3740 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 17:06:36.671: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 17:06:36.673: INFO: ExecWithOptions: Clientset creation
  Apr 19 17:06:36.673: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-3740/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.91%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.65.139%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Apr 19 17:06:36.807: INFO: Waiting for responses: map[]
  Apr 19 17:06:36.808: INFO: reached 10.233.65.139 after 0/1 tries
  Apr 19 17:06:36.808: INFO: Breadth first check of 10.233.66.90 on host 192.168.121.60...
  Apr 19 17:06:36.817: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.91:9080/dial?request=hostname&protocol=http&host=10.233.66.90&port=8083&tries=1'] Namespace:pod-network-test-3740 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 17:06:36.817: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 17:06:36.819: INFO: ExecWithOptions: Clientset creation
  Apr 19 17:06:36.820: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-3740/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.91%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.66.90%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  E0419 17:06:36.839964      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:06:36.985: INFO: Waiting for responses: map[]
  Apr 19 17:06:36.985: INFO: reached 10.233.66.90 after 0/1 tries
  Apr 19 17:06:36.985: INFO: Going to retry 0 out of 3 pods....
  Apr 19 17:06:36.986: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-3740" for this suite. @ 04/19/24 17:06:36.997
• [25.041 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:95
  STEP: Creating a kubernetes client @ 04/19/24 17:06:37.012
  Apr 19 17:06:37.012: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename var-expansion @ 04/19/24 17:06:37.017
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:06:37.047
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:06:37.054
  STEP: Creating a pod to test substitution in container's args @ 04/19/24 17:06:37.059
  E0419 17:06:37.840368      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:38.841452      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:06:39.091
  Apr 19 17:06:39.104: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod var-expansion-837cb9d4-6670-44de-9f70-f9b27b25fc86 container dapi-container: <nil>
  STEP: delete the pod @ 04/19/24 17:06:39.157
  Apr 19 17:06:39.185: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-7776" for this suite. @ 04/19/24 17:06:39.195
• [2.198 seconds]
------------------------------
[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:322
  STEP: Creating a kubernetes client @ 04/19/24 17:06:39.209
  Apr 19 17:06:39.209: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename gc @ 04/19/24 17:06:39.212
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:06:39.255
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:06:39.26
  STEP: create the rc @ 04/19/24 17:06:39.268
  W0419 17:06:39.278834      13 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0419 17:06:39.841879      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:40.842583      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:41.842639      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:42.843600      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:43.844087      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 04/19/24 17:06:44.292
  STEP: wait for all pods to be garbage collected @ 04/19/24 17:06:44.306
  E0419 17:06:44.844495      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:45.844905      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:46.845296      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:47.845793      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:48.846462      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 04/19/24 17:06:49.355
  Apr 19 17:06:49.602: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 19 17:06:49.606: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-4274" for this suite. @ 04/19/24 17:06:49.65
• [10.464 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:488
  STEP: Creating a kubernetes client @ 04/19/24 17:06:49.675
  Apr 19 17:06:49.675: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename security-context-test @ 04/19/24 17:06:49.679
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:06:49.718
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:06:49.725
  E0419 17:06:49.846414      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:50.847330      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:51.847736      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:52.849002      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:06:53.799: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-8172" for this suite. @ 04/19/24 17:06:53.808
• [4.153 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:185
  STEP: Creating a kubernetes client @ 04/19/24 17:06:53.829
  Apr 19 17:06:53.829: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename deployment @ 04/19/24 17:06:53.833
  E0419 17:06:53.849412      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:06:53.874
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:06:53.878
  STEP: creating a Deployment @ 04/19/24 17:06:53.889
  STEP: waiting for Deployment to be created @ 04/19/24 17:06:53.91
  STEP: waiting for all Replicas to be Ready @ 04/19/24 17:06:53.912
  Apr 19 17:06:53.915: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 19 17:06:53.915: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 19 17:06:53.932: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 19 17:06:53.932: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 19 17:06:53.968: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 19 17:06:53.968: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 19 17:06:54.025: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 19 17:06:54.025: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  E0419 17:06:54.850788      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:06:55.087: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  Apr 19 17:06:55.087: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  Apr 19 17:06:55.568: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 2 and labels map[test-deployment-static:true]
  STEP: patching the Deployment @ 04/19/24 17:06:55.569
  Apr 19 17:06:55.594: INFO: observed event type ADDED
  STEP: waiting for Replicas to scale @ 04/19/24 17:06:55.595
  Apr 19 17:06:55.603: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 0
  Apr 19 17:06:55.604: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 0
  Apr 19 17:06:55.604: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 0
  Apr 19 17:06:55.604: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 0
  Apr 19 17:06:55.605: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 0
  Apr 19 17:06:55.605: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 0
  Apr 19 17:06:55.606: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 0
  Apr 19 17:06:55.606: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 0
  Apr 19 17:06:55.606: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 1
  Apr 19 17:06:55.606: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 1
  Apr 19 17:06:55.607: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 2
  Apr 19 17:06:55.607: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 2
  Apr 19 17:06:55.608: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 2
  Apr 19 17:06:55.608: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 2
  Apr 19 17:06:55.617: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 2
  Apr 19 17:06:55.617: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 2
  Apr 19 17:06:55.644: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 2
  Apr 19 17:06:55.644: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 2
  Apr 19 17:06:55.674: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 1
  Apr 19 17:06:55.674: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 1
  Apr 19 17:06:55.701: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 1
  Apr 19 17:06:55.701: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 1
  E0419 17:06:55.851290      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:06:56.852459      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:06:57.158: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 2
  Apr 19 17:06:57.158: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 2
  Apr 19 17:06:57.208: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 1
  STEP: listing Deployments @ 04/19/24 17:06:57.208
  Apr 19 17:06:57.215: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
  STEP: updating the Deployment @ 04/19/24 17:06:57.215
  Apr 19 17:06:57.257: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 1
  STEP: fetching the DeploymentStatus @ 04/19/24 17:06:57.257
  Apr 19 17:06:57.269: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 19 17:06:57.292: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 19 17:06:57.354: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 19 17:06:57.403: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 19 17:06:57.430: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  E0419 17:06:57.852954      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:06:58.140: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 19 17:06:58.168: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 19 17:06:58.192: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 19 17:06:58.230: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  E0419 17:06:58.853202      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:06:59.688: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  STEP: patching the DeploymentStatus @ 04/19/24 17:06:59.745
  STEP: fetching the DeploymentStatus @ 04/19/24 17:06:59.759
  Apr 19 17:06:59.769: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 1
  Apr 19 17:06:59.769: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 1
  Apr 19 17:06:59.769: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 1
  Apr 19 17:06:59.769: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 1
  Apr 19 17:06:59.770: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 1
  Apr 19 17:06:59.770: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 2
  Apr 19 17:06:59.770: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 2
  Apr 19 17:06:59.770: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 2
  Apr 19 17:06:59.771: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 2
  Apr 19 17:06:59.771: INFO: observed Deployment test-deployment in namespace deployment-6864 with ReadyReplicas 3
  STEP: deleting the Deployment @ 04/19/24 17:06:59.771
  Apr 19 17:06:59.788: INFO: observed event type MODIFIED
  Apr 19 17:06:59.789: INFO: observed event type MODIFIED
  Apr 19 17:06:59.789: INFO: observed event type MODIFIED
  Apr 19 17:06:59.789: INFO: observed event type MODIFIED
  Apr 19 17:06:59.789: INFO: observed event type MODIFIED
  Apr 19 17:06:59.789: INFO: observed event type MODIFIED
  Apr 19 17:06:59.789: INFO: observed event type MODIFIED
  Apr 19 17:06:59.790: INFO: observed event type MODIFIED
  Apr 19 17:06:59.790: INFO: observed event type MODIFIED
  Apr 19 17:06:59.790: INFO: observed event type MODIFIED
  Apr 19 17:06:59.790: INFO: observed event type MODIFIED
  Apr 19 17:06:59.790: INFO: observed event type MODIFIED
  Apr 19 17:06:59.790: INFO: observed event type MODIFIED
  Apr 19 17:06:59.796: INFO: Log out all the ReplicaSets if there is no deployment created
  Apr 19 17:06:59.801: INFO: ReplicaSet "test-deployment-64fd565c98":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=26) "test-deployment-64fd565c98",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6864",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d8567c87-fca5-49a9-b759-50ed739def83",
      ResourceVersion: (string) (len=5) "29537",
      Generation: (int64) 4,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143215,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "64fd565c98",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=15) "test-deployment",
          UID: (types.UID) (len=36) "418257f2-ea9e-48be-beb7-0bf3b7b26931",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143219,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=827) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              000000d0  65 2d 68 61 73 68 22 3a  7b 7d 2c 22 66 3a 74 65  |e-hash":{},"f:te|
              000000e0  73 74 2d 64 65 70 6c 6f  79 6d 65 6e 74 2d 73 74  |st-deployment-st|
              000000f0  61 74 69 63 22 3a 7b 7d  7d 2c 22 66 3a 6f 77 6e  |atic":{}},"f:own|
              00000100  65 72 52 65 66 65 72 65  6e 63 65 73 22 3a 7b 22  |erReferences":{"|
              00000110  2e 22 3a 7b 7d 2c 22 6b  3a 7b 5c 22 75 69 64 5c  |.":{},"k:{\"uid\|
              00000120  22 3a 5c 22 34 31 38 32  35 37 66 32 2d 65 61 39  |":\"418257f2-ea9|
              00000130  65 2d 34 38 62 65 2d 62  65 62 37 2d 30 62 66 33  |e-48be-beb7-0bf3|
              00000140  62 37 62 32 36 39 33 31  5c 22 7d 22 3a 7b 7d 7d  |b7b26931\"}":{}}|
              00000150  7d 2c 22 66 3a 73 70 65  63 22 3a 7b 22 66 3a 72  |},"f:spec":{"f:r|
              00000160  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 73  |eplicas":{},"f:s|
              00000170  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 74  |elector":{},"f:t|
              00000180  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000190  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              000001a0  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 70 6f  |s":{".":{},"f:po|
              000001b0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001c0  3a 7b 7d 2c 22 66 3a 74  65 73 74 2d 64 65 70 6c  |:{},"f:test-depl|
              000001d0  6f 79 6d 65 6e 74 2d 73  74 61 74 69 63 22 3a 7b  |oyment-static":{|
              000001e0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000200  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 74 65 73  |:{\"name\":\"tes|
              00000210  74 2d 64 65 70 6c 6f 79  6d 65 6e 74 5c 22 7d 22  |t-deployment\"}"|
              00000220  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000230  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000240  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000250  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000260  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              00000270  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              00000280  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000290  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000002a0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000002b0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000002c0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              000002d0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000002e0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000002f0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000300  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000310  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000320  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000330  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143219,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "64fd565c98",
          (string) (len=22) "test-deployment-static": (string) (len=4) "true"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=22) "test-deployment-static": (string) (len=4) "true",
            (string) (len=17) "pod-template-hash": (string) (len=10) "64fd565c98"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=15) "test-deployment",
              Image: (string) (len=25) "registry.k8s.io/pause:3.9",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(2),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 4,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }


  Apr 19 17:06:59.809: INFO: pod: "test-deployment-64fd565c98-rzdpz":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-64fd565c98-rzdpz",
      GenerateName: (string) (len=27) "test-deployment-64fd565c98-",
      Namespace: (string) (len=15) "deployment-6864",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4baf7428-2c16-478e-adcb-0d4bbfb1f30b",
      ResourceVersion: (string) (len=5) "29529",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143215,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143221,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      DeletionGracePeriodSeconds: (*int64)(2),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "64fd565c98",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=26) "test-deployment-64fd565c98",
          UID: (types.UID) (len=36) "d8567c87-fca5-49a9-b759-50ed739def83",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143215,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  64 38 35 36 37 63 38 37  |uid\":\"d8567c87|
              000000a0  2d 66 63 61 35 2d 34 39  61 39 2d 62 37 35 39 2d  |-fca5-49a9-b759-|
              000000b0  35 30 65 64 37 33 39 64  65 66 38 33 5c 22 7d 22  |50ed739def83\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143217,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 36 2e  39 36 5c 22 7d 22 3a 7b  |.233.66.96\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-bw596",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=25) "registry.k8s.io/pause:3.9",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-bw596",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(2),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "co4fe9zoo9oc-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143217,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143215,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143217,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143217,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143215,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.60",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.60"
        }
      },
      PodIP: (string) (len=12) "10.233.66.96",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.66.96"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143215,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63849143216,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=25) "registry.k8s.io/pause:3.9",
          ImageID: (string) (len=93) "registry.k8s.io/pause@sha256:7031c1b283388d2c2e09b57badb803c05ebed362dc88d84b480cc47f72a21097",
          ContainerID: (string) (len=72) "cri-o://b49c4491e19251dc530616201a65ef88fa41208537f345c4a73b979a4b829ccb",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  Apr 19 17:06:59.815: INFO: ReplicaSet "test-deployment-79ff746c4":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=25) "test-deployment-79ff746c4",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6864",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3de90478-f76e-4d65-a303-01290ec866c9",
      ResourceVersion: (string) (len=5) "29527",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143217,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "79ff746c4",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "3"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=15) "test-deployment",
          UID: (types.UID) (len=36) "418257f2-ea9e-48be-beb7-0bf3b7b26931",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143218,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=827) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              000000d0  65 2d 68 61 73 68 22 3a  7b 7d 2c 22 66 3a 74 65  |e-hash":{},"f:te|
              000000e0  73 74 2d 64 65 70 6c 6f  79 6d 65 6e 74 2d 73 74  |st-deployment-st|
              000000f0  61 74 69 63 22 3a 7b 7d  7d 2c 22 66 3a 6f 77 6e  |atic":{}},"f:own|
              00000100  65 72 52 65 66 65 72 65  6e 63 65 73 22 3a 7b 22  |erReferences":{"|
              00000110  2e 22 3a 7b 7d 2c 22 6b  3a 7b 5c 22 75 69 64 5c  |.":{},"k:{\"uid\|
              00000120  22 3a 5c 22 34 31 38 32  35 37 66 32 2d 65 61 39  |":\"418257f2-ea9|
              00000130  65 2d 34 38 62 65 2d 62  65 62 37 2d 30 62 66 33  |e-48be-beb7-0bf3|
              00000140  62 37 62 32 36 39 33 31  5c 22 7d 22 3a 7b 7d 7d  |b7b26931\"}":{}}|
              00000150  7d 2c 22 66 3a 73 70 65  63 22 3a 7b 22 66 3a 72  |},"f:spec":{"f:r|
              00000160  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 73  |eplicas":{},"f:s|
              00000170  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 74  |elector":{},"f:t|
              00000180  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000190  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              000001a0  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 70 6f  |s":{".":{},"f:po|
              000001b0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001c0  3a 7b 7d 2c 22 66 3a 74  65 73 74 2d 64 65 70 6c  |:{},"f:test-depl|
              000001d0  6f 79 6d 65 6e 74 2d 73  74 61 74 69 63 22 3a 7b  |oyment-static":{|
              000001e0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000200  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 74 65 73  |:{\"name\":\"tes|
              00000210  74 2d 64 65 70 6c 6f 79  6d 65 6e 74 5c 22 7d 22  |t-deployment\"}"|
              00000220  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000230  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000240  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000250  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000260  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              00000270  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              00000280  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000290  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000002a0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000002b0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000002c0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              000002d0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000002e0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000002f0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000300  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000310  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000320  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000330  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143219,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(2),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=9) "79ff746c4",
          (string) (len=22) "test-deployment-static": (string) (len=4) "true"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=9) "79ff746c4",
            (string) (len=22) "test-deployment-static": (string) (len=4) "true"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=15) "test-deployment",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(1),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 2,
      FullyLabeledReplicas: (int32) 2,
      ReadyReplicas: (int32) 2,
      AvailableReplicas: (int32) 2,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }


  Apr 19 17:06:59.829: INFO: pod: "test-deployment-79ff746c4-8c957":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "test-deployment-79ff746c4-8c957",
      GenerateName: (string) (len=26) "test-deployment-79ff746c4-",
      Namespace: (string) (len=15) "deployment-6864",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7da021f3-9455-420d-8e61-cd8ef88d53d2",
      ResourceVersion: (string) (len=5) "29526",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143218,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "79ff746c4",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=25) "test-deployment-79ff746c4",
          UID: (types.UID) (len=36) "3de90478-f76e-4d65-a303-01290ec866c9",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143218,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  33 64 65 39 30 34 37 38  |uid\":\"3de90478|
              000000a0  2d 66 37 36 65 2d 34 64  36 35 2d 61 33 30 33 2d  |-f76e-4d65-a303-|
              000000b0  30 31 32 39 30 65 63 38  36 36 63 39 5c 22 7d 22  |01290ec866c9\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143219,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 35 2e  31 34 33 5c 22 7d 22 3a  |.233.65.143\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-24znj",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-24znj",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(1),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "co4fe9zoo9oc-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143219,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143218,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143219,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143219,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143218,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.39",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.39"
        }
      },
      PodIP: (string) (len=13) "10.233.65.143",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.65.143"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143218,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63849143219,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://0efd9368ba353202e9875cfa3a8677780a73e33045319a50f4ab4e5aa40468d3",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  Apr 19 17:06:59.836: INFO: pod: "test-deployment-79ff746c4-m578b":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "test-deployment-79ff746c4-m578b",
      GenerateName: (string) (len=26) "test-deployment-79ff746c4-",
      Namespace: (string) (len=15) "deployment-6864",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ad40c932-23bd-4784-9160-4743da869025",
      ResourceVersion: (string) (len=5) "29482",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143217,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "79ff746c4",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=25) "test-deployment-79ff746c4",
          UID: (types.UID) (len=36) "3de90478-f76e-4d65-a303-01290ec866c9",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143217,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  33 64 65 39 30 34 37 38  |uid\":\"3de90478|
              000000a0  2d 66 37 36 65 2d 34 64  36 35 2d 61 33 30 33 2d  |-f76e-4d65-a303-|
              000000b0  30 31 32 39 30 65 63 38  36 36 63 39 5c 22 7d 22  |01290ec866c9\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143218,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 36 2e  39 37 5c 22 7d 22 3a 7b  |.233.66.97\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-j5k66",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-j5k66",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(1),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "co4fe9zoo9oc-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143218,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143217,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143218,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143218,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143217,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.60",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.60"
        }
      },
      PodIP: (string) (len=12) "10.233.66.97",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.66.97"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143217,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63849143218,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://cad6fab3a218cb94884b9f203004f327ef3ae30acb1780b27b2eef44985bcfd6",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  Apr 19 17:06:59.839: INFO: ReplicaSet "test-deployment-7fcc79b8c7":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=26) "test-deployment-7fcc79b8c7",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6864",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "fc0e6350-cb0f-4957-b812-268e111b9abe",
      ResourceVersion: (string) (len=5) "29447",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143213,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "7fcc79b8c7",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=15) "test-deployment",
          UID: (types.UID) (len=36) "418257f2-ea9e-48be-beb7-0bf3b7b26931",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143217,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=827) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              000000d0  65 2d 68 61 73 68 22 3a  7b 7d 2c 22 66 3a 74 65  |e-hash":{},"f:te|
              000000e0  73 74 2d 64 65 70 6c 6f  79 6d 65 6e 74 2d 73 74  |st-deployment-st|
              000000f0  61 74 69 63 22 3a 7b 7d  7d 2c 22 66 3a 6f 77 6e  |atic":{}},"f:own|
              00000100  65 72 52 65 66 65 72 65  6e 63 65 73 22 3a 7b 22  |erReferences":{"|
              00000110  2e 22 3a 7b 7d 2c 22 6b  3a 7b 5c 22 75 69 64 5c  |.":{},"k:{\"uid\|
              00000120  22 3a 5c 22 34 31 38 32  35 37 66 32 2d 65 61 39  |":\"418257f2-ea9|
              00000130  65 2d 34 38 62 65 2d 62  65 62 37 2d 30 62 66 33  |e-48be-beb7-0bf3|
              00000140  62 37 62 32 36 39 33 31  5c 22 7d 22 3a 7b 7d 7d  |b7b26931\"}":{}}|
              00000150  7d 2c 22 66 3a 73 70 65  63 22 3a 7b 22 66 3a 72  |},"f:spec":{"f:r|
              00000160  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 73  |eplicas":{},"f:s|
              00000170  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 74  |elector":{},"f:t|
              00000180  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000190  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              000001a0  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 70 6f  |s":{".":{},"f:po|
              000001b0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001c0  3a 7b 7d 2c 22 66 3a 74  65 73 74 2d 64 65 70 6c  |:{},"f:test-depl|
              000001d0  6f 79 6d 65 6e 74 2d 73  74 61 74 69 63 22 3a 7b  |oyment-static":{|
              000001e0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000200  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 74 65 73  |:{\"name\":\"tes|
              00000210  74 2d 64 65 70 6c 6f 79  6d 65 6e 74 5c 22 7d 22  |t-deployment\"}"|
              00000220  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000230  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000240  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000250  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000260  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              00000270  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              00000280  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000290  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000002a0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000002b0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000002c0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              000002d0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000002e0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000002f0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000300  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000310  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000320  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000330  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143217,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "7fcc79b8c7",
          (string) (len=22) "test-deployment-static": (string) (len=4) "true"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "7fcc79b8c7",
            (string) (len=22) "test-deployment-static": (string) (len=4) "true"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=15) "test-deployment",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(1),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 3,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }


  Apr 19 17:06:59.846: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0419 17:06:59.853572      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "deployment-6864" for this suite. @ 04/19/24 17:06:59.855
• [6.037 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:624
  STEP: Creating a kubernetes client @ 04/19/24 17:06:59.867
  Apr 19 17:06:59.867: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename sched-preemption @ 04/19/24 17:06:59.878
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:06:59.914
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:06:59.918
  Apr 19 17:06:59.945: INFO: Waiting up to 1m0s for all nodes to be ready
  E0419 17:07:00.853993      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:01.854474      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:02.854805      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:03.855078      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:04.855869      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:05.864718      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:06.859910      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:07.860416      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:08.860766      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:09.861264      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:10.863019      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:11.861994      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:12.863558      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:13.863253      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:14.863539      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:15.864770      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:16.865158      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:17.865725      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:18.874928      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:19.874240      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:20.874673      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:21.874827      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:22.875806      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:23.876218      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:24.876568      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:25.877813      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:26.878769      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:27.879018      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:28.879153      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:29.880105      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:30.881018      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:31.881291      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:32.881402      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:33.882238      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:34.883061      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:35.883533      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:36.883670      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:37.884212      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:38.884599      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:39.885077      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:40.885778      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:41.886645      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:42.886853      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:43.887673      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:44.887383      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:45.887679      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:46.888046      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:47.888656      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:48.888681      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:49.889603      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:50.889967      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:51.890230      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:52.890499      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:53.891421      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:54.892319      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:55.892819      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:56.893156      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:57.893589      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:58.893781      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:07:59.894145      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:07:59.961: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 04/19/24 17:07:59.973
  Apr 19 17:07:59.973: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename sched-preemption-path @ 04/19/24 17:07:59.979
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:08:00.028
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:08:00.04
  STEP: Finding an available node @ 04/19/24 17:08:00.05
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 04/19/24 17:08:00.051
  E0419 17:08:00.894790      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:01.894614      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 04/19/24 17:08:02.11
  Apr 19 17:08:02.142: INFO: found a healthy node: co4fe9zoo9oc-3
  E0419 17:08:02.895035      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:03.895320      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:04.896775      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:05.897201      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:06.897335      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:07.898395      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:08:08.285: INFO: pods created so far: [1 1 1]
  Apr 19 17:08:08.286: INFO: length of pods created so far: 3
  E0419 17:08:08.898434      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:09.898737      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:08:10.313: INFO: pods created so far: [2 2 1]
  E0419 17:08:10.899221      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:11.899827      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:12.900617      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:13.901129      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:14.901942      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:15.901637      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:16.902594      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:08:17.561: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-1268" for this suite. @ 04/19/24 17:08:17.575
  Apr 19 17:08:17.633: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-5192" for this suite. @ 04/19/24 17:08:17.652
• [77.806 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicationController should release no longer matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:104
  STEP: Creating a kubernetes client @ 04/19/24 17:08:17.679
  Apr 19 17:08:17.679: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename replication-controller @ 04/19/24 17:08:17.686
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:08:17.729
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:08:17.739
  STEP: Given a ReplicationController is created @ 04/19/24 17:08:17.751
  STEP: When the matched label of one of its pods change @ 04/19/24 17:08:17.766
  Apr 19 17:08:17.775: INFO: Pod name pod-release: Found 0 pods out of 1
  E0419 17:08:17.904165      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:18.904409      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:19.905354      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:20.905569      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:21.905652      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:08:22.783: INFO: Pod name pod-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 04/19/24 17:08:22.806
  E0419 17:08:22.906514      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:08:23.819: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-9431" for this suite. @ 04/19/24 17:08:23.826
• [6.161 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:54
  STEP: Creating a kubernetes client @ 04/19/24 17:08:23.852
  Apr 19 17:08:23.852: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename podtemplate @ 04/19/24 17:08:23.855
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:08:23.89
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:08:23.898
  E0419 17:08:23.907273      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:08:23.961: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-8801" for this suite. @ 04/19/24 17:08:23.969
• [0.128 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:349
  STEP: Creating a kubernetes client @ 04/19/24 17:08:23.981
  Apr 19 17:08:23.981: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename security-context-test @ 04/19/24 17:08:23.984
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:08:24.013
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:08:24.017
  E0419 17:08:24.907724      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:25.908624      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:26.908705      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:27.909782      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:08:28.071: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-7019" for this suite. @ 04/19/24 17:08:28.091
• [4.131 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/flowcontrol.go:270
  STEP: Creating a kubernetes client @ 04/19/24 17:08:28.116
  Apr 19 17:08:28.116: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename apf @ 04/19/24 17:08:28.122
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:08:28.17
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:08:28.178
  STEP: getting /apis @ 04/19/24 17:08:28.188
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 04/19/24 17:08:28.201
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 04/19/24 17:08:28.205
  STEP: creating @ 04/19/24 17:08:28.209
  STEP: getting @ 04/19/24 17:08:28.259
  STEP: listing @ 04/19/24 17:08:28.273
  STEP: watching @ 04/19/24 17:08:28.284
  Apr 19 17:08:28.286: INFO: starting watch
  STEP: patching @ 04/19/24 17:08:28.291
  STEP: updating @ 04/19/24 17:08:28.302
  Apr 19 17:08:28.318: INFO: waiting for watch events with expected annotations
  Apr 19 17:08:28.319: INFO: missing expected annotations, waiting: map[string]string(nil)
  STEP: getting /status @ 04/19/24 17:08:28.32
  STEP: patching /status @ 04/19/24 17:08:28.329
  STEP: updating /status @ 04/19/24 17:08:28.341
  STEP: deleting @ 04/19/24 17:08:28.388
  STEP: deleting a collection @ 04/19/24 17:08:28.413
  Apr 19 17:08:28.453: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-737" for this suite. @ 04/19/24 17:08:28.464
• [0.363 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:245
  STEP: Creating a kubernetes client @ 04/19/24 17:08:28.479
  Apr 19 17:08:28.479: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename namespaces @ 04/19/24 17:08:28.481
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:08:28.511
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:08:28.516
  STEP: Creating a test namespace @ 04/19/24 17:08:28.521
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:08:28.555
  STEP: Creating a pod in the namespace @ 04/19/24 17:08:28.56
  STEP: Waiting for the pod to have running status @ 04/19/24 17:08:28.573
  E0419 17:08:28.909154      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:29.911229      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the namespace @ 04/19/24 17:08:30.588
  STEP: Waiting for the namespace to be removed. @ 04/19/24 17:08:30.605
  E0419 17:08:30.910718      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:31.910557      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:32.910733      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:33.911747      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:34.912041      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:35.912797      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:36.913739      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:37.914920      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:38.915952      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:39.917137      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:40.917972      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 04/19/24 17:08:41.613
  STEP: Verifying there are no pods in the namespace @ 04/19/24 17:08:41.639
  Apr 19 17:08:41.650: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-8310" for this suite. @ 04/19/24 17:08:41.661
  STEP: Destroying namespace "nsdeletetest-9256" for this suite. @ 04/19/24 17:08:41.68
  Apr 19 17:08:41.690: INFO: Namespace nsdeletetest-9256 was already deleted
  STEP: Destroying namespace "nsdeletetest-677" for this suite. @ 04/19/24 17:08:41.69
• [13.229 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should support proportional scaling [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:160
  STEP: Creating a kubernetes client @ 04/19/24 17:08:41.726
  Apr 19 17:08:41.726: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename deployment @ 04/19/24 17:08:41.731
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:08:41.769
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:08:41.777
  Apr 19 17:08:41.786: INFO: Creating deployment "webserver-deployment"
  Apr 19 17:08:41.801: INFO: Waiting for observed generation 1
  E0419 17:08:41.918412      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:42.921250      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:08:43.819: INFO: Waiting for all required pods to come up
  Apr 19 17:08:43.836: INFO: Pod name httpd: Found 10 pods out of 10
  STEP: ensuring each pod is running @ 04/19/24 17:08:43.837
  E0419 17:08:43.921298      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:44.921672      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:08:45.869: INFO: Waiting for deployment "webserver-deployment" to complete
  Apr 19 17:08:45.894: INFO: Updating deployment "webserver-deployment" with a non-existent image
  E0419 17:08:45.922881      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:08:45.925: INFO: Updating deployment webserver-deployment
  Apr 19 17:08:45.926: INFO: Waiting for observed generation 2
  E0419 17:08:46.922713      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:47.923194      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:08:47.951: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
  Apr 19 17:08:47.956: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
  Apr 19 17:08:47.965: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  Apr 19 17:08:47.987: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
  Apr 19 17:08:47.988: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
  Apr 19 17:08:47.994: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  Apr 19 17:08:48.005: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
  Apr 19 17:08:48.005: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
  Apr 19 17:08:48.030: INFO: Updating deployment webserver-deployment
  Apr 19 17:08:48.030: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
  Apr 19 17:08:48.059: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
  Apr 19 17:08:48.078: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
  Apr 19 17:08:48.115: INFO: Deployment "webserver-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=20) "webserver-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1553",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5f7197b3-7116-4de4-8ccd-9a9dfab9224b",
      ResourceVersion: (string) (len=5) "30307",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143321,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=635) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000160  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000170  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000180  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000190  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              000001a0  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001b0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001c0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001d0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001e0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001f0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              00000200  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000210  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000220  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000230  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000270  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=541) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 6e 61  |licas":{},"f:una|
              000001f0  76 61 69 6c 61 62 6c 65  52 65 70 6c 69 63 61 73  |vailableReplicas|
              00000200  22 3a 7b 7d 2c 22 66 3a  75 70 64 61 74 65 64 52  |":{},"f:updatedR|
              00000210  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(30),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 2,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 3,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 3,
      Replicas: (int32) 13,
      UpdatedReplicas: (int32) 5,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      UnavailableReplicas: (int32) 5,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143321,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=59) "ReplicaSet \"webserver-deployment-9b4f5bf69\" is progressing."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Apr 19 17:08:48.152: INFO: New ReplicaSet "webserver-deployment-9b4f5bf69" of Deployment "webserver-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1553",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5dd1d0d9-8766-45bb-9f03-34c7a20f86e9",
      ResourceVersion: (string) (len=5) "30302",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143325,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "5f7197b3-7116-4de4-8ccd-9a9dfab9224b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 35 66 37 31 39 37  62 33 2d 37 31 31 36 2d  |\"5f7197b3-7116-|
              00000120  34 64 65 34 2d 38 63 63  64 2d 39 61 39 64 66 61  |4de4-8ccd-9a9dfa|
              00000130  62 39 32 32 34 62 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |b9224b\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(13),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 5,
      FullyLabeledReplicas: (int32) 5,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 19 17:08:48.154: INFO: All old ReplicaSets of Deployment "webserver-deployment":
  Apr 19 17:08:48.154: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-557759b7c7",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1553",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1a9a8aae-5efb-46b5-9e0c-1bbabfe319e0",
      ResourceVersion: (string) (len=5) "30301",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143321,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "5f7197b3-7116-4de4-8ccd-9a9dfab9224b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 35 66 37 31 39 37  62 33 2d 37 31 31 36 2d  |\"5f7197b3-7116-|
              00000120  34 64 65 34 2d 38 63 63  64 2d 39 61 39 64 66 61  |4de4-8ccd-9a9dfa|
              00000130  62 39 32 32 34 62 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |b9224b\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(20),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 8,
      FullyLabeledReplicas: (int32) 8,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 19 17:08:48.178: INFO: Pod "webserver-deployment-557759b7c7-5mdk9" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-5mdk9",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1553",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f3b8300a-4e9c-4085-9df9-1b35d9e0eba5",
      ResourceVersion: (string) (len=5) "30202",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143321,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "1a9a8aae-5efb-46b5-9e0c-1bbabfe319e0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143321,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 61  39 61 38 61 61 65 2d 35  |d\":\"1a9a8aae-5|
              00000090  65 66 62 2d 34 36 62 35  2d 39 65 30 63 2d 31 62  |efb-46b5-9e0c-1b|
              000000a0  62 61 62 66 65 33 31 39  65 30 5c 22 7d 22 3a 7b  |babfe319e0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 35 2e  31 34 35 5c 22 7d 22 3a  |.233.65.145\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-fp44g",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-fp44g",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "co4fe9zoo9oc-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143321,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143321,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.39",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.39"
        }
      },
      PodIP: (string) (len=13) "10.233.65.145",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.65.145"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143321,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63849143322,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://72b660e44e4ce97a552e3787f4393459cd91e675438e80543755238e48bec4a6",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 19 17:08:48.206: INFO: Pod "webserver-deployment-557759b7c7-7gpgk" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-7gpgk",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1553",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c2d735bf-dc20-40f1-bd7d-5fccc6f2e29b",
      ResourceVersion: (string) (len=5) "30222",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143321,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "1a9a8aae-5efb-46b5-9e0c-1bbabfe319e0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143321,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 61  39 61 38 61 61 65 2d 35  |d\":\"1a9a8aae-5|
              00000090  65 66 62 2d 34 36 62 35  2d 39 65 30 63 2d 31 62  |efb-46b5-9e0c-1b|
              000000a0  62 61 62 66 65 33 31 39  65 30 5c 22 7d 22 3a 7b  |babfe319e0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 36 2e  31 31 30 5c 22 7d 22 3a  |.233.66.110\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-vr98d",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-vr98d",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "co4fe9zoo9oc-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143321,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143321,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.60",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.60"
        }
      },
      PodIP: (string) (len=13) "10.233.66.110",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.66.110"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143321,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63849143323,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://7558ea047f8029e4449acace719ebfb9dd2d4fe68a77087aea2161fd0c68e1ab",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 19 17:08:48.235: INFO: Pod "webserver-deployment-557759b7c7-8zd9q" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-8zd9q",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1553",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f4c731c9-6d9c-48ae-8138-c2c4cb86783f",
      ResourceVersion: (string) (len=5) "30196",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143321,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "1a9a8aae-5efb-46b5-9e0c-1bbabfe319e0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143321,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 61  39 61 38 61 61 65 2d 35  |d\":\"1a9a8aae-5|
              00000090  65 66 62 2d 34 36 62 35  2d 39 65 30 63 2d 31 62  |efb-46b5-9e0c-1b|
              000000a0  62 61 62 66 65 33 31 39  65 30 5c 22 7d 22 3a 7b  |babfe319e0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 35 2e  31 34 36 5c 22 7d 22 3a  |.233.65.146\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-qpfxj",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-qpfxj",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "co4fe9zoo9oc-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143322,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143321,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.39",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.39"
        }
      },
      PodIP: (string) (len=13) "10.233.65.146",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.65.146"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143322,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63849143322,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://55c3d43af52b5c6aeb005aafd9468da4a319b73e6fd8a8eba045f777e6cd23ab",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 19 17:08:48.245: INFO: Pod "webserver-deployment-557759b7c7-9nv7s" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-9nv7s",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1553",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "bd8edc01-00fd-43ee-97ca-0a9ff93a442d",
      ResourceVersion: (string) (len=5) "30318",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143328,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "1a9a8aae-5efb-46b5-9e0c-1bbabfe319e0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 61  39 61 38 61 61 65 2d 35  |d\":\"1a9a8aae-5|
              00000090  65 66 62 2d 34 36 62 35  2d 39 65 30 63 2d 31 62  |efb-46b5-9e0c-1b|
              000000a0  62 61 62 66 65 33 31 39  65 30 5c 22 7d 22 3a 7b  |babfe319e0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-8jfzg",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-8jfzg",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "co4fe9zoo9oc-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 19 17:08:48.266: INFO: Pod "webserver-deployment-557759b7c7-fl4cm" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-fl4cm",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1553",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2cc48db3-efbc-4c4d-961b-bfe1cfb0d7cc",
      ResourceVersion: (string) (len=5) "30225",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143321,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "1a9a8aae-5efb-46b5-9e0c-1bbabfe319e0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143321,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 61  39 61 38 61 61 65 2d 35  |d\":\"1a9a8aae-5|
              00000090  65 66 62 2d 34 36 62 35  2d 39 65 30 63 2d 31 62  |efb-46b5-9e0c-1b|
              000000a0  62 61 62 66 65 33 31 39  65 30 5c 22 7d 22 3a 7b  |babfe319e0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 36 2e  31 30 39 5c 22 7d 22 3a  |.233.66.109\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-mtgqn",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-mtgqn",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "co4fe9zoo9oc-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143322,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143321,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.60",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.60"
        }
      },
      PodIP: (string) (len=13) "10.233.66.109",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.66.109"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143322,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63849143323,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://fbe49b68c8e6637405c83640b1b6768bb78496cdefb953c2fca3dc907e10a2cb",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 19 17:08:48.282: INFO: Pod "webserver-deployment-557759b7c7-fr9vh" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-fr9vh",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1553",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ea6b26f9-9d1d-4639-a5b0-563d95683618",
      ResourceVersion: (string) (len=5) "30308",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143328,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "1a9a8aae-5efb-46b5-9e0c-1bbabfe319e0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 61  39 61 38 61 61 65 2d 35  |d\":\"1a9a8aae-5|
              00000090  65 66 62 2d 34 36 62 35  2d 39 65 30 63 2d 31 62  |efb-46b5-9e0c-1b|
              000000a0  62 61 62 66 65 33 31 39  65 30 5c 22 7d 22 3a 7b  |babfe319e0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-2jppw",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-2jppw",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "co4fe9zoo9oc-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 19 17:08:48.288: INFO: Pod "webserver-deployment-557759b7c7-hjg7h" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-hjg7h",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1553",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "aa608d0f-bbe6-4f83-adb8-79b2347bbf9a",
      ResourceVersion: (string) (len=5) "30317",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143328,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "1a9a8aae-5efb-46b5-9e0c-1bbabfe319e0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 61  39 61 38 61 61 65 2d 35  |d\":\"1a9a8aae-5|
              00000090  65 66 62 2d 34 36 62 35  2d 39 65 30 63 2d 31 62  |efb-46b5-9e0c-1b|
              000000a0  62 61 62 66 65 33 31 39  65 30 5c 22 7d 22 3a 7b  |babfe319e0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-899vp",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-899vp",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "co4fe9zoo9oc-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 19 17:08:48.293: INFO: Pod "webserver-deployment-557759b7c7-srxps" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-srxps",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1553",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7a3b50c1-b093-472b-b890-0d388e64e6d2",
      ResourceVersion: (string) (len=5) "30208",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143321,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "1a9a8aae-5efb-46b5-9e0c-1bbabfe319e0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143321,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 61  39 61 38 61 61 65 2d 35  |d\":\"1a9a8aae-5|
              00000090  65 66 62 2d 34 36 62 35  2d 39 65 30 63 2d 31 62  |efb-46b5-9e0c-1b|
              000000a0  62 61 62 66 65 33 31 39  65 30 5c 22 7d 22 3a 7b  |babfe319e0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 34 2e  31 33 30 5c 22 7d 22 3a  |.233.64.130\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-g2w9b",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-g2w9b",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "co4fe9zoo9oc-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143321,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143321,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.127",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.127"
        }
      },
      PodIP: (string) (len=13) "10.233.64.130",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.64.130"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143321,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63849143323,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://627cf16c77c225636aa623e4c08b1d288507dbd54a14a060150837f14877e72c",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 19 17:08:48.300: INFO: Pod "webserver-deployment-557759b7c7-ss7kq" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-ss7kq",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1553",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "dd565f21-6109-4434-ab41-b14395586ef9",
      ResourceVersion: (string) (len=5) "30199",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143321,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "1a9a8aae-5efb-46b5-9e0c-1bbabfe319e0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143321,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 61  39 61 38 61 61 65 2d 35  |d\":\"1a9a8aae-5|
              00000090  65 66 62 2d 34 36 62 35  2d 39 65 30 63 2d 31 62  |efb-46b5-9e0c-1b|
              000000a0  62 61 62 66 65 33 31 39  65 30 5c 22 7d 22 3a 7b  |babfe319e0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 35 2e  31 34 34 5c 22 7d 22 3a  |.233.65.144\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-l8tgb",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-l8tgb",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "co4fe9zoo9oc-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143321,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143321,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.39",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.39"
        }
      },
      PodIP: (string) (len=13) "10.233.65.144",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.65.144"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143321,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63849143322,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://e031c0c68ee8a9f8e96e5e25abeb6c028f8b9bf4094fd80bb98700b46a3d6aab",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 19 17:08:48.312: INFO: Pod "webserver-deployment-557759b7c7-w2blx" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-w2blx",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1553",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "465b083c-d187-4f26-a54b-043a7f6bcb44",
      ResourceVersion: (string) (len=5) "30228",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143321,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "1a9a8aae-5efb-46b5-9e0c-1bbabfe319e0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143321,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 61  39 61 38 61 61 65 2d 35  |d\":\"1a9a8aae-5|
              00000090  65 66 62 2d 34 36 62 35  2d 39 65 30 63 2d 31 62  |efb-46b5-9e0c-1b|
              000000a0  62 61 62 66 65 33 31 39  65 30 5c 22 7d 22 3a 7b  |babfe319e0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143324,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 34 2e  31 33 31 5c 22 7d 22 3a  |.233.64.131\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-28zgp",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-28zgp",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "co4fe9zoo9oc-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143324,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143321,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143324,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143324,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143321,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.127",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.127"
        }
      },
      PodIP: (string) (len=13) "10.233.64.131",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.64.131"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143321,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63849143323,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://9c5afd18964811b1113d7248d7c7925a4539edcd43742ef2847d4be936af2d8c",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 19 17:08:48.320: INFO: Pod "webserver-deployment-557759b7c7-zf6lc" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-zf6lc",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1553",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "72159eb2-5c45-48ec-87de-cadf6ffa3b79",
      ResourceVersion: (string) (len=5) "30212",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143321,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "1a9a8aae-5efb-46b5-9e0c-1bbabfe319e0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143321,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 61  39 61 38 61 61 65 2d 35  |d\":\"1a9a8aae-5|
              00000090  65 66 62 2d 34 36 62 35  2d 39 65 30 63 2d 31 62  |efb-46b5-9e0c-1b|
              000000a0  62 61 62 66 65 33 31 39  65 30 5c 22 7d 22 3a 7b  |babfe319e0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 34 2e  31 32 39 5c 22 7d 22 3a  |.233.64.129\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-kldzv",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-kldzv",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "co4fe9zoo9oc-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143321,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143323,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143321,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.127",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.127"
        }
      },
      PodIP: (string) (len=13) "10.233.64.129",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.64.129"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143321,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63849143322,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://6551a9a8e2c9a6fafd309b7e56bee6202e07c2ba0b168444e0d893b722ea3a93",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 19 17:08:48.329: INFO: Pod "webserver-deployment-9b4f5bf69-6fwf4" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-6fwf4",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1553",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "63bab896-26d8-4998-8dae-5f1ceb139d73",
      ResourceVersion: (string) (len=5) "30280",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143326,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "5dd1d0d9-8766-45bb-9f03-34c7a20f86e9",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 64  64 31 64 30 64 39 2d 38  |d\":\"5dd1d0d9-8|
              00000090  37 36 36 2d 34 35 62 62  2d 39 66 30 33 2d 33 34  |766-45bb-9f03-34|
              000000a0  63 37 61 32 30 66 38 36  65 39 5c 22 7d 22 3a 7b  |c7a20f86e9\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-sdbpk",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-sdbpk",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "co4fe9zoo9oc-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.39",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.39"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143326,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 19 17:08:48.357: INFO: Pod "webserver-deployment-9b4f5bf69-gst58" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-gst58",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1553",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3b4cfc42-0cd5-4a2d-9f71-7f8ec1ecd223",
      ResourceVersion: (string) (len=5) "30252",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143326,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "5dd1d0d9-8766-45bb-9f03-34c7a20f86e9",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 64  64 31 64 30 64 39 2d 38  |d\":\"5dd1d0d9-8|
              00000090  37 36 36 2d 34 35 62 62  2d 39 66 30 33 2d 33 34  |766-45bb-9f03-34|
              000000a0  63 37 61 32 30 66 38 36  65 39 5c 22 7d 22 3a 7b  |c7a20f86e9\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-sh65g",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-sh65g",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "co4fe9zoo9oc-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.127",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.127"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143326,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 19 17:08:48.364: INFO: Pod "webserver-deployment-9b4f5bf69-kpwf6" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-kpwf6",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1553",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4d4ebec7-3d1f-4d59-9bb9-dd97bd63d012",
      ResourceVersion: (string) (len=5) "30260",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143325,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "5dd1d0d9-8766-45bb-9f03-34c7a20f86e9",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143325,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 64  64 31 64 30 64 39 2d 38  |d\":\"5dd1d0d9-8|
              00000090  37 36 36 2d 34 35 62 62  2d 39 66 30 33 2d 33 34  |766-45bb-9f03-34|
              000000a0  63 37 61 32 30 66 38 36  65 39 5c 22 7d 22 3a 7b  |c7a20f86e9\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-crk54",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-crk54",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "co4fe9zoo9oc-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.39",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.39"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143326,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 19 17:08:48.379: INFO: Pod "webserver-deployment-9b4f5bf69-lp4wc" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-lp4wc",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1553",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "70e72b27-5500-447b-bbe5-776188496094",
      ResourceVersion: (string) (len=5) "30314",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143328,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "5dd1d0d9-8766-45bb-9f03-34c7a20f86e9",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 64  64 31 64 30 64 39 2d 38  |d\":\"5dd1d0d9-8|
              00000090  37 36 36 2d 34 35 62 62  2d 39 66 30 33 2d 33 34  |766-45bb-9f03-34|
              000000a0  63 37 61 32 30 66 38 36  65 39 5c 22 7d 22 3a 7b  |c7a20f86e9\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-mf75p",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-mf75p",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 19 17:08:48.391: INFO: Pod "webserver-deployment-9b4f5bf69-njlhh" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-njlhh",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1553",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "019774a7-6ce6-4255-bf63-d851a86bbd77",
      ResourceVersion: (string) (len=5) "30248",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143325,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "5dd1d0d9-8766-45bb-9f03-34c7a20f86e9",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143325,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 64  64 31 64 30 64 39 2d 38  |d\":\"5dd1d0d9-8|
              00000090  37 36 36 2d 34 35 62 62  2d 39 66 30 33 2d 33 34  |766-45bb-9f03-34|
              000000a0  63 37 61 32 30 66 38 36  65 39 5c 22 7d 22 3a 7b  |c7a20f86e9\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-nr29s",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-nr29s",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "co4fe9zoo9oc-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.60",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.60"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143326,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 19 17:08:48.400: INFO: Pod "webserver-deployment-9b4f5bf69-phz7v" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-phz7v",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1553",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "aa5fac4b-cbc8-45c3-9881-3a025c042f67",
      ResourceVersion: (string) (len=5) "30281",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143326,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "5dd1d0d9-8766-45bb-9f03-34c7a20f86e9",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 64  64 31 64 30 64 39 2d 38  |d\":\"5dd1d0d9-8|
              00000090  37 36 36 2d 34 35 62 62  2d 39 66 30 33 2d 33 34  |766-45bb-9f03-34|
              000000a0  63 37 61 32 30 66 38 36  65 39 5c 22 7d 22 3a 7b  |c7a20f86e9\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-v9xn8",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-v9xn8",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "co4fe9zoo9oc-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143326,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.60",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.60"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143326,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 19 17:08:48.408: INFO: Pod "webserver-deployment-9b4f5bf69-qs527" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-qs527",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1553",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "775eab5f-4ec2-4184-9aed-e162518a7296",
      ResourceVersion: (string) (len=5) "30319",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143328,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "5dd1d0d9-8766-45bb-9f03-34c7a20f86e9",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 64  64 31 64 30 64 39 2d 38  |d\":\"5dd1d0d9-8|
              00000090  37 36 36 2d 34 35 62 62  2d 39 66 30 33 2d 33 34  |766-45bb-9f03-34|
              000000a0  63 37 61 32 30 66 38 36  65 39 5c 22 7d 22 3a 7b  |c7a20f86e9\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-9mlhs",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-9mlhs",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "co4fe9zoo9oc-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.127",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=15) "192.168.121.127"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143328,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 19 17:08:48.458: INFO: Pod "webserver-deployment-9b4f5bf69-qw6ns" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-qw6ns",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1553",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6873e0d7-3048-4e12-a0fb-c1bfc34e0003",
      ResourceVersion: (string) (len=5) "30313",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143328,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "5dd1d0d9-8766-45bb-9f03-34c7a20f86e9",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143328,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 64  64 31 64 30 64 39 2d 38  |d\":\"5dd1d0d9-8|
              00000090  37 36 36 2d 34 35 62 62  2d 39 66 30 33 2d 33 34  |766-45bb-9f03-34|
              000000a0  63 37 61 32 30 66 38 36  65 39 5c 22 7d 22 3a 7b  |c7a20f86e9\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-2w42b",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-2w42b",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 19 17:08:48.466: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-1553" for this suite. @ 04/19/24 17:08:48.483
• [6.862 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:183
  STEP: Creating a kubernetes client @ 04/19/24 17:08:48.593
  Apr 19 17:08:48.594: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename kubelet-test @ 04/19/24 17:08:48.598
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:08:48.745
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:08:48.758
  E0419 17:08:48.923481      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:49.924623      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:08:50.865: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-4553" for this suite. @ 04/19/24 17:08:50.878
• [2.299 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:78
  STEP: Creating a kubernetes client @ 04/19/24 17:08:50.894
  Apr 19 17:08:50.894: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename resourcequota @ 04/19/24 17:08:50.898
  E0419 17:08:50.925067      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:08:50.936
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:08:50.943
  STEP: Counting existing ResourceQuota @ 04/19/24 17:08:50.951
  E0419 17:08:51.925468      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:52.926234      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:53.927951      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:54.928471      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:55.929461      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 04/19/24 17:08:55.987
  STEP: Ensuring resource quota status is calculated @ 04/19/24 17:08:56.003
  E0419 17:08:56.954732      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:57.935592      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:08:58.020: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3494" for this suite. @ 04/19/24 17:08:58.038
• [7.166 seconds]
------------------------------
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:641
  STEP: Creating a kubernetes client @ 04/19/24 17:08:58.061
  Apr 19 17:08:58.061: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename statefulset @ 04/19/24 17:08:58.065
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:08:58.102
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:08:58.107
  STEP: Creating service test in namespace statefulset-8527 @ 04/19/24 17:08:58.116
  STEP: Initializing watcher for selector baz=blah,foo=bar @ 04/19/24 17:08:58.132
  STEP: Creating stateful set ss in namespace statefulset-8527 @ 04/19/24 17:08:58.152
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8527 @ 04/19/24 17:08:58.164
  Apr 19 17:08:58.171: INFO: Found 0 stateful pods, waiting for 1
  E0419 17:08:58.936774      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:08:59.938804      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:00.939034      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:01.939389      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:02.939553      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:03.939943      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:04.940313      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:05.940660      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:06.941058      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:07.941844      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:09:08.175: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod @ 04/19/24 17:09:08.176
  Apr 19 17:09:08.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=statefulset-8527 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 19 17:09:08.594: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 19 17:09:08.595: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 19 17:09:08.595: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 19 17:09:08.601: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E0419 17:09:08.942087      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:09.943309      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:10.943511      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:11.943797      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:12.944942      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:13.945055      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:14.945416      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:15.945732      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:16.946116      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:17.946780      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:09:18.605: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Apr 19 17:09:18.606: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Apr 19 17:09:18.643: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999964s
  E0419 17:09:18.947265      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:09:19.662: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.993319158s
  E0419 17:09:19.949498      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:09:20.668: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.974912892s
  E0419 17:09:20.948822      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:09:21.680: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.968251792s
  E0419 17:09:21.949588      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:09:22.692: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.956429939s
  E0419 17:09:22.950919      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:09:23.708: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.944085415s
  E0419 17:09:23.951512      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:09:24.723: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.927843482s
  E0419 17:09:24.952480      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:09:25.737: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.913746598s
  E0419 17:09:25.953287      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:09:26.755: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.89869371s
  E0419 17:09:26.954579      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:09:27.768: INFO: Verifying statefulset ss doesn't scale past 1 for another 880.780246ms
  E0419 17:09:27.955141      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8527 @ 04/19/24 17:09:28.77
  Apr 19 17:09:28.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=statefulset-8527 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  E0419 17:09:28.956048      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:09:29.141: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 19 17:09:29.141: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 19 17:09:29.141: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 19 17:09:29.150: INFO: Found 1 stateful pods, waiting for 3
  E0419 17:09:29.956826      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:30.957683      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:31.958400      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:32.958799      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:33.959130      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:34.959340      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:35.959691      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:36.963363      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:37.963715      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:38.963945      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:09:39.155: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 19 17:09:39.155: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 19 17:09:39.155: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Verifying that stateful set ss was scaled up in order @ 04/19/24 17:09:39.156
  STEP: Scale down will halt with unhealthy stateful pod @ 04/19/24 17:09:39.156
  Apr 19 17:09:39.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=statefulset-8527 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 19 17:09:39.496: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 19 17:09:39.497: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 19 17:09:39.497: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 19 17:09:39.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=statefulset-8527 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 19 17:09:39.832: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 19 17:09:39.832: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 19 17:09:39.832: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 19 17:09:39.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=statefulset-8527 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  E0419 17:09:39.964901      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:09:40.202: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 19 17:09:40.202: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 19 17:09:40.202: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 19 17:09:40.202: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Apr 19 17:09:40.209: INFO: Waiting for statefulset status.readyReplicas to become 0, currently 1
  E0419 17:09:40.965324      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:41.965632      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:42.966355      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:43.967415      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:44.967587      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:45.968107      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:46.968356      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:47.968993      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:48.969311      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:09:49.969632      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:09:50.227: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Apr 19 17:09:50.227: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  Apr 19 17:09:50.228: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  Apr 19 17:09:50.264: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.99999943s
  E0419 17:09:50.970829      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:09:51.273: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.989208549s
  E0419 17:09:51.971539      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:09:52.284: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.980202424s
  E0419 17:09:52.971782      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:09:53.299: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.968754376s
  E0419 17:09:53.972169      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:09:54.308: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.954546716s
  E0419 17:09:54.972429      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:09:55.315: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.945473899s
  E0419 17:09:55.972456      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:09:56.325: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.938141013s
  E0419 17:09:56.972942      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:09:57.345: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.929328069s
  E0419 17:09:57.973702      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:09:58.359: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.908555395s
  E0419 17:09:58.973974      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:09:59.369: INFO: Verifying statefulset ss doesn't scale past 3 for another 894.551142ms
  E0419 17:09:59.974377      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8527 @ 04/19/24 17:10:00.37
  Apr 19 17:10:00.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=statefulset-8527 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 19 17:10:00.750: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 19 17:10:00.750: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 19 17:10:00.750: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 19 17:10:00.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=statefulset-8527 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  E0419 17:10:00.976224      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:10:01.059: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 19 17:10:01.059: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 19 17:10:01.059: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 19 17:10:01.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=statefulset-8527 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 19 17:10:01.371: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 19 17:10:01.371: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 19 17:10:01.371: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 19 17:10:01.371: INFO: Scaling statefulset ss to 0
  E0419 17:10:01.976311      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:02.977676      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:03.978508      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:04.978745      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:05.978864      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:06.979197      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:07.979811      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:08.980418      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:09.983018      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:10.981737      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying that stateful set ss was scaled down in reverse order @ 04/19/24 17:10:11.396
  Apr 19 17:10:11.397: INFO: Deleting all statefulset in ns statefulset-8527
  Apr 19 17:10:11.404: INFO: Scaling statefulset ss to 0
  Apr 19 17:10:11.428: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 19 17:10:11.435: INFO: Deleting statefulset ss
  Apr 19 17:10:11.464: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-8527" for this suite. @ 04/19/24 17:10:11.475
• [73.432 seconds]
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Update Demo should create and stop a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:344
  STEP: Creating a kubernetes client @ 04/19/24 17:10:11.493
  Apr 19 17:10:11.493: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename kubectl @ 04/19/24 17:10:11.499
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:10:11.532
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:10:11.539
  STEP: creating a replication controller @ 04/19/24 17:10:11.546
  Apr 19 17:10:11.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-864 create -f -'
  Apr 19 17:10:11.848: INFO: stderr: ""
  Apr 19 17:10:11.849: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 04/19/24 17:10:11.849
  Apr 19 17:10:11.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-864 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  E0419 17:10:11.982329      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:10:12.031: INFO: stderr: ""
  Apr 19 17:10:12.031: INFO: stdout: "update-demo-nautilus-462z4 update-demo-nautilus-k9944 "
  Apr 19 17:10:12.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-864 get pods update-demo-nautilus-462z4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 19 17:10:12.183: INFO: stderr: ""
  Apr 19 17:10:12.183: INFO: stdout: ""
  Apr 19 17:10:12.183: INFO: update-demo-nautilus-462z4 is created but not running
  E0419 17:10:12.984753      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:13.983181      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:14.983374      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:15.984230      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:16.984405      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:10:17.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-864 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 19 17:10:17.373: INFO: stderr: ""
  Apr 19 17:10:17.374: INFO: stdout: "update-demo-nautilus-462z4 update-demo-nautilus-k9944 "
  Apr 19 17:10:17.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-864 get pods update-demo-nautilus-462z4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 19 17:10:17.530: INFO: stderr: ""
  Apr 19 17:10:17.530: INFO: stdout: ""
  Apr 19 17:10:17.530: INFO: update-demo-nautilus-462z4 is created but not running
  E0419 17:10:17.984595      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:18.984847      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:19.985426      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:20.985770      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:21.985779      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:10:22.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-864 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 19 17:10:22.722: INFO: stderr: ""
  Apr 19 17:10:22.722: INFO: stdout: "update-demo-nautilus-462z4 update-demo-nautilus-k9944 "
  Apr 19 17:10:22.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-864 get pods update-demo-nautilus-462z4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 19 17:10:22.904: INFO: stderr: ""
  Apr 19 17:10:22.904: INFO: stdout: ""
  Apr 19 17:10:22.904: INFO: update-demo-nautilus-462z4 is created but not running
  E0419 17:10:22.986577      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:23.986906      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:24.987038      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:25.987499      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:26.987766      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:10:27.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-864 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  E0419 17:10:27.987925      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:10:28.116: INFO: stderr: ""
  Apr 19 17:10:28.116: INFO: stdout: "update-demo-nautilus-462z4 update-demo-nautilus-k9944 "
  Apr 19 17:10:28.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-864 get pods update-demo-nautilus-462z4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 19 17:10:28.267: INFO: stderr: ""
  Apr 19 17:10:28.267: INFO: stdout: "true"
  Apr 19 17:10:28.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-864 get pods update-demo-nautilus-462z4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 19 17:10:28.408: INFO: stderr: ""
  Apr 19 17:10:28.408: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 19 17:10:28.408: INFO: validating pod update-demo-nautilus-462z4
  Apr 19 17:10:28.433: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 19 17:10:28.433: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 19 17:10:28.433: INFO: update-demo-nautilus-462z4 is verified up and running
  Apr 19 17:10:28.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-864 get pods update-demo-nautilus-k9944 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 19 17:10:28.601: INFO: stderr: ""
  Apr 19 17:10:28.601: INFO: stdout: "true"
  Apr 19 17:10:28.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-864 get pods update-demo-nautilus-k9944 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 19 17:10:28.762: INFO: stderr: ""
  Apr 19 17:10:28.762: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 19 17:10:28.762: INFO: validating pod update-demo-nautilus-k9944
  Apr 19 17:10:28.779: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 19 17:10:28.779: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 19 17:10:28.779: INFO: update-demo-nautilus-k9944 is verified up and running
  STEP: using delete to clean up resources @ 04/19/24 17:10:28.779
  Apr 19 17:10:28.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-864 delete --grace-period=0 --force -f -'
  Apr 19 17:10:28.924: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 19 17:10:28.924: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  Apr 19 17:10:28.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-864 get rc,svc -l name=update-demo --no-headers'
  E0419 17:10:28.988655      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:10:29.165: INFO: stderr: "No resources found in kubectl-864 namespace.\n"
  Apr 19 17:10:29.165: INFO: stdout: ""
  Apr 19 17:10:29.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-864 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Apr 19 17:10:29.379: INFO: stderr: ""
  Apr 19 17:10:29.379: INFO: stdout: ""
  Apr 19 17:10:29.379: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-864" for this suite. @ 04/19/24 17:10:29.391
• [17.910 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:86
  STEP: Creating a kubernetes client @ 04/19/24 17:10:29.404
  Apr 19 17:10:29.404: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename projected @ 04/19/24 17:10:29.408
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:10:29.443
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:10:29.45
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 17:10:29.458
  E0419 17:10:29.992992      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:30.991958      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:31.992778      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:32.993219      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:10:33.508
  Apr 19 17:10:33.517: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod downwardapi-volume-d60d6319-6cd9-4773-9eb7-f9961a8e2567 container client-container: <nil>
  STEP: delete the pod @ 04/19/24 17:10:33.568
  Apr 19 17:10:33.656: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-424" for this suite. @ 04/19/24 17:10:33.672
• [4.289 seconds]
------------------------------
SSS
------------------------------
[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:531
  STEP: Creating a kubernetes client @ 04/19/24 17:10:33.696
  Apr 19 17:10:33.696: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename svcaccounts @ 04/19/24 17:10:33.703
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:10:33.739
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:10:33.747
  Apr 19 17:10:33.784: INFO: created pod
  E0419 17:10:33.994208      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:34.995007      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:35.995746      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:37.013309      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:10:37.815
  E0419 17:10:38.001823      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:39.002200      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:40.002699      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:41.002667      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:42.003377      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:43.003597      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:44.003751      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:45.005512      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:46.005383      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:47.006380      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:48.006707      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:49.007500      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:50.008808      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:51.008837      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:52.009150      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:53.009963      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:54.010140      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:55.010627      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:56.010622      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:57.010809      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:58.011380      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:10:59.011695      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:00.011782      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:01.012000      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:02.012743      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:03.013329      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:04.013493      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:05.013765      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:06.014129      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:07.014745      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:11:07.818: INFO: polling logs
  Apr 19 17:11:07.842: INFO: Pod logs: 
  I0419 17:10:34.547650       1 log.go:245] OK: Got token
  I0419 17:10:34.548938       1 log.go:245] validating with in-cluster discovery
  I0419 17:10:34.550720       1 log.go:245] OK: got issuer https://kubernetes.default.svc.cluster.local
  I0419 17:10:34.550775       1 log.go:245] Full, not-validated claims: 
  openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-7481:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc000225de0), NotBefore:(*jwt.NumericDate)(0xc000225ec8), IssuedAt:(*jwt.NumericDate)(0xc000225df0), ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-7481", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"1ffee405-d9cd-4d5d-ab7b-054e5557f62f"}}}
  I0419 17:10:34.573149       1 log.go:245] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
  I0419 17:10:34.585461       1 log.go:245] OK: Validated signature on JWT
  I0419 17:10:34.585702       1 log.go:245] OK: Got valid claims from token!
  I0419 17:10:34.585761       1 log.go:245] Full, validated claims: 
  &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-7481:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc000127078), NotBefore:(*jwt.NumericDate)(0xc0001270a0), IssuedAt:(*jwt.NumericDate)(0xc000127080), ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-7481", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"1ffee405-d9cd-4d5d-ab7b-054e5557f62f"}}}

  Apr 19 17:11:07.842: INFO: completed pod
  Apr 19 17:11:07.861: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-7481" for this suite. @ 04/19/24 17:11:07.878
• [34.203 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/sysctl.go:125
  STEP: Creating a kubernetes client @ 04/19/24 17:11:07.915
  Apr 19 17:11:07.915: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename sysctl @ 04/19/24 17:11:07.922
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:11:07.971
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:11:07.979
  STEP: Creating a pod with one valid and two invalid sysctls @ 04/19/24 17:11:07.986
  Apr 19 17:11:08.000: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-3157" for this suite. @ 04/19/24 17:11:08.009
  E0419 17:11:08.017391      13 retrywatcher.go:129] "Watch failed" err="context canceled"
• [0.116 seconds]
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:810
  STEP: Creating a kubernetes client @ 04/19/24 17:11:08.032
  Apr 19 17:11:08.032: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename svcaccounts @ 04/19/24 17:11:08.038
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:11:08.078
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:11:08.083
  STEP: Creating ServiceAccount "e2e-sa-g7t5l"  @ 04/19/24 17:11:08.09
  Apr 19 17:11:08.099: INFO: AutomountServiceAccountToken: false
  STEP: Updating ServiceAccount "e2e-sa-g7t5l"  @ 04/19/24 17:11:08.099
  Apr 19 17:11:08.114: INFO: AutomountServiceAccountToken: true
  Apr 19 17:11:08.114: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-2052" for this suite. @ 04/19/24 17:11:08.121
• [0.102 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:273
  STEP: Creating a kubernetes client @ 04/19/24 17:11:08.142
  Apr 19 17:11:08.142: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename webhook @ 04/19/24 17:11:08.147
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:11:08.176
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:11:08.182
  STEP: Setting up server cert @ 04/19/24 17:11:08.228
  E0419 17:11:09.017241      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 17:11:09.573
  STEP: Deploying the webhook pod @ 04/19/24 17:11:09.613
  STEP: Wait for the deployment to be ready @ 04/19/24 17:11:09.634
  Apr 19 17:11:09.658: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0419 17:11:10.018367      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:11.018910      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 17:11:11.695
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 17:11:11.726
  E0419 17:11:12.019704      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:11:12.728: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 04/19/24 17:11:12.746
  STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 04/19/24 17:11:12.788
  STEP: Creating a dummy validating-webhook-configuration object @ 04/19/24 17:11:12.822
  STEP: Deleting the validating-webhook-configuration, which should be possible to remove @ 04/19/24 17:11:12.843
  STEP: Creating a dummy mutating-webhook-configuration object @ 04/19/24 17:11:12.856
  STEP: Deleting the mutating-webhook-configuration, which should be possible to remove @ 04/19/24 17:11:12.873
  Apr 19 17:11:12.995: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4395" for this suite. @ 04/19/24 17:11:13.003
  E0419 17:11:13.019719      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "webhook-markers-6055" for this suite. @ 04/19/24 17:11:13.02
• [4.889 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:137
  STEP: Creating a kubernetes client @ 04/19/24 17:11:13.037
  Apr 19 17:11:13.038: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename dns @ 04/19/24 17:11:13.042
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:11:13.071
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:11:13.077
  STEP: Creating a test headless service @ 04/19/24 17:11:13.083
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4830.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4830.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4830.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4830.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4830.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4830.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4830.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4830.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4830.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4830.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 162.50.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.50.162_udp@PTR;check="$$(dig +tcp +noall +answer +search 162.50.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.50.162_tcp@PTR;sleep 1; done
   @ 04/19/24 17:11:13.115
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4830.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4830.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4830.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4830.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4830.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4830.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4830.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4830.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4830.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4830.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 162.50.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.50.162_udp@PTR;check="$$(dig +tcp +noall +answer +search 162.50.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.50.162_tcp@PTR;sleep 1; done
   @ 04/19/24 17:11:13.115
  STEP: creating a pod to probe DNS @ 04/19/24 17:11:13.115
  STEP: submitting the pod to kubernetes @ 04/19/24 17:11:13.115
  E0419 17:11:14.020000      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:15.020497      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/19/24 17:11:15.155
  STEP: looking for the results for each expected name from probers @ 04/19/24 17:11:15.162
  Apr 19 17:11:15.177: INFO: Unable to read wheezy_udp@dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:15.184: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:15.192: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:15.203: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:15.251: INFO: Unable to read jessie_udp@dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:15.260: INFO: Unable to read jessie_tcp@dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:15.268: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:15.276: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:15.310: INFO: Lookups using dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c failed for: [wheezy_udp@dns-test-service.dns-4830.svc.cluster.local wheezy_tcp@dns-test-service.dns-4830.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local jessie_udp@dns-test-service.dns-4830.svc.cluster.local jessie_tcp@dns-test-service.dns-4830.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local]

  Apr 19 17:11:15.327: INFO: Pod client logs for webserver: 
  Apr 19 17:11:15.340: INFO: Pod client logs for querier: 
  Apr 19 17:11:15.357: INFO: Pod client logs for jessie-querier: 
  E0419 17:11:16.020734      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:17.020837      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:18.022073      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:19.022115      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:20.022705      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:11:20.176: INFO: Unable to read wheezy_udp@dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:20.189: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:20.202: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:20.213: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:20.266: INFO: Unable to read jessie_udp@dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:20.277: INFO: Unable to read jessie_tcp@dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:20.287: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:20.296: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:20.332: INFO: Lookups using dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c failed for: [wheezy_udp@dns-test-service.dns-4830.svc.cluster.local wheezy_tcp@dns-test-service.dns-4830.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local jessie_udp@dns-test-service.dns-4830.svc.cluster.local jessie_tcp@dns-test-service.dns-4830.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local]

  Apr 19 17:11:20.355: INFO: Pod client logs for webserver: 
  Apr 19 17:11:20.372: INFO: Pod client logs for querier: 
  Apr 19 17:11:20.390: INFO: Pod client logs for jessie-querier: 
  E0419 17:11:21.023978      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:22.024320      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:23.025151      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:24.025306      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:25.026039      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:11:25.178: INFO: Unable to read wheezy_udp@dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:25.191: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:25.203: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:25.215: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:25.283: INFO: Unable to read jessie_udp@dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:25.290: INFO: Unable to read jessie_tcp@dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:25.295: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:25.303: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:25.347: INFO: Lookups using dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c failed for: [wheezy_udp@dns-test-service.dns-4830.svc.cluster.local wheezy_tcp@dns-test-service.dns-4830.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local jessie_udp@dns-test-service.dns-4830.svc.cluster.local jessie_tcp@dns-test-service.dns-4830.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local]

  Apr 19 17:11:25.363: INFO: Pod client logs for webserver: 
  Apr 19 17:11:25.376: INFO: Pod client logs for querier: 
  Apr 19 17:11:25.388: INFO: Pod client logs for jessie-querier: 
  E0419 17:11:26.025983      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:27.025966      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:28.026477      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:29.027336      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:30.027813      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:11:30.172: INFO: Unable to read wheezy_udp@dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:30.179: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:30.187: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:30.199: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:30.245: INFO: Unable to read jessie_udp@dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:30.253: INFO: Unable to read jessie_tcp@dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:30.261: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:30.269: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:30.300: INFO: Lookups using dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c failed for: [wheezy_udp@dns-test-service.dns-4830.svc.cluster.local wheezy_tcp@dns-test-service.dns-4830.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local jessie_udp@dns-test-service.dns-4830.svc.cluster.local jessie_tcp@dns-test-service.dns-4830.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local]

  Apr 19 17:11:30.319: INFO: Pod client logs for webserver: 
  Apr 19 17:11:30.330: INFO: Pod client logs for querier: 
  Apr 19 17:11:30.344: INFO: Pod client logs for jessie-querier: 
  E0419 17:11:31.029057      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:32.028944      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:33.030094      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:34.030610      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:35.031199      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:11:35.177: INFO: Unable to read wheezy_udp@dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:35.192: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:35.205: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:35.216: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:35.290: INFO: Unable to read jessie_udp@dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:35.301: INFO: Unable to read jessie_tcp@dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:35.312: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:35.338: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:35.379: INFO: Lookups using dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c failed for: [wheezy_udp@dns-test-service.dns-4830.svc.cluster.local wheezy_tcp@dns-test-service.dns-4830.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local jessie_udp@dns-test-service.dns-4830.svc.cluster.local jessie_tcp@dns-test-service.dns-4830.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local]

  Apr 19 17:11:35.393: INFO: Pod client logs for webserver: 
  Apr 19 17:11:35.408: INFO: Pod client logs for querier: 
  Apr 19 17:11:35.434: INFO: Pod client logs for jessie-querier: 
  E0419 17:11:36.033220      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:37.032670      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:38.033523      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:39.034369      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:40.034763      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:11:40.178: INFO: Unable to read wheezy_udp@dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:40.210: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:40.223: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:40.235: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:40.313: INFO: Unable to read jessie_udp@dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:40.328: INFO: Unable to read jessie_tcp@dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:40.339: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:40.353: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:40.403: INFO: Lookups using dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c failed for: [wheezy_udp@dns-test-service.dns-4830.svc.cluster.local wheezy_tcp@dns-test-service.dns-4830.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local jessie_udp@dns-test-service.dns-4830.svc.cluster.local jessie_tcp@dns-test-service.dns-4830.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local]

  Apr 19 17:11:40.432: INFO: Pod client logs for webserver: 
  Apr 19 17:11:40.453: INFO: Pod client logs for querier: 
  Apr 19 17:11:40.479: INFO: Pod client logs for jessie-querier: 
  E0419 17:11:41.036024      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:42.036772      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:43.036743      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:44.037263      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:45.037494      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:11:45.305: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local from pod dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c: the server could not find the requested resource (get pods dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c)
  Apr 19 17:11:45.359: INFO: Lookups using dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c failed for: [jessie_udp@_http._tcp.dns-test-service.dns-4830.svc.cluster.local]

  Apr 19 17:11:45.375: INFO: Pod client logs for webserver: 
  Apr 19 17:11:45.392: INFO: Pod client logs for querier: 
  Apr 19 17:11:45.407: INFO: Pod client logs for jessie-querier: 
  E0419 17:11:46.037880      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:47.038139      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:48.039274      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:49.039569      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:50.039551      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:11:50.352: INFO: DNS probes using dns-4830/dns-test-ac509d1b-ec6b-49c0-a068-d98691add00c succeeded

  STEP: deleting the pod @ 04/19/24 17:11:50.353
  STEP: deleting the test service @ 04/19/24 17:11:50.409
  STEP: deleting the test headless service @ 04/19/24 17:11:50.46
  Apr 19 17:11:50.496: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-4830" for this suite. @ 04/19/24 17:11:50.52
• [37.512 seconds]
------------------------------
SS
------------------------------
[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:191
  STEP: Creating a kubernetes client @ 04/19/24 17:11:50.552
  Apr 19 17:11:50.552: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename dns @ 04/19/24 17:11:50.558
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:11:50.635
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:11:50.641
  STEP: Creating a test headless service @ 04/19/24 17:11:50.648
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2149 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-2149;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2149 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-2149;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2149.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-2149.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2149.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-2149.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2149.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-2149.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2149.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-2149.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2149.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-2149.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2149.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-2149.svc;check="$$(dig +notcp +noall +answer +search 152.53.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.53.152_udp@PTR;check="$$(dig +tcp +noall +answer +search 152.53.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.53.152_tcp@PTR;sleep 1; done
   @ 04/19/24 17:11:50.721
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2149 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-2149;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2149 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-2149;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2149.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-2149.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2149.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-2149.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2149.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-2149.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2149.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-2149.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2149.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-2149.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2149.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-2149.svc;check="$$(dig +notcp +noall +answer +search 152.53.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.53.152_udp@PTR;check="$$(dig +tcp +noall +answer +search 152.53.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.53.152_tcp@PTR;sleep 1; done
   @ 04/19/24 17:11:50.722
  STEP: creating a pod to probe DNS @ 04/19/24 17:11:50.723
  STEP: submitting the pod to kubernetes @ 04/19/24 17:11:50.724
  E0419 17:11:51.040886      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:52.042756      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/19/24 17:11:52.771
  STEP: looking for the results for each expected name from probers @ 04/19/24 17:11:52.78
  Apr 19 17:11:52.795: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:11:52.806: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:11:52.817: INFO: Unable to read wheezy_udp@dns-test-service.dns-2149 from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:11:52.826: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2149 from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:11:52.838: INFO: Unable to read wheezy_udp@dns-test-service.dns-2149.svc from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:11:52.846: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2149.svc from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:11:52.857: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2149.svc from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:11:52.867: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2149.svc from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:11:52.922: INFO: Unable to read jessie_udp@dns-test-service from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:11:52.937: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:11:52.951: INFO: Unable to read jessie_udp@dns-test-service.dns-2149 from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:11:52.960: INFO: Unable to read jessie_tcp@dns-test-service.dns-2149 from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:11:52.970: INFO: Unable to read jessie_udp@dns-test-service.dns-2149.svc from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:11:52.980: INFO: Unable to read jessie_tcp@dns-test-service.dns-2149.svc from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:11:53.039: INFO: Lookups using dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-2149 wheezy_tcp@dns-test-service.dns-2149 wheezy_udp@dns-test-service.dns-2149.svc wheezy_tcp@dns-test-service.dns-2149.svc wheezy_udp@_http._tcp.dns-test-service.dns-2149.svc wheezy_tcp@_http._tcp.dns-test-service.dns-2149.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-2149 jessie_tcp@dns-test-service.dns-2149 jessie_udp@dns-test-service.dns-2149.svc jessie_tcp@dns-test-service.dns-2149.svc]

  E0419 17:11:53.043658      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:11:53.056: INFO: Pod client logs for webserver: 
  Apr 19 17:11:53.078: INFO: Pod client logs for querier: 
  Apr 19 17:11:53.100: INFO: Pod client logs for jessie-querier: 
  E0419 17:11:54.043725      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:55.044169      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:56.044143      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:11:57.044352      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:11:57.796: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:11:57.810: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:11:57.821: INFO: Unable to read wheezy_udp@dns-test-service.dns-2149 from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:11:57.835: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2149 from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:11:57.845: INFO: Unable to read wheezy_udp@dns-test-service.dns-2149.svc from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:11:57.853: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2149.svc from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:11:57.934: INFO: Unable to read jessie_udp@dns-test-service from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:11:57.942: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:11:57.950: INFO: Unable to read jessie_udp@dns-test-service.dns-2149 from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:11:57.960: INFO: Unable to read jessie_tcp@dns-test-service.dns-2149 from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:11:57.970: INFO: Unable to read jessie_udp@dns-test-service.dns-2149.svc from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:11:57.979: INFO: Unable to read jessie_tcp@dns-test-service.dns-2149.svc from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:11:58.035: INFO: Lookups using dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-2149 wheezy_tcp@dns-test-service.dns-2149 wheezy_udp@dns-test-service.dns-2149.svc wheezy_tcp@dns-test-service.dns-2149.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-2149 jessie_tcp@dns-test-service.dns-2149 jessie_udp@dns-test-service.dns-2149.svc jessie_tcp@dns-test-service.dns-2149.svc]

  E0419 17:11:58.046538      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:11:58.058: INFO: Pod client logs for webserver: 
  Apr 19 17:11:58.077: INFO: Pod client logs for querier: 
  Apr 19 17:11:58.090: INFO: Pod client logs for jessie-querier: 
  E0419 17:11:59.046203      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:00.046995      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:01.047818      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:02.047705      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:12:02.792: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:02.800: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:02.810: INFO: Unable to read wheezy_udp@dns-test-service.dns-2149 from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:02.820: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2149 from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:02.827: INFO: Unable to read wheezy_udp@dns-test-service.dns-2149.svc from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:02.838: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2149.svc from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:02.890: INFO: Unable to read jessie_udp@dns-test-service from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:02.896: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:02.903: INFO: Unable to read jessie_udp@dns-test-service.dns-2149 from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:02.911: INFO: Unable to read jessie_tcp@dns-test-service.dns-2149 from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:02.919: INFO: Unable to read jessie_udp@dns-test-service.dns-2149.svc from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:02.925: INFO: Unable to read jessie_tcp@dns-test-service.dns-2149.svc from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:02.966: INFO: Lookups using dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-2149 wheezy_tcp@dns-test-service.dns-2149 wheezy_udp@dns-test-service.dns-2149.svc wheezy_tcp@dns-test-service.dns-2149.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-2149 jessie_tcp@dns-test-service.dns-2149 jessie_udp@dns-test-service.dns-2149.svc jessie_tcp@dns-test-service.dns-2149.svc]

  Apr 19 17:12:02.979: INFO: Pod client logs for webserver: 
  Apr 19 17:12:02.990: INFO: Pod client logs for querier: 
  Apr 19 17:12:03.003: INFO: Pod client logs for jessie-querier: 
  E0419 17:12:03.048679      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:04.049410      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:05.049718      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:06.049585      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:07.049764      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:12:07.796: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:07.810: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:07.823: INFO: Unable to read wheezy_udp@dns-test-service.dns-2149 from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:07.837: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2149 from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:07.855: INFO: Unable to read wheezy_udp@dns-test-service.dns-2149.svc from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:07.867: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2149.svc from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:07.963: INFO: Unable to read jessie_udp@dns-test-service from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:07.970: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:07.978: INFO: Unable to read jessie_udp@dns-test-service.dns-2149 from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:07.987: INFO: Unable to read jessie_tcp@dns-test-service.dns-2149 from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:07.995: INFO: Unable to read jessie_udp@dns-test-service.dns-2149.svc from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:08.007: INFO: Unable to read jessie_tcp@dns-test-service.dns-2149.svc from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  E0419 17:12:08.050637      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:12:08.057: INFO: Lookups using dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-2149 wheezy_tcp@dns-test-service.dns-2149 wheezy_udp@dns-test-service.dns-2149.svc wheezy_tcp@dns-test-service.dns-2149.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-2149 jessie_tcp@dns-test-service.dns-2149 jessie_udp@dns-test-service.dns-2149.svc jessie_tcp@dns-test-service.dns-2149.svc]

  Apr 19 17:12:08.083: INFO: Pod client logs for webserver: 
  Apr 19 17:12:08.096: INFO: Pod client logs for querier: 
  Apr 19 17:12:08.107: INFO: Pod client logs for jessie-querier: 
  E0419 17:12:09.051228      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:10.051461      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:11.051981      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:12.052827      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:12:12.794: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:12.806: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:12.816: INFO: Unable to read wheezy_udp@dns-test-service.dns-2149 from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:12.829: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2149 from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:12.838: INFO: Unable to read wheezy_udp@dns-test-service.dns-2149.svc from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:12.849: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2149.svc from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:12.918: INFO: Unable to read jessie_udp@dns-test-service from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:12.929: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:12.944: INFO: Unable to read jessie_udp@dns-test-service.dns-2149 from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:12.956: INFO: Unable to read jessie_tcp@dns-test-service.dns-2149 from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:12.965: INFO: Unable to read jessie_udp@dns-test-service.dns-2149.svc from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:12.976: INFO: Unable to read jessie_tcp@dns-test-service.dns-2149.svc from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:13.047: INFO: Lookups using dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-2149 wheezy_tcp@dns-test-service.dns-2149 wheezy_udp@dns-test-service.dns-2149.svc wheezy_tcp@dns-test-service.dns-2149.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-2149 jessie_tcp@dns-test-service.dns-2149 jessie_udp@dns-test-service.dns-2149.svc jessie_tcp@dns-test-service.dns-2149.svc]

  E0419 17:12:13.053121      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:12:13.070: INFO: Pod client logs for webserver: 
  Apr 19 17:12:13.086: INFO: Pod client logs for querier: 
  Apr 19 17:12:13.101: INFO: Pod client logs for jessie-querier: 
  E0419 17:12:14.054205      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:15.055163      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:16.056009      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:17.055426      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:12:17.789: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:17.795: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:17.802: INFO: Unable to read wheezy_udp@dns-test-service.dns-2149 from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:17.807: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2149 from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:17.812: INFO: Unable to read wheezy_udp@dns-test-service.dns-2149.svc from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:17.822: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2149.svc from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:17.873: INFO: Unable to read jessie_udp@dns-test-service from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:17.879: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:17.886: INFO: Unable to read jessie_udp@dns-test-service.dns-2149 from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:17.892: INFO: Unable to read jessie_tcp@dns-test-service.dns-2149 from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:17.902: INFO: Unable to read jessie_udp@dns-test-service.dns-2149.svc from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:17.909: INFO: Unable to read jessie_tcp@dns-test-service.dns-2149.svc from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:17.959: INFO: Lookups using dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-2149 wheezy_tcp@dns-test-service.dns-2149 wheezy_udp@dns-test-service.dns-2149.svc wheezy_tcp@dns-test-service.dns-2149.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-2149 jessie_tcp@dns-test-service.dns-2149 jessie_udp@dns-test-service.dns-2149.svc jessie_tcp@dns-test-service.dns-2149.svc]

  Apr 19 17:12:17.980: INFO: Pod client logs for webserver: 
  Apr 19 17:12:17.996: INFO: Pod client logs for querier: 
  Apr 19 17:12:18.010: INFO: Pod client logs for jessie-querier: 
  E0419 17:12:18.055902      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:19.056084      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:20.056369      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:21.056907      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:22.057092      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:12:22.793: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:22.807: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:22.816: INFO: Unable to read wheezy_udp@dns-test-service.dns-2149 from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:22.825: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2149 from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:22.837: INFO: Unable to read wheezy_udp@dns-test-service.dns-2149.svc from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:22.846: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2149.svc from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:22.911: INFO: Unable to read jessie_udp@dns-test-service from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:22.921: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:22.934: INFO: Unable to read jessie_udp@dns-test-service.dns-2149 from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:22.946: INFO: Unable to read jessie_tcp@dns-test-service.dns-2149 from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:22.958: INFO: Unable to read jessie_udp@dns-test-service.dns-2149.svc from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:22.967: INFO: Unable to read jessie_tcp@dns-test-service.dns-2149.svc from pod dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237: the server could not find the requested resource (get pods dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237)
  Apr 19 17:12:23.026: INFO: Lookups using dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-2149 wheezy_tcp@dns-test-service.dns-2149 wheezy_udp@dns-test-service.dns-2149.svc wheezy_tcp@dns-test-service.dns-2149.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-2149 jessie_tcp@dns-test-service.dns-2149 jessie_udp@dns-test-service.dns-2149.svc jessie_tcp@dns-test-service.dns-2149.svc]

  Apr 19 17:12:23.043: INFO: Pod client logs for webserver: 
  E0419 17:12:23.058154      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:12:23.058: INFO: Pod client logs for querier: 
  Apr 19 17:12:23.071: INFO: Pod client logs for jessie-querier: 
  E0419 17:12:24.058488      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:25.059117      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:26.059501      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:27.059934      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:28.061493      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:12:28.092: INFO: DNS probes using dns-2149/dns-test-1d451a4f-935c-4bfd-83a6-9f3818f3a237 succeeded

  STEP: deleting the pod @ 04/19/24 17:12:28.092
  STEP: deleting the test service @ 04/19/24 17:12:28.145
  STEP: deleting the test headless service @ 04/19/24 17:12:28.195
  Apr 19 17:12:28.237: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-2149" for this suite. @ 04/19/24 17:12:28.249
• [37.717 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:425
  STEP: Creating a kubernetes client @ 04/19/24 17:12:28.279
  Apr 19 17:12:28.279: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename replication-controller @ 04/19/24 17:12:28.282
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:12:28.324
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:12:28.33
  STEP: Creating ReplicationController "e2e-rc-lv9qx" @ 04/19/24 17:12:28.337
  Apr 19 17:12:28.348: INFO: Get Replication Controller "e2e-rc-lv9qx" to confirm replicas
  E0419 17:12:29.062518      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:12:29.349: INFO: Get Replication Controller "e2e-rc-lv9qx" to confirm replicas
  Apr 19 17:12:29.357: INFO: Found 1 replicas for "e2e-rc-lv9qx" replication controller
  STEP: Getting scale subresource for ReplicationController "e2e-rc-lv9qx" @ 04/19/24 17:12:29.358
  STEP: Updating a scale subresource @ 04/19/24 17:12:29.37
  STEP: Verifying replicas where modified for replication controller "e2e-rc-lv9qx" @ 04/19/24 17:12:29.382
  Apr 19 17:12:29.382: INFO: Get Replication Controller "e2e-rc-lv9qx" to confirm replicas
  E0419 17:12:30.063568      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:12:30.383: INFO: Get Replication Controller "e2e-rc-lv9qx" to confirm replicas
  Apr 19 17:12:30.396: INFO: Found 2 replicas for "e2e-rc-lv9qx" replication controller
  Apr 19 17:12:30.397: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-6607" for this suite. @ 04/19/24 17:12:30.41
• [2.149 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:132
  STEP: Creating a kubernetes client @ 04/19/24 17:12:30.459
  Apr 19 17:12:30.459: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename downward-api @ 04/19/24 17:12:30.462
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:12:30.517
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:12:30.525
  STEP: Creating the pod @ 04/19/24 17:12:30.531
  E0419 17:12:31.063823      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:32.064518      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:33.064915      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:12:33.141: INFO: Successfully updated pod "labelsupdate248d60eb-10a1-4288-a378-25be0b1943a8"
  E0419 17:12:34.066378      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:35.065918      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:12:35.193: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2014" for this suite. @ 04/19/24 17:12:35.208
• [4.766 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:334
  STEP: Creating a kubernetes client @ 04/19/24 17:12:35.227
  Apr 19 17:12:35.227: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename sched-pred @ 04/19/24 17:12:35.23
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:12:35.262
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:12:35.266
  Apr 19 17:12:35.272: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Apr 19 17:12:35.291: INFO: Waiting for terminating namespaces to be deleted...
  Apr 19 17:12:35.299: INFO: 
  Logging pods the apiserver thinks is on node co4fe9zoo9oc-1 before test
  Apr 19 17:12:35.316: INFO: coredns-76f75df574-dnglm from kube-system started at 2024-04-19 15:34:35 +0000 UTC (1 container statuses recorded)
  Apr 19 17:12:35.316: INFO: 	Container coredns ready: true, restart count 1
  Apr 19 17:12:35.316: INFO: coredns-76f75df574-n4wlj from kube-system started at 2024-04-19 15:34:35 +0000 UTC (1 container statuses recorded)
  Apr 19 17:12:35.317: INFO: 	Container coredns ready: true, restart count 1
  Apr 19 17:12:35.317: INFO: kube-addon-manager-co4fe9zoo9oc-1 from kube-system started at 2024-04-19 15:40:36 +0000 UTC (1 container statuses recorded)
  Apr 19 17:12:35.317: INFO: 	Container kube-addon-manager ready: true, restart count 1
  Apr 19 17:12:35.317: INFO: kube-apiserver-co4fe9zoo9oc-1 from kube-system started at 2024-04-19 15:40:36 +0000 UTC (1 container statuses recorded)
  Apr 19 17:12:35.317: INFO: 	Container kube-apiserver ready: true, restart count 1
  Apr 19 17:12:35.317: INFO: kube-controller-manager-co4fe9zoo9oc-1 from kube-system started at 2024-04-19 15:40:36 +0000 UTC (1 container statuses recorded)
  Apr 19 17:12:35.317: INFO: 	Container kube-controller-manager ready: true, restart count 1
  Apr 19 17:12:35.317: INFO: kube-flannel-ds-9gpfv from kube-system started at 2024-04-19 15:34:17 +0000 UTC (1 container statuses recorded)
  Apr 19 17:12:35.317: INFO: 	Container kube-flannel ready: true, restart count 1
  Apr 19 17:12:35.317: INFO: kube-proxy-zzhn9 from kube-system started at 2024-04-19 15:27:31 +0000 UTC (1 container statuses recorded)
  Apr 19 17:12:35.317: INFO: 	Container kube-proxy ready: true, restart count 1
  Apr 19 17:12:35.317: INFO: kube-scheduler-co4fe9zoo9oc-1 from kube-system started at 2024-04-19 15:40:36 +0000 UTC (1 container statuses recorded)
  Apr 19 17:12:35.318: INFO: 	Container kube-scheduler ready: true, restart count 1
  Apr 19 17:12:35.318: INFO: sonobuoy-systemd-logs-daemon-set-f3d7cdfd30314b67-kskjf from sonobuoy started at 2024-04-19 15:41:34 +0000 UTC (2 container statuses recorded)
  Apr 19 17:12:35.318: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 19 17:12:35.318: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 19 17:12:35.318: INFO: 
  Logging pods the apiserver thinks is on node co4fe9zoo9oc-2 before test
  Apr 19 17:12:35.333: INFO: kube-addon-manager-co4fe9zoo9oc-2 from kube-system started at 2024-04-19 15:36:28 +0000 UTC (1 container statuses recorded)
  Apr 19 17:12:35.333: INFO: 	Container kube-addon-manager ready: true, restart count 1
  Apr 19 17:12:35.333: INFO: kube-apiserver-co4fe9zoo9oc-2 from kube-system started at 2024-04-19 15:36:28 +0000 UTC (1 container statuses recorded)
  Apr 19 17:12:35.333: INFO: 	Container kube-apiserver ready: true, restart count 1
  Apr 19 17:12:35.333: INFO: kube-controller-manager-co4fe9zoo9oc-2 from kube-system started at 2024-04-19 15:36:28 +0000 UTC (1 container statuses recorded)
  Apr 19 17:12:35.333: INFO: 	Container kube-controller-manager ready: true, restart count 1
  Apr 19 17:12:35.333: INFO: kube-flannel-ds-g2l7p from kube-system started at 2024-04-19 15:34:17 +0000 UTC (1 container statuses recorded)
  Apr 19 17:12:35.333: INFO: 	Container kube-flannel ready: true, restart count 1
  Apr 19 17:12:35.333: INFO: kube-proxy-6gjw7 from kube-system started at 2024-04-19 15:28:18 +0000 UTC (1 container statuses recorded)
  Apr 19 17:12:35.333: INFO: 	Container kube-proxy ready: true, restart count 1
  Apr 19 17:12:35.333: INFO: kube-scheduler-co4fe9zoo9oc-2 from kube-system started at 2024-04-19 15:36:28 +0000 UTC (1 container statuses recorded)
  Apr 19 17:12:35.333: INFO: 	Container kube-scheduler ready: true, restart count 1
  Apr 19 17:12:35.333: INFO: e2e-rc-lv9qx-wsvth from replication-controller-6607 started at 2024-04-19 17:12:29 +0000 UTC (1 container statuses recorded)
  Apr 19 17:12:35.333: INFO: 	Container httpd ready: true, restart count 0
  Apr 19 17:12:35.333: INFO: sonobuoy-systemd-logs-daemon-set-f3d7cdfd30314b67-l6thv from sonobuoy started at 2024-04-19 15:41:34 +0000 UTC (2 container statuses recorded)
  Apr 19 17:12:35.333: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 19 17:12:35.333: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 19 17:12:35.333: INFO: 
  Logging pods the apiserver thinks is on node co4fe9zoo9oc-3 before test
  Apr 19 17:12:35.349: INFO: labelsupdate248d60eb-10a1-4288-a378-25be0b1943a8 from downward-api-2014 started at 2024-04-19 17:12:30 +0000 UTC (1 container statuses recorded)
  Apr 19 17:12:35.350: INFO: 	Container client-container ready: true, restart count 0
  Apr 19 17:12:35.352: INFO: kube-flannel-ds-8xgdk from kube-system started at 2024-04-19 15:47:35 +0000 UTC (1 container statuses recorded)
  Apr 19 17:12:35.352: INFO: 	Container kube-flannel ready: true, restart count 0
  Apr 19 17:12:35.353: INFO: kube-proxy-nxtbd from kube-system started at 2024-04-19 15:28:43 +0000 UTC (1 container statuses recorded)
  Apr 19 17:12:35.354: INFO: 	Container kube-proxy ready: true, restart count 1
  Apr 19 17:12:35.355: INFO: e2e-rc-lv9qx-8x4zj from replication-controller-6607 started at 2024-04-19 17:12:28 +0000 UTC (1 container statuses recorded)
  Apr 19 17:12:35.356: INFO: 	Container httpd ready: true, restart count 0
  Apr 19 17:12:35.356: INFO: sonobuoy from sonobuoy started at 2024-04-19 15:41:27 +0000 UTC (1 container statuses recorded)
  Apr 19 17:12:35.357: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Apr 19 17:12:35.357: INFO: sonobuoy-e2e-job-8260c76ae18e4472 from sonobuoy started at 2024-04-19 15:41:34 +0000 UTC (2 container statuses recorded)
  Apr 19 17:12:35.357: INFO: 	Container e2e ready: true, restart count 0
  Apr 19 17:12:35.358: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 19 17:12:35.359: INFO: sonobuoy-systemd-logs-daemon-set-f3d7cdfd30314b67-2fw62 from sonobuoy started at 2024-04-19 15:41:34 +0000 UTC (2 container statuses recorded)
  Apr 19 17:12:35.359: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 19 17:12:35.360: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: verifying the node has the label node co4fe9zoo9oc-1 @ 04/19/24 17:12:35.399
  STEP: verifying the node has the label node co4fe9zoo9oc-2 @ 04/19/24 17:12:35.426
  STEP: verifying the node has the label node co4fe9zoo9oc-3 @ 04/19/24 17:12:35.466
  Apr 19 17:12:35.517: INFO: Pod labelsupdate248d60eb-10a1-4288-a378-25be0b1943a8 requesting resource cpu=0m on Node co4fe9zoo9oc-3
  Apr 19 17:12:35.517: INFO: Pod coredns-76f75df574-dnglm requesting resource cpu=100m on Node co4fe9zoo9oc-1
  Apr 19 17:12:35.517: INFO: Pod coredns-76f75df574-n4wlj requesting resource cpu=100m on Node co4fe9zoo9oc-1
  Apr 19 17:12:35.517: INFO: Pod kube-addon-manager-co4fe9zoo9oc-1 requesting resource cpu=5m on Node co4fe9zoo9oc-1
  Apr 19 17:12:35.517: INFO: Pod kube-addon-manager-co4fe9zoo9oc-2 requesting resource cpu=5m on Node co4fe9zoo9oc-2
  Apr 19 17:12:35.517: INFO: Pod kube-apiserver-co4fe9zoo9oc-1 requesting resource cpu=250m on Node co4fe9zoo9oc-1
  Apr 19 17:12:35.517: INFO: Pod kube-apiserver-co4fe9zoo9oc-2 requesting resource cpu=250m on Node co4fe9zoo9oc-2
  Apr 19 17:12:35.517: INFO: Pod kube-controller-manager-co4fe9zoo9oc-1 requesting resource cpu=200m on Node co4fe9zoo9oc-1
  Apr 19 17:12:35.517: INFO: Pod kube-controller-manager-co4fe9zoo9oc-2 requesting resource cpu=200m on Node co4fe9zoo9oc-2
  Apr 19 17:12:35.517: INFO: Pod kube-flannel-ds-8xgdk requesting resource cpu=100m on Node co4fe9zoo9oc-3
  Apr 19 17:12:35.517: INFO: Pod kube-flannel-ds-9gpfv requesting resource cpu=100m on Node co4fe9zoo9oc-1
  Apr 19 17:12:35.517: INFO: Pod kube-flannel-ds-g2l7p requesting resource cpu=100m on Node co4fe9zoo9oc-2
  Apr 19 17:12:35.517: INFO: Pod kube-proxy-6gjw7 requesting resource cpu=0m on Node co4fe9zoo9oc-2
  Apr 19 17:12:35.517: INFO: Pod kube-proxy-nxtbd requesting resource cpu=0m on Node co4fe9zoo9oc-3
  Apr 19 17:12:35.517: INFO: Pod kube-proxy-zzhn9 requesting resource cpu=0m on Node co4fe9zoo9oc-1
  Apr 19 17:12:35.517: INFO: Pod kube-scheduler-co4fe9zoo9oc-1 requesting resource cpu=100m on Node co4fe9zoo9oc-1
  Apr 19 17:12:35.517: INFO: Pod kube-scheduler-co4fe9zoo9oc-2 requesting resource cpu=100m on Node co4fe9zoo9oc-2
  Apr 19 17:12:35.517: INFO: Pod e2e-rc-lv9qx-8x4zj requesting resource cpu=0m on Node co4fe9zoo9oc-3
  Apr 19 17:12:35.517: INFO: Pod e2e-rc-lv9qx-wsvth requesting resource cpu=0m on Node co4fe9zoo9oc-2
  Apr 19 17:12:35.517: INFO: Pod sonobuoy requesting resource cpu=0m on Node co4fe9zoo9oc-3
  Apr 19 17:12:35.517: INFO: Pod sonobuoy-e2e-job-8260c76ae18e4472 requesting resource cpu=0m on Node co4fe9zoo9oc-3
  Apr 19 17:12:35.517: INFO: Pod sonobuoy-systemd-logs-daemon-set-f3d7cdfd30314b67-2fw62 requesting resource cpu=0m on Node co4fe9zoo9oc-3
  Apr 19 17:12:35.517: INFO: Pod sonobuoy-systemd-logs-daemon-set-f3d7cdfd30314b67-kskjf requesting resource cpu=0m on Node co4fe9zoo9oc-1
  Apr 19 17:12:35.517: INFO: Pod sonobuoy-systemd-logs-daemon-set-f3d7cdfd30314b67-l6thv requesting resource cpu=0m on Node co4fe9zoo9oc-2
  STEP: Starting Pods to consume most of the cluster CPU. @ 04/19/24 17:12:35.517
  Apr 19 17:12:35.517: INFO: Creating a pod which consumes cpu=1050m on Node co4fe9zoo9oc-3
  Apr 19 17:12:35.565: INFO: Creating a pod which consumes cpu=521m on Node co4fe9zoo9oc-1
  Apr 19 17:12:35.576: INFO: Creating a pod which consumes cpu=661m on Node co4fe9zoo9oc-2
  E0419 17:12:36.066361      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:37.067121      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating another pod that requires unavailable amount of CPU. @ 04/19/24 17:12:37.691
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-35c0b1c2-23b0-48a6-833e-d19f6e5cbadd.17c7bdb209c8a196], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8877/filler-pod-35c0b1c2-23b0-48a6-833e-d19f6e5cbadd to co4fe9zoo9oc-1] @ 04/19/24 17:12:37.703
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-35c0b1c2-23b0-48a6-833e-d19f6e5cbadd.17c7bdb232de2844], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 04/19/24 17:12:37.704
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-35c0b1c2-23b0-48a6-833e-d19f6e5cbadd.17c7bdb23a8c59a9], Reason = [Created], Message = [Created container filler-pod-35c0b1c2-23b0-48a6-833e-d19f6e5cbadd] @ 04/19/24 17:12:37.704
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-35c0b1c2-23b0-48a6-833e-d19f6e5cbadd.17c7bdb23c17dac1], Reason = [Started], Message = [Started container filler-pod-35c0b1c2-23b0-48a6-833e-d19f6e5cbadd] @ 04/19/24 17:12:37.704
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-bb22a43e-f3b8-4673-8d08-f1f6773abf5e.17c7bdb208c8d0bc], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8877/filler-pod-bb22a43e-f3b8-4673-8d08-f1f6773abf5e to co4fe9zoo9oc-3] @ 04/19/24 17:12:37.704
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-bb22a43e-f3b8-4673-8d08-f1f6773abf5e.17c7bdb2236e9a59], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 04/19/24 17:12:37.704
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-bb22a43e-f3b8-4673-8d08-f1f6773abf5e.17c7bdb229c6db04], Reason = [Created], Message = [Created container filler-pod-bb22a43e-f3b8-4673-8d08-f1f6773abf5e] @ 04/19/24 17:12:37.704
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-bb22a43e-f3b8-4673-8d08-f1f6773abf5e.17c7bdb22b9809bf], Reason = [Started], Message = [Started container filler-pod-bb22a43e-f3b8-4673-8d08-f1f6773abf5e] @ 04/19/24 17:12:37.704
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-be5b4d4f-09a1-46a4-b6a4-b70116ad4b70.17c7bdb20bc293e0], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8877/filler-pod-be5b4d4f-09a1-46a4-b6a4-b70116ad4b70 to co4fe9zoo9oc-2] @ 04/19/24 17:12:37.704
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-be5b4d4f-09a1-46a4-b6a4-b70116ad4b70.17c7bdb22f7ebedf], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 04/19/24 17:12:37.704
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-be5b4d4f-09a1-46a4-b6a4-b70116ad4b70.17c7bdb236f9924f], Reason = [Created], Message = [Created container filler-pod-be5b4d4f-09a1-46a4-b6a4-b70116ad4b70] @ 04/19/24 17:12:37.704
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-be5b4d4f-09a1-46a4-b6a4-b70116ad4b70.17c7bdb2386607e0], Reason = [Started], Message = [Started container filler-pod-be5b4d4f-09a1-46a4-b6a4-b70116ad4b70] @ 04/19/24 17:12:37.704
  STEP: Considering event: 
  Type = [Warning], Name = [additional-pod.17c7bdb287e8cf62], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod.] @ 04/19/24 17:12:37.731
  E0419 17:12:38.067759      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label node off the node co4fe9zoo9oc-1 @ 04/19/24 17:12:38.743
  STEP: verifying the node doesn't have the label node @ 04/19/24 17:12:38.785
  STEP: removing the label node off the node co4fe9zoo9oc-2 @ 04/19/24 17:12:38.802
  STEP: verifying the node doesn't have the label node @ 04/19/24 17:12:38.844
  STEP: removing the label node off the node co4fe9zoo9oc-3 @ 04/19/24 17:12:38.856
  STEP: verifying the node doesn't have the label node @ 04/19/24 17:12:38.894
  Apr 19 17:12:38.902: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-8877" for this suite. @ 04/19/24 17:12:38.909
• [3.696 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:112
  STEP: Creating a kubernetes client @ 04/19/24 17:12:38.924
  Apr 19 17:12:38.924: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename replicaset @ 04/19/24 17:12:38.927
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:12:38.955
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:12:38.961
  Apr 19 17:12:38.975: INFO: Creating ReplicaSet my-hostname-basic-a87e9dad-a85c-428a-8262-0e795a076e0f
  Apr 19 17:12:39.000: INFO: Pod name my-hostname-basic-a87e9dad-a85c-428a-8262-0e795a076e0f: Found 0 pods out of 1
  E0419 17:12:39.068100      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:40.068944      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:41.069312      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:42.069632      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:43.070206      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:12:44.014: INFO: Pod name my-hostname-basic-a87e9dad-a85c-428a-8262-0e795a076e0f: Found 1 pods out of 1
  Apr 19 17:12:44.015: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-a87e9dad-a85c-428a-8262-0e795a076e0f" is running
  Apr 19 17:12:44.026: INFO: Pod "my-hostname-basic-a87e9dad-a85c-428a-8262-0e795a076e0f-nb5sj" is running (conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-19 17:12:40 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-19 17:12:39 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-19 17:12:40 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-19 17:12:40 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-19 17:12:39 +0000 UTC Reason: Message:}])
  Apr 19 17:12:44.026: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 04/19/24 17:12:44.026
  E0419 17:12:44.070628      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:12:44.072: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-7859" for this suite. @ 04/19/24 17:12:44.086
• [5.182 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:46
  STEP: Creating a kubernetes client @ 04/19/24 17:12:44.106
  Apr 19 17:12:44.106: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename configmap @ 04/19/24 17:12:44.11
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:12:44.145
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:12:44.153
  STEP: Creating configMap configmap-4148/configmap-test-b18348ac-a675-4375-aa4e-3730026398f7 @ 04/19/24 17:12:44.161
  STEP: Creating a pod to test consume configMaps @ 04/19/24 17:12:44.173
  E0419 17:12:45.071203      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:46.071751      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:47.072952      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:48.073643      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:12:48.231
  Apr 19 17:12:48.242: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-configmaps-fca02c8d-8d7b-4db8-ad04-116a248cddb6 container env-test: <nil>
  STEP: delete the pod @ 04/19/24 17:12:48.268
  Apr 19 17:12:48.306: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4148" for this suite. @ 04/19/24 17:12:48.321
• [4.235 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
k8s.io/kubernetes/test/e2e/node/taints.go:450
  STEP: Creating a kubernetes client @ 04/19/24 17:12:48.355
  Apr 19 17:12:48.355: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename taint-multiple-pods @ 04/19/24 17:12:48.36
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:12:48.406
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:12:48.415
  Apr 19 17:12:48.424: INFO: Waiting up to 1m0s for all nodes to be ready
  E0419 17:12:49.074762      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:50.075005      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:51.075809      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:52.076271      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:53.076866      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:54.077115      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:55.077400      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:56.077721      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:57.080193      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:58.081281      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:12:59.081497      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:00.081687      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:01.082769      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:02.083784      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:03.085035      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:04.085149      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:05.085355      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:06.085624      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:07.086793      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:08.087050      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:09.087890      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:10.088888      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:11.089048      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:12.089492      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:13.090183      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:14.091171      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:15.091318      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:16.091401      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:17.091982      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:18.092822      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:19.093481      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:20.093989      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:21.094465      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:22.094788      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:23.095934      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:24.096018      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:25.096634      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:26.097627      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:27.098539      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:28.099081      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:29.099311      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:30.099588      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:31.099884      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:32.100079      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:33.101177      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:34.101305      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:35.101875      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:36.102583      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:37.103767      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:38.104202      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:39.104579      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:40.105475      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:41.106133      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:42.106554      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:43.107438      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:44.108467      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:45.108322      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:46.109120      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:47.109010      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:48.110073      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:13:48.426: INFO: Waiting for terminating namespaces to be deleted...
  Apr 19 17:13:48.437: INFO: Starting informer...
  STEP: Starting pods... @ 04/19/24 17:13:48.438
  Apr 19 17:13:48.677: INFO: Pod1 is running on co4fe9zoo9oc-3. Tainting Node
  E0419 17:13:49.110804      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:50.111702      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:13:50.929: INFO: Pod2 is running on co4fe9zoo9oc-3. Tainting Node
  STEP: Trying to apply a taint on the Node @ 04/19/24 17:13:50.929
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 04/19/24 17:13:50.969
  STEP: Waiting for Pod1 and Pod2 to be deleted @ 04/19/24 17:13:50.98
  E0419 17:13:51.112195      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:52.112653      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:53.112833      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:54.113753      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:55.114339      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:56.114915      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:13:57.011: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
  E0419 17:13:57.115895      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:58.116996      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:13:59.117372      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:00.117809      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:01.118407      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:02.118652      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:03.119767      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:04.119910      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:05.123144      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:06.121271      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:07.121606      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:08.121971      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:09.122914      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:10.123690      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:11.123758      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:12.123868      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:13.126473      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:14.126123      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:15.126767      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:16.126689      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:17.127572      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:14:17.159: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 04/19/24 17:14:17.19
  Apr 19 17:14:17.199: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-multiple-pods-3341" for this suite. @ 04/19/24 17:14:17.215
• [88.876 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:47
  STEP: Creating a kubernetes client @ 04/19/24 17:14:17.232
  Apr 19 17:14:17.232: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename secrets @ 04/19/24 17:14:17.238
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:14:17.282
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:14:17.292
  STEP: Creating secret with name secret-test-6a72780b-de79-4bd5-82cf-c29bb2bd8c3d @ 04/19/24 17:14:17.301
  STEP: Creating a pod to test consume secrets @ 04/19/24 17:14:17.312
  E0419 17:14:18.128116      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:19.128229      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:20.129193      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:21.130059      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:14:21.405
  Apr 19 17:14:21.417: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-secrets-446a8140-7cf7-4c38-880d-d1970c88bfdf container secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/24 17:14:21.469
  Apr 19 17:14:21.514: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4986" for this suite. @ 04/19/24 17:14:21.527
• [4.316 seconds]
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:223
  STEP: Creating a kubernetes client @ 04/19/24 17:14:21.548
  Apr 19 17:14:21.548: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename projected @ 04/19/24 17:14:21.553
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:14:21.592
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:14:21.598
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 17:14:21.605
  E0419 17:14:22.130851      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:23.131475      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:24.132493      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:25.132274      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:14:25.699
  Apr 19 17:14:25.715: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod downwardapi-volume-7b2c9002-b29d-458c-a560-2750c1c54f46 container client-container: <nil>
  STEP: delete the pod @ 04/19/24 17:14:25.739
  Apr 19 17:14:25.783: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4408" for this suite. @ 04/19/24 17:14:25.793
• [4.259 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:170
  STEP: Creating a kubernetes client @ 04/19/24 17:14:25.81
  Apr 19 17:14:25.811: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename emptydir @ 04/19/24 17:14:25.816
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:14:25.849
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:14:25.856
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 04/19/24 17:14:25.863
  E0419 17:14:26.133060      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:27.133225      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:28.133878      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:29.134331      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:14:29.919
  Apr 19 17:14:29.930: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-3b426ff0-9087-441a-aa18-376f2c767044 container test-container: <nil>
  STEP: delete the pod @ 04/19/24 17:14:29.95
  Apr 19 17:14:29.978: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9789" for this suite. @ 04/19/24 17:14:29.986
• [4.188 seconds]
------------------------------
S
------------------------------
[sig-node] PreStop should call prestop when killing a pod [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pre_stop.go:169
  STEP: Creating a kubernetes client @ 04/19/24 17:14:30.001
  Apr 19 17:14:30.002: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename prestop @ 04/19/24 17:14:30.008
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:14:30.046
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:14:30.051
  STEP: Creating server pod server in namespace prestop-7460 @ 04/19/24 17:14:30.06
  STEP: Waiting for pods to come up. @ 04/19/24 17:14:30.074
  E0419 17:14:30.135110      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:31.135389      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating tester pod tester in namespace prestop-7460 @ 04/19/24 17:14:32.108
  E0419 17:14:32.135855      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:33.136948      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:34.138064      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting pre-stop pod @ 04/19/24 17:14:34.145
  E0419 17:14:35.138168      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:36.138654      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:37.138999      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:38.139026      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:39.139965      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:14:39.185: INFO: Saw: {
  	"Hostname": "server",
  	"Sent": null,
  	"Received": {
  		"prestop": 1
  	},
  	"Errors": null,
  	"Log": [
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
  	],
  	"StillContactingPeers": true
  }
  STEP: Deleting the server pod @ 04/19/24 17:14:39.186
  Apr 19 17:14:39.219: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "prestop-7460" for this suite. @ 04/19/24 17:14:39.255
• [9.271 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:90
  STEP: Creating a kubernetes client @ 04/19/24 17:14:39.281
  Apr 19 17:14:39.281: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename projected @ 04/19/24 17:14:39.286
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:14:39.329
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:14:39.334
  STEP: Creating configMap with name projected-configmap-test-volume-map-37777e19-fab8-4280-ba38-b3c0949a77ce @ 04/19/24 17:14:39.341
  STEP: Creating a pod to test consume configMaps @ 04/19/24 17:14:39.35
  E0419 17:14:40.140806      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:41.142765      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:42.144823      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:43.144680      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:14:43.409
  Apr 19 17:14:43.420: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-projected-configmaps-6082e122-1151-40fd-9669-2f9b5d0db1ed container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/24 17:14:43.447
  Apr 19 17:14:43.487: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7726" for this suite. @ 04/19/24 17:14:43.503
• [4.238 seconds]
------------------------------
SSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Subdomain [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:286
  STEP: Creating a kubernetes client @ 04/19/24 17:14:43.52
  Apr 19 17:14:43.520: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename dns @ 04/19/24 17:14:43.523
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:14:43.567
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:14:43.573
  STEP: Creating a test headless service @ 04/19/24 17:14:43.582
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7310.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-7310.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7310.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-7310.svc.cluster.local;sleep 1; done
   @ 04/19/24 17:14:43.595
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7310.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-7310.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7310.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-7310.svc.cluster.local;sleep 1; done
   @ 04/19/24 17:14:43.595
  STEP: creating a pod to probe DNS @ 04/19/24 17:14:43.595
  STEP: submitting the pod to kubernetes @ 04/19/24 17:14:43.595
  E0419 17:14:44.144962      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:45.156183      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/19/24 17:14:45.647
  STEP: looking for the results for each expected name from probers @ 04/19/24 17:14:45.66
  Apr 19 17:14:45.679: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:14:45.690: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:14:45.703: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:14:45.714: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:14:45.724: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:14:45.734: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:14:45.744: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:14:45.754: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:14:45.754: INFO: Lookups using dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7310.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7310.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local jessie_udp@dns-test-service-2.dns-7310.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7310.svc.cluster.local]

  Apr 19 17:14:45.771: INFO: Pod client logs for webserver: 
  Apr 19 17:14:45.793: INFO: Pod client logs for querier: 
  Apr 19 17:14:45.811: INFO: Pod client logs for jessie-querier: 
  E0419 17:14:46.152903      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:47.154443      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:48.153316      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:49.153787      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:50.153905      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:14:50.677: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:14:50.685: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:14:50.692: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:14:50.706: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:14:50.713: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:14:50.721: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:14:50.742: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:14:50.749: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:14:50.750: INFO: Lookups using dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7310.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7310.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local jessie_udp@dns-test-service-2.dns-7310.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7310.svc.cluster.local]

  Apr 19 17:14:50.764: INFO: Pod client logs for webserver: 
  Apr 19 17:14:50.778: INFO: Pod client logs for querier: 
  Apr 19 17:14:50.790: INFO: Pod client logs for jessie-querier: 
  E0419 17:14:51.154587      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:52.155043      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:53.155591      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:54.156204      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:55.157060      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:14:55.677: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:14:55.685: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:14:55.693: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:14:55.699: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:14:55.705: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:14:55.711: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:14:55.716: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:14:55.722: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:14:55.722: INFO: Lookups using dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7310.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7310.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local jessie_udp@dns-test-service-2.dns-7310.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7310.svc.cluster.local]

  Apr 19 17:14:55.733: INFO: Pod client logs for webserver: 
  Apr 19 17:14:55.746: INFO: Pod client logs for querier: 
  Apr 19 17:14:55.756: INFO: Pod client logs for jessie-querier: 
  E0419 17:14:56.158651      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:57.158938      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:58.159982      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:14:59.160159      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:00.160303      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:15:00.674: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:15:00.685: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:15:00.698: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:15:00.710: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:15:00.720: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:15:00.732: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:15:00.743: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:15:00.755: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:15:00.755: INFO: Lookups using dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7310.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7310.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local jessie_udp@dns-test-service-2.dns-7310.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7310.svc.cluster.local]

  Apr 19 17:15:00.775: INFO: Pod client logs for webserver: 
  Apr 19 17:15:00.798: INFO: Pod client logs for querier: 
  Apr 19 17:15:00.818: INFO: Pod client logs for jessie-querier: 
  E0419 17:15:01.160966      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:02.161058      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:03.161818      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:04.162249      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:05.162455      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:15:05.669: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:15:05.686: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:15:05.695: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:15:05.702: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:15:05.709: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:15:05.715: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:15:05.721: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:15:05.729: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:15:05.729: INFO: Lookups using dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7310.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7310.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local jessie_udp@dns-test-service-2.dns-7310.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7310.svc.cluster.local]

  Apr 19 17:15:05.742: INFO: Pod client logs for webserver: 
  Apr 19 17:15:05.753: INFO: Pod client logs for querier: 
  Apr 19 17:15:05.766: INFO: Pod client logs for jessie-querier: 
  E0419 17:15:06.162761      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:07.163585      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:08.164416      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:09.165221      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:10.165358      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:15:10.673: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:15:10.684: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:15:10.693: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:15:10.713: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:15:10.720: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:15:10.729: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:15:10.737: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:15:10.744: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:15:10.744: INFO: Lookups using dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7310.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7310.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7310.svc.cluster.local jessie_udp@dns-test-service-2.dns-7310.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7310.svc.cluster.local]

  Apr 19 17:15:10.759: INFO: Pod client logs for webserver: 
  Apr 19 17:15:10.774: INFO: Pod client logs for querier: 
  Apr 19 17:15:10.787: INFO: Pod client logs for jessie-querier: 
  E0419 17:15:11.168721      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:12.169080      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:13.169966      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:14.170399      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:15.170625      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:15:15.764: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:15:15.780: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7310.svc.cluster.local from pod dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d: the server could not find the requested resource (get pods dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d)
  Apr 19 17:15:15.780: INFO: Lookups using dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d failed for: [jessie_udp@dns-test-service-2.dns-7310.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7310.svc.cluster.local]

  Apr 19 17:15:15.807: INFO: Pod client logs for webserver: 
  Apr 19 17:15:15.823: INFO: Pod client logs for querier: 
  Apr 19 17:15:15.842: INFO: Pod client logs for jessie-querier: 
  E0419 17:15:16.172075      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:17.174779      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:18.172813      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:19.173696      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:20.174583      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:15:20.726: INFO: DNS probes using dns-7310/dns-test-ca8b9588-ae94-48a6-a154-0c5af05cde0d succeeded

  STEP: deleting the pod @ 04/19/24 17:15:20.727
  STEP: deleting the test headless service @ 04/19/24 17:15:20.765
  Apr 19 17:15:20.808: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-7310" for this suite. @ 04/19/24 17:15:20.822
• [37.318 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:539
  STEP: Creating a kubernetes client @ 04/19/24 17:15:20.841
  Apr 19 17:15:20.841: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename gc @ 04/19/24 17:15:20.844
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:15:20.875
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:15:20.879
  STEP: create the deployment @ 04/19/24 17:15:20.885
  W0419 17:15:20.896414      13 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 04/19/24 17:15:20.896
  E0419 17:15:21.174940      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the deployment @ 04/19/24 17:15:21.414
  STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs @ 04/19/24 17:15:21.428
  STEP: Gathering metrics @ 04/19/24 17:15:21.984
  E0419 17:15:22.175226      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:15:22.214: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 19 17:15:22.215: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-3573" for this suite. @ 04/19/24 17:15:22.225
• [1.394 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:376
  STEP: Creating a kubernetes client @ 04/19/24 17:15:22.238
  Apr 19 17:15:22.238: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename projected @ 04/19/24 17:15:22.241
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:15:22.271
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:15:22.275
  STEP: Creating configMap with name projected-configmap-test-volume-7fa1d6ed-9ea2-4658-bf58-3e007d48eb6c @ 04/19/24 17:15:22.283
  STEP: Creating a pod to test consume configMaps @ 04/19/24 17:15:22.292
  E0419 17:15:23.179899      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:24.180283      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:25.180796      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:26.180934      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:15:26.353
  Apr 19 17:15:26.358: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-projected-configmaps-b29a84f6-e034-474c-a113-43ab2eb33510 container projected-configmap-volume-test: <nil>
  STEP: delete the pod @ 04/19/24 17:15:26.371
  Apr 19 17:15:26.413: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2058" for this suite. @ 04/19/24 17:15:26.421
• [4.204 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:276
  STEP: Creating a kubernetes client @ 04/19/24 17:15:26.447
  Apr 19 17:15:26.447: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/19/24 17:15:26.45
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:15:26.504
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:15:26.512
  STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation @ 04/19/24 17:15:26.518
  Apr 19 17:15:26.520: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  E0419 17:15:27.182197      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:28.182572      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:15:28.484: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  E0419 17:15:29.183557      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:30.184356      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:31.185467      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:32.185625      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:33.186741      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:34.186819      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:35.187523      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:15:35.744: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-7873" for this suite. @ 04/19/24 17:15:35.773
• [9.346 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:205
  STEP: Creating a kubernetes client @ 04/19/24 17:15:35.796
  Apr 19 17:15:35.796: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename secrets @ 04/19/24 17:15:35.802
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:15:35.855
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:15:35.86
  STEP: Creating secret with name s-test-opt-del-3536731c-3c02-4203-b18a-b1ca797dc627 @ 04/19/24 17:15:35.874
  STEP: Creating secret with name s-test-opt-upd-b61cbb1d-4989-4bff-bb83-a37e62e6605c @ 04/19/24 17:15:35.883
  STEP: Creating the pod @ 04/19/24 17:15:35.893
  E0419 17:15:36.188616      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:37.192025      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-3536731c-3c02-4203-b18a-b1ca797dc627 @ 04/19/24 17:15:38.014
  STEP: Updating secret s-test-opt-upd-b61cbb1d-4989-4bff-bb83-a37e62e6605c @ 04/19/24 17:15:38.034
  STEP: Creating secret with name s-test-opt-create-283962f7-d1e2-457e-b6ad-e346a5553247 @ 04/19/24 17:15:38.047
  STEP: waiting to observe update in volume @ 04/19/24 17:15:38.068
  E0419 17:15:38.189671      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:39.190464      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:40.190339      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:41.190532      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:15:42.170: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2976" for this suite. @ 04/19/24 17:15:42.187
  E0419 17:15:42.191604      13 retrywatcher.go:129] "Watch failed" err="context canceled"
• [6.408 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Services should test the lifecycle of an Endpoint [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3154
  STEP: Creating a kubernetes client @ 04/19/24 17:15:42.205
  Apr 19 17:15:42.205: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename services @ 04/19/24 17:15:42.209
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:15:42.248
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:15:42.255
  STEP: creating an Endpoint @ 04/19/24 17:15:42.286
  STEP: waiting for available Endpoint @ 04/19/24 17:15:42.304
  STEP: listing all Endpoints @ 04/19/24 17:15:42.313
  STEP: updating the Endpoint @ 04/19/24 17:15:42.324
  STEP: fetching the Endpoint @ 04/19/24 17:15:42.344
  STEP: patching the Endpoint @ 04/19/24 17:15:42.351
  STEP: fetching the Endpoint @ 04/19/24 17:15:42.373
  STEP: deleting the Endpoint by Collection @ 04/19/24 17:15:42.382
  STEP: waiting for Endpoint deletion @ 04/19/24 17:15:42.405
  STEP: fetching the Endpoint @ 04/19/24 17:15:42.413
  Apr 19 17:15:42.426: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3123" for this suite. @ 04/19/24 17:15:42.445
• [0.260 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1533
  STEP: Creating a kubernetes client @ 04/19/24 17:15:42.477
  Apr 19 17:15:42.478: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename services @ 04/19/24 17:15:42.481
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:15:42.527
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:15:42.541
  STEP: creating a service nodeport-service with the type=NodePort in namespace services-5404 @ 04/19/24 17:15:42.547
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 04/19/24 17:15:42.599
  STEP: creating service externalsvc in namespace services-5404 @ 04/19/24 17:15:42.599
  STEP: creating replication controller externalsvc in namespace services-5404 @ 04/19/24 17:15:42.625
  I0419 17:15:42.643119      13 runners.go:197] Created replication controller with name: externalsvc, namespace: services-5404, replica count: 2
  E0419 17:15:43.191481      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:44.192151      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:45.192868      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:15:45.695237      13 runners.go:197] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the NodePort service to type=ExternalName @ 04/19/24 17:15:45.703
  Apr 19 17:15:45.763: INFO: Creating new exec pod
  E0419 17:15:46.192903      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:47.194046      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:15:47.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-5404 exec execpodb8h7f -- /bin/sh -x -c nslookup nodeport-service.services-5404.svc.cluster.local'
  E0419 17:15:48.194386      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:15:48.229: INFO: stderr: "+ nslookup nodeport-service.services-5404.svc.cluster.local\n"
  Apr 19 17:15:48.229: INFO: stdout: "Server:\t\t10.233.0.10\nAddress:\t10.233.0.10#53\n\nnodeport-service.services-5404.svc.cluster.local\tcanonical name = externalsvc.services-5404.svc.cluster.local.\nName:\texternalsvc.services-5404.svc.cluster.local\nAddress: 10.233.41.239\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-5404, will wait for the garbage collector to delete the pods @ 04/19/24 17:15:48.23
  Apr 19 17:15:48.303: INFO: Deleting ReplicationController externalsvc took: 12.214047ms
  Apr 19 17:15:48.404: INFO: Terminating ReplicationController externalsvc pods took: 100.780777ms
  E0419 17:15:49.194983      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:50.195154      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:51.196258      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:15:51.674: INFO: Cleaning up the NodePort to ExternalName test service
  Apr 19 17:15:51.720: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5404" for this suite. @ 04/19/24 17:15:51.733
• [9.270 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1084
  STEP: Creating a kubernetes client @ 04/19/24 17:15:51.75
  Apr 19 17:15:51.750: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename kubectl @ 04/19/24 17:15:51.753
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:15:51.783
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:15:51.789
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 04/19/24 17:15:51.794
  Apr 19 17:15:51.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-6904 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  Apr 19 17:15:51.982: INFO: stderr: ""
  Apr 19 17:15:51.982: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: replace the image in the pod with server-side dry-run @ 04/19/24 17:15:51.982
  Apr 19 17:15:51.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-6904 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.36.1-1"}]}} --dry-run=server'
  Apr 19 17:15:52.155: INFO: stderr: ""
  Apr 19 17:15:52.155: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 04/19/24 17:15:52.155
  Apr 19 17:15:52.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-6904 delete pods e2e-test-httpd-pod'
  E0419 17:15:52.196986      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:53.197331      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:15:53.848: INFO: stderr: ""
  Apr 19 17:15:53.848: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Apr 19 17:15:53.848: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6904" for this suite. @ 04/19/24 17:15:53.861
• [2.125 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:56
  STEP: Creating a kubernetes client @ 04/19/24 17:15:53.876
  Apr 19 17:15:53.876: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename projected @ 04/19/24 17:15:53.88
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:15:53.926
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:15:53.933
  STEP: Creating projection with secret that has name projected-secret-test-3648bf5d-d06a-4ed4-8bf1-a6096af1e93e @ 04/19/24 17:15:53.941
  STEP: Creating a pod to test consume secrets @ 04/19/24 17:15:53.953
  E0419 17:15:54.198426      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:55.199193      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:15:56.008
  Apr 19 17:15:56.015: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-projected-secrets-9968b057-d61b-43d9-b7ce-52361825b3e4 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/24 17:15:56.035
  Apr 19 17:15:56.081: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8593" for this suite. @ 04/19/24 17:15:56.096
• [2.235 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:110
  STEP: Creating a kubernetes client @ 04/19/24 17:15:56.115
  Apr 19 17:15:56.115: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename emptydir @ 04/19/24 17:15:56.119
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:15:56.15
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:15:56.154
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 04/19/24 17:15:56.163
  E0419 17:15:56.200386      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:57.201386      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:58.202416      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:15:59.203045      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:00.203811      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:16:00.214
  Apr 19 17:16:00.223: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-5c666fcb-3627-4ef5-b48c-75e5f34d4252 container test-container: <nil>
  STEP: delete the pod @ 04/19/24 17:16:00.243
  Apr 19 17:16:00.287: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2413" for this suite. @ 04/19/24 17:16:00.316
• [4.216 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/empty_dir_wrapper.go:67
  STEP: Creating a kubernetes client @ 04/19/24 17:16:00.334
  Apr 19 17:16:00.334: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename emptydir-wrapper @ 04/19/24 17:16:00.338
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:16:00.373
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:16:00.381
  E0419 17:16:01.204683      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:02.205107      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Cleaning up the secret @ 04/19/24 17:16:02.463
  STEP: Cleaning up the configmap @ 04/19/24 17:16:02.483
  STEP: Cleaning up the pod @ 04/19/24 17:16:02.509
  Apr 19 17:16:02.535: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-7138" for this suite. @ 04/19/24 17:16:02.547
• [2.257 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:170
  STEP: Creating a kubernetes client @ 04/19/24 17:16:02.593
  Apr 19 17:16:02.593: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename configmap @ 04/19/24 17:16:02.596
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:16:02.625
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:16:02.63
  STEP: creating a ConfigMap @ 04/19/24 17:16:02.636
  STEP: fetching the ConfigMap @ 04/19/24 17:16:02.643
  STEP: patching the ConfigMap @ 04/19/24 17:16:02.649
  STEP: listing all ConfigMaps in all namespaces with a label selector @ 04/19/24 17:16:02.657
  STEP: deleting the ConfigMap by collection with a label selector @ 04/19/24 17:16:02.666
  STEP: listing all ConfigMaps in test namespace @ 04/19/24 17:16:02.678
  Apr 19 17:16:02.684: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-385" for this suite. @ 04/19/24 17:16:02.694
• [0.117 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:110
  STEP: Creating a kubernetes client @ 04/19/24 17:16:02.713
  Apr 19 17:16:02.713: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename projected @ 04/19/24 17:16:02.716
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:16:02.747
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:16:02.752
  STEP: Creating configMap with name projected-configmap-test-volume-map-149aa4da-afa7-4de3-9b4c-f3ad7e0e2505 @ 04/19/24 17:16:02.757
  STEP: Creating a pod to test consume configMaps @ 04/19/24 17:16:02.766
  E0419 17:16:03.205622      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:04.205882      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:05.206786      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:06.207536      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:16:06.809
  Apr 19 17:16:06.820: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-projected-configmaps-1fb5b6b5-e0be-4c4e-bc0a-0f0bee186ada container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/24 17:16:06.846
  Apr 19 17:16:06.887: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8969" for this suite. @ 04/19/24 17:16:06.91
• [4.219 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:238
  STEP: Creating a kubernetes client @ 04/19/24 17:16:06.934
  Apr 19 17:16:06.934: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename webhook @ 04/19/24 17:16:06.941
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:16:06.981
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:16:06.989
  STEP: Setting up server cert @ 04/19/24 17:16:07.048
  E0419 17:16:07.208242      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:08.208352      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 17:16:08.554
  STEP: Deploying the webhook pod @ 04/19/24 17:16:08.573
  STEP: Wait for the deployment to be ready @ 04/19/24 17:16:08.609
  Apr 19 17:16:08.643: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0419 17:16:09.208592      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:10.208825      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 17:16:10.677
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 17:16:10.724
  E0419 17:16:11.209901      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:16:11.727: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API @ 04/19/24 17:16:11.747
  STEP: create a namespace for the webhook @ 04/19/24 17:16:11.794
  STEP: create a configmap should be unconditionally rejected by the webhook @ 04/19/24 17:16:11.841
  Apr 19 17:16:11.990: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5723" for this suite. @ 04/19/24 17:16:11.998
  STEP: Destroying namespace "webhook-markers-8759" for this suite. @ 04/19/24 17:16:12.008
  STEP: Destroying namespace "fail-closed-namespace-8591" for this suite. @ 04/19/24 17:16:12.017
• [5.095 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:751
  STEP: Creating a kubernetes client @ 04/19/24 17:16:12.031
  Apr 19 17:16:12.031: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename statefulset @ 04/19/24 17:16:12.034
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:16:12.07
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:16:12.082
  STEP: Creating service test in namespace statefulset-273 @ 04/19/24 17:16:12.09
  STEP: Creating stateful set ss in namespace statefulset-273 @ 04/19/24 17:16:12.102
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-273 @ 04/19/24 17:16:12.113
  Apr 19 17:16:12.122: INFO: Found 0 stateful pods, waiting for 1
  E0419 17:16:12.210394      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:13.210682      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:14.211454      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:15.213011      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:16.212328      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:17.212624      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:18.213562      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:19.214229      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:20.214488      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:21.215031      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:16:22.122: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod @ 04/19/24 17:16:22.123
  Apr 19 17:16:22.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=statefulset-273 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  E0419 17:16:22.215530      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:16:22.416: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 19 17:16:22.416: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 19 17:16:22.416: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 19 17:16:22.423: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E0419 17:16:23.215957      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:24.216317      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:25.216839      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:26.217043      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:27.217679      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:28.218053      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:29.218586      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:30.219001      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:31.220100      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:32.220801      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:16:32.430: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Apr 19 17:16:32.430: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Apr 19 17:16:32.480: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
  Apr 19 17:16:32.480: INFO: ss-0  co4fe9zoo9oc-3  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 17:16:12 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 17:16:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-19 17:16:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-19 17:16:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 17:16:12 +0000 UTC  }]
  Apr 19 17:16:32.480: INFO: 
  Apr 19 17:16:32.480: INFO: StatefulSet ss has not reached scale 3, at 1
  E0419 17:16:33.221928      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:16:33.492: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.985604235s
  E0419 17:16:34.222155      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:16:34.522: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.974023417s
  E0419 17:16:35.223316      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:16:35.539: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.943710177s
  E0419 17:16:36.223626      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:16:36.551: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.926316496s
  E0419 17:16:37.224352      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:16:37.582: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.915129594s
  E0419 17:16:38.224546      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:16:38.598: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.883668835s
  E0419 17:16:39.225431      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:16:39.610: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.867500934s
  E0419 17:16:40.226355      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:16:40.622: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.856004576s
  E0419 17:16:41.227227      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:16:41.631: INFO: Verifying statefulset ss doesn't scale past 3 for another 844.00454ms
  E0419 17:16:42.227879      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-273 @ 04/19/24 17:16:42.633
  Apr 19 17:16:42.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=statefulset-273 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 19 17:16:42.904: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 19 17:16:42.904: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 19 17:16:42.904: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 19 17:16:42.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=statefulset-273 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  E0419 17:16:43.228611      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:16:43.244: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  Apr 19 17:16:43.244: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 19 17:16:43.244: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 19 17:16:43.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=statefulset-273 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 19 17:16:43.595: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  Apr 19 17:16:43.596: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 19 17:16:43.596: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 19 17:16:43.603: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 19 17:16:43.603: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 19 17:16:43.603: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Scale down will not halt with unhealthy stateful pod @ 04/19/24 17:16:43.603
  Apr 19 17:16:43.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=statefulset-273 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 19 17:16:43.915: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 19 17:16:43.915: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 19 17:16:43.915: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 19 17:16:43.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=statefulset-273 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 19 17:16:44.211: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 19 17:16:44.211: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 19 17:16:44.211: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 19 17:16:44.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=statefulset-273 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  E0419 17:16:44.229177      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:16:44.536: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 19 17:16:44.536: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 19 17:16:44.536: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 19 17:16:44.536: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Apr 19 17:16:44.542: INFO: Waiting for statefulset status.readyReplicas to become 0, currently 1
  E0419 17:16:45.229735      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:46.230054      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:47.231095      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:48.231289      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:49.231746      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:50.232055      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:51.233036      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:52.233222      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:53.234507      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:16:54.235302      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:16:54.589: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Apr 19 17:16:54.589: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  Apr 19 17:16:54.590: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  Apr 19 17:16:54.618: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
  Apr 19 17:16:54.618: INFO: ss-0  co4fe9zoo9oc-3  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 17:16:12 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 17:16:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-19 17:16:44 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-19 17:16:44 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 17:16:12 +0000 UTC  }]
  Apr 19 17:16:54.619: INFO: ss-1  co4fe9zoo9oc-2  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 17:16:35 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 17:16:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-19 17:16:44 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-19 17:16:44 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 17:16:32 +0000 UTC  }]
  Apr 19 17:16:54.619: INFO: ss-2  co4fe9zoo9oc-1  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 17:16:33 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 17:16:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-19 17:16:44 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-19 17:16:44 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 17:16:32 +0000 UTC  }]
  Apr 19 17:16:54.620: INFO: 
  Apr 19 17:16:54.621: INFO: StatefulSet ss has not reached scale 0, at 3
  E0419 17:16:55.235793      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:16:55.629: INFO: POD   NODE            PHASE      GRACE  CONDITIONS
  Apr 19 17:16:55.629: INFO: ss-1  co4fe9zoo9oc-2  Succeeded  30s    [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-04-19 17:16:55 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 17:16:32 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-19 17:16:44 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-19 17:16:44 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-19 17:16:32 +0000 UTC  }]
  Apr 19 17:16:55.629: INFO: 
  Apr 19 17:16:55.629: INFO: StatefulSet ss has not reached scale 0, at 1
  E0419 17:16:56.236126      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:16:56.639: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.980394973s
  E0419 17:16:57.236622      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:16:57.649: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.96944369s
  E0419 17:16:58.237411      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:16:58.658: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.960543032s
  E0419 17:16:59.237968      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:16:59.671: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.951742853s
  E0419 17:17:00.239218      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:17:00.680: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.939053664s
  E0419 17:17:01.240207      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:17:01.687: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.928917422s
  E0419 17:17:02.240882      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:17:02.699: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.923200634s
  E0419 17:17:03.240797      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:17:03.710: INFO: Verifying statefulset ss doesn't scale past 0 for another 909.028143ms
  E0419 17:17:04.240976      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-273 @ 04/19/24 17:17:04.711
  Apr 19 17:17:04.721: INFO: Scaling statefulset ss to 0
  Apr 19 17:17:04.754: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 19 17:17:04.763: INFO: Deleting all statefulset in ns statefulset-273
  Apr 19 17:17:04.772: INFO: Scaling statefulset ss to 0
  Apr 19 17:17:04.798: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 19 17:17:04.808: INFO: Deleting statefulset ss
  Apr 19 17:17:04.842: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-273" for this suite. @ 04/19/24 17:17:04.852
• [52.833 seconds]
------------------------------
SS
------------------------------
[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:75
  STEP: Creating a kubernetes client @ 04/19/24 17:17:04.865
  Apr 19 17:17:04.865: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename containers @ 04/19/24 17:17:04.867
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:17:04.902
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:17:04.907
  STEP: Creating a pod to test override command @ 04/19/24 17:17:04.912
  E0419 17:17:05.241642      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:06.241815      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:07.242734      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:08.242671      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:17:08.954
  Apr 19 17:17:08.965: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod client-containers-63c486af-0a28-47c4-a8a9-76d491ebd566 container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/24 17:17:08.991
  Apr 19 17:17:09.034: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-5133" for this suite. @ 04/19/24 17:17:09.047
• [4.201 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:57
  STEP: Creating a kubernetes client @ 04/19/24 17:17:09.07
  Apr 19 17:17:09.070: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename secrets @ 04/19/24 17:17:09.076
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:17:09.123
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:17:09.131
  STEP: Creating secret with name secret-test-5da4fd82-4dd0-4b44-9102-a61869018ea9 @ 04/19/24 17:17:09.141
  STEP: Creating a pod to test consume secrets @ 04/19/24 17:17:09.15
  E0419 17:17:09.243761      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:10.244120      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:11.245422      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:12.245635      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:17:13.193
  Apr 19 17:17:13.203: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-secrets-7b40b9b9-9541-4eba-8db1-066dcab99746 container secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/24 17:17:13.227
  E0419 17:17:13.246502      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:17:13.268: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6056" for this suite. @ 04/19/24 17:17:13.283
• [4.231 seconds]
------------------------------
[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:223
  STEP: Creating a kubernetes client @ 04/19/24 17:17:13.305
  Apr 19 17:17:13.306: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename downward-api @ 04/19/24 17:17:13.31
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:17:13.346
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:17:13.351
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 17:17:13.356
  E0419 17:17:14.246764      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:15.247208      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:16.248228      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:17.249117      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:17:17.411
  Apr 19 17:17:17.422: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod downwardapi-volume-82c1e77b-d72f-4d9e-8b7b-f3726e07d9cf container client-container: <nil>
  STEP: delete the pod @ 04/19/24 17:17:17.443
  Apr 19 17:17:17.479: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-421" for this suite. @ 04/19/24 17:17:17.493
• [4.207 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:251
  STEP: Creating a kubernetes client @ 04/19/24 17:17:17.517
  Apr 19 17:17:17.518: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename projected @ 04/19/24 17:17:17.522
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:17:17.564
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:17:17.568
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 17:17:17.572
  E0419 17:17:18.249485      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:19.249853      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:20.250202      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:21.250586      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:17:21.665
  Apr 19 17:17:21.670: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod downwardapi-volume-6272ee75-8e04-48dc-a947-9e90c8c1b887 container client-container: <nil>
  STEP: delete the pod @ 04/19/24 17:17:21.681
  Apr 19 17:17:21.709: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4019" for this suite. @ 04/19/24 17:17:21.72
• [4.217 seconds]
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl version should check is all data is printed [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1731
  STEP: Creating a kubernetes client @ 04/19/24 17:17:21.736
  Apr 19 17:17:21.736: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename kubectl @ 04/19/24 17:17:21.74
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:17:21.772
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:17:21.777
  Apr 19 17:17:21.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-9757 version'
  Apr 19 17:17:21.912: INFO: stderr: ""
  Apr 19 17:17:21.912: INFO: stdout: "Client Version: v1.29.4\nKustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3\nServer Version: v1.29.4\n"
  Apr 19 17:17:21.912: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9757" for this suite. @ 04/19/24 17:17:21.922
• [0.202 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should delete old replica sets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:122
  STEP: Creating a kubernetes client @ 04/19/24 17:17:21.939
  Apr 19 17:17:21.939: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename deployment @ 04/19/24 17:17:21.941
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:17:21.973
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:17:21.978
  Apr 19 17:17:22.005: INFO: Pod name cleanup-pod: Found 0 pods out of 1
  E0419 17:17:22.251294      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:23.251745      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:24.252428      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:25.253083      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:26.253618      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:17:27.012: INFO: Pod name cleanup-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/19/24 17:17:27.012
  Apr 19 17:17:27.013: INFO: Creating deployment test-cleanup-deployment
  STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up @ 04/19/24 17:17:27.032
  Apr 19 17:17:27.055: INFO: Deployment "test-cleanup-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1278",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "58d9e334-664d-4054-9aa4-7bd5ca063c1b",
      ResourceVersion: (string) (len=5) "33338",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143847,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143847,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(0),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 0,
      Replicas: (int32) 0,
      UpdatedReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) <nil>,
      CollisionCount: (*int32)(<nil>)
    }
  }


  Apr 19 17:17:27.061: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
  Apr 19 17:17:27.061: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
  Apr 19 17:17:27.063: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1278",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8e19c2f0-01c4-4b2d-b4f3-0a61733967e3",
      ResourceVersion: (string) (len=5) "33339",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143841,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=3) "pod": (string) (len=5) "httpd",
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=23) "test-cleanup-deployment",
          UID: (types.UID) (len=36) "58d9e334-664d-4054-9aa4-7bd5ca063c1b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143841,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=483) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000050  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000060  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000070  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000080  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000090  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              000000a0  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000b0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000c0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000d0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000e0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000f0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000100  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000110  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000120  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000130  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000140  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000160  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000170  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000180  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000190  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000001a0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001b0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001c0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001d0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001e0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143847,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=103) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000020  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              00000030  22 75 69 64 5c 22 3a 5c  22 35 38 64 39 65 33 33  |"uid\":\"58d9e33|
              00000040  34 2d 36 36 34 64 2d 34  30 35 34 2d 39 61 61 34  |4-664d-4054-9aa4|
              00000050  2d 37 62 64 35 63 61 30  36 33 63 31 62 5c 22 7d  |-7bd5ca063c1b\"}|
              00000060  22 3a 7b 7d 7d 7d 7d                              |":{}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 19 17:17:27.081: INFO: Pod "test-cleanup-controller-k46wl" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=29) "test-cleanup-controller-k46wl",
      GenerateName: (string) (len=24) "test-cleanup-controller-",
      Namespace: (string) (len=15) "deployment-1278",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "baa4450b-54c2-4e07-b110-c8dcfddb54d9",
      ResourceVersion: (string) (len=5) "33326",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143842,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=23) "test-cleanup-controller",
          UID: (types.UID) (len=36) "8e19c2f0-01c4-4b2d-b4f3-0a61733967e3",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143842,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=500) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 2c 22 66  |},"f:pod":{}},"f|
              00000050  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000060  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000070  75 69 64 5c 22 3a 5c 22  38 65 31 39 63 32 66 30  |uid\":\"8e19c2f0|
              00000080  2d 30 31 63 34 2d 34 62  32 64 2d 62 34 66 33 2d  |-01c4-4b2d-b4f3-|
              00000090  30 61 36 31 37 33 33 39  36 37 65 33 5c 22 7d 22  |0a61733967e3\"}"|
              000000a0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000b0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000c0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              000000d0  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              000000e0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              000000f0  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000100  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000110  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000120  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000130  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000140  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000150  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000160  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              00000170  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              00000180  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              00000190  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001a0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001b0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001c0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              000001d0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              000001e0  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              000001f0  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 36 2e  31 35 35 5c 22 7d 22 3a  |.233.66.155\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-2wcv5",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-2wcv5",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)(<nil>),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "co4fe9zoo9oc-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143842,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143843,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849143842,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.60",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.60"
        }
      },
      PodIP: (string) (len=13) "10.233.66.155",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.66.155"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849143842,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63849143842,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://157a4253b6716daf79efa14cbfa8901791b5a11b4ef9af174fda5c15002188d4",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 19 17:17:27.086: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-1278" for this suite. @ 04/19/24 17:17:27.095
• [5.174 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:224
  STEP: Creating a kubernetes client @ 04/19/24 17:17:27.124
  Apr 19 17:17:27.124: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename sched-preemption @ 04/19/24 17:17:27.132
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:17:27.164
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:17:27.17
  Apr 19 17:17:27.202: INFO: Waiting up to 1m0s for all nodes to be ready
  E0419 17:17:27.254423      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:28.255335      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:29.256127      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:30.256466      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:31.261911      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:32.262720      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:33.262929      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:34.263053      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:35.263279      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:36.263691      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:37.264422      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:38.264852      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:39.265770      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:40.266826      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:41.267274      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:42.267577      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:43.268698      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:44.269562      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:45.270703      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:46.271144      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:47.272035      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:48.272331      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:49.272762      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:50.273145      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:51.274027      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:52.274642      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:53.275376      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:54.275696      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:55.276799      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:56.277264      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:57.279099      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:58.279179      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:17:59.280145      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:00.280853      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:01.281169      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:02.282368      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:03.282759      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:04.283074      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:05.283286      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:06.283908      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:07.284385      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:08.284819      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:09.285506      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:10.285873      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:11.286125      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:12.287148      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:13.287448      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:14.287803      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:15.288812      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:16.289218      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:17.290048      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:18.291322      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:19.292287      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:20.293000      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:21.293489      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:22.294061      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:23.294459      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:24.295192      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:25.296223      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:26.297035      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:18:27.216: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 04/19/24 17:18:27.225
  Apr 19 17:18:27.275: INFO: Created pod: pod0-0-sched-preemption-low-priority
  Apr 19 17:18:27.284: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  E0419 17:18:27.297191      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:18:27.344: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  Apr 19 17:18:27.398: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  Apr 19 17:18:27.438: INFO: Created pod: pod2-0-sched-preemption-medium-priority
  Apr 19 17:18:27.446: INFO: Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 04/19/24 17:18:27.446
  E0419 17:18:28.298540      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:29.298646      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:30.299171      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:31.300306      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Run a critical pod that use same resources as that of a lower priority pod @ 04/19/24 17:18:31.529
  E0419 17:18:32.301578      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:33.302078      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:34.302414      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:35.302954      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:18:35.837: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-4219" for this suite. @ 04/19/24 17:18:35.855
• [68.755 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2236
  STEP: Creating a kubernetes client @ 04/19/24 17:18:35.878
  Apr 19 17:18:35.878: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename services @ 04/19/24 17:18:35.881
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:18:35.939
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:18:35.944
  STEP: creating service in namespace services-5211 @ 04/19/24 17:18:35.95
  STEP: creating service affinity-nodeport-transition in namespace services-5211 @ 04/19/24 17:18:35.95
  STEP: creating replication controller affinity-nodeport-transition in namespace services-5211 @ 04/19/24 17:18:35.99
  I0419 17:18:36.001046      13 runners.go:197] Created replication controller with name: affinity-nodeport-transition, namespace: services-5211, replica count: 3
  E0419 17:18:36.303527      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:37.303098      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:38.304073      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:18:39.054229      13 runners.go:197] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 19 17:18:39.086: INFO: Creating new exec pod
  E0419 17:18:39.304797      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:40.305231      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:41.305542      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:18:42.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-5211 exec execpod-affinitykzkv8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
  E0419 17:18:42.305807      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:18:42.437: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
  Apr 19 17:18:42.438: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 17:18:42.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-5211 exec execpod-affinitykzkv8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.48.250 80'
  Apr 19 17:18:42.689: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.48.250 80\nConnection to 10.233.48.250 80 port [tcp/http] succeeded!\n"
  Apr 19 17:18:42.689: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 17:18:42.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-5211 exec execpod-affinitykzkv8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.39 31256'
  Apr 19 17:18:43.056: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.39 31256\nConnection to 192.168.121.39 31256 port [tcp/*] succeeded!\n"
  Apr 19 17:18:43.056: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 17:18:43.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-5211 exec execpod-affinitykzkv8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.127 31256'
  Apr 19 17:18:43.285: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.127 31256\nConnection to 192.168.121.127 31256 port [tcp/*] succeeded!\n"
  Apr 19 17:18:43.285: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 17:18:43.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-5211 exec execpod-affinitykzkv8 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.127:31256/ ; done'
  E0419 17:18:43.306031      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:18:43.796: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31256/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31256/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31256/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31256/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31256/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31256/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31256/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31256/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31256/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31256/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31256/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31256/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31256/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31256/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31256/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31256/\n"
  Apr 19 17:18:43.797: INFO: stdout: "\naffinity-nodeport-transition-mvhgt\naffinity-nodeport-transition-mvhgt\naffinity-nodeport-transition-mvhgt\naffinity-nodeport-transition-pljcb\naffinity-nodeport-transition-pljcb\naffinity-nodeport-transition-pljcb\naffinity-nodeport-transition-pljcb\naffinity-nodeport-transition-mvhgt\naffinity-nodeport-transition-mvhgt\naffinity-nodeport-transition-rg789\naffinity-nodeport-transition-pljcb\naffinity-nodeport-transition-pljcb\naffinity-nodeport-transition-mvhgt\naffinity-nodeport-transition-pljcb\naffinity-nodeport-transition-mvhgt\naffinity-nodeport-transition-pljcb"
  Apr 19 17:18:43.797: INFO: Received response from host: affinity-nodeport-transition-mvhgt
  Apr 19 17:18:43.797: INFO: Received response from host: affinity-nodeport-transition-mvhgt
  Apr 19 17:18:43.797: INFO: Received response from host: affinity-nodeport-transition-mvhgt
  Apr 19 17:18:43.797: INFO: Received response from host: affinity-nodeport-transition-pljcb
  Apr 19 17:18:43.797: INFO: Received response from host: affinity-nodeport-transition-pljcb
  Apr 19 17:18:43.797: INFO: Received response from host: affinity-nodeport-transition-pljcb
  Apr 19 17:18:43.797: INFO: Received response from host: affinity-nodeport-transition-pljcb
  Apr 19 17:18:43.797: INFO: Received response from host: affinity-nodeport-transition-mvhgt
  Apr 19 17:18:43.797: INFO: Received response from host: affinity-nodeport-transition-mvhgt
  Apr 19 17:18:43.797: INFO: Received response from host: affinity-nodeport-transition-rg789
  Apr 19 17:18:43.797: INFO: Received response from host: affinity-nodeport-transition-pljcb
  Apr 19 17:18:43.797: INFO: Received response from host: affinity-nodeport-transition-pljcb
  Apr 19 17:18:43.797: INFO: Received response from host: affinity-nodeport-transition-mvhgt
  Apr 19 17:18:43.797: INFO: Received response from host: affinity-nodeport-transition-pljcb
  Apr 19 17:18:43.797: INFO: Received response from host: affinity-nodeport-transition-mvhgt
  Apr 19 17:18:43.797: INFO: Received response from host: affinity-nodeport-transition-pljcb
  Apr 19 17:18:43.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-5211 exec execpod-affinitykzkv8 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.127:31256/ ; done'
  Apr 19 17:18:44.292: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31256/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31256/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31256/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31256/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31256/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31256/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31256/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31256/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31256/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31256/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31256/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31256/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31256/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31256/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31256/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31256/\n"
  Apr 19 17:18:44.292: INFO: stdout: "\naffinity-nodeport-transition-mvhgt\naffinity-nodeport-transition-mvhgt\naffinity-nodeport-transition-mvhgt\naffinity-nodeport-transition-mvhgt\naffinity-nodeport-transition-mvhgt\naffinity-nodeport-transition-mvhgt\naffinity-nodeport-transition-mvhgt\naffinity-nodeport-transition-mvhgt\naffinity-nodeport-transition-mvhgt\naffinity-nodeport-transition-mvhgt\naffinity-nodeport-transition-mvhgt\naffinity-nodeport-transition-mvhgt\naffinity-nodeport-transition-mvhgt\naffinity-nodeport-transition-mvhgt\naffinity-nodeport-transition-mvhgt\naffinity-nodeport-transition-mvhgt"
  Apr 19 17:18:44.292: INFO: Received response from host: affinity-nodeport-transition-mvhgt
  Apr 19 17:18:44.292: INFO: Received response from host: affinity-nodeport-transition-mvhgt
  Apr 19 17:18:44.292: INFO: Received response from host: affinity-nodeport-transition-mvhgt
  Apr 19 17:18:44.292: INFO: Received response from host: affinity-nodeport-transition-mvhgt
  Apr 19 17:18:44.292: INFO: Received response from host: affinity-nodeport-transition-mvhgt
  Apr 19 17:18:44.292: INFO: Received response from host: affinity-nodeport-transition-mvhgt
  Apr 19 17:18:44.292: INFO: Received response from host: affinity-nodeport-transition-mvhgt
  Apr 19 17:18:44.292: INFO: Received response from host: affinity-nodeport-transition-mvhgt
  Apr 19 17:18:44.292: INFO: Received response from host: affinity-nodeport-transition-mvhgt
  Apr 19 17:18:44.292: INFO: Received response from host: affinity-nodeport-transition-mvhgt
  Apr 19 17:18:44.292: INFO: Received response from host: affinity-nodeport-transition-mvhgt
  Apr 19 17:18:44.292: INFO: Received response from host: affinity-nodeport-transition-mvhgt
  Apr 19 17:18:44.292: INFO: Received response from host: affinity-nodeport-transition-mvhgt
  Apr 19 17:18:44.292: INFO: Received response from host: affinity-nodeport-transition-mvhgt
  Apr 19 17:18:44.292: INFO: Received response from host: affinity-nodeport-transition-mvhgt
  Apr 19 17:18:44.292: INFO: Received response from host: affinity-nodeport-transition-mvhgt
  Apr 19 17:18:44.292: INFO: Cleaning up the exec pod
  E0419 17:18:44.308556      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-5211, will wait for the garbage collector to delete the pods @ 04/19/24 17:18:44.316
  Apr 19 17:18:44.393: INFO: Deleting ReplicationController affinity-nodeport-transition took: 15.49266ms
  Apr 19 17:18:44.494: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 101.082276ms
  E0419 17:18:45.308164      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:46.308955      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:47.309973      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:18:47.467: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5211" for this suite. @ 04/19/24 17:18:47.485
• [11.625 seconds]
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:1031
  STEP: Creating a kubernetes client @ 04/19/24 17:18:47.503
  Apr 19 17:18:47.503: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename statefulset @ 04/19/24 17:18:47.505
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:18:47.555
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:18:47.561
  STEP: Creating service test in namespace statefulset-7957 @ 04/19/24 17:18:47.566
  STEP: Creating statefulset ss in namespace statefulset-7957 @ 04/19/24 17:18:47.588
  Apr 19 17:18:47.611: INFO: Found 0 stateful pods, waiting for 1
  E0419 17:18:48.310867      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:49.311773      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:50.312173      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:51.313152      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:52.313291      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:53.315464      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:54.313900      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:55.314163      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:56.315062      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:57.315804      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:18:57.640: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Patch Statefulset to include a label @ 04/19/24 17:18:57.653
  STEP: Getting /status @ 04/19/24 17:18:57.674
  Apr 19 17:18:57.684: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
  STEP: updating the StatefulSet Status @ 04/19/24 17:18:57.684
  Apr 19 17:18:57.700: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the statefulset status to be updated @ 04/19/24 17:18:57.7
  Apr 19 17:18:57.703: INFO: Observed &StatefulSet event: ADDED
  Apr 19 17:18:57.703: INFO: Found Statefulset ss in namespace statefulset-7957 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 19 17:18:57.703: INFO: Statefulset ss has an updated status
  STEP: patching the Statefulset Status @ 04/19/24 17:18:57.703
  Apr 19 17:18:57.703: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Apr 19 17:18:57.716: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Statefulset status to be patched @ 04/19/24 17:18:57.716
  Apr 19 17:18:57.720: INFO: Observed &StatefulSet event: ADDED
  Apr 19 17:18:57.720: INFO: Deleting all statefulset in ns statefulset-7957
  Apr 19 17:18:57.726: INFO: Scaling statefulset ss to 0
  E0419 17:18:58.318487      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:18:59.318444      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:00.318536      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:01.319571      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:02.324237      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:03.322225      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:04.324149      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:05.322955      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:06.323263      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:07.324148      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:19:07.753: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 19 17:19:07.762: INFO: Deleting statefulset ss
  Apr 19 17:19:07.802: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-7957" for this suite. @ 04/19/24 17:19:07.819
• [20.343 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:168
  STEP: Creating a kubernetes client @ 04/19/24 17:19:07.857
  Apr 19 17:19:07.857: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename field-validation @ 04/19/24 17:19:07.865
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:19:07.909
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:19:07.917
  Apr 19 17:19:07.926: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  E0419 17:19:08.325158      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:09.325398      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:10.326385      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0419 17:19:10.708975      13 warnings.go:70] unknown field "alpha"
  W0419 17:19:10.709052      13 warnings.go:70] unknown field "beta"
  W0419 17:19:10.709073      13 warnings.go:70] unknown field "delta"
  W0419 17:19:10.709090      13 warnings.go:70] unknown field "epsilon"
  W0419 17:19:10.709107      13 warnings.go:70] unknown field "gamma"
  Apr 19 17:19:11.312: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-754" for this suite. @ 04/19/24 17:19:11.321
  E0419 17:19:11.326712      13 retrywatcher.go:129] "Watch failed" err="context canceled"
• [3.481 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Secrets should patch a secret [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:155
  STEP: Creating a kubernetes client @ 04/19/24 17:19:11.339
  Apr 19 17:19:11.339: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename secrets @ 04/19/24 17:19:11.342
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:19:11.372
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:19:11.375
  STEP: creating a secret @ 04/19/24 17:19:11.38
  STEP: listing secrets in all namespaces to ensure that there are more than zero @ 04/19/24 17:19:11.386
  STEP: patching the secret @ 04/19/24 17:19:11.391
  STEP: deleting the secret using a LabelSelector @ 04/19/24 17:19:11.409
  STEP: listing secrets in all namespaces, searching for label name and value in patch @ 04/19/24 17:19:11.422
  Apr 19 17:19:11.427: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-885" for this suite. @ 04/19/24 17:19:11.434
• [0.106 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:380
  STEP: Creating a kubernetes client @ 04/19/24 17:19:11.445
  Apr 19 17:19:11.446: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename proxy @ 04/19/24 17:19:11.449
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:19:11.474
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:19:11.48
  Apr 19 17:19:11.485: INFO: Creating pod...
  E0419 17:19:12.327202      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:13.327848      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:19:13.524: INFO: Creating service...
  Apr 19 17:19:13.562: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7746/pods/agnhost/proxy?method=DELETE
  Apr 19 17:19:13.586: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Apr 19 17:19:13.587: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7746/pods/agnhost/proxy?method=OPTIONS
  Apr 19 17:19:13.637: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Apr 19 17:19:13.645: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7746/pods/agnhost/proxy?method=PATCH
  Apr 19 17:19:13.654: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Apr 19 17:19:13.654: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7746/pods/agnhost/proxy?method=POST
  Apr 19 17:19:13.662: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Apr 19 17:19:13.662: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7746/pods/agnhost/proxy?method=PUT
  Apr 19 17:19:13.668: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Apr 19 17:19:13.668: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7746/services/e2e-proxy-test-service/proxy?method=DELETE
  Apr 19 17:19:13.676: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Apr 19 17:19:13.677: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7746/services/e2e-proxy-test-service/proxy?method=OPTIONS
  Apr 19 17:19:13.686: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Apr 19 17:19:13.687: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7746/services/e2e-proxy-test-service/proxy?method=PATCH
  Apr 19 17:19:13.695: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Apr 19 17:19:13.695: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7746/services/e2e-proxy-test-service/proxy?method=POST
  Apr 19 17:19:13.703: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Apr 19 17:19:13.703: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7746/services/e2e-proxy-test-service/proxy?method=PUT
  Apr 19 17:19:13.713: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Apr 19 17:19:13.713: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7746/pods/agnhost/proxy?method=GET
  Apr 19 17:19:13.717: INFO: http.Client request:GET StatusCode:301
  Apr 19 17:19:13.717: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7746/services/e2e-proxy-test-service/proxy?method=GET
  Apr 19 17:19:13.726: INFO: http.Client request:GET StatusCode:301
  Apr 19 17:19:13.726: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7746/pods/agnhost/proxy?method=HEAD
  Apr 19 17:19:13.731: INFO: http.Client request:HEAD StatusCode:301
  Apr 19 17:19:13.732: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7746/services/e2e-proxy-test-service/proxy?method=HEAD
  Apr 19 17:19:13.737: INFO: http.Client request:HEAD StatusCode:301
  Apr 19 17:19:13.738: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-7746" for this suite. @ 04/19/24 17:19:13.745
• [2.312 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support proxy with --port 0 [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1838
  STEP: Creating a kubernetes client @ 04/19/24 17:19:13.76
  Apr 19 17:19:13.760: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename kubectl @ 04/19/24 17:19:13.765
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:19:13.792
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:19:13.797
  STEP: starting the proxy server @ 04/19/24 17:19:13.802
  Apr 19 17:19:13.802: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-5725 proxy -p 0 --disable-filter'
  STEP: curling proxy /api/ output @ 04/19/24 17:19:13.93
  Apr 19 17:19:13.950: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5725" for this suite. @ 04/19/24 17:19:13.959
• [0.212 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:250
  STEP: Creating a kubernetes client @ 04/19/24 17:19:13.972
  Apr 19 17:19:13.972: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename webhook @ 04/19/24 17:19:13.976
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:19:14.005
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:19:14.011
  STEP: Setting up server cert @ 04/19/24 17:19:14.099
  E0419 17:19:14.328068      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 17:19:14.82
  STEP: Deploying the webhook pod @ 04/19/24 17:19:14.838
  STEP: Wait for the deployment to be ready @ 04/19/24 17:19:14.865
  Apr 19 17:19:14.899: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0419 17:19:15.328560      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:16.329053      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 17:19:16.921
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 17:19:16.94
  E0419 17:19:17.330548      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:19:17.941: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating configmap webhook via the AdmissionRegistration API @ 04/19/24 17:19:17.959
  STEP: create a configmap that should be updated by the webhook @ 04/19/24 17:19:17.991
  Apr 19 17:19:18.145: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1385" for this suite. @ 04/19/24 17:19:18.155
  STEP: Destroying namespace "webhook-markers-8716" for this suite. @ 04/19/24 17:19:18.17
• [4.211 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/ephemeral_containers.go:98
  STEP: Creating a kubernetes client @ 04/19/24 17:19:18.185
  Apr 19 17:19:18.186: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 04/19/24 17:19:18.189
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:19:18.223
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:19:18.228
  STEP: creating a target pod @ 04/19/24 17:19:18.235
  E0419 17:19:18.330796      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:19.331245      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 04/19/24 17:19:20.286
  E0419 17:19:20.331867      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:21.332079      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:22.332982      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:23.333134      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:24.333386      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 04/19/24 17:19:24.361
  Apr 19 17:19:24.362: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-671 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 17:19:24.362: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 17:19:24.364: INFO: ExecWithOptions: Clientset creation
  Apr 19 17:19:24.365: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/ephemeral-containers-test-671/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  Apr 19 17:19:24.518: INFO: Exec stderr: ""
  STEP: checking pod "ephemeral-containers-target-pod" has only one ephemeralcontainer @ 04/19/24 17:19:24.556
  STEP: adding another ephemeralcontainer to pod "ephemeral-containers-target-pod" @ 04/19/24 17:19:24.568
  STEP: checking pod "ephemeral-containers-target-pod" has only two ephemeralcontainers @ 04/19/24 17:19:24.589
  Apr 19 17:19:24.608: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-671" for this suite. @ 04/19/24 17:19:24.619
• [6.450 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:948
  STEP: Creating a kubernetes client @ 04/19/24 17:19:24.637
  Apr 19 17:19:24.637: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename resourcequota @ 04/19/24 17:19:24.64
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:19:24.674
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:19:24.682
  STEP: Creating a ResourceQuota @ 04/19/24 17:19:24.688
  STEP: Getting a ResourceQuota @ 04/19/24 17:19:24.699
  STEP: Listing all ResourceQuotas with LabelSelector @ 04/19/24 17:19:24.713
  STEP: Patching the ResourceQuota @ 04/19/24 17:19:24.72
  STEP: Deleting a Collection of ResourceQuotas @ 04/19/24 17:19:24.729
  STEP: Verifying the deleted ResourceQuota @ 04/19/24 17:19:24.747
  Apr 19 17:19:24.754: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3281" for this suite. @ 04/19/24 17:19:24.767
• [0.143 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should delete a collection of pod templates [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:123
  STEP: Creating a kubernetes client @ 04/19/24 17:19:24.781
  Apr 19 17:19:24.781: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename podtemplate @ 04/19/24 17:19:24.785
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:19:24.816
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:19:24.822
  STEP: Create set of pod templates @ 04/19/24 17:19:24.828
  Apr 19 17:19:24.839: INFO: created test-podtemplate-1
  Apr 19 17:19:24.852: INFO: created test-podtemplate-2
  Apr 19 17:19:24.862: INFO: created test-podtemplate-3
  STEP: get a list of pod templates with a label in the current namespace @ 04/19/24 17:19:24.862
  STEP: delete collection of pod templates @ 04/19/24 17:19:24.87
  Apr 19 17:19:24.870: INFO: requesting DeleteCollection of pod templates
  STEP: check that the list of pod templates matches the requested quantity @ 04/19/24 17:19:24.911
  Apr 19 17:19:24.911: INFO: requesting list of pod templates to confirm quantity
  Apr 19 17:19:24.920: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-6456" for this suite. @ 04/19/24 17:19:24.933
• [0.166 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should complete a service status lifecycle [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3338
  STEP: Creating a kubernetes client @ 04/19/24 17:19:24.953
  Apr 19 17:19:24.953: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename services @ 04/19/24 17:19:24.956
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:19:24.984
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:19:24.99
  STEP: creating a Service @ 04/19/24 17:19:25.013
  STEP: watching for the Service to be added @ 04/19/24 17:19:25.067
  Apr 19 17:19:25.069: INFO: Found Service test-service-cvkm2 in namespace services-1882 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 30473}]
  Apr 19 17:19:25.070: INFO: Service test-service-cvkm2 created
  STEP: Getting /status @ 04/19/24 17:19:25.07
  Apr 19 17:19:25.087: INFO: Service test-service-cvkm2 has LoadBalancer: {[]}
  STEP: patching the ServiceStatus @ 04/19/24 17:19:25.087
  STEP: watching for the Service to be patched @ 04/19/24 17:19:25.101
  Apr 19 17:19:25.105: INFO: observed Service test-service-cvkm2 in namespace services-1882 with annotations: map[] & LoadBalancer: {[]}
  Apr 19 17:19:25.105: INFO: Found Service test-service-cvkm2 in namespace services-1882 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  <nil> []}]}
  Apr 19 17:19:25.106: INFO: Service test-service-cvkm2 has service status patched
  STEP: updating the ServiceStatus @ 04/19/24 17:19:25.107
  Apr 19 17:19:25.125: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Service to be updated @ 04/19/24 17:19:25.126
  Apr 19 17:19:25.129: INFO: Observed Service test-service-cvkm2 in namespace services-1882 with annotations: map[] & Conditions: {[]}
  Apr 19 17:19:25.130: INFO: Observed event: &Service{ObjectMeta:{test-service-cvkm2  services-1882  2ce12a7c-427a-4232-8896-09f52089b1b5 34082 0 2024-04-19 17:19:25 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2024-04-19 17:19:25 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:allocateLoadBalancerNodePorts":{},"f:externalTrafficPolicy":{},"f:internalTrafficPolicy":{},"f:loadBalancerClass":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2024-04-19 17:19:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:30473,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.233.13.178,Type:LoadBalancer,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:Cluster,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.233.13.178],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:*true,LoadBalancerClass:*example.com/internal-vip,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,IPMode:nil,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
  Apr 19 17:19:25.130: INFO: Found Service test-service-cvkm2 in namespace services-1882 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Apr 19 17:19:25.131: INFO: Service test-service-cvkm2 has service status updated
  STEP: patching the service @ 04/19/24 17:19:25.131
  STEP: watching for the Service to be patched @ 04/19/24 17:19:25.16
  Apr 19 17:19:25.162: INFO: observed Service test-service-cvkm2 in namespace services-1882 with labels: map[test-service-static:true]
  Apr 19 17:19:25.162: INFO: observed Service test-service-cvkm2 in namespace services-1882 with labels: map[test-service-static:true]
  Apr 19 17:19:25.163: INFO: observed Service test-service-cvkm2 in namespace services-1882 with labels: map[test-service-static:true]
  Apr 19 17:19:25.163: INFO: Found Service test-service-cvkm2 in namespace services-1882 with labels: map[test-service:patched test-service-static:true]
  Apr 19 17:19:25.163: INFO: Service test-service-cvkm2 patched
  STEP: deleting the service @ 04/19/24 17:19:25.163
  STEP: watching for the Service to be deleted @ 04/19/24 17:19:25.187
  Apr 19 17:19:25.190: INFO: Observed event: ADDED
  Apr 19 17:19:25.190: INFO: Observed event: MODIFIED
  Apr 19 17:19:25.191: INFO: Observed event: MODIFIED
  Apr 19 17:19:25.191: INFO: Observed event: MODIFIED
  Apr 19 17:19:25.192: INFO: Found Service test-service-cvkm2 in namespace services-1882 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
  Apr 19 17:19:25.192: INFO: Service test-service-cvkm2 deleted
  Apr 19 17:19:25.193: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1882" for this suite. @ 04/19/24 17:19:25.201
• [0.261 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:70
  STEP: Creating a kubernetes client @ 04/19/24 17:19:25.214
  Apr 19 17:19:25.214: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename cronjob @ 04/19/24 17:19:25.217
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:19:25.246
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:19:25.251
  STEP: Creating a cronjob @ 04/19/24 17:19:25.259
  STEP: Ensuring more than one job is running at a time @ 04/19/24 17:19:25.287
  E0419 17:19:25.334641      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:26.335536      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:27.336771      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:28.337085      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:29.338368      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:30.338671      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:31.339366      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:32.339667      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:33.340362      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:34.340386      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:35.340566      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:36.341118      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:37.341149      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:38.341998      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:39.342582      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:40.342996      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:41.343725      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:42.344001      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:43.344797      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:44.345149      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:45.345357      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:46.346103      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:47.347213      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:48.347423      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:49.347519      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:50.348365      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:51.349285      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:52.349638      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:53.350402      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:54.350720      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:55.351770      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:56.352738      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:57.353138      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:58.354660      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:19:59.355293      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:00.356172      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:01.356928      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:02.357921      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:03.358888      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:04.360004      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:05.360443      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:06.360896      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:07.361262      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:08.362077      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:09.362806      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:10.363215      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:11.363552      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:12.364637      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:13.364955      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:14.365528      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:15.365609      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:16.366039      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:17.366032      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:18.366426      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:19.366752      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:20.367692      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:21.368282      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:22.369231      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:23.370185      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:24.370590      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:25.370876      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:26.371206      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:27.371803      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:28.373013      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:29.373490      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:30.373916      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:31.374785      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:32.375807      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:33.375738      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:34.376181      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:35.376720      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:36.377150      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:37.377652      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:38.377934      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:39.378681      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:40.379035      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:41.379155      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:42.379403      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:43.379626      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:44.380027      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:45.380801      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:46.382049      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:47.382804      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:48.383971      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:49.384233      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:50.384900      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:51.386483      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:52.386113      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:53.386689      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:54.387913      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:55.388898      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:56.389591      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:57.389972      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:58.391254      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:20:59.391417      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:00.391690      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring at least two running jobs exists by listing jobs explicitly @ 04/19/24 17:21:01.297
  STEP: Removing cronjob @ 04/19/24 17:21:01.311
  Apr 19 17:21:01.363: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-4181" for this suite. @ 04/19/24 17:21:01.376
  E0419 17:21:01.393111      13 retrywatcher.go:129] "Watch failed" err="context canceled"
• [96.186 seconds]
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:199
  STEP: Creating a kubernetes client @ 04/19/24 17:21:01.4
  Apr 19 17:21:01.400: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/19/24 17:21:01.405
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:21:01.45
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:21:01.455
  STEP: fetching the /apis discovery document @ 04/19/24 17:21:01.46
  STEP: finding the apiextensions.k8s.io API group in the /apis discovery document @ 04/19/24 17:21:01.462
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document @ 04/19/24 17:21:01.462
  STEP: fetching the /apis/apiextensions.k8s.io discovery document @ 04/19/24 17:21:01.462
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document @ 04/19/24 17:21:01.465
  STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document @ 04/19/24 17:21:01.465
  STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document @ 04/19/24 17:21:01.471
  Apr 19 17:21:01.471: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-3297" for this suite. @ 04/19/24 17:21:01.479
• [0.089 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:92
  STEP: Creating a kubernetes client @ 04/19/24 17:21:01.49
  Apr 19 17:21:01.490: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename downward-api @ 04/19/24 17:21:01.494
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:21:01.519
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:21:01.527
  STEP: Creating a pod to test downward api env vars @ 04/19/24 17:21:01.531
  E0419 17:21:02.393565      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:03.394056      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:04.394452      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:05.395249      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:21:05.578
  Apr 19 17:21:05.587: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod downward-api-10d5fa21-f47d-48fa-837d-8c87075389ea container dapi-container: <nil>
  STEP: delete the pod @ 04/19/24 17:21:05.636
  Apr 19 17:21:05.688: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4284" for this suite. @ 04/19/24 17:21:05.697
• [4.217 seconds]
------------------------------
S
------------------------------
[sig-network] Services should find a service from listing all namespaces [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3129
  STEP: Creating a kubernetes client @ 04/19/24 17:21:05.708
  Apr 19 17:21:05.708: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename services @ 04/19/24 17:21:05.713
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:21:05.741
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:21:05.749
  STEP: fetching services @ 04/19/24 17:21:05.756
  Apr 19 17:21:05.764: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6925" for this suite. @ 04/19/24 17:21:05.772
• [0.081 seconds]
------------------------------
SSSS
------------------------------
[sig-auth] SubjectReview should support SubjectReview API operations [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/subjectreviews.go:50
  STEP: Creating a kubernetes client @ 04/19/24 17:21:05.791
  Apr 19 17:21:05.792: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename subjectreview @ 04/19/24 17:21:05.795
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:21:05.821
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:21:05.825
  STEP: Creating a Serviceaccount "e2e" in namespace "subjectreview-1356" @ 04/19/24 17:21:05.831
  Apr 19 17:21:05.839: INFO: saUsername: "system:serviceaccount:subjectreview-1356:e2e"
  Apr 19 17:21:05.840: INFO: saGroups: []string{"system:authenticated", "system:serviceaccounts", "system:serviceaccounts:subjectreview-1356"}
  Apr 19 17:21:05.840: INFO: saUID: "20fc13d2-7183-45aa-bbb2-77854c1d3bfe"
  STEP: Creating clientset to impersonate "system:serviceaccount:subjectreview-1356:e2e" @ 04/19/24 17:21:05.84
  STEP: Creating SubjectAccessReview for "system:serviceaccount:subjectreview-1356:e2e" @ 04/19/24 17:21:05.84
  Apr 19 17:21:05.844: INFO: sarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  STEP: Verifying as "system:serviceaccount:subjectreview-1356:e2e" api 'list' configmaps in "subjectreview-1356" namespace @ 04/19/24 17:21:05.844
  Apr 19 17:21:05.847: INFO: SubjectAccessReview has been verified
  STEP: Creating a LocalSubjectAccessReview for "system:serviceaccount:subjectreview-1356:e2e" @ 04/19/24 17:21:05.847
  Apr 19 17:21:05.851: INFO: lsarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  Apr 19 17:21:05.851: INFO: LocalSubjectAccessReview has been verified
  Apr 19 17:21:05.851: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subjectreview-1356" for this suite. @ 04/19/24 17:21:05.86
• [0.083 seconds]
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:169
  STEP: Creating a kubernetes client @ 04/19/24 17:21:05.875
  Apr 19 17:21:05.875: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 04/19/24 17:21:05.878
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:21:05.905
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:21:05.909
  STEP: create the container to handle the HTTPGet hook request. @ 04/19/24 17:21:05.924
  E0419 17:21:06.396254      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:07.396266      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 04/19/24 17:21:07.969
  E0419 17:21:08.397243      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:09.397276      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 04/19/24 17:21:10.021
  STEP: delete the pod with lifecycle hook @ 04/19/24 17:21:10.055
  E0419 17:21:10.398481      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:11.399011      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:21:12.094: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-6932" for this suite. @ 04/19/24 17:21:12.107
• [6.253 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:391
  STEP: Creating a kubernetes client @ 04/19/24 17:21:12.134
  Apr 19 17:21:12.136: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/19/24 17:21:12.144
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:21:12.187
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:21:12.194
  STEP: set up a multi version CRD @ 04/19/24 17:21:12.203
  Apr 19 17:21:12.204: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  E0419 17:21:12.400002      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:13.401021      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:14.402472      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:15.403088      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:16.404103      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: rename a version @ 04/19/24 17:21:16.872
  STEP: check the new version name is served @ 04/19/24 17:21:16.917
  E0419 17:21:17.404911      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the old version name is removed @ 04/19/24 17:21:18.301
  E0419 17:21:18.405651      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the other version is not changed @ 04/19/24 17:21:19.255
  E0419 17:21:19.406178      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:20.406189      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:21.407254      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:22.408231      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:21:22.981: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-9169" for this suite. @ 04/19/24 17:21:23.009
• [10.892 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined should project all components that make up the projection API [Projection] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_combined.go:44
  STEP: Creating a kubernetes client @ 04/19/24 17:21:23.027
  Apr 19 17:21:23.027: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename projected @ 04/19/24 17:21:23.034
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:21:23.089
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:21:23.096
  STEP: Creating configMap with name configmap-projected-all-test-volume-78733cd6-60f1-4500-bc97-0ce05fb0428e @ 04/19/24 17:21:23.11
  STEP: Creating secret with name secret-projected-all-test-volume-18fa8370-f3f9-4190-bba4-5183e632cbcb @ 04/19/24 17:21:23.125
  STEP: Creating a pod to test Check all projections for projected volume plugin @ 04/19/24 17:21:23.143
  E0419 17:21:23.409482      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:24.410262      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:25.410551      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:26.412370      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:21:27.212
  Apr 19 17:21:27.220: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod projected-volume-2d468b9c-caeb-4de0-bae7-c359650a2c66 container projected-all-volume-test: <nil>
  STEP: delete the pod @ 04/19/24 17:21:27.242
  Apr 19 17:21:27.283: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5418" for this suite. @ 04/19/24 17:21:27.304
• [4.295 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:200
  STEP: Creating a kubernetes client @ 04/19/24 17:21:27.323
  Apr 19 17:21:27.323: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename emptydir @ 04/19/24 17:21:27.326
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:21:27.358
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:21:27.365
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 04/19/24 17:21:27.372
  E0419 17:21:27.412762      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:28.413535      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:29.414210      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:30.414207      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:31.415593      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:21:31.422
  Apr 19 17:21:31.432: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-acd77d81-2388-4a6b-98d8-e5242dc6e72a container test-container: <nil>
  STEP: delete the pod @ 04/19/24 17:21:31.452
  Apr 19 17:21:31.509: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2930" for this suite. @ 04/19/24 17:21:31.518
• [4.214 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/events.go:207
  STEP: Creating a kubernetes client @ 04/19/24 17:21:31.54
  Apr 19 17:21:31.540: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename events @ 04/19/24 17:21:31.543
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:21:31.576
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:21:31.581
  STEP: Create set of events @ 04/19/24 17:21:31.587
  STEP: get a list of Events with a label in the current namespace @ 04/19/24 17:21:31.617
  STEP: delete a list of events @ 04/19/24 17:21:31.623
  Apr 19 17:21:31.623: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 04/19/24 17:21:31.7
  Apr 19 17:21:31.710: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-8185" for this suite. @ 04/19/24 17:21:31.721
• [0.196 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:270
  STEP: Creating a kubernetes client @ 04/19/24 17:21:31.741
  Apr 19 17:21:31.741: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/19/24 17:21:31.744
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:21:31.778
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:21:31.782
  Apr 19 17:21:31.805: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  E0419 17:21:32.415682      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:33.415874      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:34.416093      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:21:35.380: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-2815" for this suite. @ 04/19/24 17:21:35.394
• [3.670 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS  E0419 17:21:35.416518      13 retrywatcher.go:129] "Watch failed" err="context canceled"
S
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:305
  STEP: Creating a kubernetes client @ 04/19/24 17:21:35.418
  Apr 19 17:21:35.418: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename namespaces @ 04/19/24 17:21:35.423
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:21:35.466
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:21:35.472
  STEP: Read namespace status @ 04/19/24 17:21:35.487
  Apr 19 17:21:35.499: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
  STEP: Patch namespace status @ 04/19/24 17:21:35.499
  Apr 19 17:21:35.515: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
  STEP: Update namespace status @ 04/19/24 17:21:35.515
  Apr 19 17:21:35.541: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
  Apr 19 17:21:35.541: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-3250" for this suite. @ 04/19/24 17:21:35.557
• [0.155 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:198
  STEP: Creating a kubernetes client @ 04/19/24 17:21:35.573
  Apr 19 17:21:35.573: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename container-probe @ 04/19/24 17:21:35.577
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:21:35.609
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:21:35.614
  STEP: Creating pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558 @ 04/19/24 17:21:35.62
  E0419 17:21:36.417193      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:37.418008      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/19/24 17:21:37.657
  Apr 19 17:21:37.668: INFO: Initial restart count of pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da is 0
  Apr 19 17:21:37.679: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:21:38.419025      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:39.420222      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:21:39.688: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:21:40.420966      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:41.421340      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:21:41.698: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:21:42.421774      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:43.422144      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:21:43.713: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:21:44.422548      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:45.423731      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:21:45.728: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:21:46.424174      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:47.424396      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:21:47.740: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:21:48.425078      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:49.425469      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:21:49.755: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:21:50.426567      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:51.427599      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:21:51.767: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:21:52.428109      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:53.428321      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:21:53.779: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:21:54.428872      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:55.428986      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:21:55.792: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:21:56.429224      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:57.430091      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:21:57.803: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  Apr 19 17:21:57.804: INFO: Restart count of pod container-probe-7558/liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da is now 1 (20.135218738s elapsed)
  E0419 17:21:58.430348      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:21:59.430780      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:21:59.814: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:22:00.430865      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:01.431884      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:22:01.825: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:22:02.432915      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:03.433970      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:22:03.838: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:22:04.435026      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:05.435559      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:22:05.847: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:22:06.435558      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:07.436045      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:22:07.858: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:22:08.436327      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:09.436676      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:22:09.869: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:22:10.436817      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:11.436998      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:22:11.881: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:22:12.437411      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:13.438455      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:22:13.897: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:22:14.438700      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:15.439849      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:22:15.908: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:22:16.440295      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:17.440733      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:22:17.927: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  Apr 19 17:22:17.928: INFO: Restart count of pod container-probe-7558/liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da is now 2 (40.25985495s elapsed)
  E0419 17:22:18.440843      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:19.441964      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:22:19.940: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:22:20.443061      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:21.444013      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:22:21.952: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:22:22.444252      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:23.445326      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:22:23.967: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:22:24.445679      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:25.445868      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:22:25.980: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:22:26.446383      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:27.447236      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:22:27.992: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:22:28.447520      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:29.447588      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:22:30.004: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:22:30.448058      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:31.448190      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:22:32.015: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:22:32.448534      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:33.449738      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:22:34.028: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:22:34.449784      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:35.450006      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:22:36.036: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:22:36.451080      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:37.451137      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:22:38.044: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  Apr 19 17:22:38.046: INFO: Restart count of pod container-probe-7558/liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da is now 3 (1m0.377247242s elapsed)
  E0419 17:22:38.451563      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:39.451945      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:22:40.059: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:22:40.452904      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:41.452883      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:22:42.072: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:22:42.453188      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:43.453384      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:22:44.081: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:22:44.454563      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:45.454599      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:22:46.091: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:22:46.455807      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:47.456753      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:22:48.100: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:22:48.457797      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:49.458608      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:22:50.110: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:22:50.458998      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:51.459689      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:22:52.125: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:22:52.459409      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:53.459783      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:22:54.137: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:22:54.460034      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:55.460287      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:22:56.159: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:22:56.462099      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:57.462166      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:22:58.174: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  Apr 19 17:22:58.174: INFO: Restart count of pod container-probe-7558/liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da is now 4 (1m20.505943034s elapsed)
  E0419 17:22:58.465309      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:22:59.462844      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:23:00.187: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:23:00.464051      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:01.464810      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:23:02.199: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:23:02.465172      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:03.465956      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:23:04.210: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:23:04.466539      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:05.466770      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:23:06.222: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:23:06.467671      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:07.467968      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:23:08.234: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:23:08.468803      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:09.469852      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:23:10.252: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:23:10.470573      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:11.471433      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:23:12.264: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:23:12.471923      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:13.472998      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:23:14.275: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:23:14.474024      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:15.474216      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:23:16.291: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:23:16.475498      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:17.475842      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:23:18.304: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:23:18.476135      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:19.476529      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:23:20.316: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:23:20.478031      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:21.479022      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:23:22.328: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:23:22.479248      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:23.479613      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:23:24.339: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:23:24.479823      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:25.480133      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:23:26.354: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:23:26.481475      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:27.482035      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:23:28.366: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:23:28.482199      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:29.482613      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:23:30.379: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:23:30.484069      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:31.484935      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:23:32.391: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:23:32.485162      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:33.487557      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:23:34.405: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:23:34.487050      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:35.486823      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:23:36.418: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:23:36.486922      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:37.487741      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:23:38.432: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:23:38.488196      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:39.488914      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:23:40.442: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:23:40.490388      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:41.491127      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:23:42.453: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:23:42.492212      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:43.493147      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:23:44.465: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:23:44.494114      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:45.493949      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:23:46.479: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:23:46.496289      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:47.497740      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:23:48.487: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:23:48.498130      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:49.502634      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:23:50.499: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:23:50.501648      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:51.504163      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:52.502728      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:23:52.511: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:23:53.503396      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:54.503842      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:23:54.527: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:23:55.514417      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:56.508544      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:23:56.539: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:23:57.513139      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:23:58.510578      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:23:58.551: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:23:59.511031      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:00.521579      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:24:00.572: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:24:01.518402      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:02.518736      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:24:02.590: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:24:03.518885      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:04.520293      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:24:04.599: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:24:05.520845      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:06.523850      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:24:06.609: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:24:07.524125      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:08.524455      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:24:08.628: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  E0419 17:24:09.525124      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:10.526100      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:24:10.645: INFO: Get pod liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da in namespace container-probe-7558
  Apr 19 17:24:10.646: INFO: Restart count of pod container-probe-7558/liveness-c6ffaa8d-6e20-4e3a-8a0e-c6bb136d80da is now 5 (2m32.977170181s elapsed)
  STEP: deleting the pod @ 04/19/24 17:24:10.647
  Apr 19 17:24:10.686: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-7558" for this suite. @ 04/19/24 17:24:10.701
• [155.158 seconds]
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl label should update the label on a resource [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1632
  STEP: Creating a kubernetes client @ 04/19/24 17:24:10.732
  Apr 19 17:24:10.732: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename kubectl @ 04/19/24 17:24:10.746
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:24:10.775
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:24:10.779
  STEP: creating the pod @ 04/19/24 17:24:10.785
  Apr 19 17:24:10.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-762 create -f -'
  Apr 19 17:24:11.149: INFO: stderr: ""
  Apr 19 17:24:11.149: INFO: stdout: "pod/pause created\n"
  E0419 17:24:11.527222      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:12.527382      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding the label testing-label with value testing-label-value to a pod @ 04/19/24 17:24:13.175
  Apr 19 17:24:13.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-762 label pods pause testing-label=testing-label-value'
  Apr 19 17:24:13.380: INFO: stderr: ""
  Apr 19 17:24:13.380: INFO: stdout: "pod/pause labeled\n"
  STEP: verifying the pod has the label testing-label with the value testing-label-value @ 04/19/24 17:24:13.38
  Apr 19 17:24:13.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-762 get pod pause -L testing-label'
  E0419 17:24:13.528012      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:24:13.554: INFO: stderr: ""
  Apr 19 17:24:13.554: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
  STEP: removing the label testing-label of a pod @ 04/19/24 17:24:13.554
  Apr 19 17:24:13.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-762 label pods pause testing-label-'
  Apr 19 17:24:13.751: INFO: stderr: ""
  Apr 19 17:24:13.751: INFO: stdout: "pod/pause unlabeled\n"
  STEP: verifying the pod doesn't have the label testing-label @ 04/19/24 17:24:13.751
  Apr 19 17:24:13.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-762 get pod pause -L testing-label'
  Apr 19 17:24:13.924: INFO: stderr: ""
  Apr 19 17:24:13.924: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
  STEP: using delete to clean up resources @ 04/19/24 17:24:13.924
  Apr 19 17:24:13.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-762 delete --grace-period=0 --force -f -'
  Apr 19 17:24:14.110: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 19 17:24:14.110: INFO: stdout: "pod \"pause\" force deleted\n"
  Apr 19 17:24:14.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-762 get rc,svc -l name=pause --no-headers'
  Apr 19 17:24:14.300: INFO: stderr: "No resources found in kubectl-762 namespace.\n"
  Apr 19 17:24:14.300: INFO: stdout: ""
  Apr 19 17:24:14.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-762 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Apr 19 17:24:14.480: INFO: stderr: ""
  Apr 19 17:24:14.480: INFO: stdout: ""
  Apr 19 17:24:14.480: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-762" for this suite. @ 04/19/24 17:24:14.507
  E0419 17:24:14.538611      13 retrywatcher.go:129] "Watch failed" err="context canceled"
• [3.815 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:153
  STEP: Creating a kubernetes client @ 04/19/24 17:24:14.547
  Apr 19 17:24:14.547: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/19/24 17:24:14.549
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:24:14.587
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:24:14.592
  Apr 19 17:24:14.598: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  E0419 17:24:15.538967      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 04/19/24 17:24:16.442
  Apr 19 17:24:16.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=crd-publish-openapi-8450 --namespace=crd-publish-openapi-8450 create -f -'
  E0419 17:24:16.539746      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:24:16.951: INFO: stderr: ""
  Apr 19 17:24:16.951: INFO: stdout: "e2e-test-crd-publish-openapi-840-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  Apr 19 17:24:16.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=crd-publish-openapi-8450 --namespace=crd-publish-openapi-8450 delete e2e-test-crd-publish-openapi-840-crds test-cr'
  Apr 19 17:24:17.174: INFO: stderr: ""
  Apr 19 17:24:17.174: INFO: stdout: "e2e-test-crd-publish-openapi-840-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  Apr 19 17:24:17.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=crd-publish-openapi-8450 --namespace=crd-publish-openapi-8450 apply -f -'
  Apr 19 17:24:17.358: INFO: stderr: ""
  Apr 19 17:24:17.359: INFO: stdout: "e2e-test-crd-publish-openapi-840-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  Apr 19 17:24:17.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=crd-publish-openapi-8450 --namespace=crd-publish-openapi-8450 delete e2e-test-crd-publish-openapi-840-crds test-cr'
  Apr 19 17:24:17.537: INFO: stderr: ""
  Apr 19 17:24:17.537: INFO: stdout: "e2e-test-crd-publish-openapi-840-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR without validation schema @ 04/19/24 17:24:17.537
  Apr 19 17:24:17.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=crd-publish-openapi-8450 explain e2e-test-crd-publish-openapi-840-crds'
  E0419 17:24:17.540327      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:24:17.714: INFO: stderr: ""
  Apr 19 17:24:17.714: INFO: stdout: "GROUP:      crd-publish-openapi-test-empty.example.com\nKIND:       e2e-test-crd-publish-openapi-840-crd\nVERSION:    v1\n\nDESCRIPTION:\n    <empty>\nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n\n"
  E0419 17:24:18.541133      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:24:19.499: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-8450" for this suite. @ 04/19/24 17:24:19.517
• [4.981 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:55
  STEP: Creating a kubernetes client @ 04/19/24 17:24:19.538
  Apr 19 17:24:19.539: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  E0419 17:24:19.541578      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Building a namespace api object, basename downward-api @ 04/19/24 17:24:19.545
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:24:19.579
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:24:19.589
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 17:24:19.606
  E0419 17:24:20.542516      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:21.543002      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:22.542736      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:23.543912      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:24:23.677
  Apr 19 17:24:23.685: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod downwardapi-volume-aa4c482a-f2f9-42ce-910a-90ebd87c7200 container client-container: <nil>
  STEP: delete the pod @ 04/19/24 17:24:23.736
  Apr 19 17:24:23.775: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9412" for this suite. @ 04/19/24 17:24:23.787
• [4.263 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:113
  STEP: Creating a kubernetes client @ 04/19/24 17:24:23.803
  Apr 19 17:24:23.803: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename deployment @ 04/19/24 17:24:23.807
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:24:23.845
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:24:23.852
  Apr 19 17:24:23.860: INFO: Creating deployment "test-recreate-deployment"
  Apr 19 17:24:23.871: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
  Apr 19 17:24:23.894: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
  E0419 17:24:24.544172      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:25.547350      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:24:25.915: INFO: Waiting deployment "test-recreate-deployment" to complete
  Apr 19 17:24:25.933: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
  Apr 19 17:24:25.961: INFO: Updating deployment test-recreate-deployment
  Apr 19 17:24:25.963: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
  Apr 19 17:24:26.143: INFO: Deployment "test-recreate-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-recreate-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9742",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "186cdc8d-a24c-433a-a509-664e63f27cdc",
      ResourceVersion: (string) (len=5) "35063",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849144263,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849144265,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=570) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |":{"f:type":{}},|
              000000b0  22 66 3a 74 65 6d 70 6c  61 74 65 22 3a 7b 22 66  |"f:template":{"f|
              000000c0  3a 6d 65 74 61 64 61 74  61 22 3a 7b 22 66 3a 6c  |:metadata":{"f:l|
              000000d0  61 62 65 6c 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |abels":{".":{},"|
              000000e0  66 3a 6e 61 6d 65 22 3a  7b 7d 7d 7d 2c 22 66 3a  |f:name":{}}},"f:|
              000000f0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              00000100  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              00000110  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              00000120  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000130  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000140  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000150  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000160  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000170  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000180  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000190  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              000001a0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000001b0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000001c0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000001d0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000001e0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000001f0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              00000200  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000210  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000220  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000230  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849144266,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=495) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 63 6f 6e 64 69 74 69  6f 6e 73 22 3a 7b 22 2e  |:conditions":{".|
              00000070  22 3a 7b 7d 2c 22 6b 3a  7b 5c 22 74 79 70 65 5c  |":{},"k:{\"type\|
              00000080  22 3a 5c 22 41 76 61 69  6c 61 62 6c 65 5c 22 7d  |":\"Available\"}|
              00000090  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              000000a0  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              000000b0  3a 7b 7d 2c 22 66 3a 6c  61 73 74 55 70 64 61 74  |:{},"f:lastUpdat|
              000000c0  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6d 65 73  |eTime":{},"f:mes|
              000000d0  73 61 67 65 22 3a 7b 7d  2c 22 66 3a 72 65 61 73  |sage":{},"f:reas|
              000000e0  6f 6e 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |on":{},"f:status|
              000000f0  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000100  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000110  22 50 72 6f 67 72 65 73  73 69 6e 67 5c 22 7d 22  |"Progressing\"}"|
              00000120  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000130  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000140  7b 7d 2c 22 66 3a 6c 61  73 74 55 70 64 61 74 65  |{},"f:lastUpdate|
              00000150  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000160  61 67 65 22 3a 7b 7d 2c  22 66 3a 72 65 61 73 6f  |age":{},"f:reaso|
              00000170  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000180  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000190  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              000001a0  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              000001b0  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 75  |eplicas":{},"f:u|
              000001c0  6e 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |navailableReplic|
              000001d0  61 73 22 3a 7b 7d 2c 22  66 3a 75 70 64 61 74 65  |as":{},"f:update|
              000001e0  64 52 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 7d     |dReplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=8) "Recreate",
        RollingUpdate: (*v1.RollingUpdateDeployment)(<nil>)
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 1,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849144266,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849144266,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849144266,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849144263,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=63) "ReplicaSet \"test-recreate-deployment-76fb77d45\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Apr 19 17:24:26.152: INFO: New ReplicaSet "test-recreate-deployment-76fb77d45" of Deployment "test-recreate-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-recreate-deployment-76fb77d45",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9742",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "cf0e257f-019f-4cef-a53c-f34a42a86ba8",
      ResourceVersion: (string) (len=5) "35061",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849144266,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "186cdc8d-a24c-433a-a509-664e63f27cdc",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849144266,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 31 38 36 63 64 63  38 64 2d 61 32 34 63 2d  |\"186cdc8d-a24c-|
              00000120  34 33 33 61 2d 61 35 30  39 2d 36 36 34 65 36 33  |433a-a509-664e63|
              00000130  66 32 37 63 64 63 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |f27cdc\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849144266,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45",
          (string) (len=4) "name": (string) (len=12) "sample-pod-3"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 19 17:24:26.180: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
  Apr 19 17:24:26.182: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-recreate-deployment-5cf87b5b86",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9742",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "abf97230-dc8f-4582-aae3-1fe8a39f46b5",
      ResourceVersion: (string) (len=5) "35051",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849144263,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "5cf87b5b86",
        (string) (len=4) "name": (string) (len=12) "sample-pod-3"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "186cdc8d-a24c-433a-a509-664e63f27cdc",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849144265,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 31 38 36 63 64 63  38 64 2d 61 32 34 63 2d  |\"186cdc8d-a24c-|
              00000120  34 33 33 61 2d 61 35 30  39 2d 36 36 34 65 36 33  |433a-a509-664e63|
              00000130  66 32 37 63 64 63 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |f27cdc\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849144266,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=10) "5cf87b5b86"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=10) "5cf87b5b86"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 19 17:24:26.202: INFO: Pod "test-recreate-deployment-76fb77d45-v8c9n" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-recreate-deployment-76fb77d45-v8c9n",
      GenerateName: (string) (len=35) "test-recreate-deployment-76fb77d45-",
      Namespace: (string) (len=15) "deployment-9742",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8cd12fe2-ae4e-4e19-888c-3a9d30c1f244",
      ResourceVersion: (string) (len=5) "35062",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849144266,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=34) "test-recreate-deployment-76fb77d45",
          UID: (types.UID) (len=36) "cf0e257f-019f-4cef-a53c-f34a42a86ba8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849144266,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 66  30 65 32 35 37 66 2d 30  |d\":\"cf0e257f-0|
              00000090  31 39 66 2d 34 63 65 66  2d 61 35 33 63 2d 66 33  |19f-4cef-a53c-f3|
              000000a0  34 61 34 32 61 38 36 62  61 38 5c 22 7d 22 3a 7b  |4a42a86ba8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849144266,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-pzgpg",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-pzgpg",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "co4fe9zoo9oc-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849144266,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849144266,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849144266,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849144266,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849144266,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.60",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.60"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849144266,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 19 17:24:26.209: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-9742" for this suite. @ 04/19/24 17:24:26.218
• [2.426 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:60
  STEP: Creating a kubernetes client @ 04/19/24 17:24:26.229
  Apr 19 17:24:26.229: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename watch @ 04/19/24 17:24:26.233
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:24:26.255
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:24:26.259
  STEP: creating a watch on configmaps with label A @ 04/19/24 17:24:26.264
  STEP: creating a watch on configmaps with label B @ 04/19/24 17:24:26.266
  STEP: creating a watch on configmaps with label A or B @ 04/19/24 17:24:26.268
  STEP: creating a configmap with label A and ensuring the correct watchers observe the notification @ 04/19/24 17:24:26.27
  Apr 19 17:24:26.280: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9952  cca9a60c-3e38-4f20-b21b-b2cd14fc5565 35068 0 2024-04-19 17:24:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-19 17:24:26 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 19 17:24:26.281: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9952  cca9a60c-3e38-4f20-b21b-b2cd14fc5565 35068 0 2024-04-19 17:24:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-19 17:24:26 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A and ensuring the correct watchers observe the notification @ 04/19/24 17:24:26.281
  Apr 19 17:24:26.293: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9952  cca9a60c-3e38-4f20-b21b-b2cd14fc5565 35069 0 2024-04-19 17:24:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-19 17:24:26 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 19 17:24:26.293: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9952  cca9a60c-3e38-4f20-b21b-b2cd14fc5565 35069 0 2024-04-19 17:24:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-19 17:24:26 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A again and ensuring the correct watchers observe the notification @ 04/19/24 17:24:26.293
  Apr 19 17:24:26.307: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9952  cca9a60c-3e38-4f20-b21b-b2cd14fc5565 35070 0 2024-04-19 17:24:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-19 17:24:26 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 19 17:24:26.307: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9952  cca9a60c-3e38-4f20-b21b-b2cd14fc5565 35070 0 2024-04-19 17:24:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-19 17:24:26 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap A and ensuring the correct watchers observe the notification @ 04/19/24 17:24:26.308
  Apr 19 17:24:26.318: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9952  cca9a60c-3e38-4f20-b21b-b2cd14fc5565 35071 0 2024-04-19 17:24:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-19 17:24:26 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 19 17:24:26.318: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9952  cca9a60c-3e38-4f20-b21b-b2cd14fc5565 35071 0 2024-04-19 17:24:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-19 17:24:26 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: creating a configmap with label B and ensuring the correct watchers observe the notification @ 04/19/24 17:24:26.318
  Apr 19 17:24:26.324: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9952  a19a0cd6-e0be-483f-b798-89de9389eee3 35072 0 2024-04-19 17:24:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-04-19 17:24:26 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 19 17:24:26.325: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9952  a19a0cd6-e0be-483f-b798-89de9389eee3 35072 0 2024-04-19 17:24:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-04-19 17:24:26 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0419 17:24:26.546018      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:27.547398      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:28.547791      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:29.548054      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:30.549132      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:31.549822      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:32.551136      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:33.551579      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:34.552203      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:35.552875      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting configmap B and ensuring the correct watchers observe the notification @ 04/19/24 17:24:36.326
  Apr 19 17:24:36.347: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9952  a19a0cd6-e0be-483f-b798-89de9389eee3 35122 0 2024-04-19 17:24:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-04-19 17:24:26 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 19 17:24:36.347: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9952  a19a0cd6-e0be-483f-b798-89de9389eee3 35122 0 2024-04-19 17:24:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-04-19 17:24:26 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0419 17:24:36.553575      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:37.554245      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:38.554340      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:39.557250      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:40.557179      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:41.557262      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:42.559177      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:43.558241      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:44.558766      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:45.559832      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:24:46.350: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-9952" for this suite. @ 04/19/24 17:24:46.374
• [20.171 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:572
  STEP: Creating a kubernetes client @ 04/19/24 17:24:46.406
  Apr 19 17:24:46.407: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename webhook @ 04/19/24 17:24:46.413
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:24:46.455
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:24:46.462
  STEP: Setting up server cert @ 04/19/24 17:24:46.521
  E0419 17:24:46.560727      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 17:24:47.119
  STEP: Deploying the webhook pod @ 04/19/24 17:24:47.138
  STEP: Wait for the deployment to be ready @ 04/19/24 17:24:47.161
  Apr 19 17:24:47.181: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0419 17:24:47.561144      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:48.562098      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 17:24:49.219
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 17:24:49.262
  E0419 17:24:49.561887      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:24:50.263: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 04/19/24 17:24:50.43
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/19/24 17:24:50.494
  STEP: Deleting the collection of validation webhooks @ 04/19/24 17:24:50.556
  E0419 17:24:50.561878      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/19/24 17:24:50.646
  Apr 19 17:24:50.755: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6672" for this suite. @ 04/19/24 17:24:50.77
  STEP: Destroying namespace "webhook-markers-6770" for this suite. @ 04/19/24 17:24:50.784
• [4.389 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should delete a collection of services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3565
  STEP: Creating a kubernetes client @ 04/19/24 17:24:50.802
  Apr 19 17:24:50.802: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename services @ 04/19/24 17:24:50.806
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:24:50.83
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:24:50.836
  STEP: creating a collection of services @ 04/19/24 17:24:50.842
  Apr 19 17:24:50.843: INFO: Creating e2e-svc-a-8dcvg
  Apr 19 17:24:50.858: INFO: Creating e2e-svc-b-62pdx
  Apr 19 17:24:50.877: INFO: Creating e2e-svc-c-jssx7
  STEP: deleting service collection @ 04/19/24 17:24:50.898
  Apr 19 17:24:50.945: INFO: Collection of services has been deleted
  Apr 19 17:24:50.945: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1037" for this suite. @ 04/19/24 17:24:50.955
• [0.173 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:155
  STEP: Creating a kubernetes client @ 04/19/24 17:24:50.976
  Apr 19 17:24:50.976: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename var-expansion @ 04/19/24 17:24:50.98
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:24:51.013
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:24:51.017
  E0419 17:24:51.562404      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:52.562743      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:24:53.072: INFO: Deleting pod "var-expansion-a913e7f7-ee8c-4df8-a200-4137b6e0261c" in namespace "var-expansion-4493"
  Apr 19 17:24:53.087: INFO: Wait up to 5m0s for pod "var-expansion-a913e7f7-ee8c-4df8-a200-4137b6e0261c" to be fully deleted
  E0419 17:24:53.563038      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:54.563198      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:24:55.102: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-4493" for this suite. @ 04/19/24 17:24:55.117
• [4.164 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:622
  STEP: Creating a kubernetes client @ 04/19/24 17:24:55.146
  Apr 19 17:24:55.146: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename field-validation @ 04/19/24 17:24:55.15
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:24:55.183
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:24:55.189
  Apr 19 17:24:55.197: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  E0419 17:24:55.566571      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:56.568638      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:24:57.568108      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0419 17:24:58.090974      13 warnings.go:70] unknown field "alpha"
  W0419 17:24:58.091312      13 warnings.go:70] unknown field "beta"
  W0419 17:24:58.091555      13 warnings.go:70] unknown field "delta"
  W0419 17:24:58.091772      13 warnings.go:70] unknown field "epsilon"
  W0419 17:24:58.091977      13 warnings.go:70] unknown field "gamma"
  E0419 17:24:58.568826      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:24:58.700: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-1636" for this suite. @ 04/19/24 17:24:58.716
• [3.587 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment should validate Deployment Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:489
  STEP: Creating a kubernetes client @ 04/19/24 17:24:58.736
  Apr 19 17:24:58.736: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename deployment @ 04/19/24 17:24:58.74
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:24:58.777
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:24:58.785
  STEP: creating a Deployment @ 04/19/24 17:24:58.802
  Apr 19 17:24:58.802: INFO: Creating simple deployment test-deployment-csrlw
  Apr 19 17:24:58.834: INFO: deployment "test-deployment-csrlw" doesn't have the required revision set
  E0419 17:24:59.569815      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:00.571960      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Getting /status @ 04/19/24 17:25:00.859
  Apr 19 17:25:00.866: INFO: Deployment test-deployment-csrlw has Conditions: [{Available True 2024-04-19 17:25:00 +0000 UTC 2024-04-19 17:25:00 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2024-04-19 17:25:00 +0000 UTC 2024-04-19 17:24:58 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-csrlw-5d576bd769" has successfully progressed.}]
  STEP: updating Deployment Status @ 04/19/24 17:25:00.867
  Apr 19 17:25:00.882: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 25, 0, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 25, 0, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 25, 0, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 24, 58, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-csrlw-5d576bd769\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Deployment status to be updated @ 04/19/24 17:25:00.882
  Apr 19 17:25:00.885: INFO: Observed &Deployment event: ADDED
  Apr 19 17:25:00.885: INFO: Observed Deployment test-deployment-csrlw in namespace deployment-3139 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-19 17:24:58 +0000 UTC 2024-04-19 17:24:58 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-csrlw-5d576bd769"}
  Apr 19 17:25:00.886: INFO: Observed &Deployment event: MODIFIED
  Apr 19 17:25:00.886: INFO: Observed Deployment test-deployment-csrlw in namespace deployment-3139 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-19 17:24:58 +0000 UTC 2024-04-19 17:24:58 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-csrlw-5d576bd769"}
  Apr 19 17:25:00.886: INFO: Observed Deployment test-deployment-csrlw in namespace deployment-3139 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-04-19 17:24:58 +0000 UTC 2024-04-19 17:24:58 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Apr 19 17:25:00.886: INFO: Observed &Deployment event: MODIFIED
  Apr 19 17:25:00.886: INFO: Observed Deployment test-deployment-csrlw in namespace deployment-3139 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-04-19 17:24:58 +0000 UTC 2024-04-19 17:24:58 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Apr 19 17:25:00.886: INFO: Observed Deployment test-deployment-csrlw in namespace deployment-3139 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-19 17:24:58 +0000 UTC 2024-04-19 17:24:58 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-csrlw-5d576bd769" is progressing.}
  Apr 19 17:25:00.886: INFO: Observed &Deployment event: MODIFIED
  Apr 19 17:25:00.887: INFO: Observed Deployment test-deployment-csrlw in namespace deployment-3139 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-04-19 17:25:00 +0000 UTC 2024-04-19 17:25:00 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Apr 19 17:25:00.887: INFO: Observed Deployment test-deployment-csrlw in namespace deployment-3139 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-19 17:25:00 +0000 UTC 2024-04-19 17:24:58 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-csrlw-5d576bd769" has successfully progressed.}
  Apr 19 17:25:00.887: INFO: Observed &Deployment event: MODIFIED
  Apr 19 17:25:00.887: INFO: Observed Deployment test-deployment-csrlw in namespace deployment-3139 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-04-19 17:25:00 +0000 UTC 2024-04-19 17:25:00 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Apr 19 17:25:00.887: INFO: Observed Deployment test-deployment-csrlw in namespace deployment-3139 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-19 17:25:00 +0000 UTC 2024-04-19 17:24:58 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-csrlw-5d576bd769" has successfully progressed.}
  Apr 19 17:25:00.887: INFO: Found Deployment test-deployment-csrlw in namespace deployment-3139 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 19 17:25:00.887: INFO: Deployment test-deployment-csrlw has an updated status
  STEP: patching the Statefulset Status @ 04/19/24 17:25:00.887
  Apr 19 17:25:00.887: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Apr 19 17:25:00.901: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Deployment status to be patched @ 04/19/24 17:25:00.901
  Apr 19 17:25:00.905: INFO: Observed &Deployment event: ADDED
  Apr 19 17:25:00.905: INFO: Observed deployment test-deployment-csrlw in namespace deployment-3139 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-19 17:24:58 +0000 UTC 2024-04-19 17:24:58 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-csrlw-5d576bd769"}
  Apr 19 17:25:00.905: INFO: Observed &Deployment event: MODIFIED
  Apr 19 17:25:00.905: INFO: Observed deployment test-deployment-csrlw in namespace deployment-3139 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-19 17:24:58 +0000 UTC 2024-04-19 17:24:58 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-csrlw-5d576bd769"}
  Apr 19 17:25:00.905: INFO: Observed deployment test-deployment-csrlw in namespace deployment-3139 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-04-19 17:24:58 +0000 UTC 2024-04-19 17:24:58 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Apr 19 17:25:00.906: INFO: Observed &Deployment event: MODIFIED
  Apr 19 17:25:00.906: INFO: Observed deployment test-deployment-csrlw in namespace deployment-3139 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-04-19 17:24:58 +0000 UTC 2024-04-19 17:24:58 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Apr 19 17:25:00.906: INFO: Observed deployment test-deployment-csrlw in namespace deployment-3139 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-19 17:24:58 +0000 UTC 2024-04-19 17:24:58 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-csrlw-5d576bd769" is progressing.}
  Apr 19 17:25:00.906: INFO: Observed &Deployment event: MODIFIED
  Apr 19 17:25:00.906: INFO: Observed deployment test-deployment-csrlw in namespace deployment-3139 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-04-19 17:25:00 +0000 UTC 2024-04-19 17:25:00 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Apr 19 17:25:00.906: INFO: Observed deployment test-deployment-csrlw in namespace deployment-3139 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-19 17:25:00 +0000 UTC 2024-04-19 17:24:58 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-csrlw-5d576bd769" has successfully progressed.}
  Apr 19 17:25:00.907: INFO: Observed &Deployment event: MODIFIED
  Apr 19 17:25:00.907: INFO: Observed deployment test-deployment-csrlw in namespace deployment-3139 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-04-19 17:25:00 +0000 UTC 2024-04-19 17:25:00 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Apr 19 17:25:00.907: INFO: Observed deployment test-deployment-csrlw in namespace deployment-3139 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-19 17:25:00 +0000 UTC 2024-04-19 17:24:58 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-csrlw-5d576bd769" has successfully progressed.}
  Apr 19 17:25:00.907: INFO: Observed deployment test-deployment-csrlw in namespace deployment-3139 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 19 17:25:00.907: INFO: Observed &Deployment event: MODIFIED
  Apr 19 17:25:00.907: INFO: Found deployment test-deployment-csrlw in namespace deployment-3139 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
  Apr 19 17:25:00.907: INFO: Deployment test-deployment-csrlw has a patched status
  Apr 19 17:25:00.915: INFO: Deployment "test-deployment-csrlw":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=21) "test-deployment-csrlw",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3139",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "08ab6fce-fbb0-4f5e-96dc-3adedf0f2346",
      ResourceVersion: (string) (len=5) "35339",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849144298,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849144298,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=657) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              00000030  6e 61 6d 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |name":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  70 72 6f 67 72 65 73 73  |ec":{"f:progress|
              00000050  44 65 61 64 6c 69 6e 65  53 65 63 6f 6e 64 73 22  |DeadlineSeconds"|
              00000060  3a 7b 7d 2c 22 66 3a 72  65 70 6c 69 63 61 73 22  |:{},"f:replicas"|
              00000070  3a 7b 7d 2c 22 66 3a 72  65 76 69 73 69 6f 6e 48  |:{},"f:revisionH|
              00000080  69 73 74 6f 72 79 4c 69  6d 69 74 22 3a 7b 7d 2c  |istoryLimit":{},|
              00000090  22 66 3a 73 65 6c 65 63  74 6f 72 22 3a 7b 7d 2c  |"f:selector":{},|
              000000a0  22 66 3a 73 74 72 61 74  65 67 79 22 3a 7b 22 66  |"f:strategy":{"f|
              000000b0  3a 72 6f 6c 6c 69 6e 67  55 70 64 61 74 65 22 3a  |:rollingUpdate":|
              000000c0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6d 61 78 53 75  |{".":{},"f:maxSu|
              000000d0  72 67 65 22 3a 7b 7d 2c  22 66 3a 6d 61 78 55 6e  |rge":{},"f:maxUn|
              000000e0  61 76 61 69 6c 61 62 6c  65 22 3a 7b 7d 7d 2c 22  |available":{}},"|
              000000f0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 66 3a 74  |f:type":{}},"f:t|
              00000100  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000110  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              00000120  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 65 32  |s":{".":{},"f:e2|
              00000130  65 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |e":{},"f:name":{|
              00000140  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              00000150  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000160  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              00000170  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              00000180  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000190  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              000001a0  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              000001b0  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              000001c0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000001d0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000001e0  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000210  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000220  69 63 79 22 3a 7b 7d 2c  22 66 3a 72 65 73 74 61  |icy":{},"f:resta|
              00000230  72 74 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |rtPolicy":{},"f:|
              00000240  73 63 68 65 64 75 6c 65  72 4e 61 6d 65 22 3a 7b  |schedulerName":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 47  72 61 63 65 50 65 72 69  |inationGracePeri|
              00000280  6f 64 53 65 63 6f 6e 64  73 22 3a 7b 7d 7d 7d 7d  |odSeconds":{}}}}|
              00000290  7d                                                |}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849144300,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=147) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 53 74 61 74  |{\"type\":\"Stat|
              00000030  75 73 50 61 74 63 68 65  64 5c 22 7d 22 3a 7b 22  |usPatched\"}":{"|
              00000040  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |.":{},"f:lastTra|
              00000050  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000060  22 66 3a 6c 61 73 74 55  70 64 61 74 65 54 69 6d  |"f:lastUpdateTim|
              00000070  65 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |e":{},"f:status"|
              00000080  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000090  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849144300,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=373) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 50 72 6f  |:{\"type\":\"Pro|
              000000a0  67 72 65 73 73 69 6e 67  5c 22 7d 22 3a 7b 22 2e  |gressing\"}":{".|
              000000b0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000000c0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000000d0  66 3a 6c 61 73 74 55 70  64 61 74 65 54 69 6d 65  |f:lastUpdateTime|
              000000e0  22 3a 7b 7d 2c 22 66 3a  6d 65 73 73 61 67 65 22  |":{},"f:message"|
              000000f0  3a 7b 7d 2c 22 66 3a 72  65 61 73 6f 6e 22 3a 7b  |:{},"f:reason":{|
              00000100  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              00000110  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              00000120  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000130  69 6f 6e 22 3a 7b 7d 2c  22 66 3a 72 65 61 64 79  |ion":{},"f:ready|
              00000140  52 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |Replicas":{},"f:|
              00000150  72 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |replicas":{},"f:|
              00000160  75 70 64 61 74 65 64 52  65 70 6c 69 63 61 73 22  |updatedReplicas"|
              00000170  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=13) "StatusPatched",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849144300,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849144300,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "FoundNewReplicaSet",
          Message: (string) (len=56) "Found new replica set \"test-deployment-csrlw-5d576bd769\""
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Apr 19 17:25:00.925: INFO: New ReplicaSet "test-deployment-csrlw-5d576bd769" of Deployment "test-deployment-csrlw":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-csrlw-5d576bd769",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3139",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a870f2b0-6670-4c6e-88d6-b4414764da7b",
      ResourceVersion: (string) (len=5) "35327",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849144298,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769",
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=21) "test-deployment-csrlw",
          UID: (types.UID) (len=36) "08ab6fce-fbb0-4f5e-96dc-3adedf0f2346",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849144298,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=803) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              000000d0  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 70 6f 64 2d  |name":{},"f:pod-|
              000000e0  74 65 6d 70 6c 61 74 65  2d 68 61 73 68 22 3a 7b  |template-hash":{|
              000000f0  7d 7d 2c 22 66 3a 6f 77  6e 65 72 52 65 66 65 72  |}},"f:ownerRefer|
              00000100  65 6e 63 65 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |ences":{".":{},"|
              00000110  6b 3a 7b 5c 22 75 69 64  5c 22 3a 5c 22 30 38 61  |k:{\"uid\":\"08a|
              00000120  62 36 66 63 65 2d 66 62  62 30 2d 34 66 35 65 2d  |b6fce-fbb0-4f5e-|
              00000130  39 36 64 63 2d 33 61 64  65 64 66 30 66 32 33 34  |96dc-3adedf0f234|
              00000140  36 5c 22 7d 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |6\"}":{}}},"f:sp|
              00000150  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000160  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000180  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000190  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              000001a0  3a 7b 7d 2c 22 66 3a 65  32 65 22 3a 7b 7d 2c 22  |:{},"f:e2e":{},"|
              000001b0  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 70 6f  |f:name":{},"f:po|
              000001c0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001d0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000001e0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000001f0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              00000200  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              00000210  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000220  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000230  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000240  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000280  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000290  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              000002a0  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              000002b0  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              000002c0  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              000002d0  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000002e0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000002f0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              00000300  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              00000310  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              00000320  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849144300,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=3) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769",
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=3) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 19 17:25:00.946: INFO: Pod "test-deployment-csrlw-5d576bd769-xvb72" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=38) "test-deployment-csrlw-5d576bd769-xvb72",
      GenerateName: (string) (len=33) "test-deployment-csrlw-5d576bd769-",
      Namespace: (string) (len=15) "deployment-3139",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "491ca038-1bb4-4598-926b-1feb89c62d79",
      ResourceVersion: (string) (len=5) "35326",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849144298,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769",
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=32) "test-deployment-csrlw-5d576bd769",
          UID: (types.UID) (len=36) "a870f2b0-6670-4c6e-88d6-b4414764da7b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849144298,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=548) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 65 32 65 22 3a 7b 7d  |.":{},"f:e2e":{}|
              00000040  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000050  70 6f 64 2d 74 65 6d 70  6c 61 74 65 2d 68 61 73  |pod-template-has|
              00000060  68 22 3a 7b 7d 7d 2c 22  66 3a 6f 77 6e 65 72 52  |h":{}},"f:ownerR|
              00000070  65 66 65 72 65 6e 63 65  73 22 3a 7b 22 2e 22 3a  |eferences":{".":|
              00000080  7b 7d 2c 22 6b 3a 7b 5c  22 75 69 64 5c 22 3a 5c  |{},"k:{\"uid\":\|
              00000090  22 61 38 37 30 66 32 62  30 2d 36 36 37 30 2d 34  |"a870f2b0-6670-4|
              000000a0  63 36 65 2d 38 38 64 36  2d 62 34 34 31 34 37 36  |c6e-88d6-b441476|
              000000b0  34 64 61 37 62 5c 22 7d  22 3a 7b 7d 7d 7d 2c 22  |4da7b\"}":{}}},"|
              000000c0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000d0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              000000e0  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              000000f0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000100  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000110  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000120  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000130  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 73 65  |ources":{},"f:se|
              00000140  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000150  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000160  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000170  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000180  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000190  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              000001a0  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              000001b0  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              000001c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000200  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000210  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000220  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849144300,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 33 33 2e 36 36 2e  31 37 35 5c 22 7d 22 3a  |.233.66.175\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-nkpht",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-nkpht",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "co4fe9zoo9oc-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849144300,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849144298,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849144300,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849144300,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63849144298,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.60",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.60"
        }
      },
      PodIP: (string) (len=13) "10.233.66.175",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.66.175"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63849144298,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63849144299,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://48d97b6ccc018f21ae344845f75f2dafdf66c735de380e61eebc4037e4a4fc81",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 19 17:25:00.961: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-3139" for this suite. @ 04/19/24 17:25:00.969
• [2.243 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:142
  STEP: Creating a kubernetes client @ 04/19/24 17:25:00.984
  Apr 19 17:25:00.985: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename watch @ 04/19/24 17:25:00.988
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:25:01.01
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:25:01.014
  STEP: creating a new configmap @ 04/19/24 17:25:01.019
  STEP: modifying the configmap once @ 04/19/24 17:25:01.025
  STEP: modifying the configmap a second time @ 04/19/24 17:25:01.042
  STEP: deleting the configmap @ 04/19/24 17:25:01.054
  STEP: creating a watch on configmaps from the resource version returned by the first update @ 04/19/24 17:25:01.077
  STEP: Expecting to observe notifications for all changes to the configmap after the first update @ 04/19/24 17:25:01.081
  Apr 19 17:25:01.081: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-9459  e5b5db08-058d-4fb5-a20e-2af713b0b08f 35347 0 2024-04-19 17:25:01 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-04-19 17:25:01 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 19 17:25:01.082: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-9459  e5b5db08-058d-4fb5-a20e-2af713b0b08f 35348 0 2024-04-19 17:25:01 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-04-19 17:25:01 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 19 17:25:01.083: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-9459" for this suite. @ 04/19/24 17:25:01.094
• [0.119 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:221
  STEP: Creating a kubernetes client @ 04/19/24 17:25:01.106
  Apr 19 17:25:01.106: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename webhook @ 04/19/24 17:25:01.109
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:25:01.135
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:25:01.141
  STEP: Setting up server cert @ 04/19/24 17:25:01.188
  E0419 17:25:01.571623      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 17:25:02.367
  STEP: Deploying the webhook pod @ 04/19/24 17:25:02.378
  STEP: Wait for the deployment to be ready @ 04/19/24 17:25:02.404
  Apr 19 17:25:02.423: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0419 17:25:02.572794      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:03.573452      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:25:04.446: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 19, 17, 25, 2, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 25, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 19, 17, 25, 2, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 19, 17, 25, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7c55c7d74c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0419 17:25:04.574710      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:05.574989      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 17:25:06.454
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 17:25:06.499
  E0419 17:25:06.575083      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:25:07.499: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 19 17:25:07.513: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  E0419 17:25:07.576132      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the custom resource webhook via the AdmissionRegistration API @ 04/19/24 17:25:08.036
  STEP: Creating a custom resource that should be denied by the webhook @ 04/19/24 17:25:08.109
  E0419 17:25:08.577270      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:09.577490      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a custom resource whose deletion would be denied by the webhook @ 04/19/24 17:25:10.246
  STEP: Updating the custom resource with disallowed data should be denied @ 04/19/24 17:25:10.264
  STEP: Deleting the custom resource should be denied @ 04/19/24 17:25:10.285
  STEP: Remove the offending key and value from the custom resource data @ 04/19/24 17:25:10.3
  STEP: Deleting the updated custom resource should be successful @ 04/19/24 17:25:10.32
  E0419 17:25:10.577851      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:25:10.948: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5966" for this suite. @ 04/19/24 17:25:10.962
  STEP: Destroying namespace "webhook-markers-7983" for this suite. @ 04/19/24 17:25:10.984
• [9.896 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:572
  STEP: Creating a kubernetes client @ 04/19/24 17:25:11.007
  Apr 19 17:25:11.007: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename job @ 04/19/24 17:25:11.011
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:25:11.046
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:25:11.062
  STEP: Creating a job @ 04/19/24 17:25:11.07
  STEP: Ensuring job reaches completions @ 04/19/24 17:25:11.082
  E0419 17:25:11.578350      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:12.579349      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:13.580011      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:14.580282      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:15.580785      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:16.584207      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:17.582464      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:18.583306      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:19.583697      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:20.584685      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:25:21.093: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-6211" for this suite. @ 04/19/24 17:25:21.108
• [10.121 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:480
  STEP: Creating a kubernetes client @ 04/19/24 17:25:21.129
  Apr 19 17:25:21.129: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename gc @ 04/19/24 17:25:21.133
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:25:21.169
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:25:21.183
  STEP: create the deployment @ 04/19/24 17:25:21.194
  W0419 17:25:21.212626      13 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 04/19/24 17:25:21.212
  E0419 17:25:21.585615      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the deployment @ 04/19/24 17:25:21.723
  STEP: wait for all rs to be garbage collected @ 04/19/24 17:25:21.738
  STEP: expected 0 rs, got 1 rs @ 04/19/24 17:25:21.763
  STEP: expected 0 pods, got 2 pods @ 04/19/24 17:25:21.77
  STEP: Gathering metrics @ 04/19/24 17:25:22.264
  Apr 19 17:25:22.551: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 19 17:25:22.555: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-1268" for this suite. @ 04/19/24 17:25:22.567
• [1.452 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:47
  STEP: Creating a kubernetes client @ 04/19/24 17:25:22.583
  Apr 19 17:25:22.583: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  E0419 17:25:22.585831      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Building a namespace api object, basename var-expansion @ 04/19/24 17:25:22.587
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:25:22.614
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:25:22.617
  STEP: Creating a pod to test env composition @ 04/19/24 17:25:22.62
  E0419 17:25:23.589214      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:24.587446      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:25:24.652
  Apr 19 17:25:24.673: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod var-expansion-7a57703f-f1b1-4f18-a8c3-839bf8ab7549 container dapi-container: <nil>
  STEP: delete the pod @ 04/19/24 17:25:24.699
  Apr 19 17:25:24.738: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-2883" for this suite. @ 04/19/24 17:25:24.75
• [2.195 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:254
  STEP: Creating a kubernetes client @ 04/19/24 17:25:24.781
  Apr 19 17:25:24.781: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename namespaces @ 04/19/24 17:25:24.786
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:25:24.866
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:25:24.873
  STEP: Creating a test namespace @ 04/19/24 17:25:24.882
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:25:24.909
  STEP: Creating a service in the namespace @ 04/19/24 17:25:24.918
  STEP: Deleting the namespace @ 04/19/24 17:25:24.948
  STEP: Waiting for the namespace to be removed. @ 04/19/24 17:25:24.968
  E0419 17:25:25.587951      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:26.588050      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:27.588670      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:28.589081      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:29.589701      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:30.590803      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 04/19/24 17:25:30.983
  STEP: Verifying there is no service in the namespace @ 04/19/24 17:25:31.019
  Apr 19 17:25:31.035: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-6142" for this suite. @ 04/19/24 17:25:31.048
  STEP: Destroying namespace "nsdeletetest-8087" for this suite. @ 04/19/24 17:25:31.067
  Apr 19 17:25:31.077: INFO: Namespace nsdeletetest-8087 was already deleted
  STEP: Destroying namespace "nsdeletetest-1244" for this suite. @ 04/19/24 17:25:31.078
• [6.318 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:332
  STEP: Creating a kubernetes client @ 04/19/24 17:25:31.104
  Apr 19 17:25:31.105: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename webhook @ 04/19/24 17:25:31.11
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:25:31.144
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:25:31.153
  STEP: Setting up server cert @ 04/19/24 17:25:31.211
  E0419 17:25:31.591847      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 17:25:31.7
  STEP: Deploying the webhook pod @ 04/19/24 17:25:31.719
  STEP: Wait for the deployment to be ready @ 04/19/24 17:25:31.749
  Apr 19 17:25:31.768: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0419 17:25:32.593037      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:33.594007      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 17:25:33.796
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 17:25:33.821
  E0419 17:25:34.593586      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:25:34.823: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 19 17:25:34.844: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4797-crds.webhook.example.com via the AdmissionRegistration API @ 04/19/24 17:25:35.386
  STEP: Creating a custom resource that should be mutated by the webhook @ 04/19/24 17:25:35.441
  E0419 17:25:35.594799      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:36.595233      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:37.595867      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:25:38.351: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7125" for this suite. @ 04/19/24 17:25:38.368
  STEP: Destroying namespace "webhook-markers-1560" for this suite. @ 04/19/24 17:25:38.394
• [7.314 seconds]
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:153
  STEP: Creating a kubernetes client @ 04/19/24 17:25:38.419
  Apr 19 17:25:38.419: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 04/19/24 17:25:38.426
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:25:38.473
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:25:38.478
  STEP: create the container to handle the HTTPGet hook request. @ 04/19/24 17:25:38.502
  E0419 17:25:38.596301      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:39.597013      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:40.598814      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 04/19/24 17:25:40.599
  E0419 17:25:41.598933      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:42.599310      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 04/19/24 17:25:42.641
  E0419 17:25:43.599555      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:44.600055      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 04/19/24 17:25:44.68
  Apr 19 17:25:44.727: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-3211" for this suite. @ 04/19/24 17:25:44.742
• [6.340 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet_etc_hosts.go:64
  STEP: Creating a kubernetes client @ 04/19/24 17:25:44.761
  Apr 19 17:25:44.761: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts @ 04/19/24 17:25:44.765
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:25:44.807
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:25:44.813
  STEP: Setting up the test @ 04/19/24 17:25:44.825
  STEP: Creating hostNetwork=false pod @ 04/19/24 17:25:44.825
  E0419 17:25:45.601772      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:46.602013      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating hostNetwork=true pod @ 04/19/24 17:25:46.884
  E0419 17:25:47.602845      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:48.603148      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Running the test @ 04/19/24 17:25:48.937
  STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false @ 04/19/24 17:25:48.938
  Apr 19 17:25:48.938: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7174 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 17:25:48.938: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 17:25:48.941: INFO: ExecWithOptions: Clientset creation
  Apr 19 17:25:48.941: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7174/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Apr 19 17:25:49.118: INFO: Exec stderr: ""
  Apr 19 17:25:49.119: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7174 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 17:25:49.119: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 17:25:49.123: INFO: ExecWithOptions: Clientset creation
  Apr 19 17:25:49.123: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7174/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Apr 19 17:25:49.246: INFO: Exec stderr: ""
  Apr 19 17:25:49.246: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7174 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 17:25:49.246: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 17:25:49.250: INFO: ExecWithOptions: Clientset creation
  Apr 19 17:25:49.250: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7174/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Apr 19 17:25:49.378: INFO: Exec stderr: ""
  Apr 19 17:25:49.378: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7174 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 17:25:49.378: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 17:25:49.380: INFO: ExecWithOptions: Clientset creation
  Apr 19 17:25:49.381: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7174/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Apr 19 17:25:49.487: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount @ 04/19/24 17:25:49.487
  Apr 19 17:25:49.487: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7174 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 17:25:49.488: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 17:25:49.489: INFO: ExecWithOptions: Clientset creation
  Apr 19 17:25:49.489: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7174/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  E0419 17:25:49.603830      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:25:49.634: INFO: Exec stderr: ""
  Apr 19 17:25:49.634: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7174 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 17:25:49.634: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 17:25:49.638: INFO: ExecWithOptions: Clientset creation
  Apr 19 17:25:49.638: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7174/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  Apr 19 17:25:49.734: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true @ 04/19/24 17:25:49.736
  Apr 19 17:25:49.736: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7174 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 17:25:49.736: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 17:25:49.739: INFO: ExecWithOptions: Clientset creation
  Apr 19 17:25:49.739: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7174/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Apr 19 17:25:49.886: INFO: Exec stderr: ""
  Apr 19 17:25:49.887: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7174 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 17:25:49.887: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 17:25:49.890: INFO: ExecWithOptions: Clientset creation
  Apr 19 17:25:49.890: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7174/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Apr 19 17:25:50.007: INFO: Exec stderr: ""
  Apr 19 17:25:50.007: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7174 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 17:25:50.007: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 17:25:50.010: INFO: ExecWithOptions: Clientset creation
  Apr 19 17:25:50.010: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7174/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Apr 19 17:25:50.122: INFO: Exec stderr: ""
  Apr 19 17:25:50.123: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7174 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 17:25:50.123: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  Apr 19 17:25:50.125: INFO: ExecWithOptions: Clientset creation
  Apr 19 17:25:50.125: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7174/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Apr 19 17:25:50.261: INFO: Exec stderr: ""
  Apr 19 17:25:50.262: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "e2e-kubelet-etc-hosts-7174" for this suite. @ 04/19/24 17:25:50.279
• [5.529 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:301
  STEP: Creating a kubernetes client @ 04/19/24 17:25:50.293
  Apr 19 17:25:50.293: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename webhook @ 04/19/24 17:25:50.297
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:25:50.34
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:25:50.345
  STEP: Setting up server cert @ 04/19/24 17:25:50.388
  E0419 17:25:50.604167      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 17:25:51.311
  STEP: Deploying the webhook pod @ 04/19/24 17:25:51.329
  STEP: Wait for the deployment to be ready @ 04/19/24 17:25:51.356
  Apr 19 17:25:51.378: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0419 17:25:51.605465      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:52.606628      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 17:25:53.403
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 17:25:53.438
  E0419 17:25:53.607605      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:25:54.438: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the crd webhook via the AdmissionRegistration API @ 04/19/24 17:25:54.459
  STEP: Creating a custom resource definition that should be denied by the webhook @ 04/19/24 17:25:54.5
  Apr 19 17:25:54.500: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  E0419 17:25:54.608800      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:25:54.631: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4723" for this suite. @ 04/19/24 17:25:54.642
  STEP: Destroying namespace "webhook-markers-3503" for this suite. @ 04/19/24 17:25:54.656
• [4.376 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:332
  STEP: Creating a kubernetes client @ 04/19/24 17:25:54.671
  Apr 19 17:25:54.672: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename statefulset @ 04/19/24 17:25:54.676
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:25:54.7
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:25:54.707
  STEP: Creating service test in namespace statefulset-9917 @ 04/19/24 17:25:54.715
  STEP: Creating a new StatefulSet @ 04/19/24 17:25:54.725
  Apr 19 17:25:54.756: INFO: Found 0 stateful pods, waiting for 3
  E0419 17:25:55.610879      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:56.610060      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:57.611026      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:58.611407      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:25:59.612061      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:00.611966      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:01.612229      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:02.614103      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:03.612925      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:04.613697      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:26:04.758: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 19 17:26:04.759: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 19 17:26:04.759: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 04/19/24 17:26:04.798
  Apr 19 17:26:04.831: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 04/19/24 17:26:04.831
  E0419 17:26:05.613620      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:06.615541      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:07.616811      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:08.617198      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:09.616666      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:10.617016      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:11.617249      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:12.617970      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:13.621162      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:14.618792      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Not applying an update when the partition is greater than the number of replicas @ 04/19/24 17:26:14.863
  STEP: Performing a canary update @ 04/19/24 17:26:14.865
  Apr 19 17:26:14.900: INFO: Updating stateful set ss2
  Apr 19 17:26:14.921: INFO: Waiting for Pod statefulset-9917/ss2-2 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0419 17:26:15.620259      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:16.620078      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:17.627166      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:18.620755      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:19.621283      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:20.621787      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:21.641370      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:22.630071      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:23.630465      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:24.632797      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Restoring Pods to the correct revision when they are deleted @ 04/19/24 17:26:24.938
  Apr 19 17:26:25.075: INFO: Found 2 stateful pods, waiting for 3
  E0419 17:26:25.631974      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:26.632391      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:27.632846      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:28.635141      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:29.635364      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:30.636575      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:31.637282      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:32.638096      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:33.638685      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:34.638968      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:26:35.060: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 19 17:26:35.061: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 19 17:26:35.062: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Performing a phased rolling update @ 04/19/24 17:26:35.084
  Apr 19 17:26:35.126: INFO: Updating stateful set ss2
  Apr 19 17:26:35.157: INFO: Waiting for Pod statefulset-9917/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0419 17:26:35.642749      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:36.642885      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:37.643828      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:38.643932      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:39.644055      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:40.645032      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:41.646010      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:42.646046      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:43.646814      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:44.646888      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:26:45.189: INFO: Updating stateful set ss2
  Apr 19 17:26:45.212: INFO: Waiting for StatefulSet statefulset-9917/ss2 to complete update
  Apr 19 17:26:45.212: INFO: Waiting for Pod statefulset-9917/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0419 17:26:45.647769      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:46.648113      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:47.648383      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:48.648726      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:49.648979      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:50.649430      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:51.649837      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:52.650195      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:53.650941      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:54.651074      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:26:55.206: INFO: Deleting all statefulset in ns statefulset-9917
  Apr 19 17:26:55.215: INFO: Scaling statefulset ss2 to 0
  E0419 17:26:55.651162      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:56.651408      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:57.651640      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:58.652196      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:26:59.652512      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:00.652896      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:01.653098      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:02.654075      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:03.654357      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:04.654541      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:27:05.246: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 19 17:27:05.255: INFO: Deleting statefulset ss2
  Apr 19 17:27:05.295: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-9917" for this suite. @ 04/19/24 17:27:05.314
• [70.657 seconds]
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:442
  STEP: Creating a kubernetes client @ 04/19/24 17:27:05.329
  Apr 19 17:27:05.329: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/19/24 17:27:05.335
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:27:05.384
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:27:05.389
  STEP: set up a multi version CRD @ 04/19/24 17:27:05.394
  Apr 19 17:27:05.395: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  E0419 17:27:05.654805      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:06.655158      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:07.655307      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:08.655646      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:09.655841      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mark a version not serverd @ 04/19/24 17:27:10.113
  STEP: check the unserved version gets removed @ 04/19/24 17:27:10.162
  E0419 17:27:10.656578      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:11.657173      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the other version is not changed @ 04/19/24 17:27:11.755
  E0419 17:27:12.657493      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:13.658763      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:14.659570      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:27:15.498: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-2503" for this suite. @ 04/19/24 17:27:15.527
• [10.216 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:120
  STEP: Creating a kubernetes client @ 04/19/24 17:27:15.55
  Apr 19 17:27:15.550: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename emptydir @ 04/19/24 17:27:15.558
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:27:15.592
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:27:15.599
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 04/19/24 17:27:15.606
  E0419 17:27:15.659828      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:16.660821      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:17.661164      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:18.672053      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:27:19.667
  E0419 17:27:19.669639      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:27:19.677: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-1cea9967-1d6e-46b9-a94a-4ecc64df205c container test-container: <nil>
  STEP: delete the pod @ 04/19/24 17:27:19.723
  Apr 19 17:27:19.759: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9845" for this suite. @ 04/19/24 17:27:19.768
• [4.234 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2214
  STEP: Creating a kubernetes client @ 04/19/24 17:27:19.791
  Apr 19 17:27:19.791: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename services @ 04/19/24 17:27:19.797
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:27:19.832
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:27:19.839
  STEP: creating service in namespace services-4337 @ 04/19/24 17:27:19.848
  STEP: creating service affinity-nodeport in namespace services-4337 @ 04/19/24 17:27:19.848
  STEP: creating replication controller affinity-nodeport in namespace services-4337 @ 04/19/24 17:27:19.887
  I0419 17:27:19.905153      13 runners.go:197] Created replication controller with name: affinity-nodeport, namespace: services-4337, replica count: 3
  E0419 17:27:20.669780      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:21.672772      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:22.672265      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0419 17:27:22.956800      13 runners.go:197] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 19 17:27:22.986: INFO: Creating new exec pod
  E0419 17:27:23.672326      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:24.672820      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:25.675281      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:27:26.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-4337 exec execpod-affinityrkh4j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
  E0419 17:27:26.673872      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:27.674263      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:27:28.488: INFO: rc: 1
  Apr 19 17:27:28.488: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-4337 exec execpod-affinityrkh4j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 affinity-nodeport 80
  nc: connect to affinity-nodeport port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  Apr 19 17:27:28.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-4337 exec execpod-affinityrkh4j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
  E0419 17:27:28.675189      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:29.676110      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:30.676564      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:27:30.885: INFO: rc: 1
  Apr 19 17:27:30.885: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-4337 exec execpod-affinityrkh4j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 affinity-nodeport 80
  nc: connect to affinity-nodeport port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  Apr 19 17:27:30.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-4337 exec execpod-affinityrkh4j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
  E0419 17:27:31.676957      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:32.677216      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:27:33.241: INFO: rc: 1
  Apr 19 17:27:33.241: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-4337 exec execpod-affinityrkh4j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 affinity-nodeport 80
  nc: connect to affinity-nodeport port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  Apr 19 17:27:33.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-4337 exec execpod-affinityrkh4j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
  E0419 17:27:33.679697      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:34.678778      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:27:35.590: INFO: rc: 1
  Apr 19 17:27:35.590: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-4337 exec execpod-affinityrkh4j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80:
  Command stdout:

  stderr:
  + nc -v -t -w 2 affinity-nodeport 80
  + echo hostName
  nc: connect to affinity-nodeport port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  Apr 19 17:27:35.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-4337 exec execpod-affinityrkh4j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
  E0419 17:27:35.679416      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:27:35.973: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
  Apr 19 17:27:35.973: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 17:27:35.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-4337 exec execpod-affinityrkh4j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.11.212 80'
  Apr 19 17:27:36.263: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.11.212 80\nConnection to 10.233.11.212 80 port [tcp/http] succeeded!\n"
  Apr 19 17:27:36.263: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 17:27:36.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-4337 exec execpod-affinityrkh4j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.60 31127'
  Apr 19 17:27:36.577: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.60 31127\nConnection to 192.168.121.60 31127 port [tcp/*] succeeded!\n"
  Apr 19 17:27:36.577: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 17:27:36.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-4337 exec execpod-affinityrkh4j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.39 31127'
  E0419 17:27:36.679987      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:27:36.927: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.39 31127\nConnection to 192.168.121.39 31127 port [tcp/*] succeeded!\n"
  Apr 19 17:27:36.927: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 17:27:36.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=services-4337 exec execpod-affinityrkh4j -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.127:31127/ ; done'
  Apr 19 17:27:37.622: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31127/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31127/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31127/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31127/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31127/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31127/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31127/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31127/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31127/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31127/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31127/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31127/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31127/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31127/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31127/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.127:31127/\n"
  Apr 19 17:27:37.622: INFO: stdout: "\naffinity-nodeport-jdzdt\naffinity-nodeport-jdzdt\naffinity-nodeport-jdzdt\naffinity-nodeport-jdzdt\naffinity-nodeport-jdzdt\naffinity-nodeport-jdzdt\naffinity-nodeport-jdzdt\naffinity-nodeport-jdzdt\naffinity-nodeport-jdzdt\naffinity-nodeport-jdzdt\naffinity-nodeport-jdzdt\naffinity-nodeport-jdzdt\naffinity-nodeport-jdzdt\naffinity-nodeport-jdzdt\naffinity-nodeport-jdzdt\naffinity-nodeport-jdzdt"
  Apr 19 17:27:37.622: INFO: Received response from host: affinity-nodeport-jdzdt
  Apr 19 17:27:37.622: INFO: Received response from host: affinity-nodeport-jdzdt
  Apr 19 17:27:37.622: INFO: Received response from host: affinity-nodeport-jdzdt
  Apr 19 17:27:37.622: INFO: Received response from host: affinity-nodeport-jdzdt
  Apr 19 17:27:37.622: INFO: Received response from host: affinity-nodeport-jdzdt
  Apr 19 17:27:37.622: INFO: Received response from host: affinity-nodeport-jdzdt
  Apr 19 17:27:37.622: INFO: Received response from host: affinity-nodeport-jdzdt
  Apr 19 17:27:37.622: INFO: Received response from host: affinity-nodeport-jdzdt
  Apr 19 17:27:37.622: INFO: Received response from host: affinity-nodeport-jdzdt
  Apr 19 17:27:37.622: INFO: Received response from host: affinity-nodeport-jdzdt
  Apr 19 17:27:37.622: INFO: Received response from host: affinity-nodeport-jdzdt
  Apr 19 17:27:37.622: INFO: Received response from host: affinity-nodeport-jdzdt
  Apr 19 17:27:37.622: INFO: Received response from host: affinity-nodeport-jdzdt
  Apr 19 17:27:37.622: INFO: Received response from host: affinity-nodeport-jdzdt
  Apr 19 17:27:37.622: INFO: Received response from host: affinity-nodeport-jdzdt
  Apr 19 17:27:37.622: INFO: Received response from host: affinity-nodeport-jdzdt
  Apr 19 17:27:37.623: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport in namespace services-4337, will wait for the garbage collector to delete the pods @ 04/19/24 17:27:37.656
  E0419 17:27:37.680881      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:27:37.760: INFO: Deleting ReplicationController affinity-nodeport took: 10.188536ms
  Apr 19 17:27:37.861: INFO: Terminating ReplicationController affinity-nodeport pods took: 101.094026ms
  E0419 17:27:38.681479      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:39.682729      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:40.683403      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:27:40.807: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4337" for this suite. @ 04/19/24 17:27:40.818
• [21.039 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:46
  STEP: Creating a kubernetes client @ 04/19/24 17:27:40.831
  Apr 19 17:27:40.832: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename downward-api @ 04/19/24 17:27:40.836
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:27:40.87
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:27:40.873
  STEP: Creating a pod to test downward api env vars @ 04/19/24 17:27:40.878
  E0419 17:27:41.684397      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:42.684978      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:43.686217      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:44.687217      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:27:44.924
  Apr 19 17:27:44.934: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod downward-api-918b3e62-b3ec-4953-bea3-aceaa0d6630f container dapi-container: <nil>
  STEP: delete the pod @ 04/19/24 17:27:44.956
  Apr 19 17:27:44.994: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7663" for this suite. @ 04/19/24 17:27:45.008
• [4.193 seconds]
------------------------------
[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:257
  STEP: Creating a kubernetes client @ 04/19/24 17:27:45.029
  Apr 19 17:27:45.030: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename watch @ 04/19/24 17:27:45.036
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:27:45.08
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:27:45.088
  STEP: creating a watch on configmaps with a certain label @ 04/19/24 17:27:45.097
  STEP: creating a new configmap @ 04/19/24 17:27:45.101
  STEP: modifying the configmap once @ 04/19/24 17:27:45.116
  STEP: changing the label value of the configmap @ 04/19/24 17:27:45.14
  STEP: Expecting to observe a delete notification for the watched object @ 04/19/24 17:27:45.159
  Apr 19 17:27:45.159: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1566  a2e33596-5ba3-4203-b51a-a096c02b36f8 36664 0 2024-04-19 17:27:45 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-19 17:27:45 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 19 17:27:45.160: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1566  a2e33596-5ba3-4203-b51a-a096c02b36f8 36665 0 2024-04-19 17:27:45 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-19 17:27:45 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 19 17:27:45.160: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1566  a2e33596-5ba3-4203-b51a-a096c02b36f8 36666 0 2024-04-19 17:27:45 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-19 17:27:45 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time @ 04/19/24 17:27:45.161
  STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements @ 04/19/24 17:27:45.182
  E0419 17:27:45.686942      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:46.687066      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:47.687873      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:48.688086      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:49.688408      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:50.688670      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:51.689657      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:52.690022      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:53.690500      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:54.690706      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: changing the label value of the configmap back @ 04/19/24 17:27:55.183
  STEP: modifying the configmap a third time @ 04/19/24 17:27:55.208
  STEP: deleting the configmap @ 04/19/24 17:27:55.234
  STEP: Expecting to observe an add notification for the watched object when the label value was restored @ 04/19/24 17:27:55.251
  Apr 19 17:27:55.251: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1566  a2e33596-5ba3-4203-b51a-a096c02b36f8 36721 0 2024-04-19 17:27:45 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-19 17:27:55 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 19 17:27:55.252: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1566  a2e33596-5ba3-4203-b51a-a096c02b36f8 36722 0 2024-04-19 17:27:45 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-19 17:27:55 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 19 17:27:55.252: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1566  a2e33596-5ba3-4203-b51a-a096c02b36f8 36723 0 2024-04-19 17:27:45 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-19 17:27:55 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 19 17:27:55.252: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-1566" for this suite. @ 04/19/24 17:27:55.273
• [10.261 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:46
  STEP: Creating a kubernetes client @ 04/19/24 17:27:55.299
  Apr 19 17:27:55.299: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename projected @ 04/19/24 17:27:55.304
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:27:55.337
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:27:55.345
  STEP: Creating projection with secret that has name projected-secret-test-44ff3615-1dd3-4c9a-b392-7612976a31ac @ 04/19/24 17:27:55.356
  STEP: Creating a pod to test consume secrets @ 04/19/24 17:27:55.369
  E0419 17:27:55.691348      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:56.691841      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:57.692588      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:27:58.693294      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:27:59.424
  Apr 19 17:27:59.434: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-projected-secrets-e7ed51db-5ddb-4196-b90f-ad6926e2514b container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/24 17:27:59.455
  Apr 19 17:27:59.500: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9838" for this suite. @ 04/19/24 17:27:59.52
• [4.252 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/chunking.go:83
  STEP: Creating a kubernetes client @ 04/19/24 17:27:59.557
  Apr 19 17:27:59.558: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename chunking @ 04/19/24 17:27:59.562
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:27:59.617
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:27:59.622
  STEP: creating a large number of resources @ 04/19/24 17:27:59.63
  E0419 17:27:59.698796      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:00.699837      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:01.700647      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:02.701075      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:03.701723      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:04.701443      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:05.703010      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:06.704142      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:07.704323      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:08.705508      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:09.706001      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:10.706549      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:11.706631      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:12.707844      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:13.708102      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:14.708743      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:15.708534      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:16.709604      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving those results in paged fashion several times @ 04/19/24 17:28:17.287
  Apr 19 17:28:17.324: INFO: Retrieved 17/17 results with rv 37194 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTQsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  Apr 19 17:28:17.372: INFO: Retrieved 17/17 results with rv 37194 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTQsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  Apr 19 17:28:17.432: INFO: Retrieved 17/17 results with rv 37194 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTQsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  Apr 19 17:28:17.476: INFO: Retrieved 17/17 results with rv 37194 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTQsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  Apr 19 17:28:17.524: INFO: Retrieved 17/17 results with rv 37194 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTQsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  Apr 19 17:28:17.575: INFO: Retrieved 17/17 results with rv 37194 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTQsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  Apr 19 17:28:17.648: INFO: Retrieved 17/17 results with rv 37194 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTQsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  Apr 19 17:28:17.671: INFO: Retrieved 17/17 results with rv 37194 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTQsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  E0419 17:28:17.710197      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:28:17.722: INFO: Retrieved 17/17 results with rv 37194 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTQsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  Apr 19 17:28:17.771: INFO: Retrieved 17/17 results with rv 37194 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTQsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  Apr 19 17:28:17.820: INFO: Retrieved 17/17 results with rv 37194 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTQsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  Apr 19 17:28:17.877: INFO: Retrieved 17/17 results with rv 37194 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTQsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  Apr 19 17:28:17.921: INFO: Retrieved 17/17 results with rv 37194 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTQsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  Apr 19 17:28:17.973: INFO: Retrieved 17/17 results with rv 37194 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTQsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  Apr 19 17:28:18.027: INFO: Retrieved 17/17 results with rv 37194 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTQsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  Apr 19 17:28:18.084: INFO: Retrieved 17/17 results with rv 37194 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTQsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  Apr 19 17:28:18.131: INFO: Retrieved 17/17 results with rv 37194 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTQsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  Apr 19 17:28:18.177: INFO: Retrieved 17/17 results with rv 37194 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTQsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  Apr 19 17:28:18.225: INFO: Retrieved 17/17 results with rv 37194 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTQsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  Apr 19 17:28:18.274: INFO: Retrieved 17/17 results with rv 37194 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTQsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  Apr 19 17:28:18.323: INFO: Retrieved 17/17 results with rv 37194 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTQsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  Apr 19 17:28:18.374: INFO: Retrieved 17/17 results with rv 37194 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTQsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  Apr 19 17:28:18.428: INFO: Retrieved 17/17 results with rv 37194 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTQsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  Apr 19 17:28:18.475: INFO: Retrieved 9/17 results with rv 37194 and continue 
  Apr 19 17:28:18.523: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  Apr 19 17:28:18.572: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  Apr 19 17:28:18.627: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  Apr 19 17:28:18.676: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  E0419 17:28:18.710706      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:28:18.726: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  Apr 19 17:28:18.775: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  Apr 19 17:28:18.826: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  Apr 19 17:28:18.873: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  Apr 19 17:28:18.934: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  Apr 19 17:28:18.972: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  Apr 19 17:28:19.022: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  Apr 19 17:28:19.072: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  Apr 19 17:28:19.121: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  Apr 19 17:28:19.171: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  Apr 19 17:28:19.223: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  Apr 19 17:28:19.274: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  Apr 19 17:28:19.324: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  Apr 19 17:28:19.379: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  Apr 19 17:28:19.425: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  Apr 19 17:28:19.473: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  Apr 19 17:28:19.528: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  Apr 19 17:28:19.576: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  Apr 19 17:28:19.624: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  Apr 19 17:28:19.675: INFO: Retrieved 9/17 results with rv 37198 and continue 
  E0419 17:28:19.711400      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:28:19.725: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  Apr 19 17:28:19.774: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  Apr 19 17:28:19.825: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  Apr 19 17:28:19.874: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  Apr 19 17:28:19.925: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  Apr 19 17:28:19.975: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  Apr 19 17:28:20.024: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  Apr 19 17:28:20.075: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  Apr 19 17:28:20.132: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  Apr 19 17:28:20.174: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  Apr 19 17:28:20.229: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  Apr 19 17:28:20.278: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  Apr 19 17:28:20.326: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  Apr 19 17:28:20.371: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  Apr 19 17:28:20.422: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  Apr 19 17:28:20.472: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  Apr 19 17:28:20.524: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  Apr 19 17:28:20.574: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  Apr 19 17:28:20.626: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  Apr 19 17:28:20.672: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  E0419 17:28:20.712162      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:28:20.723: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  Apr 19 17:28:20.775: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  Apr 19 17:28:20.824: INFO: Retrieved 17/17 results with rv 37198 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzcxOTgsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  Apr 19 17:28:20.874: INFO: Retrieved 9/17 results with rv 37198 and continue 
  STEP: retrieving those results all at once @ 04/19/24 17:28:20.874
  Apr 19 17:28:20.957: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-9736" for this suite. @ 04/19/24 17:28:20.979
• [21.474 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:241
  STEP: Creating a kubernetes client @ 04/19/24 17:28:21.033
  Apr 19 17:28:21.033: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename configmap @ 04/19/24 17:28:21.045
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:28:21.087
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:28:21.094
  STEP: Creating configMap with name cm-test-opt-del-86b3b879-1ac0-4d32-9ced-f13d2b7bc657 @ 04/19/24 17:28:21.117
  STEP: Creating configMap with name cm-test-opt-upd-b3ec3dbe-78ad-40b8-bc30-a6a562c2ac8c @ 04/19/24 17:28:21.126
  STEP: Creating the pod @ 04/19/24 17:28:21.138
  E0419 17:28:21.713105      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:22.714112      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-86b3b879-1ac0-4d32-9ced-f13d2b7bc657 @ 04/19/24 17:28:23.247
  STEP: Updating configmap cm-test-opt-upd-b3ec3dbe-78ad-40b8-bc30-a6a562c2ac8c @ 04/19/24 17:28:23.262
  STEP: Creating configMap with name cm-test-opt-create-ad7852c6-586d-4205-b093-d000773dfe68 @ 04/19/24 17:28:23.277
  STEP: waiting to observe update in volume @ 04/19/24 17:28:23.285
  E0419 17:28:23.714566      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:24.715098      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:25.716595      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:26.716819      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:27.717890      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:28.718207      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:29.719254      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:30.720284      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:31.721213      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:32.722197      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:33.722451      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:34.722596      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:35.722786      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:36.724131      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:37.725025      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:38.725506      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:39.725973      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:40.726351      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:41.726351      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:42.726952      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:43.727467      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:44.728401      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:45.728685      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:46.729110      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:47.729517      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:48.730073      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:49.730371      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:50.731095      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:51.731216      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:52.732263      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:53.732572      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:54.734996      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:55.735652      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:56.736244      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:57.737109      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:58.737040      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:28:59.737369      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:00.739102      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:01.739721      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:02.739727      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:03.740119      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:04.740236      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:05.740531      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:06.742037      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:07.746117      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:08.744408      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:09.744566      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:10.744880      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:11.746190      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:12.746205      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:13.746414      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:14.746765      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:15.747787      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:16.747783      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:17.748928      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:18.777313      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:19.765138      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:20.763193      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:21.763617      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:22.764895      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:23.765181      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:24.767999      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:25.767020      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:26.769710      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:27.769909      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:28.771035      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:29.772120      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:30.772383      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:31.773441      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:32.774022      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:33.774456      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:34.774724      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:35.775052      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:36.776157      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:37.776212      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:38.776668      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:39.778357      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:40.777383      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:41.777503      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:42.777862      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:43.778618      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:44.779599      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:45.780820      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:29:46.463: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2624" for this suite. @ 04/19/24 17:29:46.479
• [85.480 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:109
  STEP: Creating a kubernetes client @ 04/19/24 17:29:46.516
  Apr 19 17:29:46.517: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename kubelet-test @ 04/19/24 17:29:46.524
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:29:46.571
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:29:46.577
  E0419 17:29:46.781442      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:47.782821      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:48.783735      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:49.784593      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:29:50.622: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-3293" for this suite. @ 04/19/24 17:29:50.635
• [4.134 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:134
  STEP: Creating a kubernetes client @ 04/19/24 17:29:50.655
  Apr 19 17:29:50.655: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename kubelet-test @ 04/19/24 17:29:50.66
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:29:50.716
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:29:50.726
  E0419 17:29:50.785165      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:29:50.791: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-1930" for this suite. @ 04/19/24 17:29:50.803
• [0.164 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:902
  STEP: Creating a kubernetes client @ 04/19/24 17:29:50.829
  Apr 19 17:29:50.829: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename statefulset @ 04/19/24 17:29:50.833
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:29:50.873
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:29:50.879
  STEP: Creating service test in namespace statefulset-2839 @ 04/19/24 17:29:50.886
  STEP: Creating statefulset ss in namespace statefulset-2839 @ 04/19/24 17:29:50.903
  Apr 19 17:29:50.929: INFO: Found 0 stateful pods, waiting for 1
  E0419 17:29:51.786615      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:52.787484      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:53.787553      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:54.787831      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:55.788098      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:56.788376      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:57.788560      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:58.788998      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:29:59.789294      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:00.789545      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:30:00.931: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: getting scale subresource @ 04/19/24 17:30:00.961
  STEP: updating a scale subresource @ 04/19/24 17:30:00.971
  STEP: verifying the statefulset Spec.Replicas was modified @ 04/19/24 17:30:00.992
  STEP: Patch a scale subresource @ 04/19/24 17:30:01.009
  STEP: verifying the statefulset Spec.Replicas was modified @ 04/19/24 17:30:01.03
  Apr 19 17:30:01.051: INFO: Deleting all statefulset in ns statefulset-2839
  Apr 19 17:30:01.058: INFO: Scaling statefulset ss to 0
  E0419 17:30:01.789766      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:02.790583      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:03.791129      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:04.791366      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:05.791502      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:06.792426      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:07.792753      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:08.792985      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:09.793401      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:10.793536      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:30:11.136: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 19 17:30:11.144: INFO: Deleting statefulset ss
  Apr 19 17:30:11.177: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-2839" for this suite. @ 04/19/24 17:30:11.19
• [20.375 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:70
  STEP: Creating a kubernetes client @ 04/19/24 17:30:11.206
  Apr 19 17:30:11.206: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename projected @ 04/19/24 17:30:11.21
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:30:11.252
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:30:11.258
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 17:30:11.268
  E0419 17:30:11.793602      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:12.794404      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:13.794738      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:14.795515      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:30:15.308
  Apr 19 17:30:15.315: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod downwardapi-volume-a5e2df87-b019-424a-baac-1c62a94ef7fe container client-container: <nil>
  STEP: delete the pod @ 04/19/24 17:30:15.327
  Apr 19 17:30:15.362: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3204" for this suite. @ 04/19/24 17:30:15.371
• [4.175 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:232
  STEP: Creating a kubernetes client @ 04/19/24 17:30:15.386
  Apr 19 17:30:15.386: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename container-runtime @ 04/19/24 17:30:15.39
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:30:15.417
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:30:15.422
  STEP: create the container @ 04/19/24 17:30:15.428
  W0419 17:30:15.445496      13 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 04/19/24 17:30:15.446
  E0419 17:30:15.796262      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:16.797262      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:17.797659      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 04/19/24 17:30:18.523
  STEP: the container should be terminated @ 04/19/24 17:30:18.53
  STEP: the termination message should be set @ 04/19/24 17:30:18.53
  Apr 19 17:30:18.531: INFO: Expected: &{} to match Container's Termination Message:  --
  STEP: delete the container @ 04/19/24 17:30:18.531
  Apr 19 17:30:18.590: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-7430" for this suite. @ 04/19/24 17:30:18.599
• [3.228 seconds]
------------------------------
[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:97
  STEP: Creating a kubernetes client @ 04/19/24 17:30:18.614
  Apr 19 17:30:18.614: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename cronjob @ 04/19/24 17:30:18.617
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:30:18.648
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:30:18.653
  STEP: Creating a suspended cronjob @ 04/19/24 17:30:18.659
  STEP: Ensuring no jobs are scheduled @ 04/19/24 17:30:18.67
  E0419 17:30:18.797788      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:19.798201      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:20.798758      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:21.799954      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:22.800048      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:23.800302      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:24.801055      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:25.802716      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:26.803488      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:27.803745      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:28.804865      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:29.805280      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:30.806588      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:31.807644      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:32.808516      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:33.808976      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:34.809089      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:35.809467      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:36.810784      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:37.811576      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:38.812253      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:39.812719      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:40.813839      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:41.814432      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:42.814616      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:43.814832      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:44.815104      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:45.815451      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:46.815667      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:47.816116      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:48.817010      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:49.817636      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:50.818081      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:51.819068      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:52.819575      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:53.819890      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:54.821294      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:55.821583      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:56.821409      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:57.821770      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:58.821986      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:30:59.822413      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:00.823557      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:01.823753      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:02.826203      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:03.826065      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:04.826572      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:05.827885      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:06.828051      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:07.828576      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:08.829282      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:09.830788      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:10.830456      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:11.830791      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:12.831452      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:13.831718      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:14.831782      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:15.832138      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:16.832507      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:17.832557      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:18.832699      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:19.832901      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:20.833605      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:21.833858      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:22.834702      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:23.835049      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:24.835817      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:25.836847      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:26.837048      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:27.837983      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:28.839213      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:29.839845      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:30.840186      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:31.840459      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:32.841098      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:33.841698      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:34.841663      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:35.842451      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:36.842868      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:37.844270      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:38.844859      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:39.845161      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:40.845971      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:41.846691      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:42.847566      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:43.848169      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:44.848414      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:45.848738      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:46.849971      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:47.850715      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:48.850795      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:49.851751      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:50.852598      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:51.853421      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:52.853518      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:53.854516      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:54.855005      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:55.856107      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:56.856532      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:57.857026      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:58.857837      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:31:59.858699      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:00.858887      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:01.859299      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:02.859999      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:03.860415      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:04.861147      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:05.862178      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:06.862249      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:07.863006      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:08.863220      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:09.863943      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:10.864185      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:11.864602      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:12.865257      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:13.865547      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:14.866543      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:15.866929      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:16.866893      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:17.867190      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:18.867763      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:19.868623      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:20.869122      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:21.869543      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:22.869492      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:23.870631      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:24.871361      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:25.872103      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:26.872751      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:27.873772      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:28.874673      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:29.874999      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:30.875699      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:31.876134      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:32.876486      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:33.876998      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:34.878505      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:35.879432      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:36.880115      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:37.880840      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:38.881110      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:39.881423      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:40.882065      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:41.883269      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:42.883465      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:43.883753      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:44.884458      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:45.884911      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:46.885065      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:47.885937      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:48.886209      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:49.886781      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:50.887048      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:51.888091      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:52.888834      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:53.889140      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:54.889888      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:55.890903      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:56.891037      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:57.892223      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:58.892798      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:32:59.893189      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:00.893708      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:01.894142      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:02.894964      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:03.895160      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:04.896236      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:05.896514      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:06.897347      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:07.904922      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:08.899406      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:09.899762      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:10.901158      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:11.901171      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:12.902342      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:13.902991      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:14.904021      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:15.905106      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:16.911930      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:17.912706      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:18.913432      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:19.913763      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:20.915068      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:21.914717      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:22.916321      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:23.916756      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:24.917087      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:25.917951      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:26.918489      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:27.919733      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:28.919872      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:29.920947      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:30.921526      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:31.921586      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:32.922514      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:33.922704      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:34.923976      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:35.924331      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:36.924791      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:37.925073      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:38.925726      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:39.926099      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:40.926485      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:41.927015      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:42.927800      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:43.928283      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:44.929256      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:45.929966      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:46.930757      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:47.931091      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:48.931308      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:49.932033      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:50.934002      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:51.933539      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:52.934106      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:53.934605      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:54.934772      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:55.935062      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:56.935674      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:57.939750      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:58.941397      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:33:59.941815      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:00.942382      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:01.942609      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:02.943344      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:03.945488      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:04.944945      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:05.945912      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:06.946083      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:07.946678      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:08.947651      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:09.948402      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:10.948475      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:11.949202      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:12.949311      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:13.949893      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:14.949924      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:15.951071      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:16.951008      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:17.951452      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:18.951794      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:19.953134      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:20.952798      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:21.953916      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:22.953755      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:23.954465      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:24.954582      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:25.955203      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:26.956441      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:27.957302      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:28.957443      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:29.957760      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:30.957653      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:31.958389      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:32.958477      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:33.959717      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:34.960472      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:35.960920      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:36.961523      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:37.961796      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:38.961985      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:39.963102      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:40.963181      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:41.963315      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:42.964489      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:43.964860      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:44.964969      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:45.965271      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:46.966501      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:47.966757      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:48.966901      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:49.968081      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:50.968147      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:51.968387      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:52.969196      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:53.969659      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:54.969840      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:55.970190      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:56.971506      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:57.971530      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:58.972206      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:34:59.972597      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:00.972835      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:01.973203      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:02.974140      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:03.976807      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:04.977549      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:05.978378      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:06.979444      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:07.979786      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:08.979714      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:09.980102      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:10.981009      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:11.982227      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:12.982590      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:13.983560      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:14.983519      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:15.984763      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:16.985217      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:17.985716      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring no job exists by listing jobs explicitly @ 04/19/24 17:35:18.687
  STEP: Removing cronjob @ 04/19/24 17:35:18.695
  Apr 19 17:35:18.713: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-5329" for this suite. @ 04/19/24 17:35:18.729
• [300.137 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance] [sig-storage, Serial, Conformance]
k8s.io/kubernetes/test/e2e/storage/empty_dir_wrapper.go:188
  STEP: Creating a kubernetes client @ 04/19/24 17:35:18.752
  Apr 19 17:35:18.752: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename emptydir-wrapper @ 04/19/24 17:35:18.761
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:35:18.811
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:35:18.816
  STEP: Creating 50 configmaps @ 04/19/24 17:35:18.823
  E0419 17:35:18.986059      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating RC which spawns configmap-volume pods @ 04/19/24 17:35:19.399
  Apr 19 17:35:19.437: INFO: Pod name wrapped-volume-race-bb83f9ff-a5f3-4de1-9f91-867f34f22d03: Found 0 pods out of 5
  E0419 17:35:19.986327      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:20.988872      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:21.989056      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:22.989685      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:23.989847      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:35:24.456: INFO: Pod name wrapped-volume-race-bb83f9ff-a5f3-4de1-9f91-867f34f22d03: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 04/19/24 17:35:24.457
  STEP: Creating RC which spawns configmap-volume pods @ 04/19/24 17:35:24.529
  Apr 19 17:35:24.579: INFO: Pod name wrapped-volume-race-36ffa8ab-3ffc-4033-b14e-52ec40acdbbf: Found 0 pods out of 5
  E0419 17:35:24.991183      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:25.991661      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:26.991932      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:27.992523      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:28.992854      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:35:29.628: INFO: Pod name wrapped-volume-race-36ffa8ab-3ffc-4033-b14e-52ec40acdbbf: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 04/19/24 17:35:29.628
  STEP: Creating RC which spawns configmap-volume pods @ 04/19/24 17:35:29.685
  Apr 19 17:35:29.723: INFO: Pod name wrapped-volume-race-6f1d54c7-b767-4b5f-a1e9-a4dec27b8067: Found 0 pods out of 5
  E0419 17:35:29.993543      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:30.993459      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:31.993680      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:32.994830      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:33.996603      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:35:34.761: INFO: Pod name wrapped-volume-race-6f1d54c7-b767-4b5f-a1e9-a4dec27b8067: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 04/19/24 17:35:34.761
  STEP: deleting ReplicationController wrapped-volume-race-6f1d54c7-b767-4b5f-a1e9-a4dec27b8067 in namespace emptydir-wrapper-7735, will wait for the garbage collector to delete the pods @ 04/19/24 17:35:34.834
  Apr 19 17:35:34.924: INFO: Deleting ReplicationController wrapped-volume-race-6f1d54c7-b767-4b5f-a1e9-a4dec27b8067 took: 24.22037ms
  E0419 17:35:34.997751      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:35:35.125: INFO: Terminating ReplicationController wrapped-volume-race-6f1d54c7-b767-4b5f-a1e9-a4dec27b8067 pods took: 201.167997ms
  E0419 17:35:35.998850      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:36.999708      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-36ffa8ab-3ffc-4033-b14e-52ec40acdbbf in namespace emptydir-wrapper-7735, will wait for the garbage collector to delete the pods @ 04/19/24 17:35:37.526
  Apr 19 17:35:37.627: INFO: Deleting ReplicationController wrapped-volume-race-36ffa8ab-3ffc-4033-b14e-52ec40acdbbf took: 37.001206ms
  Apr 19 17:35:37.728: INFO: Terminating ReplicationController wrapped-volume-race-36ffa8ab-3ffc-4033-b14e-52ec40acdbbf pods took: 101.001507ms
  E0419 17:35:38.000471      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:39.005910      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-bb83f9ff-a5f3-4de1-9f91-867f34f22d03 in namespace emptydir-wrapper-7735, will wait for the garbage collector to delete the pods @ 04/19/24 17:35:39.931
  E0419 17:35:40.005942      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:35:40.018: INFO: Deleting ReplicationController wrapped-volume-race-bb83f9ff-a5f3-4de1-9f91-867f34f22d03 took: 22.0354ms
  Apr 19 17:35:40.119: INFO: Terminating ReplicationController wrapped-volume-race-bb83f9ff-a5f3-4de1-9f91-867f34f22d03 pods took: 101.281061ms
  E0419 17:35:41.006641      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Cleaning up the configMaps @ 04/19/24 17:35:41.321
  Apr 19 17:35:41.928: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-7735" for this suite. @ 04/19/24 17:35:41.937
• [23.200 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:176
  STEP: Creating a kubernetes client @ 04/19/24 17:35:41.955
  Apr 19 17:35:41.956: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename configmap @ 04/19/24 17:35:41.959
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:35:41.99
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:35:41.998
  E0419 17:35:42.007291      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating configMap with name configmap-test-upd-d963589b-8fd1-4a73-99bc-d828b0299e8e @ 04/19/24 17:35:42.011
  STEP: Creating the pod @ 04/19/24 17:35:42.018
  E0419 17:35:43.008213      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:44.009059      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for pod with text data @ 04/19/24 17:35:44.059
  STEP: Waiting for pod with binary data @ 04/19/24 17:35:44.113
  Apr 19 17:35:44.136: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-663" for this suite. @ 04/19/24 17:35:44.152
• [2.219 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:177
  STEP: Creating a kubernetes client @ 04/19/24 17:35:44.179
  Apr 19 17:35:44.179: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename replicaset @ 04/19/24 17:35:44.186
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:35:44.232
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:35:44.239
  STEP: Create a Replicaset @ 04/19/24 17:35:44.261
  STEP: Verify that the required pods have come up. @ 04/19/24 17:35:44.276
  Apr 19 17:35:44.285: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0419 17:35:45.010411      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:46.010971      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:47.011930      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:48.012771      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:49.012988      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:35:49.294: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/19/24 17:35:49.294
  STEP: Getting /status @ 04/19/24 17:35:49.294
  Apr 19 17:35:49.343: INFO: Replicaset test-rs has Conditions: []
  STEP: updating the Replicaset Status @ 04/19/24 17:35:49.344
  Apr 19 17:35:49.374: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the ReplicaSet status to be updated @ 04/19/24 17:35:49.374
  Apr 19 17:35:49.377: INFO: Observed &ReplicaSet event: ADDED
  Apr 19 17:35:49.378: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 19 17:35:49.378: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 19 17:35:49.379: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 19 17:35:49.379: INFO: Found replicaset test-rs in namespace replicaset-337 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Apr 19 17:35:49.379: INFO: Replicaset test-rs has an updated status
  STEP: patching the Replicaset Status @ 04/19/24 17:35:49.38
  Apr 19 17:35:49.380: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Apr 19 17:35:49.393: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Replicaset status to be patched @ 04/19/24 17:35:49.394
  Apr 19 17:35:49.397: INFO: Observed &ReplicaSet event: ADDED
  Apr 19 17:35:49.397: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 19 17:35:49.397: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 19 17:35:49.398: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 19 17:35:49.399: INFO: Observed replicaset test-rs in namespace replicaset-337 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 19 17:35:49.399: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 19 17:35:49.400: INFO: Found replicaset test-rs in namespace replicaset-337 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
  Apr 19 17:35:49.400: INFO: Replicaset test-rs has a patched status
  Apr 19 17:35:49.401: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-337" for this suite. @ 04/19/24 17:35:49.409
• [5.245 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:228
  STEP: Creating a kubernetes client @ 04/19/24 17:35:49.427
  Apr 19 17:35:49.427: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename var-expansion @ 04/19/24 17:35:49.43
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:35:49.457
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:35:49.462
  STEP: creating the pod with failed condition @ 04/19/24 17:35:49.468
  E0419 17:35:50.013806      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:51.014648      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:52.015695      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:53.016774      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:54.017130      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:55.017287      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:56.017583      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:57.018213      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:58.018524      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:35:59.019145      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:00.019697      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:01.020377      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:02.020283      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:03.020636      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:04.020929      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:05.021566      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:06.022026      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:07.023025      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:08.023677      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:09.024415      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:10.025400      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:11.025765      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:12.026576      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:13.026539      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:14.026659      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:15.027616      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:16.028696      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:17.029229      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:18.029416      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:19.030044      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:20.030918      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:21.031412      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:22.032430      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:23.033504      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:24.033978      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:25.034794      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:26.035141      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:27.035868      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:28.036475      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:29.037696      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:30.037931      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:31.038142      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:32.038196      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:33.038730      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:34.039694      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:35.040082      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:36.040156      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:37.041229      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:38.042208      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:39.042545      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:40.043282      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:41.044578      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:42.044691      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:43.044798      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:44.045514      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:45.046430      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:46.047180      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:47.047599      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:48.048487      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:49.049925      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:50.050355      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:51.052590      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:52.052254      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:53.053097      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:54.053679      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:55.054089      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:56.055049      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:57.055439      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:58.056152      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:36:59.056490      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:00.059917      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:01.057905      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:02.058841      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:03.060484      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:04.060262      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:05.060920      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:06.061437      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:07.061745      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:08.063818      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:09.062905      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:10.064157      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:11.064216      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:12.064633      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:13.065698      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:14.066223      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:15.067165      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:16.067893      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:17.069097      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:18.070157      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:19.070443      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:20.070489      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:21.071155      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:22.071401      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:23.072216      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:24.072463      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:25.075189      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:26.074462      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:27.074672      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:28.074813      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:29.075578      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:30.076406      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:31.076777      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:32.076891      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:33.077523      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:34.077817      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:35.078603      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:36.079638      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:37.079790      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:38.080866      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:39.081615      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:40.082030      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:41.082320      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:42.082726      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:43.083086      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:44.083771      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:45.084011      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:46.084966      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:47.085084      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:48.085437      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:49.085579      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: updating the pod @ 04/19/24 17:37:49.488
  Apr 19 17:37:50.021: INFO: Successfully updated pod "var-expansion-8eb8c095-d7c0-423d-87bc-200cf7faf995"
  STEP: waiting for pod running @ 04/19/24 17:37:50.022
  E0419 17:37:50.085683      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:51.086451      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 04/19/24 17:37:52.044
  Apr 19 17:37:52.044: INFO: Deleting pod "var-expansion-8eb8c095-d7c0-423d-87bc-200cf7faf995" in namespace "var-expansion-5872"
  Apr 19 17:37:52.061: INFO: Wait up to 5m0s for pod "var-expansion-8eb8c095-d7c0-423d-87bc-200cf7faf995" to be fully deleted
  E0419 17:37:52.087016      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:53.088123      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:54.088623      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:55.089298      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:56.089843      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:57.089965      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:58.090677      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:37:59.091051      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:00.091590      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:01.091990      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:02.092153      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:03.092377      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:04.092633      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:05.093535      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:06.094142      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:07.094005      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:08.094814      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:09.095102      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:10.095483      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:11.095850      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:12.096263      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:13.096354      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:14.096715      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:15.097667      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:16.097959      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:17.098613      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:18.098723      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:19.099047      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:20.099610      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:21.100196      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:22.100730      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:23.101188      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:24.101687      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:38:24.271: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-5872" for this suite. @ 04/19/24 17:38:24.287
• [154.878 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:47
  STEP: Creating a kubernetes client @ 04/19/24 17:38:24.314
  Apr 19 17:38:24.315: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename secrets @ 04/19/24 17:38:24.321
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:38:24.362
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:38:24.369
  STEP: Creating secret with name secret-test-74919544-6f03-49c3-b9ae-9fdd777a9d30 @ 04/19/24 17:38:24.376
  STEP: Creating a pod to test consume secrets @ 04/19/24 17:38:24.387
  E0419 17:38:25.102407      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:26.103262      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:27.103370      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:28.103856      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:38:28.431
  Apr 19 17:38:28.438: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod pod-secrets-3296d23a-f37b-4e9c-93fe-fd3aeb12cc79 container secret-env-test: <nil>
  STEP: delete the pod @ 04/19/24 17:38:28.49
  Apr 19 17:38:28.522: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9033" for this suite. @ 04/19/24 17:38:28.532
• [4.230 seconds]
------------------------------
SS
------------------------------
[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:208
  STEP: Creating a kubernetes client @ 04/19/24 17:38:28.545
  Apr 19 17:38:28.546: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename endpointslice @ 04/19/24 17:38:28.549
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:38:28.579
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:38:28.585
  E0419 17:38:29.104134      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:30.104748      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:31.105049      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:32.106021      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:33.106137      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: referencing a single matching pod @ 04/19/24 17:38:33.709
  E0419 17:38:34.106967      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:35.107962      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:36.109123      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:37.109328      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:38.109478      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: referencing matching pods with named port @ 04/19/24 17:38:38.73
  E0419 17:38:39.110601      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:40.111001      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:41.111132      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:42.111298      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:43.111943      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating empty Endpoints and EndpointSlices for no matching Pods @ 04/19/24 17:38:43.75
  E0419 17:38:44.112365      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:45.113167      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:46.113502      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:47.113888      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:48.115145      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: recreating EndpointSlices after they've been deleted @ 04/19/24 17:38:48.767
  Apr 19 17:38:48.822: INFO: EndpointSlice for Service endpointslice-6633/example-named-port not found
  E0419 17:38:49.115713      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:50.116111      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:51.116083      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:52.116788      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:53.116574      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:54.117508      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:55.118434      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:56.121658      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:57.119329      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:38:58.120216      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:38:58.844: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-6633" for this suite. @ 04/19/24 17:38:58.865
• [30.341 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:132
  STEP: Creating a kubernetes client @ 04/19/24 17:38:58.887
  Apr 19 17:38:58.887: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename replicaset @ 04/19/24 17:38:58.893
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:38:58.945
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:38:58.951
  STEP: Given a Pod with a 'name' label pod-adoption-release is created @ 04/19/24 17:38:58.96
  E0419 17:38:59.120622      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:39:00.121460      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When a replicaset with a matching selector is created @ 04/19/24 17:39:01.013
  STEP: Then the orphan pod is adopted @ 04/19/24 17:39:01.023
  E0419 17:39:01.122078      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When the matched label of one of its pods change @ 04/19/24 17:39:02.046
  Apr 19 17:39:02.059: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 04/19/24 17:39:02.109
  E0419 17:39:02.122202      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:39:03.122581      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:39:03.133: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-7075" for this suite. @ 04/19/24 17:39:03.146
• [4.277 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:397
  STEP: Creating a kubernetes client @ 04/19/24 17:39:03.164
  Apr 19 17:39:03.165: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename resourcequota @ 04/19/24 17:39:03.169
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:39:03.213
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:39:03.22
  STEP: Counting existing ResourceQuota @ 04/19/24 17:39:03.229
  E0419 17:39:04.122748      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:39:05.122881      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:39:06.123942      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:39:07.124376      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:39:08.124624      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 04/19/24 17:39:08.239
  STEP: Ensuring resource quota status is calculated @ 04/19/24 17:39:08.252
  E0419 17:39:09.125142      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:39:10.125439      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ReplicationController @ 04/19/24 17:39:10.262
  STEP: Ensuring resource quota status captures replication controller creation @ 04/19/24 17:39:10.3
  E0419 17:39:11.125776      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:39:12.126339      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicationController @ 04/19/24 17:39:12.309
  STEP: Ensuring resource quota status released usage @ 04/19/24 17:39:12.327
  E0419 17:39:13.126696      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:39:14.127031      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:39:14.335: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6793" for this suite. @ 04/19/24 17:39:14.344
• [11.190 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:195
  STEP: Creating a kubernetes client @ 04/19/24 17:39:14.358
  Apr 19 17:39:14.358: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename projected @ 04/19/24 17:39:14.361
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:39:14.386
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:39:14.392
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 17:39:14.397
  E0419 17:39:15.128552      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:39:16.128458      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:39:17.128376      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:39:18.128617      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:39:18.446
  Apr 19 17:39:18.458: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod downwardapi-volume-0db9dce3-769a-40e6-a413-a7156c2a2a63 container client-container: <nil>
  STEP: delete the pod @ 04/19/24 17:39:18.479
  Apr 19 17:39:18.508: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3593" for this suite. @ 04/19/24 17:39:18.534
• [4.187 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslicemirroring.go:55
  STEP: Creating a kubernetes client @ 04/19/24 17:39:18.545
  Apr 19 17:39:18.545: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename endpointslicemirroring @ 04/19/24 17:39:18.549
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:39:18.609
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:39:18.612
  STEP: mirroring a new custom Endpoint @ 04/19/24 17:39:18.639
  Apr 19 17:39:18.655: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
  E0419 17:39:19.130202      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:39:20.130868      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mirroring an update to a custom Endpoint @ 04/19/24 17:39:20.667
  STEP: mirroring deletion of a custom Endpoint @ 04/19/24 17:39:20.697
  Apr 19 17:39:20.728: INFO: Waiting for 0 EndpointSlices to exist, got 1
  E0419 17:39:21.130454      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:39:22.131708      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:39:22.738: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslicemirroring-7383" for this suite. @ 04/19/24 17:39:22.747
• [4.217 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:695
  STEP: Creating a kubernetes client @ 04/19/24 17:39:22.764
  Apr 19 17:39:22.764: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename resourcequota @ 04/19/24 17:39:22.769
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:39:22.798
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:39:22.803
  STEP: Creating a ResourceQuota with terminating scope @ 04/19/24 17:39:22.81
  STEP: Ensuring ResourceQuota status is calculated @ 04/19/24 17:39:22.821
  E0419 17:39:23.132633      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:39:24.133232      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not terminating scope @ 04/19/24 17:39:24.836
  STEP: Ensuring ResourceQuota status is calculated @ 04/19/24 17:39:24.849
  E0419 17:39:25.133959      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:39:26.133977      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a long running pod @ 04/19/24 17:39:26.859
  STEP: Ensuring resource quota with not terminating scope captures the pod usage @ 04/19/24 17:39:26.891
  E0419 17:39:27.134611      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:39:28.135645      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with terminating scope ignored the pod usage @ 04/19/24 17:39:28.906
  E0419 17:39:29.136072      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:39:30.136311      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 04/19/24 17:39:30.914
  STEP: Ensuring resource quota status released the pod usage @ 04/19/24 17:39:30.931
  E0419 17:39:31.137343      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:39:32.137942      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a terminating pod @ 04/19/24 17:39:32.942
  STEP: Ensuring resource quota with terminating scope captures the pod usage @ 04/19/24 17:39:32.968
  E0419 17:39:33.138876      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:39:34.139817      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not terminating scope ignored the pod usage @ 04/19/24 17:39:34.98
  E0419 17:39:35.140389      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:39:36.140770      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 04/19/24 17:39:36.992
  STEP: Ensuring resource quota status released the pod usage @ 04/19/24 17:39:37.016
  E0419 17:39:37.141666      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:39:38.141736      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:39:39.025: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4718" for this suite. @ 04/19/24 17:39:39.036
• [16.286 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] server version should find the server version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/server_version.go:41
  STEP: Creating a kubernetes client @ 04/19/24 17:39:39.069
  Apr 19 17:39:39.069: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename server-version @ 04/19/24 17:39:39.072
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:39:39.11
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:39:39.121
  STEP: Request ServerVersion @ 04/19/24 17:39:39.129
  STEP: Confirm major version @ 04/19/24 17:39:39.131
  Apr 19 17:39:39.131: INFO: Major version: 1
  STEP: Confirm minor version @ 04/19/24 17:39:39.131
  Apr 19 17:39:39.132: INFO: cleanMinorVersion: 29
  Apr 19 17:39:39.132: INFO: Minor version: 29
  Apr 19 17:39:39.132: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "server-version-244" for this suite. @ 04/19/24 17:39:39.14
  E0419 17:39:39.142461      13 retrywatcher.go:129] "Watch failed" err="context canceled"
• [0.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:263
  STEP: Creating a kubernetes client @ 04/19/24 17:39:39.157
  Apr 19 17:39:39.157: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename projected @ 04/19/24 17:39:39.16
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:39:39.192
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:39:39.199
  STEP: Creating a pod to test downward API volume plugin @ 04/19/24 17:39:39.207
  E0419 17:39:40.143254      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:39:41.143443      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:39:42.143780      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:39:43.143880      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/24 17:39:43.256
  Apr 19 17:39:43.264: INFO: Trying to get logs from node co4fe9zoo9oc-3 pod downwardapi-volume-38054738-f5a1-4e8a-b521-33739dcb4bf3 container client-container: <nil>
  STEP: delete the pod @ 04/19/24 17:39:43.281
  Apr 19 17:39:43.309: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4970" for this suite. @ 04/19/24 17:39:43.319
• [4.178 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should scale a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:357
  STEP: Creating a kubernetes client @ 04/19/24 17:39:43.337
  Apr 19 17:39:43.337: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename kubectl @ 04/19/24 17:39:43.341
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:39:43.376
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:39:43.381
  STEP: creating a replication controller @ 04/19/24 17:39:43.389
  Apr 19 17:39:43.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-2198 create -f -'
  Apr 19 17:39:43.747: INFO: stderr: ""
  Apr 19 17:39:43.747: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 04/19/24 17:39:43.747
  Apr 19 17:39:43.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-2198 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 19 17:39:43.925: INFO: stderr: ""
  Apr 19 17:39:43.925: INFO: stdout: "update-demo-nautilus-8p7nc update-demo-nautilus-n8nmd "
  Apr 19 17:39:43.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-2198 get pods update-demo-nautilus-8p7nc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 19 17:39:44.120: INFO: stderr: ""
  Apr 19 17:39:44.120: INFO: stdout: ""
  Apr 19 17:39:44.120: INFO: update-demo-nautilus-8p7nc is created but not running
  E0419 17:39:44.144748      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:39:45.145235      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:39:46.145767      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:39:47.146239      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:39:48.147202      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:39:49.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-2198 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  E0419 17:39:49.148207      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:39:49.324: INFO: stderr: ""
  Apr 19 17:39:49.324: INFO: stdout: "update-demo-nautilus-8p7nc update-demo-nautilus-n8nmd "
  Apr 19 17:39:49.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-2198 get pods update-demo-nautilus-8p7nc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 19 17:39:49.488: INFO: stderr: ""
  Apr 19 17:39:49.488: INFO: stdout: "true"
  Apr 19 17:39:49.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-2198 get pods update-demo-nautilus-8p7nc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 19 17:39:49.644: INFO: stderr: ""
  Apr 19 17:39:49.644: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 19 17:39:49.644: INFO: validating pod update-demo-nautilus-8p7nc
  Apr 19 17:39:49.662: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 19 17:39:49.662: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 19 17:39:49.662: INFO: update-demo-nautilus-8p7nc is verified up and running
  Apr 19 17:39:49.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-2198 get pods update-demo-nautilus-n8nmd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 19 17:39:49.807: INFO: stderr: ""
  Apr 19 17:39:49.807: INFO: stdout: "true"
  Apr 19 17:39:49.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-2198 get pods update-demo-nautilus-n8nmd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 19 17:39:49.966: INFO: stderr: ""
  Apr 19 17:39:49.966: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 19 17:39:49.966: INFO: validating pod update-demo-nautilus-n8nmd
  Apr 19 17:39:49.982: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 19 17:39:49.982: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 19 17:39:49.982: INFO: update-demo-nautilus-n8nmd is verified up and running
  STEP: scaling down the replication controller @ 04/19/24 17:39:49.982
  Apr 19 17:39:49.999: INFO: scanned /root for discovery docs: <nil>
  Apr 19 17:39:50.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-2198 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
  E0419 17:39:50.149120      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:39:51.149312      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:39:51.226: INFO: stderr: ""
  Apr 19 17:39:51.226: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 04/19/24 17:39:51.226
  Apr 19 17:39:51.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-2198 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 19 17:39:51.388: INFO: stderr: ""
  Apr 19 17:39:51.388: INFO: stdout: "update-demo-nautilus-8p7nc "
  Apr 19 17:39:51.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-2198 get pods update-demo-nautilus-8p7nc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 19 17:39:51.555: INFO: stderr: ""
  Apr 19 17:39:51.555: INFO: stdout: "true"
  Apr 19 17:39:51.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-2198 get pods update-demo-nautilus-8p7nc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 19 17:39:51.717: INFO: stderr: ""
  Apr 19 17:39:51.718: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 19 17:39:51.718: INFO: validating pod update-demo-nautilus-8p7nc
  Apr 19 17:39:51.739: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 19 17:39:51.739: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 19 17:39:51.739: INFO: update-demo-nautilus-8p7nc is verified up and running
  STEP: scaling up the replication controller @ 04/19/24 17:39:51.739
  Apr 19 17:39:51.751: INFO: scanned /root for discovery docs: <nil>
  Apr 19 17:39:51.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-2198 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
  E0419 17:39:52.149628      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:39:52.975: INFO: stderr: ""
  Apr 19 17:39:52.975: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 04/19/24 17:39:52.976
  Apr 19 17:39:52.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-2198 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  E0419 17:39:53.149682      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:39:53.161: INFO: stderr: ""
  Apr 19 17:39:53.161: INFO: stdout: "update-demo-nautilus-8p7nc update-demo-nautilus-l4h9w "
  Apr 19 17:39:53.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-2198 get pods update-demo-nautilus-8p7nc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 19 17:39:53.325: INFO: stderr: ""
  Apr 19 17:39:53.325: INFO: stdout: "true"
  Apr 19 17:39:53.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-2198 get pods update-demo-nautilus-8p7nc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 19 17:39:53.472: INFO: stderr: ""
  Apr 19 17:39:53.473: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 19 17:39:53.473: INFO: validating pod update-demo-nautilus-8p7nc
  Apr 19 17:39:53.484: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 19 17:39:53.484: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 19 17:39:53.484: INFO: update-demo-nautilus-8p7nc is verified up and running
  Apr 19 17:39:53.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-2198 get pods update-demo-nautilus-l4h9w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 19 17:39:53.636: INFO: stderr: ""
  Apr 19 17:39:53.636: INFO: stdout: "true"
  Apr 19 17:39:53.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-2198 get pods update-demo-nautilus-l4h9w -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 19 17:39:53.787: INFO: stderr: ""
  Apr 19 17:39:53.787: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 19 17:39:53.787: INFO: validating pod update-demo-nautilus-l4h9w
  Apr 19 17:39:53.806: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 19 17:39:53.806: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 19 17:39:53.806: INFO: update-demo-nautilus-l4h9w is verified up and running
  STEP: using delete to clean up resources @ 04/19/24 17:39:53.806
  Apr 19 17:39:53.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-2198 delete --grace-period=0 --force -f -'
  Apr 19 17:39:53.952: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 19 17:39:53.952: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  Apr 19 17:39:53.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-2198 get rc,svc -l name=update-demo --no-headers'
  E0419 17:39:54.149979      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:39:54.155: INFO: stderr: "No resources found in kubectl-2198 namespace.\n"
  Apr 19 17:39:54.155: INFO: stdout: ""
  Apr 19 17:39:54.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4132756479 --namespace=kubectl-2198 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Apr 19 17:39:54.346: INFO: stderr: ""
  Apr 19 17:39:54.346: INFO: stdout: ""
  Apr 19 17:39:54.346: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2198" for this suite. @ 04/19/24 17:39:54.354
• [11.028 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:498
  STEP: Creating a kubernetes client @ 04/19/24 17:39:54.366
  Apr 19 17:39:54.366: INFO: >>> kubeConfig: /tmp/kubeconfig-4132756479
  STEP: Building a namespace api object, basename webhook @ 04/19/24 17:39:54.369
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/24 17:39:54.392
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/24 17:39:54.396
  STEP: Setting up server cert @ 04/19/24 17:39:54.435
  E0419 17:39:55.151023      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/24 17:39:55.844
  STEP: Deploying the webhook pod @ 04/19/24 17:39:55.869
  STEP: Wait for the deployment to be ready @ 04/19/24 17:39:55.898
  Apr 19 17:39:55.918: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0419 17:39:56.151697      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0419 17:39:57.152436      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/24 17:39:57.947
  STEP: Verifying the service has paired with the endpoint @ 04/19/24 17:39:57.973
  E0419 17:39:58.153397      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:39:58.974: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a mutating webhook configuration @ 04/19/24 17:39:58.993
  STEP: Updating a mutating webhook configuration's rules to not include the create operation @ 04/19/24 17:39:59.038
  STEP: Creating a configMap that should not be mutated @ 04/19/24 17:39:59.051
  STEP: Patching a mutating webhook configuration's rules to include the create operation @ 04/19/24 17:39:59.074
  STEP: Creating a configMap that should be mutated @ 04/19/24 17:39:59.088
  E0419 17:39:59.153734      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 19 17:39:59.239: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4399" for this suite. @ 04/19/24 17:39:59.255
  STEP: Destroying namespace "webhook-markers-5326" for this suite. @ 04/19/24 17:39:59.264
• [4.909 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[SynchronizedAfterSuite] 
k8s.io/kubernetes/test/e2e/e2e.go:88
  Apr 19 17:39:59.282: INFO: Running AfterSuite actions on node 1
  Apr 19 17:39:59.282: INFO: Skipping dumping logs from cluster
[SynchronizedAfterSuite] PASSED [0.001 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
k8s.io/kubernetes/test/e2e/e2e_test.go:161
[ReportAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
k8s.io/kubernetes/test/e2e/framework/test_context.go:621
[ReportAfterSuite] PASSED [0.134 seconds]
------------------------------

Ran 388 of 7407 Specs in 7065.964 seconds
SUCCESS! -- 388 Passed | 0 Failed | 0 Pending | 7019 Skipped
PASS

Ginkgo ran 1 suite in 1h57m48.484019254s
Test Suite Passed
